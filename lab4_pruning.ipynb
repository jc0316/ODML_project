{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from itertools import product\n",
    "\n",
    "import torch.ao.quantization as quantization\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx, prepare_qat_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        self.labels = data.iloc[:, 0].values\n",
    "        self.pixels = data.iloc[:, 1:].values.astype('float32')\n",
    "        self.pixels = self.pixels.reshape(-1, 28, 28)  # Reshape to 28x28 images\n",
    "\n",
    "        # Normalize the pixel values\n",
    "        self.pixels_mean = self.pixels.mean()\n",
    "        self.pixels_std = self.pixels.std()\n",
    "        self.pixels = (self.pixels - self.pixels_mean) / self.pixels_std\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.pixels[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(torch.tensor(image).unsqueeze(0))\n",
    "\n",
    "        return image.squeeze(0), torch.tensor(label)\n",
    "    \n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_hidden_layers):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        self.layers.append(nn.Linear(hidden_size, num_classes))\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.relu(layer(x))\n",
    "        return self.layers[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset_path, batch_size, is_train=True):\n",
    "    # Create center crop transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.CenterCrop(20)  # Crop to 20x20 as specified\n",
    "    ])\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = MNISTDataset(dataset_path, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=is_train)\n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (MB):', size/1e6)\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, learning_rate, device):\n",
    "    print(f\"Training normal precision model for {epochs} epochs\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Accuracy: {100 * correct / total:.2f}%')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_mixed_precision(model, train_loader, val_loader, epochs, learning_rate, device):\n",
    "    print(f\"Training model with mixed precision for {epochs} epochs\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Do mixed precision training with torch.autocast and GradScaler\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Accuracy: {100 * correct / total:.2f}%')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(model, test_loader, batch_size, num_runs=5):\n",
    "    model.eval()\n",
    "    times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            data, _ = next(iter(test_loader))\n",
    "            if batch_size == 1:\n",
    "                data = data[0:1]\n",
    "                \n",
    "            start_time = time.time()\n",
    "            _ = model(data)\n",
    "            end_time = time.time()\n",
    "            times.append(end_time - start_time)\n",
    "    \n",
    "    mean_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    return mean_time, std_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, mixed_precision=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if mixed_precision:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(data)\n",
    "            else:\n",
    "                outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Hyperparameters\n",
    "    input_size = 20 * 20  # 20x20 pixels\n",
    "    hidden_size = 1024\n",
    "    num_classes = 10\n",
    "    num_hidden_layers = 2\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    epochs = 2\n",
    "    \n",
    "    # Create model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = FFNN(input_size, hidden_size, num_classes, num_hidden_layers)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = create_dataloader('data/mnist_train.csv', batch_size, True)\n",
    "    test_loader = create_dataloader('data/mnist_test.csv', batch_size, False)\n",
    "    \n",
    "    # Train base model\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model = train_model(model, train_loader, test_loader, epochs, learning_rate, device)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
