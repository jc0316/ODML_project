{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "can't load coreml model by running xcode cuz it doesn't work and not resolved.\n",
        "Then convert to onnx and then to pytorch since there's no direct way to do it.\n",
        "Colab runs on linux so can't run coreml, which runs on mac\n",
        "Then do on mac. Got some env problem."
      ],
      "metadata": {
        "id": "v-3H14ewYA7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install torch torchvision\n",
        "!pip install tqdm\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "epochs = 2\n",
        "hidden_size = 1024\n",
        "num_workers = 4  # Number of workers for data loading\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # MNIST to 3 channels (for RGB)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "# Load ResNet50 model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet50(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # Modify last layer for MNIST\n",
        "model.to(device)  # Move model to GPU if available\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88d6-yDHXv1L",
        "outputId": "068c64c0-242a-43cc-8623-66989a3536a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#     model.train()\n",
        "#     running_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in train_loader:\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item()\n",
        "\n",
        "#         _, predicted = torch.max(outputs, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "\n",
        "# Training loop with tqdm progress bar\n",
        "# for epoch in range(epochs):\n",
        "#     model.train()\n",
        "#     running_loss = 0.0\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for i, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # Forward pass\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item()\n",
        "\n",
        "#         # Calculate accuracy\n",
        "#         _, predicted = torch.max(outputs, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'resnet50_mnist.pth')\n",
        "print(\"Model saved.\")\n",
        "\n",
        "#7:58am started"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKHe8OluXyvC",
        "outputId": "1ad94dd6-4dc7-4352-c138-f947dafe0444"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 938/938 [10:10<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Loss: 0.1550, Accuracy: 95.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2/2: 100%|██████████| 938/938 [10:10<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/2], Loss: 0.0616, Accuracy: 98.14%\n",
            "Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the saved model\n",
        "model = models.resnet50(pretrained=False)  # Initialize the model again\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # Modify the last fully connected layer again\n",
        "model.load_state_dict(torch.load('resnet50_mnist.pth'))  # Load the saved weights\n",
        "model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "id": "Ufs2M_3rXyyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b75e6d0-7152-43bd-bb75-c6477b05fe10"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-cacb3ca82c44>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('resnet50_mnist.pth'))  # Load the saved weights\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def print_size_of_model(model, label=\"\"):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size=os.path.getsize(\"temp.p\")\n",
        "    print(\"model: \",label,' \\t','Size (MB):', size/1e6)\n",
        "    os.remove('temp.p')\n",
        "    return size"
      ],
      "metadata": {
        "id": "rrsVrkp9Xy--"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = print_size_of_model(model,\"full unpruned\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsHDmgAg6JHg",
        "outputId": "93c0cb59-dd6f-4444-8f40-2ee7bbb439be"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  full unpruned  \t Size (MB): 94.40919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Print model parameters and buffers before pruning\n",
        "# print(\"Before pruning:\")\n",
        "# print(model.named_parameters())\n",
        "# print(model.named_buffers())\n",
        "\n",
        "# # Apply pruning using L1Unstructured\n",
        "# params_to_prune = [\n",
        "#     (model.layer1[0], 'weight'),\n",
        "#     (model.layer1[1], 'weight'),\n",
        "#     (model.fc, 'weight')  # Prune the fully connected layer\n",
        "# ]\n",
        "\n",
        "# Apply global unstructured pruning\n",
        "# prune.global_unstructured(\n",
        "#     params_to_prune,\n",
        "#     pruning_method=prune.L1Unstructured,\n",
        "#     amount=0.33,\n",
        "# )\n",
        "\n",
        "# # Print model parameters and buffers after pruning\n",
        "# print(\"After pruning:\")\n",
        "# print(model.named_parameters())\n",
        "# print(model.named_buffers())\n"
      ],
      "metadata": {
        "id": "Lh3__EZiXy1e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The error is occurring because Bottleneck blocks inside the ResNet architecture don't have a direct attribute weight. Instead, they contain multiple sub-layers (e.g., conv1, conv2, conv3), and you need to specify the weight attribute of these sub-layers for pruning. To perform unstructured pruning on the layer1 block, you should select the weights of these individual convolutional layers within the Bottleneck blocks."
      ],
      "metadata": {
        "id": "LCZqT0w71_i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before pruning:\")\n",
        "# for name, param in model.named_parameters():\n",
        "#     print(name, param.shape)\n",
        "# for name, buffer in model.named_buffers():\n",
        "#     print(name, buffer.shape)\n",
        "\n",
        "# Apply pruning using L1Unstructured\n",
        "params_to_prune = [\n",
        "    (model.layer1[0].conv1, 'weight'),  # Prune the first conv layer in the first Bottleneck block of layer1\n",
        "    (model.layer1[0].conv2, 'weight'),  # Prune the second conv layer in the first Bottleneck block of layer1\n",
        "    (model.layer1[0].conv3, 'weight'),  # Prune the third conv layer in the first Bottleneck block of layer1\n",
        "    (model.layer1[1].conv1, 'weight'),  # Prune the first conv layer in the second Bottleneck block of layer1\n",
        "    (model.layer1[1].conv2, 'weight'),  # Prune the second conv layer in the second Bottleneck block of layer1\n",
        "    (model.layer1[1].conv3, 'weight'),  # Prune the third conv layer in the second Bottleneck block of layer1\n",
        "    (model.fc, 'weight')                # Prune the fully connected layer\n",
        "]\n",
        "\n",
        "# Apply global unstructured pruning\n",
        "prune.global_unstructured(\n",
        "    params_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.33,\n",
        ")\n"
      ],
      "metadata": {
        "id": "LQUxygKGXy4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e07a381a-5b2a-45fe-ebb8-ea51ad4cc8dc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before pruning:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After pruning:\")\n",
        "print(model.named_parameters())\n",
        "print(model.named_buffers())"
      ],
      "metadata": {
        "id": "lnuVX8HTXy6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655e546b-17d6-4b32-8945-ee3a8dd7b031"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After pruning:\n",
            "<generator object Module.named_parameters at 0x7c0d4bc48040>\n",
            "<generator object Module.named_buffers at 0x7c0d4bc48040>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print model parameters and buffers after pruning\n",
        "print(\"\\nAfter pruning:\")\n",
        "# for name, param in model.named_parameters():\n",
        "#     print(\"parameter:\",name, param.shape)\n",
        "# for name, buffer in model.named_buffers():\n",
        "#     print(\"buffer:\",name, buffer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ciKGkja2Gy1",
        "outputId": "1a8e5bcf-2211-4dfb-e109-99387f195fba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After pruning:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in params_to_prune :\n",
        "    # p takes the form (module, 'weight')\n",
        "    prune.remove(*p)\n",
        "\n",
        "\"\"\"\n",
        "Observe that model size is doubled. This is because mask buffers are stored in addition to the original parameters.\n",
        "So we might want to convert to sparse representations when storing on disk.\n",
        "\n",
        "First, we remove the reparameterization, i.e. make the pruning \"permanent\":\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xUTgCIdj9Q4O",
        "outputId": "dfc54101-be1f-4ac0-e19a-800dc64ca289"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nObserve that model size is doubled. This is because mask buffers are stored in addition to the original parameters. \\nSo we might want to convert to sparse representations when storing on disk.\\n\\nFirst, we remove the reparameterization, i.e. make the pruning \"permanent\":\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = print_size_of_model(model, \"newly pruned\")\n",
        "print(\"{0:.2f} times smaller\".format(f/p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzzxuydw6bWD",
        "outputId": "b7b83f32-b582-4926-99b1-5906a70a8a54"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  newly pruned  \t Size (MB): 94.40919\n",
            "1.00 times smaller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def calculate_sparsity(param):\n",
        "    \"\"\"\n",
        "    Calculate the sparsity of a given parameter tensor.\n",
        "\n",
        "    Args:\n",
        "        param (torch.Tensor): The parameter tensor for which sparsity is calculated.\n",
        "\n",
        "    Returns:\n",
        "        float: The sparsity percentage (between 0 and 100).\n",
        "    \"\"\"\n",
        "    total_elements = param.numel()  # Total number of elements in the tensor\n",
        "    zero_elements = torch.sum(param == 0).item()  # Count of zero elements\n",
        "    sparsity = (zero_elements / total_elements) * 100  # Calculate sparsity as a percentage\n",
        "    return sparsity\n",
        "\n",
        "\n",
        "def calculate_sparsity_overall(model, params_to_prune):\n",
        "    \"\"\"\n",
        "    Calculate the overall sparsity for specific parameters in the model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model containing the parameters.\n",
        "        params_to_prune (list): List of tuples of (layer, 'attribute_name') indicating layers to be pruned.\n",
        "\n",
        "    Returns:\n",
        "        float: The overall sparsity percentage (between 0 and 100) for the specified parameters.\n",
        "    \"\"\"\n",
        "    total_elements = 0\n",
        "    zero_elements = 0\n",
        "\n",
        "    for layer, attr in params_to_prune:\n",
        "        param = getattr(layer, attr)  # Get the parameter (e.g., weight)\n",
        "        total_elements += param.numel()  # Add to total count\n",
        "        zero_elements += torch.sum(param == 0).item()  # Count zero elements\n",
        "\n",
        "    overall_sparsity = (zero_elements / total_elements) * 100  # Calculate overall sparsity as a percentage\n",
        "    return overall_sparsity\n",
        "\n",
        "\n",
        "def calculate_sparsity_model(model):\n",
        "    \"\"\"\n",
        "    Calculate the overall sparsity of all parameters in the model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model containing the parameters.\n",
        "\n",
        "    Returns:\n",
        "        float: The overall sparsity percentage (between 0 and 100) across the entire model.\n",
        "    \"\"\"\n",
        "    total_elements = 0\n",
        "    zero_elements = 0\n",
        "\n",
        "    for param in model.parameters():\n",
        "        total_elements += param.numel()  # Total elements across all parameters\n",
        "        zero_elements += torch.sum(param == 0).item()  # Count of zero elements across all parameters\n",
        "\n",
        "    model_sparsity = (zero_elements / total_elements) * 100  # Calculate model-wide sparsity as a percentage\n",
        "    return model_sparsity\n",
        "# Assuming model and params_to_prune are defined and pruning has been applied\n",
        "print(\"Sparsity of specific layer (model.layer1[0].conv1.weight):\", calculate_sparsity(model.layer1[0].conv1.weight))\n",
        "print(\"Overall sparsity of pruned layers:\", calculate_sparsity_overall(model, params_to_prune))\n",
        "print(\"Overall model sparsity:\", calculate_sparsity_model(model))\n"
      ],
      "metadata": {
        "id": "J6zRZMJcXzBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24d335f-e317-4308-c02f-6185232342c3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity of specific layer (model.layer1[0].conv1.weight): 11.3525390625\n",
            "Overall sparsity of pruned layers: 32.99967447916667\n",
            "Overall model sparsity: 0.206812820626812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we can easily convert the parameters to sparse representations:\n",
        "\n",
        "sd = model.state_dict()\n",
        "for item in sd:\n",
        "    # if 'weight' in item: # shortcut, this assumes you pruned (and removed reparameterization for) all weight parameters\n",
        "    #     print(\"sparsifying\", item)\n",
        "    sd[item] = model.state_dict()[item].to_sparse()\n",
        "sd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Qjw2SY9pS_",
        "outputId": "ceae8421-cf42-41f9-aad1-2602f22f65c7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv1.weight',\n",
              "              tensor(indices=tensor([[ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  0,  ...,  2,  2,  2],\n",
              "                                     [ 0,  0,  0,  ...,  6,  6,  6],\n",
              "                                     [ 0,  1,  2,  ...,  4,  5,  6]]),\n",
              "                     values=tensor([-0.0241,  0.0240,  0.0032,  ..., -0.0450,  0.0107,\n",
              "                                    -0.0123]),\n",
              "                     size=(64, 3, 7, 7), nnz=9408, layout=torch.sparse_coo)),\n",
              "             ('bn1.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([1.0198, 1.0112, 1.0057, 0.9988, 0.9963, 0.9921, 0.9984,\n",
              "                                    1.0160, 0.9942, 1.0204, 0.9968, 1.0149, 0.9996, 1.0014,\n",
              "                                    0.9937, 0.9884, 0.9992, 0.9995, 0.9797, 0.9955, 0.9916,\n",
              "                                    0.9998, 1.0075, 0.9979, 1.0012, 0.9926, 1.0079, 0.9889,\n",
              "                                    1.0145, 0.9966, 0.9990, 0.9971, 0.9997, 0.9986, 1.0154,\n",
              "                                    1.0117, 0.9910, 1.0248, 0.9792, 1.0207, 1.0103, 0.9916,\n",
              "                                    0.9966, 1.0046, 0.9993, 1.0017, 0.9835, 1.0049, 0.9873,\n",
              "                                    1.0139, 1.0067, 0.9932, 1.0035, 0.9927, 1.0029, 0.9891,\n",
              "                                    1.0029, 1.0001, 1.0010, 1.0137, 0.9984, 1.0134, 1.0053,\n",
              "                                    1.0204]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('bn1.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 2.4470e-02,  1.0978e-02,  6.6360e-03,  3.4627e-03,\n",
              "                                    -1.9095e-03, -8.4281e-03,  1.8483e-03,  1.4608e-02,\n",
              "                                    -1.5219e-02,  2.4127e-02, -1.7130e-02,  1.1397e-02,\n",
              "                                    -9.2584e-04,  1.3473e-02, -1.2007e-02, -1.2133e-02,\n",
              "                                    -1.8563e-02,  7.0202e-03, -2.0583e-02, -1.2047e-02,\n",
              "                                    -4.1270e-03, -6.9203e-03,  1.7815e-02, -1.1053e-02,\n",
              "                                     1.0251e-02, -1.3641e-02,  1.8523e-02, -1.0987e-02,\n",
              "                                     2.7164e-02, -7.0927e-03,  4.6873e-03,  3.8273e-03,\n",
              "                                    -7.5191e-03, -6.1889e-03,  1.5115e-02,  8.8393e-03,\n",
              "                                    -1.3290e-02,  2.2337e-02, -2.2818e-02,  1.2390e-02,\n",
              "                                     1.3103e-03, -3.7862e-03, -1.6249e-05, -2.0267e-02,\n",
              "                                     6.3310e-03,  4.8594e-03, -3.5133e-02,  2.7820e-03,\n",
              "                                    -1.2400e-02,  1.8229e-02,  6.8232e-03, -5.8810e-03,\n",
              "                                     1.4572e-03,  3.3448e-05,  1.0369e-03, -3.4388e-03,\n",
              "                                     9.7007e-03, -2.3818e-04,  8.9749e-03,  1.4634e-02,\n",
              "                                    -7.7558e-03,  6.2667e-03, -1.9922e-03,  1.0785e-02]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('bn1.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 1.1112, -0.4437,  1.8962,  1.2224,  1.7895, -1.4558,\n",
              "                                    -0.5759, -1.1291,  1.4676,  1.9816,  1.4907, -0.6149,\n",
              "                                     1.0770,  0.8078, -0.4535, -1.6085, -0.9227,  0.6248,\n",
              "                                    -1.0407,  1.7411,  1.5842, -1.7702, -1.1490,  1.3985,\n",
              "                                     0.5202,  1.1397, -0.8645, -1.1859, -0.7661,  1.1832,\n",
              "                                    -0.7821,  1.4531,  1.5121, -0.6299,  0.8364,  0.6025,\n",
              "                                    -1.2736,  1.4471,  1.8286,  1.4211,  1.7084, -1.3673,\n",
              "                                     1.8009, -1.0786,  1.1684, -0.7919, -1.0598, -0.8548,\n",
              "                                    -1.4272,  1.5143,  1.1785, -1.2987, -0.7646, -1.6173,\n",
              "                                     0.5500,  1.1357,  1.1721,  2.0062,  1.5354, -0.7195,\n",
              "                                     1.2390, -0.5095, -2.6732,  0.9690]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('bn1.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([1.0886, 0.2308, 3.1025, 1.2311, 2.6792, 1.6804, 0.3498,\n",
              "                                    1.3500, 1.6420, 3.1897, 1.7827, 0.4029, 0.8910, 0.6313,\n",
              "                                    0.2403, 2.2178, 0.7260, 0.3226, 0.8759, 2.5509, 2.0383,\n",
              "                                    2.4090, 1.0322, 1.5582, 0.2851, 1.1223, 0.6042, 1.1778,\n",
              "                                    0.5495, 1.0625, 0.5164, 1.6754, 1.7468, 0.3114, 0.5909,\n",
              "                                    0.3187, 1.4186, 1.8572, 2.6792, 1.7664, 2.5927, 1.4525,\n",
              "                                    2.7398, 0.9492, 1.3403, 0.6853, 0.9439, 0.5346, 1.4540,\n",
              "                                    2.1146, 1.1748, 1.4285, 0.6005, 2.2507, 0.2874, 0.9426,\n",
              "                                    1.2271, 3.4691, 1.9375, 0.5170, 1.2849, 0.2930, 5.7387,\n",
              "                                    0.7388]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.conv1.weight',\n",
              "              tensor(indices=tensor([[ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  1,  2,  ..., 61, 62, 63],\n",
              "                                     [ 0,  0,  0,  ...,  0,  0,  0],\n",
              "                                     [ 0,  0,  0,  ...,  0,  0,  0]]),\n",
              "                     values=tensor([-0.1239,  0.1735,  0.0354,  ...,  0.3278, -0.0980,\n",
              "                                     0.0493]),\n",
              "                     size=(64, 64, 1, 1), nnz=3631, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn1.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([1.0059, 0.9935, 1.0085, 0.9985, 1.0002, 0.9958, 1.0138,\n",
              "                                    0.9832, 1.0295, 1.0164, 1.0015, 1.0284, 0.9947, 0.9989,\n",
              "                                    0.9987, 0.9937, 1.0034, 0.9951, 0.9988, 0.9853, 0.9944,\n",
              "                                    0.9910, 1.0005, 1.0074, 0.9912, 1.0064, 0.9989, 1.0093,\n",
              "                                    1.0030, 0.9936, 0.9957, 0.9981, 0.9881, 0.9918, 0.9885,\n",
              "                                    1.0019, 0.9912, 1.0073, 0.9917, 1.0173, 0.9974, 0.9941,\n",
              "                                    0.9838, 0.9993, 0.9898, 0.9859, 1.0168, 1.0183, 0.9990,\n",
              "                                    1.0162, 1.0037, 0.9931, 0.9797, 1.0068, 1.0058, 0.9799,\n",
              "                                    1.0067, 1.0134, 0.9811, 0.9935, 1.0079, 0.9948, 0.9984,\n",
              "                                    0.9956]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn1.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.0045, -0.0148,  0.0067,  0.0057, -0.0048, -0.0014,\n",
              "                                     0.0179,  0.0064,  0.0105,  0.0128,  0.0012,  0.0096,\n",
              "                                    -0.0074, -0.0022, -0.0085, -0.0053,  0.0015, -0.0083,\n",
              "                                    -0.0085, -0.0039, -0.0196, -0.0119, -0.0039, -0.0048,\n",
              "                                    -0.0085,  0.0049, -0.0039,  0.0014, -0.0023, -0.0010,\n",
              "                                    -0.0102,  0.0106, -0.0108, -0.0020, -0.0063,  0.0044,\n",
              "                                     0.0004, -0.0004, -0.0077, -0.0034, -0.0095, -0.0067,\n",
              "                                    -0.0141, -0.0082, -0.0019, -0.0092,  0.0111,  0.0051,\n",
              "                                    -0.0026,  0.0130, -0.0031,  0.0107, -0.0025, -0.0130,\n",
              "                                     0.0086, -0.0158, -0.0036,  0.0066, -0.0196, -0.0103,\n",
              "                                     0.0072, -0.0059,  0.0080, -0.0071]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn1.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.0539, -0.1607, -0.2773, -0.1626, -0.0028, -0.4378,\n",
              "                                     0.0963, -0.2840, -0.3301, -0.0482, -0.7728, -0.1398,\n",
              "                                     0.7727, -0.5341, -1.0683,  1.1612, -0.4664,  1.1661,\n",
              "                                     0.2679, -0.4511,  0.2304,  0.3517, -0.2797,  0.8907,\n",
              "                                    -0.2218, -0.2889,  0.0313,  0.3983, -0.9606, -0.1445,\n",
              "                                    -0.3627,  0.2819, -0.3707,  0.3257,  0.6594, -0.4514,\n",
              "                                     1.2160, -0.2577,  0.8919,  0.0996,  0.6699, -1.2200,\n",
              "                                     0.1815,  0.9533, -0.7107,  0.3425,  0.8607,  0.1339,\n",
              "                                    -0.9752, -0.2171, -0.0398,  0.2538,  0.1910,  0.0036,\n",
              "                                    -0.0275, -0.7976,  0.0596, -0.3343,  0.0663, -0.3204,\n",
              "                                    -0.1014,  0.8396,  0.2768, -0.9604]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn1.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([0.2084, 0.2852, 1.8485, 0.2981, 1.1956, 0.6135, 0.1099,\n",
              "                                    0.1212, 0.1475, 0.2616, 1.1756, 0.1381, 0.1157, 0.2591,\n",
              "                                    0.6963, 2.6453, 0.3772, 1.2419, 0.5478, 0.3506, 1.4276,\n",
              "                                    0.1274, 0.1919, 2.4503, 0.5478, 2.4684, 0.6894, 3.6957,\n",
              "                                    0.8179, 0.2012, 0.6022, 0.8756, 4.4519, 0.4301, 0.0487,\n",
              "                                    2.2060, 1.8547, 0.3657, 2.7148, 0.2819, 2.1405, 0.1177,\n",
              "                                    0.0896, 0.1762, 1.7332, 0.7543, 2.3936, 0.3060, 0.5192,\n",
              "                                    0.2854, 0.2449, 0.2729, 0.7317, 0.2238, 0.7254, 3.2297,\n",
              "                                    0.4245, 0.2878, 0.6683, 1.3341, 0.1674, 1.2521, 0.1036,\n",
              "                                    1.0361]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.conv2.weight',\n",
              "              tensor(indices=tensor([[ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  1,  ...,  0,  1,  2],\n",
              "                                     [ 1,  2,  0,  ...,  2,  0,  2]]),\n",
              "                     values=tensor([ 0.1146, -0.0690,  0.0763,  ...,  0.0443,  0.0593,\n",
              "                                    -0.0595]),\n",
              "                     size=(64, 64, 3, 3), nnz=25369, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn2.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([0.9837, 1.0095, 1.0009, 0.9850, 0.9958, 1.0009, 0.9902,\n",
              "                                    0.9935, 0.9862, 1.0044, 0.9867, 1.0117, 1.0023, 0.9979,\n",
              "                                    1.0007, 1.0089, 0.9875, 1.0060, 1.0029, 0.9954, 1.0042,\n",
              "                                    1.0071, 0.9996, 1.0181, 1.0070, 1.0147, 0.9945, 1.0169,\n",
              "                                    1.0268, 0.9814, 1.0015, 1.0124, 0.9865, 1.0023, 1.0125,\n",
              "                                    1.0019, 0.9954, 0.9905, 0.9855, 1.0059, 0.9968, 0.9934,\n",
              "                                    0.9946, 0.9826, 0.9997, 0.9937, 0.9963, 1.0061, 1.0027,\n",
              "                                    1.0017, 0.9956, 0.9949, 0.9906, 0.9945, 0.9912, 1.0174,\n",
              "                                    0.9989, 1.0157, 1.0100, 0.9857, 0.9902, 0.9917, 1.0046,\n",
              "                                    0.9969]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn2.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([-0.0064, -0.0106,  0.0156, -0.0070,  0.0071,  0.0175,\n",
              "                                    -0.0180, -0.0093,  0.0027, -0.0015, -0.0151,  0.0060,\n",
              "                                     0.0032,  0.0047,  0.0040, -0.0066, -0.0100,  0.0031,\n",
              "                                    -0.0010, -0.0067, -0.0020,  0.0007,  0.0018, -0.0002,\n",
              "                                    -0.0049, -0.0033,  0.0201,  0.0109,  0.0102, -0.0229,\n",
              "                                    -0.0047,  0.0040, -0.0043,  0.0126,  0.0052,  0.0063,\n",
              "                                     0.0040, -0.0277, -0.0096,  0.0042, -0.0090,  0.0082,\n",
              "                                     0.0039, -0.0033,  0.0159, -0.0142, -0.0074,  0.0153,\n",
              "                                     0.0022,  0.0061, -0.0042, -0.0148, -0.0083,  0.0014,\n",
              "                                    -0.0017,  0.0010, -0.0011,  0.0028,  0.0110,  0.0031,\n",
              "                                     0.0135,  0.0022, -0.0032, -0.0162]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn2.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([-0.7295, -0.1738, -0.7740, -0.3210,  0.4416, -0.5561,\n",
              "                                     1.2928, -0.2772, -1.0205, -0.8582, -0.7576, -0.5297,\n",
              "                                    -0.3937, -1.0698, -0.4339, -0.1160,  0.7322, -0.2408,\n",
              "                                     0.0948,  0.5365,  0.1098,  0.6018,  0.8546,  0.8777,\n",
              "                                     0.2050, -0.5655, -0.2947,  1.4883, -0.7902, -1.2034,\n",
              "                                     1.5119,  0.7636, -0.2006, -0.4358, -0.1270,  0.5040,\n",
              "                                    -1.2961,  0.7772,  0.7812,  0.0622,  1.0328, -0.0916,\n",
              "                                    -0.7186, -1.3511,  0.6628,  0.1137,  0.0773, -0.3208,\n",
              "                                    -0.7691, -0.2439,  0.1072,  0.6730, -0.8383,  0.8945,\n",
              "                                    -1.5070,  0.3956, -0.7152,  0.0145, -0.5784, -0.5895,\n",
              "                                    -0.8191,  0.3314, -1.0696, -0.1379]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn2.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([0.7419, 1.2949, 1.6500, 1.4670, 3.2055, 2.2687, 0.7933,\n",
              "                                    2.6132, 3.6799, 2.6219, 4.3403, 1.5840, 0.4619, 4.6217,\n",
              "                                    7.4666, 2.8828, 1.2037, 1.4656, 3.6846, 1.1594, 2.7892,\n",
              "                                    2.6969, 7.4784, 1.9802, 1.4894, 1.6496, 1.1968, 2.1619,\n",
              "                                    0.8004, 4.3510, 3.1023, 7.2013, 1.3746, 1.8077, 2.2305,\n",
              "                                    2.8509, 5.2703, 0.6570, 2.4114, 3.6455, 5.7034, 1.7710,\n",
              "                                    7.2326, 5.5592, 2.0831, 2.6927, 2.3212, 2.1011, 2.1286,\n",
              "                                    4.8441, 0.8232, 1.7412, 4.9618, 1.7609, 3.0723, 2.6287,\n",
              "                                    1.9648, 0.8048, 1.0346, 1.9312, 0.6542, 2.8681, 2.9515,\n",
              "                                    3.4694]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   1,   2,  ...,  58,  61,  62],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.1167,  0.1343,  0.1127,  ..., -0.0601,  0.0361,\n",
              "                                    -0.0358]),\n",
              "                     size=(256, 64, 1, 1), nnz=12792, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9901, 0.9985, 0.9981, 0.9963, 0.9859, 1.0068, 1.0060,\n",
              "                                    0.9916, 0.9593, 1.0012, 0.9942, 0.9934, 0.9910, 0.9937,\n",
              "                                    1.0255, 0.9865, 1.0154, 0.9879, 1.0007, 0.9738, 0.9950,\n",
              "                                    0.9907, 0.9806, 1.0143, 1.0023, 1.0107, 1.0108, 1.0055,\n",
              "                                    1.0103, 0.9817, 0.9889, 0.9912, 1.0050, 0.9904, 0.9973,\n",
              "                                    0.9936, 1.0156, 0.9949, 1.0007, 0.9992, 1.0091, 0.9978,\n",
              "                                    1.0180, 0.9978, 0.9979, 0.9949, 0.9820, 1.0090, 1.0168,\n",
              "                                    0.9808, 1.0001, 1.0168, 0.9908, 0.9952, 0.9856, 1.0116,\n",
              "                                    1.0033, 1.0063, 1.0048, 0.9876, 1.0004, 1.0129, 1.0002,\n",
              "                                    1.0069, 1.0061, 1.0198, 1.0196, 1.0006, 0.9832, 0.9876,\n",
              "                                    0.9997, 0.9945, 1.0064, 0.9971, 0.9966, 1.0281, 0.9797,\n",
              "                                    0.9907, 1.0194, 0.9999, 1.0068, 0.9764, 1.0111, 0.9989,\n",
              "                                    0.9876, 1.0096, 0.9911, 0.9835, 0.9798, 1.0116, 1.0015,\n",
              "                                    1.0090, 0.9941, 0.9990, 0.9953, 0.9982, 0.9912, 1.0040,\n",
              "                                    1.0121, 1.0093, 0.9826, 1.0106, 0.9958, 1.0045, 1.0081,\n",
              "                                    1.0090, 0.9977, 1.0189, 0.9959, 1.0485, 1.0197, 1.0037,\n",
              "                                    0.9968, 0.9865, 1.0184, 0.9928, 1.0211, 1.0021, 0.9943,\n",
              "                                    0.9925, 0.9935, 1.0047, 1.0096, 0.9871, 1.0099, 1.0171,\n",
              "                                    0.9992, 1.0021, 1.0035, 0.9962, 0.9915, 0.9913, 1.0061,\n",
              "                                    0.9879, 0.9975, 1.0226, 0.9993, 0.9822, 0.9988, 1.0271,\n",
              "                                    1.0048, 0.9900, 1.0045, 1.0042, 1.0145, 1.0149, 0.9745,\n",
              "                                    0.9830, 0.9956, 1.0094, 1.0237, 0.9891, 1.0065, 1.0045,\n",
              "                                    1.0016, 1.0111, 0.9848, 0.9986, 0.9996, 0.9874, 1.0122,\n",
              "                                    0.9944, 1.0106, 1.0220, 0.9947, 1.0072, 1.0289, 0.9920,\n",
              "                                    0.9852, 1.0122, 1.0226, 1.0063, 0.9934, 1.0066, 1.0074,\n",
              "                                    0.9920, 1.0044, 0.9963, 1.0401, 1.0089, 0.9974, 0.9851,\n",
              "                                    0.9922, 0.9970, 0.9776, 1.0146, 0.9981, 0.9915, 1.0057,\n",
              "                                    1.0155, 0.9913, 1.0132, 1.0116, 0.9904, 0.9930, 1.0051,\n",
              "                                    0.9576, 0.9939, 1.0036, 0.9772, 1.0088, 1.0006, 0.9903,\n",
              "                                    0.9899, 1.0011, 0.9763, 1.0117, 1.0207, 0.9916, 0.9889,\n",
              "                                    0.9846, 0.9993, 0.9898, 1.0062, 1.0139, 0.9818, 1.0074,\n",
              "                                    0.9829, 0.9801, 0.9908, 1.0090, 0.9981, 0.9766, 0.9949,\n",
              "                                    0.9988, 0.9835, 1.0030, 0.9981, 0.9767, 1.0065, 1.0035,\n",
              "                                    1.0191, 1.0216, 0.9936, 0.9826, 1.0004, 1.0137, 0.9945,\n",
              "                                    1.0057, 0.9942, 1.0037, 0.9963, 1.0006, 1.0074, 1.0230,\n",
              "                                    0.9964, 1.0053, 1.0152, 0.9875, 1.0118, 0.9916, 1.0130,\n",
              "                                    0.9864, 1.0014, 1.0330, 1.0063]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-1.4071e-02,  1.2562e-02,  2.3962e-02,  1.2385e-02,\n",
              "                                    -7.3474e-03,  1.1489e-02,  4.4771e-03, -1.5044e-02,\n",
              "                                    -1.5066e-02,  8.1559e-03,  7.5175e-03,  4.4563e-03,\n",
              "                                    -1.4378e-02,  6.2979e-03, -1.2332e-03, -9.2250e-04,\n",
              "                                     2.1953e-02, -3.9613e-03,  1.3994e-03,  2.2894e-03,\n",
              "                                     4.8876e-03, -9.8288e-03,  1.2036e-03,  7.5944e-03,\n",
              "                                     1.7337e-02,  1.0329e-02,  8.4649e-03,  2.6203e-02,\n",
              "                                     6.1059e-03, -5.9519e-03, -1.6264e-03, -2.7565e-03,\n",
              "                                    -1.5820e-02,  5.0574e-03,  6.1522e-04,  4.8265e-03,\n",
              "                                     1.5676e-02,  1.6996e-03, -1.5454e-02, -4.0315e-03,\n",
              "                                     2.5153e-03, -1.4818e-02,  2.1719e-02, -6.8578e-04,\n",
              "                                    -1.3819e-02, -9.3194e-03, -1.1494e-03,  1.8250e-02,\n",
              "                                     1.2027e-02, -1.2770e-02,  2.0483e-02, -7.0089e-03,\n",
              "                                    -1.5999e-02,  7.1189e-03,  1.1738e-02,  3.8814e-03,\n",
              "                                     1.4525e-03,  2.3485e-02,  1.2931e-03, -1.1646e-03,\n",
              "                                     9.4192e-03, -6.1217e-03, -7.6661e-03,  4.3588e-03,\n",
              "                                     1.1650e-02, -6.2221e-03,  1.6411e-02,  9.5010e-04,\n",
              "                                     8.7157e-04, -1.5458e-02, -2.0177e-02,  2.6971e-02,\n",
              "                                     1.8043e-02, -1.8769e-02,  6.2958e-03,  9.8299e-03,\n",
              "                                     8.7012e-03, -6.8410e-03,  4.3861e-03,  1.9876e-02,\n",
              "                                    -1.3982e-02,  1.1797e-02,  6.1668e-03,  1.5388e-03,\n",
              "                                    -4.7251e-03, -3.4184e-03,  3.5666e-03, -6.1935e-03,\n",
              "                                     9.6740e-04, -1.1264e-02,  4.4960e-03,  3.4574e-03,\n",
              "                                    -2.0302e-02,  7.6148e-04,  1.1881e-02, -6.6299e-03,\n",
              "                                    -2.8925e-03, -1.7061e-03,  1.0457e-03,  2.9120e-05,\n",
              "                                    -7.2231e-04, -8.5345e-03,  1.8155e-02, -6.8426e-04,\n",
              "                                    -1.2831e-02,  1.2974e-04,  1.6159e-02,  5.2246e-03,\n",
              "                                     5.6812e-03,  7.9222e-03,  1.5502e-02, -2.8937e-02,\n",
              "                                    -6.5060e-03, -8.8762e-03,  2.2834e-02,  1.2797e-02,\n",
              "                                     1.4388e-02,  6.6381e-03,  2.1770e-02, -6.7873e-03,\n",
              "                                     9.9956e-03, -8.4506e-03, -1.3063e-04, -1.4309e-02,\n",
              "                                     2.0720e-02,  6.8278e-03,  1.0329e-02, -5.1261e-03,\n",
              "                                     9.4096e-03,  4.0258e-06, -1.8451e-02, -5.8011e-04,\n",
              "                                     1.9602e-02,  8.1182e-03,  5.4150e-03,  1.3868e-02,\n",
              "                                     5.5503e-05, -7.6507e-03,  1.8526e-02,  4.5937e-04,\n",
              "                                     1.5353e-02, -7.7370e-03, -3.1107e-03, -8.3795e-03,\n",
              "                                     2.3873e-03,  1.6194e-02, -1.6306e-02, -1.0040e-02,\n",
              "                                     2.0465e-02, -2.2481e-03,  1.2288e-02, -1.5995e-02,\n",
              "                                    -4.4665e-03,  8.7037e-04,  7.8402e-03,  2.0154e-03,\n",
              "                                    -1.6540e-03,  6.4216e-05,  7.8144e-03, -1.6460e-02,\n",
              "                                    -5.6874e-03, -6.7543e-05,  2.9662e-02,  2.8009e-05,\n",
              "                                    -9.3721e-03,  4.8333e-03,  9.7447e-03, -1.1703e-02,\n",
              "                                     9.7957e-03,  5.0690e-03, -1.2559e-02,  1.3033e-02,\n",
              "                                    -1.0367e-02, -4.0446e-03,  1.1009e-02, -1.0803e-02,\n",
              "                                     2.9690e-03, -4.7249e-03,  3.3954e-02,  3.3648e-03,\n",
              "                                    -9.2017e-03, -1.6178e-03,  2.9043e-03,  1.6603e-02,\n",
              "                                     6.2585e-04,  3.9583e-02, -2.3493e-03, -8.8041e-04,\n",
              "                                    -3.9869e-03,  4.0236e-03,  5.1074e-05,  1.5689e-02,\n",
              "                                     1.3772e-03,  1.4675e-02, -3.3446e-03,  2.4071e-03,\n",
              "                                     4.3194e-03, -6.3570e-03,  2.3091e-03,  1.6012e-02,\n",
              "                                     7.8601e-03,  5.1359e-03, -7.6619e-04,  4.2846e-03,\n",
              "                                    -4.5113e-03,  1.6745e-02, -2.6273e-03,  6.8803e-03,\n",
              "                                    -6.0388e-03, -5.2813e-03, -9.0901e-03,  2.1601e-03,\n",
              "                                     3.5706e-03,  8.2767e-03,  3.9017e-03,  1.0583e-02,\n",
              "                                     2.1225e-02, -9.5688e-03, -1.2448e-02, -1.0172e-03,\n",
              "                                     1.6430e-02,  4.1201e-04,  4.6182e-03, -5.3869e-03,\n",
              "                                     7.8533e-03, -3.2048e-03,  9.6401e-03, -3.7475e-03,\n",
              "                                    -2.3281e-02, -6.6294e-03, -4.2335e-03,  1.5186e-02,\n",
              "                                     5.6061e-03, -4.6649e-03, -5.4520e-03, -2.4395e-03,\n",
              "                                     2.2752e-02,  1.9895e-03, -2.5803e-03,  5.4603e-03,\n",
              "                                    -5.6750e-03,  7.7515e-03, -6.3536e-03,  4.0030e-03,\n",
              "                                     1.3434e-02,  5.5865e-03, -6.6879e-03,  1.4027e-02,\n",
              "                                     1.1539e-02, -2.1838e-03,  1.4933e-03,  1.8991e-02,\n",
              "                                    -3.7126e-03,  7.9282e-03,  2.4969e-03,  1.4985e-02]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 7.0828e-02,  3.7090e-01, -1.7415e-01,  4.9975e-01,\n",
              "                                     1.0067e-01,  1.1831e-01, -2.2338e-01,  4.7985e-04,\n",
              "                                     2.0364e-01,  6.7803e-01,  2.0805e-01,  1.0739e-01,\n",
              "                                     6.4336e-01,  5.1107e-01, -3.2243e-01, -1.2901e-01,\n",
              "                                    -9.8483e-02, -8.4664e-02, -1.3145e-01,  4.8250e-02,\n",
              "                                    -3.8745e-01, -1.5799e-01, -4.5749e-01,  1.6098e-01,\n",
              "                                     1.6684e-01, -2.1945e-02,  2.5506e-01, -3.4795e-01,\n",
              "                                     2.0396e-02,  2.2504e-01, -6.9788e-01,  6.1620e-02,\n",
              "                                    -1.5702e-01,  1.3803e-03,  1.5021e-01, -1.7816e-01,\n",
              "                                    -2.7973e-03, -4.6672e-03, -8.9695e-02,  1.8104e-01,\n",
              "                                     1.0891e-01,  1.9876e-01, -1.8948e-01, -1.8373e-01,\n",
              "                                    -9.3320e-03,  3.9495e-01,  1.3944e-01, -3.4588e-01,\n",
              "                                    -8.3330e-02, -2.9159e-01,  9.6282e-02,  5.3916e-01,\n",
              "                                     5.9048e-01,  5.8530e-01, -1.4815e-01, -6.0625e-02,\n",
              "                                     4.9054e-02,  3.2765e-01, -2.5323e-02,  6.5996e-02,\n",
              "                                     3.3346e-02,  2.6662e-01, -1.2131e-01, -2.2875e-02,\n",
              "                                    -2.5459e-01,  9.7509e-02, -2.3358e-01, -1.9650e-01,\n",
              "                                     2.2677e-01, -2.0316e-03,  2.0819e-01, -1.0524e-02,\n",
              "                                     3.2743e-01, -2.0572e-01,  1.3995e-01, -4.7215e-01,\n",
              "                                    -4.4421e-01,  2.8131e-01,  3.4699e-03,  1.2212e-01,\n",
              "                                    -6.5785e-02, -2.3643e-01,  2.7399e-01,  6.0054e-01,\n",
              "                                    -4.1686e-01, -6.1635e-01,  2.3301e-01,  4.0059e-02,\n",
              "                                    -1.2010e-01,  2.8362e-01,  1.0890e-01,  1.6170e-01,\n",
              "                                    -1.1681e-01,  3.1382e-01, -1.0938e-01, -6.0489e-02,\n",
              "                                    -1.8781e-01,  6.8493e-03,  1.1720e-01, -4.5382e-01,\n",
              "                                    -3.6817e-01, -6.2426e-01,  4.3213e-02, -3.0811e-01,\n",
              "                                    -3.4103e-01,  3.3279e-01, -1.1947e-01,  1.2979e-01,\n",
              "                                     2.4107e-01, -2.6038e-02, -8.3196e-02, -2.2455e-02,\n",
              "                                     3.3862e-02, -2.7884e-01,  1.7760e-01, -1.0372e-01,\n",
              "                                    -2.8675e-01,  3.2417e-02, -8.2236e-02, -1.6533e-01,\n",
              "                                    -3.1322e-01, -2.2370e-01, -1.2168e-01,  2.2357e-01,\n",
              "                                     5.2715e-02, -2.4134e-01, -8.3743e-02, -2.2010e-02,\n",
              "                                     2.1573e-02,  2.6893e-01, -3.9044e-01,  1.4259e-01,\n",
              "                                    -7.6253e-02, -8.0597e-01, -2.2904e-01,  1.8457e-01,\n",
              "                                     1.8738e-01, -9.4708e-02,  2.4299e-01, -1.8586e-02,\n",
              "                                    -1.8514e-01, -2.0805e-01,  7.9710e-01,  3.3006e-01,\n",
              "                                    -6.9246e-02, -2.0037e-01,  2.4099e-01,  1.4172e-01,\n",
              "                                    -1.5732e-01, -8.9019e-02, -2.5156e-01, -1.3721e-01,\n",
              "                                     1.1886e-01, -5.4067e-04, -1.5165e-01, -8.1761e-02,\n",
              "                                    -2.1786e-01, -1.5163e-01, -1.8280e-01,  4.9693e-01,\n",
              "                                     1.6269e-01,  1.5817e-01,  1.3692e-01,  1.8659e-01,\n",
              "                                    -4.2301e-02, -6.1691e-02, -1.5896e-01, -3.4078e-02,\n",
              "                                    -2.7534e-01, -1.1244e-01,  4.6249e-01,  2.3302e-01,\n",
              "                                    -2.7974e-02,  2.9187e-01,  5.1540e-01, -9.6410e-02,\n",
              "                                     3.4665e-01, -1.9196e-01, -1.0760e-01,  3.4516e-02,\n",
              "                                    -1.2479e-01, -2.2781e-02, -2.5173e-01,  1.6249e-01,\n",
              "                                    -9.5937e-02, -7.9295e-02,  1.2093e-01,  3.5675e-01,\n",
              "                                    -5.9408e-01, -2.1995e-02,  2.2980e-01,  3.7475e-02,\n",
              "                                    -2.2536e-01,  1.2951e-01,  1.8922e-01, -4.4186e-01,\n",
              "                                    -9.9481e-01,  1.3476e-01, -2.3131e-01, -8.9190e-02,\n",
              "                                     2.2303e-01, -1.2587e-01, -2.2389e-01, -4.4752e-01,\n",
              "                                     8.7376e-03, -2.7996e-01, -5.0758e-01, -2.0571e-01,\n",
              "                                     1.2571e-01, -1.1317e-01, -3.0726e-01,  8.8133e-02,\n",
              "                                    -1.0990e-01, -6.6127e-01,  1.9985e-01, -4.6311e-01,\n",
              "                                     2.4940e-01, -1.1718e-01, -2.9951e-01, -3.9432e-01,\n",
              "                                     2.6840e-01, -1.0191e-01, -4.4853e-01,  3.3241e-01,\n",
              "                                    -9.6221e-02,  3.1558e-02,  1.7618e-01,  2.2413e-01,\n",
              "                                    -2.9428e-01, -1.7075e-01,  1.1860e-01,  1.5407e-01,\n",
              "                                    -2.9884e-01,  5.0867e-01, -3.3992e-01, -3.0552e-03,\n",
              "                                    -6.1828e-01, -3.6552e-01, -8.7801e-02,  1.8463e-01,\n",
              "                                     1.4922e-01,  5.4353e-01, -1.4947e-01,  4.8778e-01,\n",
              "                                     1.0165e-01, -1.5212e-01,  1.9564e-01, -8.4403e-02,\n",
              "                                     4.8802e-02,  8.4977e-02,  1.3380e-01,  9.8396e-03,\n",
              "                                    -3.8598e-01, -1.1874e-01,  1.2241e-01,  3.2316e-01]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.0930, 0.0958, 0.2672, 1.2405, 0.0852, 0.1417, 0.0877,\n",
              "                                    0.0832, 0.3630, 0.2664, 0.1637, 0.1405, 0.5793, 0.4390,\n",
              "                                    0.2526, 0.3203, 0.0759, 0.1489, 0.0873, 0.1701, 0.0259,\n",
              "                                    0.2424, 0.3480, 0.1681, 0.1170, 0.4003, 0.2231, 0.1220,\n",
              "                                    0.0897, 0.1753, 0.2111, 0.1724, 0.1240, 0.1417, 0.1887,\n",
              "                                    0.1225, 0.1048, 0.1715, 0.1683, 0.3338, 0.1280, 0.0522,\n",
              "                                    0.2541, 0.1423, 0.0860, 0.1966, 0.1757, 0.0725, 0.1325,\n",
              "                                    0.0870, 0.2523, 0.4462, 0.3669, 0.3916, 0.0733, 0.4813,\n",
              "                                    0.0694, 0.2100, 0.4209, 0.1764, 0.4225, 0.1183, 0.0875,\n",
              "                                    0.1049, 0.0988, 0.2296, 0.1521, 0.1932, 0.1792, 0.1255,\n",
              "                                    0.5861, 0.1163, 0.5196, 0.0573, 0.1722, 0.1050, 0.2558,\n",
              "                                    0.0369, 0.2326, 0.1405, 0.0907, 0.2677, 0.0911, 0.4034,\n",
              "                                    0.3488, 0.0439, 0.1731, 0.3450, 0.0916, 0.1171, 0.2260,\n",
              "                                    0.2422, 0.1229, 0.1569, 0.2192, 0.1970, 0.1120, 0.3956,\n",
              "                                    0.1981, 0.4109, 0.0990, 0.1293, 0.1652, 0.3147, 0.3727,\n",
              "                                    0.3879, 0.2206, 0.2495, 0.2845, 0.0923, 0.1171, 0.2675,\n",
              "                                    0.2307, 0.4924, 0.1555, 0.1605, 0.3649, 0.6495, 0.2788,\n",
              "                                    0.1326, 0.1885, 0.0995, 0.0360, 0.2838, 0.1192, 0.0850,\n",
              "                                    0.1687, 0.0825, 0.0868, 0.0638, 0.0883, 0.2337, 0.0740,\n",
              "                                    0.0699, 0.2410, 0.1010, 0.1747, 0.0938, 0.2116, 0.1225,\n",
              "                                    0.0973, 0.4512, 0.0852, 0.4040, 0.0849, 0.1653, 0.1268,\n",
              "                                    0.3356, 0.3643, 0.7131, 0.1362, 0.1905, 0.0862, 0.2398,\n",
              "                                    0.0771, 0.1686, 0.1294, 0.4891, 0.4542, 0.7058, 0.0435,\n",
              "                                    0.1561, 0.0700, 0.2748, 0.0588, 0.1376, 0.0611, 0.2465,\n",
              "                                    0.2520, 0.1774, 0.1456, 0.0898, 0.1780, 0.3172, 0.1609,\n",
              "                                    0.1098, 0.1950, 0.3848, 0.2164, 0.3142, 0.2144, 0.0716,\n",
              "                                    0.2430, 0.1561, 0.2855, 0.8979, 0.0836, 0.2821, 0.1166,\n",
              "                                    0.2380, 0.1264, 0.0929, 0.1462, 0.4918, 0.1967, 0.2312,\n",
              "                                    0.1493, 0.3496, 0.3005, 0.3756, 0.0742, 0.2519, 0.1385,\n",
              "                                    0.2736, 0.3095, 0.0806, 0.0627, 0.1460, 0.0383, 0.1224,\n",
              "                                    0.0772, 0.0589, 0.0677, 0.7327, 0.1068, 0.2669, 0.2575,\n",
              "                                    0.2552, 0.1664, 0.3561, 0.0929, 0.2621, 0.2893, 0.3231,\n",
              "                                    0.0991, 0.3127, 0.0741, 0.1363, 0.2110, 0.1100, 0.1282,\n",
              "                                    0.6348, 0.1070, 0.1036, 0.5164, 0.2775, 0.0655, 0.0643,\n",
              "                                    0.2382, 0.1079, 0.0836, 0.0608, 0.2063, 0.3630, 0.1735,\n",
              "                                    0.1230, 0.1984, 0.1984, 0.1977, 0.6481, 0.2247, 0.0867,\n",
              "                                    0.2536, 0.2673, 0.1668, 0.2353]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.downsample.0.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   1,   2,  ...,  61,  62,  63],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.1249, -0.0764,  0.0374,  ...,  0.1302,  0.0790,\n",
              "                                     0.0058]),\n",
              "                     size=(256, 64, 1, 1), nnz=16384, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.downsample.1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([1.0074, 1.0059, 1.0176, 1.0152, 1.0004, 1.0007, 1.0050,\n",
              "                                    0.9970, 1.0354, 1.0091, 1.0150, 0.9977, 1.0168, 1.0012,\n",
              "                                    1.0002, 1.0133, 1.0179, 0.9980, 1.0016, 1.0191, 1.0121,\n",
              "                                    1.0056, 1.0040, 0.9873, 0.9947, 0.9944, 1.0188, 1.0161,\n",
              "                                    1.0075, 1.0004, 0.9943, 0.9989, 0.9936, 1.0050, 1.0093,\n",
              "                                    0.9935, 1.0099, 0.9934, 0.9991, 1.0034, 1.0024, 0.9882,\n",
              "                                    1.0119, 0.9721, 0.9945, 0.9865, 1.0012, 0.9926, 1.0105,\n",
              "                                    1.0003, 1.0145, 1.0025, 1.0090, 0.9937, 1.0139, 0.9945,\n",
              "                                    1.0000, 1.0176, 0.9963, 1.0110, 1.0033, 1.0074, 0.9880,\n",
              "                                    1.0066, 1.0036, 0.9828, 1.0082, 1.0046, 0.9976, 0.9986,\n",
              "                                    1.0012, 1.0134, 1.0098, 0.9913, 1.0092, 0.9857, 1.0149,\n",
              "                                    1.0161, 1.0036, 1.0135, 0.9908, 1.0161, 1.0209, 1.0003,\n",
              "                                    0.9939, 0.9980, 1.0088, 1.0121, 1.0121, 1.0025, 0.9964,\n",
              "                                    0.9758, 0.9865, 1.0044, 1.0121, 0.9973, 1.0072, 0.9876,\n",
              "                                    0.9969, 0.9987, 1.0130, 1.0108, 1.0074, 1.0034, 0.9934,\n",
              "                                    1.0166, 1.0132, 0.9794, 1.0167, 0.9852, 1.0072, 0.9846,\n",
              "                                    0.9964, 0.9958, 0.9932, 1.0159, 1.0138, 1.0113, 1.0104,\n",
              "                                    1.0033, 0.9928, 0.9851, 1.0147, 0.9747, 1.0132, 0.9904,\n",
              "                                    1.0201, 0.9910, 1.0174, 1.0086, 1.0205, 0.9936, 1.0075,\n",
              "                                    1.0186, 0.9920, 0.9856, 1.0010, 1.0051, 0.9939, 0.9833,\n",
              "                                    1.0168, 0.9992, 0.9953, 0.9978, 0.9937, 0.9991, 0.9695,\n",
              "                                    1.0000, 1.0158, 0.9887, 0.9859, 0.9875, 0.9762, 0.9970,\n",
              "                                    0.9969, 0.9848, 0.9990, 1.0008, 0.9876, 1.0122, 0.9873,\n",
              "                                    1.0269, 1.0145, 1.0073, 1.0098, 0.9913, 1.0028, 1.0022,\n",
              "                                    1.0048, 0.9999, 0.9925, 1.0244, 1.0053, 0.9949, 1.0122,\n",
              "                                    1.0208, 0.9959, 0.9921, 1.0261, 0.9928, 1.0036, 1.0154,\n",
              "                                    1.0021, 0.9899, 0.9920, 1.0428, 1.0048, 1.0062, 0.9973,\n",
              "                                    1.0169, 1.0039, 0.9913, 0.9969, 1.0138, 0.9952, 0.9771,\n",
              "                                    0.9985, 1.0053, 0.9872, 1.0108, 1.0021, 1.0037, 1.0112,\n",
              "                                    1.0088, 1.0199, 1.0044, 0.9934, 0.9927, 1.0052, 0.9927,\n",
              "                                    0.9969, 1.0027, 1.0240, 1.0109, 0.9792, 1.0284, 1.0064,\n",
              "                                    0.9977, 0.9931, 0.9993, 1.0071, 1.0008, 1.0150, 1.0044,\n",
              "                                    1.0152, 0.9915, 1.0091, 1.0048, 0.9977, 0.9918, 0.9945,\n",
              "                                    1.0063, 0.9850, 0.9966, 0.9981, 1.0010, 1.0098, 1.0087,\n",
              "                                    0.9981, 0.9987, 1.0034, 1.0001, 0.9823, 0.9877, 0.9832,\n",
              "                                    0.9978, 1.0243, 1.0510, 1.0319, 0.9810, 0.9982, 0.9963,\n",
              "                                    1.0056, 0.9719, 1.0090, 1.0283]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.downsample.1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-1.4071e-02,  1.2562e-02,  2.3962e-02,  1.2385e-02,\n",
              "                                    -7.3474e-03,  1.1489e-02,  4.4771e-03, -1.5044e-02,\n",
              "                                    -1.5066e-02,  8.1559e-03,  7.5175e-03,  4.4563e-03,\n",
              "                                    -1.4378e-02,  6.2979e-03, -1.2332e-03, -9.2250e-04,\n",
              "                                     2.1953e-02, -3.9613e-03,  1.3994e-03,  2.2894e-03,\n",
              "                                     4.8876e-03, -9.8288e-03,  1.2036e-03,  7.5944e-03,\n",
              "                                     1.7337e-02,  1.0329e-02,  8.4649e-03,  2.6203e-02,\n",
              "                                     6.1059e-03, -5.9519e-03, -1.6264e-03, -2.7565e-03,\n",
              "                                    -1.5820e-02,  5.0574e-03,  6.1522e-04,  4.8265e-03,\n",
              "                                     1.5676e-02,  1.6996e-03, -1.5454e-02, -4.0315e-03,\n",
              "                                     2.5153e-03, -1.4818e-02,  2.1719e-02, -6.8578e-04,\n",
              "                                    -1.3819e-02, -9.3194e-03, -1.1494e-03,  1.8250e-02,\n",
              "                                     1.2027e-02, -1.2770e-02,  2.0483e-02, -7.0089e-03,\n",
              "                                    -1.5999e-02,  7.1189e-03,  1.1738e-02,  3.8814e-03,\n",
              "                                     1.4525e-03,  2.3485e-02,  1.2931e-03, -1.1646e-03,\n",
              "                                     9.4192e-03, -6.1217e-03, -7.6661e-03,  4.3588e-03,\n",
              "                                     1.1650e-02, -6.2221e-03,  1.6411e-02,  9.5010e-04,\n",
              "                                     8.7157e-04, -1.5458e-02, -2.0177e-02,  2.6971e-02,\n",
              "                                     1.8043e-02, -1.8769e-02,  6.2958e-03,  9.8299e-03,\n",
              "                                     8.7012e-03, -6.8410e-03,  4.3861e-03,  1.9876e-02,\n",
              "                                    -1.3982e-02,  1.1797e-02,  6.1668e-03,  1.5388e-03,\n",
              "                                    -4.7251e-03, -3.4184e-03,  3.5666e-03, -6.1935e-03,\n",
              "                                     9.6740e-04, -1.1264e-02,  4.4960e-03,  3.4574e-03,\n",
              "                                    -2.0302e-02,  7.6148e-04,  1.1881e-02, -6.6299e-03,\n",
              "                                    -2.8925e-03, -1.7061e-03,  1.0457e-03,  2.9120e-05,\n",
              "                                    -7.2231e-04, -8.5345e-03,  1.8155e-02, -6.8426e-04,\n",
              "                                    -1.2831e-02,  1.2974e-04,  1.6159e-02,  5.2246e-03,\n",
              "                                     5.6812e-03,  7.9222e-03,  1.5502e-02, -2.8937e-02,\n",
              "                                    -6.5060e-03, -8.8762e-03,  2.2834e-02,  1.2797e-02,\n",
              "                                     1.4388e-02,  6.6381e-03,  2.1770e-02, -6.7873e-03,\n",
              "                                     9.9956e-03, -8.4506e-03, -1.3063e-04, -1.4309e-02,\n",
              "                                     2.0720e-02,  6.8278e-03,  1.0329e-02, -5.1261e-03,\n",
              "                                     9.4096e-03,  4.0258e-06, -1.8451e-02, -5.8011e-04,\n",
              "                                     1.9602e-02,  8.1182e-03,  5.4150e-03,  1.3868e-02,\n",
              "                                     5.5503e-05, -7.6507e-03,  1.8526e-02,  4.5937e-04,\n",
              "                                     1.5353e-02, -7.7370e-03, -3.1107e-03, -8.3795e-03,\n",
              "                                     2.3873e-03,  1.6194e-02, -1.6306e-02, -1.0040e-02,\n",
              "                                     2.0465e-02, -2.2481e-03,  1.2288e-02, -1.5995e-02,\n",
              "                                    -4.4665e-03,  8.7037e-04,  7.8402e-03,  2.0154e-03,\n",
              "                                    -1.6540e-03,  6.4216e-05,  7.8144e-03, -1.6460e-02,\n",
              "                                    -5.6874e-03, -6.7543e-05,  2.9662e-02,  2.8009e-05,\n",
              "                                    -9.3721e-03,  4.8333e-03,  9.7447e-03, -1.1703e-02,\n",
              "                                     9.7957e-03,  5.0690e-03, -1.2559e-02,  1.3033e-02,\n",
              "                                    -1.0367e-02, -4.0446e-03,  1.1009e-02, -1.0803e-02,\n",
              "                                     2.9690e-03, -4.7249e-03,  3.3954e-02,  3.3648e-03,\n",
              "                                    -9.2017e-03, -1.6178e-03,  2.9043e-03,  1.6603e-02,\n",
              "                                     6.2585e-04,  3.9583e-02, -2.3493e-03, -8.8041e-04,\n",
              "                                    -3.9869e-03,  4.0236e-03,  5.1074e-05,  1.5689e-02,\n",
              "                                     1.3772e-03,  1.4675e-02, -3.3446e-03,  2.4071e-03,\n",
              "                                     4.3194e-03, -6.3570e-03,  2.3091e-03,  1.6012e-02,\n",
              "                                     7.8601e-03,  5.1359e-03, -7.6619e-04,  4.2846e-03,\n",
              "                                    -4.5113e-03,  1.6745e-02, -2.6273e-03,  6.8803e-03,\n",
              "                                    -6.0388e-03, -5.2813e-03, -9.0901e-03,  2.1601e-03,\n",
              "                                     3.5706e-03,  8.2767e-03,  3.9017e-03,  1.0583e-02,\n",
              "                                     2.1225e-02, -9.5688e-03, -1.2448e-02, -1.0172e-03,\n",
              "                                     1.6430e-02,  4.1201e-04,  4.6182e-03, -5.3869e-03,\n",
              "                                     7.8533e-03, -3.2048e-03,  9.6401e-03, -3.7475e-03,\n",
              "                                    -2.3281e-02, -6.6294e-03, -4.2335e-03,  1.5186e-02,\n",
              "                                     5.6061e-03, -4.6649e-03, -5.4520e-03, -2.4395e-03,\n",
              "                                     2.2752e-02,  1.9895e-03, -2.5803e-03,  5.4603e-03,\n",
              "                                    -5.6750e-03,  7.7515e-03, -6.3536e-03,  4.0030e-03,\n",
              "                                     1.3434e-02,  5.5865e-03, -6.6879e-03,  1.4027e-02,\n",
              "                                     1.1539e-02, -2.1838e-03,  1.4933e-03,  1.8991e-02,\n",
              "                                    -3.7126e-03,  7.9282e-03,  2.4969e-03,  1.4985e-02]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.downsample.1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-5.1721e-01, -7.9548e-03,  8.6907e-02,  1.0527e-01,\n",
              "                                     2.5120e-01,  1.6248e-03, -2.6870e-01, -4.9504e-01,\n",
              "                                     3.5317e-02,  7.9142e-01,  2.8951e-01, -6.3162e-01,\n",
              "                                    -2.5165e-01,  1.5838e-01, -2.7985e-01,  3.7724e-01,\n",
              "                                    -3.9283e-01, -3.3785e-01, -1.7896e-01,  5.0465e-01,\n",
              "                                     2.2728e-01, -2.8139e-01, -4.7236e-02, -1.5407e-01,\n",
              "                                    -4.9650e-01,  1.2758e-01,  2.2071e-01,  2.3209e-02,\n",
              "                                    -4.0852e-01, -9.6765e-02, -2.2149e-01, -2.4930e-01,\n",
              "                                     1.8842e-02, -3.4132e-01, -2.5866e-01,  3.3249e-01,\n",
              "                                     2.1950e-01,  2.7300e-01,  1.1349e-01,  3.3177e-02,\n",
              "                                     6.4306e-01, -1.8720e-01,  3.2846e-01,  3.9976e-02,\n",
              "                                     2.6897e-01,  3.1821e-02,  2.7326e-01, -4.8053e-02,\n",
              "                                     7.5578e-01, -7.7207e-02, -4.2679e-02,  1.2859e-01,\n",
              "                                    -1.3296e-01, -3.7106e-03, -7.4319e-03,  1.7479e-01,\n",
              "                                     1.4796e-01, -1.0329e-01,  1.7808e-02, -2.7969e-02,\n",
              "                                     3.5811e-01,  1.4336e-01, -6.8764e-01, -2.2294e-01,\n",
              "                                     4.2967e-01,  1.7142e-01,  2.4907e-01, -2.2823e-01,\n",
              "                                     3.9289e-01, -1.1617e-01, -6.2386e-01, -8.1719e-02,\n",
              "                                    -2.0989e-01, -2.6033e-01,  4.9757e-02,  1.8494e-01,\n",
              "                                     4.5357e-01, -2.6207e-01,  3.0254e-01,  1.6348e-01,\n",
              "                                     1.6654e-01,  4.4735e-01, -5.3032e-01,  3.7837e-01,\n",
              "                                    -3.8501e-01, -2.6472e-01, -7.1496e-01,  3.0788e-01,\n",
              "                                     6.7399e-01,  6.9453e-02,  5.7161e-01, -8.1730e-04,\n",
              "                                     2.3406e-01,  4.2348e-02,  2.2516e-01, -1.8324e-01,\n",
              "                                     5.5076e-02,  2.9229e-02, -9.2349e-02,  3.4120e-01,\n",
              "                                    -2.7003e-01, -3.0840e-01, -4.7086e-01,  2.0774e-01,\n",
              "                                     7.5213e-01, -1.8093e-01, -3.3416e-01, -2.9666e-01,\n",
              "                                     4.5065e-01,  1.8521e-01, -3.8074e-01, -2.2444e-01,\n",
              "                                     2.8527e-02, -1.9817e-02,  1.5616e-01, -4.5928e-02,\n",
              "                                    -1.6078e-01,  8.0217e-03, -2.3682e-01, -2.5784e-02,\n",
              "                                    -1.4254e-01, -1.2286e-01,  3.3557e-01, -1.0677e-01,\n",
              "                                    -6.2034e-02, -2.9796e-01,  1.3188e-01, -1.3651e-01,\n",
              "                                    -6.1080e-01, -1.9079e-01, -6.3512e-01, -6.9618e-02,\n",
              "                                    -1.6268e-01,  2.4185e-01,  8.6135e-02, -9.2384e-02,\n",
              "                                     3.2758e-02, -7.9366e-02, -7.6596e-02,  5.8828e-01,\n",
              "                                     4.3532e-01, -8.3553e-02,  4.0686e-01, -1.7622e-01,\n",
              "                                     2.1925e-01, -2.2004e-01,  2.3623e-01, -4.0613e-01,\n",
              "                                     2.8767e-01,  1.2483e-01, -4.1774e-01,  5.8711e-01,\n",
              "                                    -1.8298e-01, -7.3109e-02,  3.4757e-01, -3.4956e-01,\n",
              "                                    -2.4123e-01, -2.4698e-01,  1.0630e-01, -3.2227e-01,\n",
              "                                    -5.7658e-01,  5.9968e-02, -5.0656e-01, -2.2317e-01,\n",
              "                                     2.3363e-01, -5.3966e-01, -4.6499e-01,  1.1077e-01,\n",
              "                                     2.7459e-02, -4.5118e-01,  3.1034e-01,  1.7249e-01,\n",
              "                                     6.2467e-01, -2.8072e-01,  7.1614e-02,  5.4124e-01,\n",
              "                                    -7.8938e-03,  2.3302e-01, -2.7059e-01,  1.2635e-01,\n",
              "                                     2.0792e-01,  2.3545e-01, -7.0357e-02, -1.0105e-01,\n",
              "                                    -1.9568e-01,  8.4666e-03,  1.8436e-01, -1.0014e-01,\n",
              "                                    -5.6387e-01,  1.8117e-01, -1.1404e-01, -2.5227e-01,\n",
              "                                    -1.6507e-01, -2.2143e-01, -2.5296e-01, -3.4831e-01,\n",
              "                                     2.4112e-03, -1.1742e-01,  4.5958e-01,  1.6760e-01,\n",
              "                                    -2.0091e-01,  1.6506e-01, -3.9299e-01, -2.5199e-01,\n",
              "                                     2.6009e-01,  4.3333e-01, -5.1173e-02,  2.9713e-01,\n",
              "                                    -2.6214e-01,  3.2351e-01, -1.5009e-02,  1.9972e-03,\n",
              "                                    -3.1928e-01, -5.8123e-01,  1.1589e-01,  2.0863e-01,\n",
              "                                     1.8044e-01,  4.8255e-01,  1.4853e-01, -5.1225e-02,\n",
              "                                     6.8503e-03, -1.5774e-01,  3.6416e-01,  6.2695e-02,\n",
              "                                    -8.2801e-02,  1.1361e-01, -7.1515e-02, -1.7083e-01,\n",
              "                                     9.1075e-02,  2.0408e-01, -5.0962e-01, -1.1394e-01,\n",
              "                                    -2.9909e-01,  2.8352e-01, -1.7906e-01, -2.9662e-01,\n",
              "                                    -2.8801e-01, -1.0794e-01,  6.3769e-01, -1.7375e-02,\n",
              "                                     4.1914e-01,  4.2776e-01,  4.8492e-01,  7.1199e-03,\n",
              "                                    -5.2290e-02,  5.3358e-02,  2.5126e-01,  3.0127e-01,\n",
              "                                    -8.4680e-01,  3.3966e-01, -6.3387e-02, -4.8137e-01,\n",
              "                                     6.3565e-01, -5.0525e-01,  6.3987e-01, -6.2302e-02]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.downsample.1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.1453, 0.5332, 0.4218, 0.2881, 0.0630, 0.8265, 0.1924,\n",
              "                                    1.0640, 0.1319, 0.1392, 0.8001, 0.3924, 0.1325, 0.9066,\n",
              "                                    0.2879, 0.8904, 0.3980, 0.0710, 0.1033, 0.0545, 0.3387,\n",
              "                                    0.4560, 0.0296, 0.3941, 0.1392, 0.0567, 0.2698, 0.0736,\n",
              "                                    0.1482, 0.7138, 0.3603, 0.4015, 0.2762, 0.6113, 0.3511,\n",
              "                                    0.1328, 0.5543, 0.1147, 0.1765, 0.0423, 0.2192, 0.0420,\n",
              "                                    0.2523, 0.1295, 0.3375, 0.0230, 0.3144, 0.2040, 0.4215,\n",
              "                                    0.2034, 0.1150, 0.8692, 0.3964, 0.1754, 0.1415, 0.1201,\n",
              "                                    0.1757, 0.3285, 0.1365, 0.2418, 0.3686, 0.0730, 0.4827,\n",
              "                                    0.0347, 0.4264, 0.4166, 0.1966, 0.2114, 0.0783, 0.1112,\n",
              "                                    0.6316, 0.1080, 0.2474, 0.1330, 0.0965, 0.8349, 0.7265,\n",
              "                                    0.5647, 0.0431, 0.1757, 0.1840, 0.1474, 0.0127, 0.4325,\n",
              "                                    0.3326, 0.0477, 0.3157, 0.0632, 0.6596, 0.2181, 0.3158,\n",
              "                                    0.3013, 0.3979, 0.1665, 0.4183, 0.0458, 0.1642, 0.1920,\n",
              "                                    0.0549, 0.1936, 0.0844, 0.1393, 0.0593, 0.0278, 0.2760,\n",
              "                                    0.1981, 0.4509, 0.0880, 0.4318, 0.0984, 0.0751, 0.0578,\n",
              "                                    0.4849, 0.0214, 0.1077, 0.1014, 0.1109, 0.3691, 0.0215,\n",
              "                                    0.4128, 0.3722, 0.8602, 0.6047, 0.2575, 0.0887, 0.2604,\n",
              "                                    0.0216, 0.0129, 0.2193, 0.0576, 0.4798, 0.2039, 0.0695,\n",
              "                                    0.3033, 0.5753, 0.0641, 0.1291, 0.2591, 0.1594, 1.1609,\n",
              "                                    0.0912, 0.0582, 0.3146, 0.1857, 0.9741, 0.2833, 0.3315,\n",
              "                                    0.3015, 0.2939, 0.0503, 0.1241, 0.4016, 0.0960, 0.0751,\n",
              "                                    0.7530, 1.1505, 0.3437, 0.0412, 0.1185, 0.2701, 0.5407,\n",
              "                                    0.1222, 0.5864, 0.2091, 0.1889, 0.0459, 0.0228, 0.0556,\n",
              "                                    0.0680, 0.0287, 0.0348, 0.0924, 0.2176, 0.4227, 0.4591,\n",
              "                                    0.4839, 0.2643, 0.1016, 0.1935, 0.0972, 0.2093, 0.3934,\n",
              "                                    0.0125, 0.0151, 0.0432, 0.1055, 0.0908, 0.7801, 0.0797,\n",
              "                                    0.0390, 0.1523, 0.1165, 0.3123, 0.2099, 0.0641, 0.1152,\n",
              "                                    0.5231, 0.2707, 0.7124, 0.1091, 0.8164, 1.3588, 0.5951,\n",
              "                                    0.3937, 0.0450, 0.5930, 0.0371, 0.2707, 0.2615, 0.2366,\n",
              "                                    0.2042, 0.3308, 0.3136, 0.0232, 1.1406, 0.0727, 0.0438,\n",
              "                                    0.3110, 0.1765, 0.2458, 0.2361, 0.4049, 0.3157, 0.1546,\n",
              "                                    0.1647, 0.2811, 0.1630, 0.0370, 0.2094, 0.2199, 0.3949,\n",
              "                                    0.2603, 0.1260, 0.3085, 0.0872, 0.5376, 0.4350, 0.0386,\n",
              "                                    0.7934, 0.0131, 0.0564, 0.0556, 0.6479, 0.1301, 0.4311,\n",
              "                                    0.1711, 0.0558, 0.1067, 0.0574, 0.1077, 0.0751, 0.9059,\n",
              "                                    0.4535, 0.2323, 0.1497, 0.0810]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.0.downsample.1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ...,  63,  63,  63],\n",
              "                                     [  1,   2,   3,  ..., 253, 254, 255],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.0618, -0.3412, -0.0893,  ..., -0.1034,  0.0905,\n",
              "                                    -0.2239]),\n",
              "                     size=(64, 256, 1, 1), nnz=14609, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn1.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([0.9949, 0.9945, 1.0048, 1.0223, 0.9959, 1.0035, 0.9612,\n",
              "                                    0.9882, 1.0104, 0.9814, 0.9815, 0.9968, 1.0086, 1.0083,\n",
              "                                    0.9889, 1.0175, 0.9888, 0.9957, 1.0284, 1.0235, 1.0030,\n",
              "                                    1.0022, 1.0061, 1.0115, 0.9947, 1.0118, 1.0021, 1.0040,\n",
              "                                    0.9933, 1.0050, 1.0153, 1.0056, 1.0135, 0.9992, 0.9727,\n",
              "                                    0.9794, 0.9977, 0.9893, 0.9902, 0.9855, 1.0122, 0.9968,\n",
              "                                    0.9883, 0.9953, 0.9833, 1.0007, 0.9858, 1.0031, 0.9913,\n",
              "                                    0.9946, 1.0045, 1.0084, 1.0036, 1.0000, 1.0139, 1.0088,\n",
              "                                    0.9866, 1.0059, 1.0128, 0.9976, 1.0115, 1.0109, 1.0183,\n",
              "                                    0.9883]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn1.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 5.5816e-03, -1.7941e-02,  1.4631e-02,  1.6745e-02,\n",
              "                                    -6.1434e-03, -8.9311e-03, -1.2286e-02, -1.7486e-02,\n",
              "                                    -1.4882e-03, -1.4606e-02, -3.2389e-03,  3.1451e-03,\n",
              "                                     6.3107e-03,  1.1843e-02,  1.2343e-02,  1.3860e-02,\n",
              "                                    -5.7810e-03, -1.2544e-02,  1.4893e-02,  1.0413e-02,\n",
              "                                    -1.4812e-03, -5.1551e-03,  1.2074e-02,  1.2602e-02,\n",
              "                                    -4.6525e-03,  5.6193e-03, -1.5584e-05, -5.0267e-04,\n",
              "                                    -6.3572e-03,  9.7408e-03,  8.3106e-03,  1.2626e-02,\n",
              "                                     5.5636e-04, -1.1737e-02, -2.1160e-02, -2.2429e-03,\n",
              "                                    -3.1851e-03, -1.7119e-02, -3.2169e-03,  5.2091e-03,\n",
              "                                     2.8512e-02,  3.9412e-03, -1.1725e-02,  6.0168e-03,\n",
              "                                    -2.6142e-03,  1.2898e-03, -1.2729e-02, -4.5835e-03,\n",
              "                                     6.7729e-04, -9.2230e-03,  1.2409e-02, -1.9702e-03,\n",
              "                                     8.5155e-03,  5.4957e-05,  1.8004e-03,  9.6762e-03,\n",
              "                                    -3.5654e-03,  1.0735e-03,  3.6705e-04, -1.2590e-02,\n",
              "                                    -3.8462e-03,  1.8376e-02,  2.4401e-02, -1.1081e-02]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn1.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([-1.0517,  1.3728,  0.5403,  1.6445, -1.1011, -0.3067,\n",
              "                                    -1.2990, -0.7468, -0.8406,  2.4106, -1.4761,  2.0470,\n",
              "                                    -1.4530, -3.0774,  1.7653,  1.9227,  0.2992,  1.5337,\n",
              "                                    -0.8668, -0.6650, -0.0699, -0.1690, -0.6694,  0.7611,\n",
              "                                    -0.6736, -3.3196,  0.4614, -1.6264,  1.5090,  0.5458,\n",
              "                                    -0.7406,  3.1612,  1.6762,  0.1480,  1.1240, -0.2938,\n",
              "                                    -1.2473,  1.3008,  0.0518, -1.5839,  1.0592,  1.0871,\n",
              "                                     0.1108, -2.2738, -2.0320, -0.9089,  1.7051, -0.5040,\n",
              "                                    -0.0436, -0.9018,  0.3892,  0.4293,  0.4455, -2.7778,\n",
              "                                     1.0046,  1.3773, -0.3020,  2.2351,  0.2464, -1.8843,\n",
              "                                    -1.8145, -1.1686, -0.9558,  1.0590]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn1.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 9.6636,  6.0246, 12.2502,  9.0822,  8.6220, 11.5182,\n",
              "                                     3.4830,  4.0895,  5.2145,  6.7378,  6.6049, 14.5898,\n",
              "                                     5.8004, 18.5866,  3.6288, 10.1504, 11.2437, 27.1570,\n",
              "                                     6.3227,  8.0017,  2.8505, 27.0522, 35.9629, 10.9421,\n",
              "                                     7.6138, 18.0429,  8.4888,  8.4609,  7.8752,  7.7232,\n",
              "                                    11.4783, 23.1982, 11.7573, 14.1144,  3.3766,  4.0045,\n",
              "                                     4.9860,  9.4755,  9.2030, 11.3859, 16.5358,  8.4949,\n",
              "                                     6.3909, 13.0604,  9.3542, 20.1613,  6.4622,  7.4122,\n",
              "                                     3.3313,  7.8702,  3.1480,  8.4253, 11.9907,  2.8059,\n",
              "                                     5.1080, 20.1859, 15.5352, 16.6386, 15.2854, 17.2378,\n",
              "                                    12.3747, 13.3625,  7.7175, 10.7418]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.conv2.weight',\n",
              "              tensor(indices=tensor([[ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  1,  ...,  1,  2,  2],\n",
              "                                     [ 1,  2,  1,  ...,  2,  0,  1]]),\n",
              "                     values=tensor([-0.0560,  0.0248,  0.0362,  ...,  0.0618,  0.0373,\n",
              "                                    -0.0843]),\n",
              "                     size=(64, 64, 3, 3), nnz=25163, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn2.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([1.0144, 0.9994, 0.9995, 0.9929, 1.0079, 0.9961, 0.9998,\n",
              "                                    1.0099, 0.9963, 1.0025, 0.9935, 0.9924, 0.9998, 1.0106,\n",
              "                                    1.0136, 0.9973, 0.9927, 0.9934, 1.0200, 0.9889, 0.9763,\n",
              "                                    1.0166, 1.0145, 0.9648, 0.9981, 1.0005, 0.9902, 0.9892,\n",
              "                                    0.9820, 0.9906, 1.0063, 1.0133, 1.0156, 0.9920, 0.9974,\n",
              "                                    1.0032, 1.0020, 1.0001, 0.9881, 0.9973, 1.0095, 1.0021,\n",
              "                                    0.9936, 0.9824, 0.9973, 1.0182, 1.0285, 1.0156, 0.9935,\n",
              "                                    0.9903, 0.9974, 0.9954, 1.0203, 0.9932, 1.0140, 0.9801,\n",
              "                                    1.0292, 1.0041, 1.0023, 1.0077, 0.9881, 0.9983, 1.0007,\n",
              "                                    0.9952]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn2.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.0062, -0.0070,  0.0014, -0.0034, -0.0060,  0.0046,\n",
              "                                    -0.0052,  0.0098, -0.0074,  0.0008,  0.0175, -0.0107,\n",
              "                                    -0.0088,  0.0026,  0.0020, -0.0032, -0.0030, -0.0314,\n",
              "                                     0.0029, -0.0095, -0.0102,  0.0139,  0.0043, -0.0129,\n",
              "                                    -0.0118,  0.0199, -0.0039,  0.0023, -0.0088,  0.0106,\n",
              "                                    -0.0070,  0.0016,  0.0089, -0.0086,  0.0097, -0.0017,\n",
              "                                     0.0108, -0.0014, -0.0079, -0.0068,  0.0061,  0.0144,\n",
              "                                    -0.0080, -0.0258,  0.0034,  0.0094,  0.0193,  0.0029,\n",
              "                                     0.0089,  0.0119,  0.0050, -0.0056, -0.0011,  0.0040,\n",
              "                                     0.0207, -0.0153,  0.0168,  0.0035,  0.0008,  0.0025,\n",
              "                                    -0.0236, -0.0018,  0.0061,  0.0083]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn2.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([-0.9291, -0.4045,  0.9464, -0.6265,  1.5558,  0.5125,\n",
              "                                    -0.4268,  0.4967,  0.1086, -0.3370,  0.8995,  0.5198,\n",
              "                                    -0.9053, -0.3195,  0.5139, -1.0316,  0.0092,  0.8296,\n",
              "                                    -0.2794,  0.2709, -0.8010,  0.1605,  0.7733,  0.4875,\n",
              "                                     0.3899,  0.1714,  0.6620, -0.1972, -0.5257,  0.6758,\n",
              "                                     1.4126,  0.0328, -0.4558, -0.1461, -0.4835, -0.3497,\n",
              "                                    -0.6451, -0.2272,  0.6987, -0.6648, -0.3574, -0.0697,\n",
              "                                     0.8364, -0.0537,  0.5032, -0.7925, -0.6359,  0.1836,\n",
              "                                     0.6991, -0.2073,  1.0776,  1.2396,  1.3683, -1.2796,\n",
              "                                     0.0634, -1.1116,  0.6171, -0.2343,  0.6668,  0.0268,\n",
              "                                     0.8604, -0.4189, -1.3621, -0.4998]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn2.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([1.5775, 2.2427, 3.0599, 1.0361, 3.7611, 2.3274, 1.7554,\n",
              "                                    5.3916, 1.6682, 2.0920, 6.0450, 0.5456, 2.2962, 0.9326,\n",
              "                                    2.9261, 2.0534, 1.6580, 1.7366, 2.0421, 3.7558, 1.1614,\n",
              "                                    1.0615, 1.6152, 4.6267, 3.2807, 3.6450, 0.8681, 1.5354,\n",
              "                                    2.2716, 2.9855, 4.2681, 1.7180, 1.9063, 1.6479, 0.8265,\n",
              "                                    3.7787, 1.2548, 1.5992, 2.6835, 1.7765, 3.4401, 1.2670,\n",
              "                                    4.8486, 1.9845, 2.3078, 1.1716, 3.5860, 2.2342, 3.1679,\n",
              "                                    1.8851, 2.0776, 1.6831, 5.8840, 3.2044, 4.2355, 0.8666,\n",
              "                                    1.8082, 2.6597, 1.1266, 1.9235, 2.8173, 2.9543, 5.1762,\n",
              "                                    1.4302]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  2,   3,   4,  ...,  60,  61,  62],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.1304,  0.1293, -0.1181,  ...,  0.0335,  0.0566,\n",
              "                                     0.0760]),\n",
              "                     size=(256, 64, 1, 1), nnz=12887, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9955, 0.9912, 0.9866, 1.0017, 1.0020, 1.0017, 0.9742,\n",
              "                                    1.0003, 0.9872, 0.9833, 0.9980, 0.9952, 1.0075, 0.9963,\n",
              "                                    0.9966, 1.0066, 0.9999, 1.0084, 0.9862, 0.9840, 0.9983,\n",
              "                                    0.9972, 0.9983, 0.9973, 1.0030, 1.0057, 0.9975, 0.9934,\n",
              "                                    0.9980, 1.0011, 1.0011, 1.0091, 1.0079, 0.9999, 1.0031,\n",
              "                                    0.9932, 1.0043, 1.0020, 0.9904, 1.0045, 1.0057, 1.0032,\n",
              "                                    0.9943, 0.9965, 0.9929, 0.9822, 1.0035, 1.0052, 1.0075,\n",
              "                                    1.0001, 0.9761, 0.9916, 0.9966, 1.0060, 1.0059, 1.0005,\n",
              "                                    0.9931, 0.9814, 0.9892, 1.0137, 0.9900, 0.9822, 1.0039,\n",
              "                                    1.0115, 0.9854, 0.9976, 0.9949, 0.9951, 1.0020, 0.9816,\n",
              "                                    0.9951, 0.9699, 0.9816, 0.9986, 0.9813, 0.9847, 0.9928,\n",
              "                                    1.0055, 1.0037, 0.9949, 1.0015, 0.9875, 0.9794, 0.9952,\n",
              "                                    1.0006, 0.9992, 0.9892, 0.9903, 0.9915, 0.9878, 0.9855,\n",
              "                                    0.9954, 1.0059, 1.0131, 1.0027, 0.9971, 0.9797, 1.0082,\n",
              "                                    0.9917, 1.0078, 0.9907, 1.0040, 1.0074, 0.9860, 1.0363,\n",
              "                                    1.0058, 1.0157, 1.0037, 0.9891, 1.0281, 0.9674, 0.9808,\n",
              "                                    1.0038, 0.9909, 0.9979, 0.9958, 0.9927, 0.9849, 0.9901,\n",
              "                                    0.9942, 0.9916, 1.0000, 0.9924, 1.0185, 0.9908, 0.9885,\n",
              "                                    0.9737, 1.0041, 0.9895, 0.9993, 0.9858, 1.0057, 1.0123,\n",
              "                                    0.9891, 1.0049, 0.9974, 1.0015, 0.9940, 1.0080, 1.0118,\n",
              "                                    0.9928, 0.9952, 1.0046, 1.0000, 0.9956, 0.9872, 0.9928,\n",
              "                                    0.9939, 1.0083, 0.9879, 0.9826, 0.9927, 0.9761, 0.9811,\n",
              "                                    1.0005, 1.0070, 0.9932, 0.9958, 1.0003, 0.9791, 1.0052,\n",
              "                                    1.0092, 0.9867, 0.9949, 0.9952, 1.0049, 0.9940, 1.0103,\n",
              "                                    1.0136, 1.0184, 0.9865, 1.0165, 0.9987, 1.0004, 1.0011,\n",
              "                                    1.0104, 1.0182, 1.0098, 1.0183, 0.9987, 1.0118, 0.9951,\n",
              "                                    1.0258, 0.9891, 0.9745, 0.9966, 0.9927, 0.9938, 1.0044,\n",
              "                                    1.0004, 1.0075, 1.0005, 1.0225, 0.9987, 0.9927, 1.0098,\n",
              "                                    0.9974, 0.9998, 0.9995, 1.0001, 0.9903, 0.9984, 1.0132,\n",
              "                                    0.9965, 0.9958, 0.9946, 0.9910, 0.9969, 1.0127, 0.9932,\n",
              "                                    1.0095, 1.0020, 1.0232, 1.0001, 1.0018, 1.0064, 1.0095,\n",
              "                                    0.9943, 1.0118, 0.9860, 0.9884, 0.9985, 0.9945, 0.9943,\n",
              "                                    1.0095, 0.9865, 1.0135, 1.0137, 1.0008, 0.9846, 1.0153,\n",
              "                                    0.9867, 1.0034, 0.9835, 0.9845, 1.0115, 0.9825, 0.9966,\n",
              "                                    0.9983, 1.0082, 0.9935, 0.9869, 0.9960, 1.0068, 1.0010,\n",
              "                                    1.0146, 0.9885, 0.9783, 0.9912, 1.0049, 0.9955, 1.0226,\n",
              "                                    0.9851, 1.0013, 0.9979, 1.0096]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 1.2190e-03,  9.8780e-03,  1.4330e-02,  1.2752e-02,\n",
              "                                    -8.4611e-03,  1.2269e-02,  8.5898e-03,  6.2586e-04,\n",
              "                                    -1.0728e-02, -1.4442e-02, -6.6957e-03,  8.5157e-03,\n",
              "                                     1.7712e-03,  2.3337e-03,  5.1783e-03,  1.1499e-02,\n",
              "                                     4.2874e-04, -6.6170e-03, -7.5292e-04,  4.1587e-03,\n",
              "                                    -4.2545e-03, -1.6497e-02, -1.9154e-02,  3.9173e-03,\n",
              "                                     4.3676e-03,  2.0598e-02,  1.4729e-02, -2.2684e-03,\n",
              "                                    -2.2732e-03,  1.3784e-02,  7.3465e-03,  1.2634e-02,\n",
              "                                     2.9048e-03, -1.5987e-03, -6.3035e-03,  4.7758e-04,\n",
              "                                     4.4857e-03, -4.5334e-03, -8.5447e-03, -7.7271e-03,\n",
              "                                     4.1667e-03, -5.6600e-03,  9.4793e-03, -1.1099e-02,\n",
              "                                     2.9221e-03, -4.9999e-03, -2.4784e-02, -5.7069e-03,\n",
              "                                     2.7614e-03, -1.1708e-02, -6.2825e-03,  4.1337e-03,\n",
              "                                    -9.5755e-04,  1.8843e-02,  5.3859e-03, -1.0228e-03,\n",
              "                                     1.1311e-02,  1.9726e-02,  7.3277e-03,  9.6553e-03,\n",
              "                                     1.2698e-02, -1.7394e-02, -1.7464e-03,  7.5857e-03,\n",
              "                                     1.0612e-02,  7.0257e-04,  2.9585e-03,  8.5632e-03,\n",
              "                                     1.3645e-02, -1.7038e-02, -1.3185e-02,  5.2913e-04,\n",
              "                                     4.9269e-03,  4.9232e-03,  6.7701e-03,  1.8018e-02,\n",
              "                                    -9.3352e-03,  4.3321e-03,  1.6042e-02,  3.1029e-03,\n",
              "                                    -1.5902e-02, -1.8192e-02,  2.1115e-02, -6.2550e-03,\n",
              "                                     7.7379e-03,  4.0060e-03,  4.7547e-03, -8.3614e-03,\n",
              "                                    -1.9167e-02,  4.9416e-04,  1.5374e-02,  1.3828e-03,\n",
              "                                    -3.6658e-03,  1.3261e-02,  4.8617e-03, -1.9472e-02,\n",
              "                                    -4.5598e-03, -1.1312e-04,  1.4177e-02,  1.0247e-02,\n",
              "                                    -6.4285e-03,  1.6810e-02,  1.4724e-02,  7.0427e-03,\n",
              "                                    -2.5813e-03, -2.6483e-03,  8.2785e-03, -1.0996e-02,\n",
              "                                    -2.5366e-04,  1.2711e-02,  2.1506e-02, -2.2926e-02,\n",
              "                                    -1.1329e-02, -3.4645e-03,  1.7888e-02,  9.4398e-03,\n",
              "                                     1.4120e-02, -1.5548e-03,  5.2734e-03, -5.9564e-03,\n",
              "                                     8.6996e-03,  1.2950e-02,  4.9820e-03, -5.8616e-03,\n",
              "                                     2.4728e-03, -1.2870e-02, -3.6551e-03,  4.3125e-04,\n",
              "                                     1.1885e-02,  5.6838e-03, -2.4066e-03,  2.5368e-04,\n",
              "                                     1.2500e-02,  5.9873e-03,  1.8038e-02, -7.4553e-03,\n",
              "                                    -2.1349e-03, -1.4488e-02,  1.1023e-02,  1.2800e-02,\n",
              "                                     1.8812e-02, -1.1475e-02,  3.1610e-03, -1.4591e-02,\n",
              "                                    -1.0586e-02, -6.2062e-03,  5.7360e-03, -1.0125e-02,\n",
              "                                     1.9018e-02, -8.0176e-03, -1.2127e-03, -1.4240e-02,\n",
              "                                    -1.7422e-02, -2.2412e-03,  5.7330e-03,  1.9961e-02,\n",
              "                                    -8.0415e-03,  1.3347e-02, -7.2399e-03, -2.1322e-02,\n",
              "                                    -8.3822e-03,  2.2188e-03, -1.5121e-03, -1.2514e-02,\n",
              "                                    -1.2581e-02, -2.6491e-03,  1.2217e-02, -2.7533e-03,\n",
              "                                     1.6467e-02,  4.5448e-03,  8.0725e-03,  4.7860e-03,\n",
              "                                    -6.6568e-03,  8.6533e-03,  3.9592e-03,  1.0058e-02,\n",
              "                                     9.7645e-03, -3.6170e-03,  2.7234e-02,  1.7483e-02,\n",
              "                                     6.5561e-03, -2.7646e-02,  1.1542e-03,  7.8958e-03,\n",
              "                                    -1.5340e-02,  3.1287e-02,  4.8175e-03,  4.8196e-03,\n",
              "                                     7.5411e-04,  1.5716e-03, -1.8278e-02, -1.4862e-02,\n",
              "                                     1.0133e-02,  5.1255e-03, -8.5200e-03, -1.6260e-02,\n",
              "                                     1.8753e-03, -4.2580e-03, -1.8608e-02, -1.5936e-02,\n",
              "                                     5.6717e-03,  3.4682e-03,  4.4327e-03,  2.2179e-03,\n",
              "                                    -4.8273e-03, -7.8018e-03, -3.1435e-03,  2.0383e-02,\n",
              "                                     9.9985e-03, -7.6542e-03, -3.0749e-03, -7.2968e-03,\n",
              "                                     7.7842e-03, -3.7337e-03, -2.1764e-02,  2.5512e-04,\n",
              "                                     2.7455e-02, -1.7959e-02,  1.6009e-02, -3.8327e-03,\n",
              "                                     1.8045e-02,  5.2858e-03,  8.2816e-03,  9.6610e-03,\n",
              "                                    -6.7668e-04, -7.1722e-03,  2.3761e-02,  4.8120e-03,\n",
              "                                    -2.1726e-03,  4.6235e-03, -7.3490e-03,  1.7644e-02,\n",
              "                                     1.3507e-03,  5.6978e-03, -1.4002e-02, -1.0009e-03,\n",
              "                                     7.6001e-03,  1.5387e-03,  1.9706e-03,  2.5060e-03,\n",
              "                                    -2.0464e-03,  5.7777e-04, -8.0744e-05,  4.2604e-03,\n",
              "                                     1.9187e-03,  4.1798e-03, -9.1360e-03,  2.2550e-02,\n",
              "                                     1.1851e-02, -7.5704e-03, -8.4285e-04,  1.0132e-02,\n",
              "                                     1.7665e-03, -9.6866e-03, -4.7482e-03,  4.6621e-03]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-8.8147e-02, -2.1052e-01, -2.4412e-01, -2.6150e-01,\n",
              "                                     2.4446e-02,  2.5770e-01,  1.5546e-01,  2.4733e-01,\n",
              "                                     1.2240e-01,  2.1207e-01,  3.0956e-01, -1.6494e-01,\n",
              "                                    -2.2612e-02, -1.4176e-02, -2.5498e-01,  5.8698e-01,\n",
              "                                     4.7721e-02, -2.8283e-01, -5.5378e-01, -4.4446e-02,\n",
              "                                    -2.5170e-01, -3.0374e-01, -1.2843e-01,  2.0302e-01,\n",
              "                                    -9.4325e-02,  1.9215e-01, -5.1716e-02,  2.1535e-01,\n",
              "                                    -2.9403e-01,  1.2318e-01,  5.0143e-02, -2.5397e-01,\n",
              "                                     1.8621e-01,  2.0536e-02,  1.2030e-01,  3.7685e-01,\n",
              "                                     1.1618e-01, -1.8083e-01, -2.6877e-01, -1.6493e-01,\n",
              "                                    -7.1483e-03,  2.2579e-01,  4.4917e-01, -1.0055e-04,\n",
              "                                    -2.3975e-01,  1.0725e-01,  1.8685e-01, -1.4041e-01,\n",
              "                                     6.5417e-02, -7.5419e-02, -1.4043e-01,  1.4287e-02,\n",
              "                                    -2.8402e-01, -4.1333e-02,  3.5418e-02,  2.8222e-01,\n",
              "                                    -1.6909e-02, -6.5776e-01, -9.2052e-02,  3.9896e-01,\n",
              "                                    -3.0845e-01,  2.3025e-03, -2.3115e-01,  4.1625e-01,\n",
              "                                    -1.7392e-01,  1.3928e-01,  1.3765e-01,  1.5524e-01,\n",
              "                                     1.5838e-04,  3.1865e-01,  2.4528e-01, -2.0534e-01,\n",
              "                                    -2.7636e-01, -1.0830e-02, -4.5978e-01,  3.1538e-02,\n",
              "                                     2.9449e-01, -2.5429e-01, -3.1274e-02, -5.2482e-02,\n",
              "                                    -1.6761e-02,  2.7394e-01, -2.4859e-02,  1.8802e-01,\n",
              "                                    -2.3250e-01,  2.9972e-01, -1.1876e-01, -4.8783e-01,\n",
              "                                     2.8036e-01, -2.2065e-01, -4.1544e-01, -3.2973e-01,\n",
              "                                     4.5175e-01, -4.6151e-02,  5.9931e-02,  1.9532e-01,\n",
              "                                    -2.2204e-01,  2.1369e-01,  4.8430e-02, -1.9332e-01,\n",
              "                                    -1.8603e-01,  1.3067e-01, -2.0066e-02,  2.0507e-01,\n",
              "                                     1.2850e-01, -1.8721e-01,  2.4332e-01,  8.5764e-02,\n",
              "                                     4.0021e-01, -3.2146e-01,  4.6333e-01, -3.0826e-01,\n",
              "                                     3.5681e-01,  8.0707e-02, -2.6627e-01,  3.5060e-01,\n",
              "                                     1.6323e-01,  1.6596e-01, -1.7088e-01, -3.3673e-01,\n",
              "                                     2.8453e-01,  3.6322e-01,  2.2309e-01, -2.3361e-01,\n",
              "                                     1.7033e-01, -4.7768e-02,  1.8058e-01, -2.0846e-01,\n",
              "                                    -1.7468e-01, -3.2939e-01,  2.3878e-01, -2.7340e-01,\n",
              "                                     1.2456e-01,  1.0252e-01, -2.1180e-01, -9.9479e-02,\n",
              "                                    -3.5964e-01, -1.1288e-02, -2.6510e-01,  1.6568e-01,\n",
              "                                     9.3366e-02, -1.1213e-01,  1.9526e-01, -3.5571e-02,\n",
              "                                     4.0837e-01,  1.1534e-01, -9.5099e-02,  2.2448e-01,\n",
              "                                     1.2114e-01, -5.6699e-01,  2.9507e-02, -6.6949e-02,\n",
              "                                    -1.2790e-01,  3.1943e-01, -1.1200e-01,  3.7638e-01,\n",
              "                                     1.7830e-01,  4.3576e-01, -4.5613e-02, -1.0755e-01,\n",
              "                                    -1.4869e-02, -2.2206e-01, -2.0322e-01, -2.8416e-01,\n",
              "                                     1.4291e-01, -4.2872e-01, -1.7204e-01, -5.3544e-02,\n",
              "                                     1.2969e-01,  2.9199e-02, -3.8336e-02,  1.9222e-01,\n",
              "                                     4.1205e-01, -3.6044e-01,  1.1024e-02, -2.8381e-01,\n",
              "                                     1.5942e-01, -3.5993e-01, -2.0219e-01, -2.8889e-01,\n",
              "                                     3.5058e-01,  2.3451e-01,  4.8297e-01,  2.5171e-02,\n",
              "                                    -4.4679e-01, -1.7043e-01, -4.1848e-02, -3.5986e-01,\n",
              "                                     2.5341e-01,  1.8660e-01,  2.6416e-01, -1.5226e-01,\n",
              "                                    -1.9772e-01, -6.1413e-01, -5.6609e-01,  6.7901e-02,\n",
              "                                     3.3487e-01, -6.6359e-02, -2.5107e-02,  4.1309e-01,\n",
              "                                     2.4330e-02,  4.1859e-01,  4.8311e-01,  9.2790e-03,\n",
              "                                    -8.9557e-02, -1.9704e-01, -3.4391e-02,  7.3963e-02,\n",
              "                                     5.1633e-01, -1.0558e-01,  1.5025e-01, -4.0034e-01,\n",
              "                                     1.3417e-01,  1.8119e-01,  1.9032e-01, -2.3060e-01,\n",
              "                                     2.6641e-01,  2.6458e-01,  3.6615e-01,  5.7286e-02,\n",
              "                                     1.3873e-01,  2.3038e-01, -8.2927e-02,  2.3474e-01,\n",
              "                                     7.9196e-02,  3.3177e-01,  1.8703e-01, -3.8009e-01,\n",
              "                                     6.3327e-02, -5.2025e-01,  2.0439e-01,  7.2636e-01,\n",
              "                                     1.0950e-01, -1.5115e-01, -3.5415e-01, -5.8527e-01,\n",
              "                                    -4.5661e-03, -4.4611e-01, -5.7910e-01,  3.0719e-01,\n",
              "                                    -1.7501e-02,  3.5917e-01,  1.1910e-01, -1.0455e-01,\n",
              "                                     6.5150e-01,  3.9362e-02, -4.8654e-02,  8.9894e-02,\n",
              "                                    -2.1493e-01, -1.3122e-01, -1.7427e-01, -1.4515e-01,\n",
              "                                    -4.1000e-01,  3.7483e-03,  5.4166e-02,  1.9599e-01]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.0449, 0.1806, 0.1773, 0.2862, 0.2038, 0.3356, 0.2962,\n",
              "                                    0.1120, 0.0587, 0.8998, 0.3424, 0.4822, 0.1499, 0.4038,\n",
              "                                    0.1669, 1.3394, 0.2616, 0.3327, 0.5949, 0.3299, 0.1368,\n",
              "                                    0.0507, 0.1122, 0.2279, 0.1851, 0.1535, 0.3026, 0.6340,\n",
              "                                    0.2987, 0.1258, 0.1938, 0.7622, 0.1823, 0.4027, 0.1365,\n",
              "                                    0.3563, 0.3748, 0.1505, 0.1119, 0.2364, 0.2972, 0.1054,\n",
              "                                    0.7930, 0.4129, 0.3380, 0.1519, 0.4070, 0.2039, 0.1624,\n",
              "                                    0.1149, 0.2087, 0.1467, 0.7155, 0.1512, 0.1841, 0.3974,\n",
              "                                    0.1515, 0.3615, 0.1581, 0.5687, 0.2085, 0.0804, 0.4501,\n",
              "                                    0.2316, 0.1899, 0.1322, 0.1654, 0.3505, 0.3395, 0.4187,\n",
              "                                    0.2303, 0.1399, 0.1324, 0.3456, 0.4170, 0.2538, 0.2924,\n",
              "                                    0.3866, 0.2282, 0.2686, 0.1492, 0.0894, 0.3454, 0.1493,\n",
              "                                    0.2491, 0.2111, 0.1677, 0.5972, 0.1945, 0.4139, 0.0674,\n",
              "                                    0.1527, 0.7568, 0.1880, 0.2444, 0.1703, 0.2746, 0.0936,\n",
              "                                    0.3515, 0.1447, 0.3614, 0.2625, 0.2114, 0.4894, 0.2320,\n",
              "                                    0.2000, 0.2168, 0.0997, 0.2543, 0.1856, 0.2819, 0.6131,\n",
              "                                    0.1107, 0.1601, 0.4969, 0.0987, 0.3792, 0.3243, 0.0797,\n",
              "                                    0.5188, 0.1465, 0.4633, 0.1219, 0.4448, 0.2064, 0.0838,\n",
              "                                    0.2603, 0.1647, 0.1383, 0.1527, 0.3050, 0.2252, 0.1688,\n",
              "                                    0.1235, 0.1361, 0.2001, 0.2396, 0.2199, 0.0920, 0.2176,\n",
              "                                    0.6188, 0.4578, 0.1130, 0.3095, 0.0667, 0.2464, 0.2654,\n",
              "                                    0.3550, 0.7412, 0.5435, 0.5503, 0.5545, 0.1922, 0.2545,\n",
              "                                    0.4143, 0.2434, 0.1367, 0.2496, 0.1476, 0.2054, 0.2018,\n",
              "                                    0.2450, 0.3043, 0.2422, 0.2720, 0.1176, 0.2732, 0.1050,\n",
              "                                    0.3477, 0.0756, 0.1527, 0.3215, 0.1370, 0.2053, 0.0931,\n",
              "                                    0.3146, 0.1110, 0.2867, 0.1468, 0.1025, 0.3612, 0.2643,\n",
              "                                    0.2300, 0.3314, 0.1780, 0.2360, 0.4204, 0.4890, 0.2143,\n",
              "                                    0.1744, 0.3614, 0.1333, 0.2096, 0.2789, 0.6960, 0.3359,\n",
              "                                    0.2915, 0.3412, 0.1261, 0.3852, 0.1401, 0.1297, 0.5599,\n",
              "                                    0.4643, 0.2390, 0.1649, 0.2378, 0.0938, 0.5102, 0.2891,\n",
              "                                    0.2025, 0.2428, 0.1647, 0.3924, 0.2416, 0.1422, 0.1568,\n",
              "                                    0.1339, 0.4187, 0.1173, 0.2499, 0.2350, 0.3503, 0.2526,\n",
              "                                    0.1533, 0.3329, 0.3373, 0.1884, 0.1256, 0.3005, 0.1720,\n",
              "                                    0.7463, 0.1819, 0.2668, 0.0871, 0.1545, 0.2724, 0.1929,\n",
              "                                    0.6546, 0.3161, 0.1721, 0.3768, 0.1137, 0.2265, 0.4144,\n",
              "                                    0.1815, 0.2566, 0.3028, 0.1203, 0.1357, 0.2282, 0.1839,\n",
              "                                    0.4319, 0.2875, 0.1562, 0.2961]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.1.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ...,  63,  63,  63],\n",
              "                                     [  0,   1,   2,  ..., 253, 254, 255],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.1433, -0.1719,  0.0086,  ..., -0.2350, -0.1345,\n",
              "                                    -0.1451]),\n",
              "                     size=(64, 256, 1, 1), nnz=16384, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn1.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([0.9747, 1.0043, 0.9946, 1.0000, 0.9990, 0.9943, 0.9940,\n",
              "                                    0.9940, 0.9965, 0.9873, 1.0116, 0.9864, 1.0019, 1.0076,\n",
              "                                    0.9762, 0.9900, 0.9883, 1.0185, 1.0014, 1.0020, 0.9965,\n",
              "                                    0.9935, 0.9949, 0.9850, 1.0117, 1.0005, 0.9888, 0.9807,\n",
              "                                    1.0224, 0.9926, 1.0037, 0.9944, 1.0083, 0.9946, 1.0025,\n",
              "                                    1.0050, 0.9919, 1.0109, 1.0104, 0.9948, 0.9854, 1.0045,\n",
              "                                    0.9994, 1.0073, 1.0077, 1.0071, 0.9994, 1.0111, 0.9949,\n",
              "                                    1.0136, 0.9787, 1.0212, 0.9928, 0.9964, 1.0032, 1.0146,\n",
              "                                    0.9690, 1.0169, 0.9999, 1.0083, 0.9914, 1.0199, 0.9909,\n",
              "                                    0.9993]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn1.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.0005,  0.0097,  0.0111,  0.0168, -0.0020,  0.0015,\n",
              "                                     0.0051,  0.0029, -0.0048, -0.0169,  0.0200, -0.0141,\n",
              "                                    -0.0059,  0.0076, -0.0082, -0.0141,  0.0007,  0.0128,\n",
              "                                    -0.0206, -0.0041, -0.0074, -0.0030,  0.0066, -0.0126,\n",
              "                                     0.0070,  0.0055, -0.0027,  0.0020, -0.0003, -0.0030,\n",
              "                                     0.0015, -0.0047,  0.0097, -0.0054,  0.0042,  0.0031,\n",
              "                                     0.0056,  0.0145, -0.0091,  0.0119, -0.0023,  0.0092,\n",
              "                                     0.0143,  0.0016, -0.0025,  0.0183,  0.0118, -0.0006,\n",
              "                                     0.0034,  0.0149, -0.0143,  0.0015, -0.0045,  0.0047,\n",
              "                                     0.0069,  0.0049, -0.0137, -0.0019,  0.0155,  0.0080,\n",
              "                                    -0.0164,  0.0091,  0.0005,  0.0036]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn1.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.9547, -1.0056, -0.0857, -3.0207, -1.5309, -2.4362,\n",
              "                                    -2.8543,  2.5399,  0.2559, -2.3385, -0.0666, -2.3431,\n",
              "                                     0.7515,  1.1865, -2.5247,  0.0916,  1.0559,  2.1082,\n",
              "                                    -1.1177, -1.5090, -1.3615, -2.4642,  3.5721, -0.0639,\n",
              "                                    -0.0279, -0.0836, -4.1944, -3.9060,  0.8323, -4.6115,\n",
              "                                    -1.9127, -2.0426,  2.0820,  1.2125,  1.1039, -1.7368,\n",
              "                                    -1.0284, -0.6723, -1.7052, -0.6374, -0.6268, -0.5843,\n",
              "                                     2.2327, -3.7094,  1.2824,  1.5559, -1.0055,  0.0215,\n",
              "                                     0.8931,  1.7131,  2.8434,  1.4563,  0.1060, -1.2715,\n",
              "                                     1.6958,  0.7880, -1.0092, -0.2642, -0.9453, -0.7213,\n",
              "                                     2.2419,  1.1258,  1.5659, -4.8518]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn1.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([12.5935, 15.2029,  8.8443, 20.6010, 14.7958, 34.6743,\n",
              "                                    18.9769, 13.3426,  9.6510, 19.2872, 50.1489, 22.5819,\n",
              "                                    11.7307, 18.1053,  6.1212, 11.3214, 16.2136, 14.3833,\n",
              "                                    17.0698, 13.0791,  9.3743, 13.8263, 18.4953, 11.8595,\n",
              "                                    13.2688,  5.8227, 16.8238, 27.3204, 11.9222, 14.2086,\n",
              "                                     8.8908, 17.0852, 23.0967, 11.7050, 11.4411,  5.6034,\n",
              "                                    13.9374, 11.5280, 14.9574, 25.4001, 18.5759,  9.3965,\n",
              "                                    35.3873, 12.3643, 11.5468, 25.9103, 11.6815, 16.3254,\n",
              "                                    10.2434, 15.1326,  7.9099, 21.1882,  8.1156, 12.1907,\n",
              "                                    14.1190, 19.4778, 12.1583, 13.6345, 13.3052, 15.0879,\n",
              "                                    21.7619, 15.4241, 10.6674, 21.0096]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.conv2.weight',\n",
              "              tensor(indices=tensor([[ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  0,  ..., 63, 63, 63],\n",
              "                                     [ 0,  0,  0,  ...,  2,  2,  2],\n",
              "                                     [ 0,  1,  2,  ...,  0,  1,  2]]),\n",
              "                     values=tensor([-0.0027,  0.0258, -0.0650,  ...,  0.1239, -0.1012,\n",
              "                                    -0.1623]),\n",
              "                     size=(64, 64, 3, 3), nnz=36864, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn2.weight',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([0.9917, 1.0134, 0.9954, 0.9824, 1.0132, 1.0145, 1.0077,\n",
              "                                    1.0063, 1.0017, 1.0106, 0.9843, 1.0138, 1.0018, 1.0011,\n",
              "                                    1.0019, 1.0219, 0.9895, 0.9912, 0.9769, 0.9834, 1.0081,\n",
              "                                    1.0049, 0.9965, 1.0012, 1.0148, 1.0030, 0.9851, 0.9852,\n",
              "                                    1.0116, 1.0174, 1.0087, 0.9876, 1.0122, 0.9972, 0.9881,\n",
              "                                    1.0135, 0.9937, 0.9859, 0.9979, 1.0043, 1.0051, 1.0002,\n",
              "                                    0.9713, 0.9957, 1.0180, 1.0053, 0.9951, 1.0060, 1.0090,\n",
              "                                    0.9837, 0.9747, 1.0015, 0.9955, 0.9973, 0.9924, 0.9993,\n",
              "                                    0.9876, 0.9965, 1.0036, 1.0103, 1.0164, 0.9966, 0.9903,\n",
              "                                    1.0103]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn2.bias',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.0086, -0.0075,  0.0079, -0.0098,  0.0148, -0.0059,\n",
              "                                     0.0116,  0.0098, -0.0114,  0.0049, -0.0307,  0.0229,\n",
              "                                    -0.0066,  0.0005,  0.0091,  0.0023, -0.0097, -0.0201,\n",
              "                                    -0.0296, -0.0170,  0.0067,  0.0058,  0.0138, -0.0035,\n",
              "                                    -0.0007, -0.0128, -0.0002,  0.0058,  0.0410,  0.0150,\n",
              "                                     0.0077, -0.0139,  0.0007,  0.0004, -0.0124,  0.0060,\n",
              "                                    -0.0314, -0.0035,  0.0030,  0.0103, -0.0046, -0.0020,\n",
              "                                    -0.0086, -0.0143,  0.0180, -0.0055, -0.0095,  0.0017,\n",
              "                                     0.0036, -0.0130, -0.0167,  0.0124,  0.0086, -0.0119,\n",
              "                                    -0.0153,  0.0157, -0.0029,  0.0063,  0.0035,  0.0077,\n",
              "                                     0.0139,  0.0085, -0.0058, -0.0072]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn2.running_mean',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([ 0.7717,  0.5456, -0.4858,  0.0181,  1.2019,  0.0351,\n",
              "                                    -0.6705, -0.0621, -0.0138, -0.3478, -0.0943,  0.4055,\n",
              "                                    -1.1737, -0.1443,  0.0333,  0.4187, -0.8419, -0.4280,\n",
              "                                    -0.3910, -0.4343, -0.2916, -0.0832,  0.2611, -0.1644,\n",
              "                                     0.1314,  0.6915,  0.0541,  1.0544,  0.1644,  0.1073,\n",
              "                                    -0.3934, -0.5473, -0.6923, -0.9493, -0.3505,  0.3792,\n",
              "                                    -0.8719,  0.1582, -0.3008,  1.0605,  0.3846,  0.5212,\n",
              "                                    -0.3184,  0.3444, -0.7127,  0.3866, -0.2124,  0.5058,\n",
              "                                    -0.6299,  0.8176, -0.3563, -0.3520, -1.0611, -0.3818,\n",
              "                                     0.1936, -0.9605, -0.7237, -0.2909,  0.2368,  0.0432,\n",
              "                                    -0.1091,  0.4689, -0.0083,  0.1850]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn2.running_var',\n",
              "              tensor(indices=tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,\n",
              "                                      14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
              "                                      28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n",
              "                                      42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
              "                                      56, 57, 58, 59, 60, 61, 62, 63]]),\n",
              "                     values=tensor([2.2883, 1.4114, 1.5855, 1.2493, 4.1616, 3.0449, 3.4088,\n",
              "                                    1.3985, 1.1625, 1.2681, 1.1278, 2.6410, 2.3066, 1.6845,\n",
              "                                    1.0611, 0.8796, 3.9571, 1.6995, 3.0846, 2.0569, 1.7466,\n",
              "                                    3.3016, 4.7943, 1.9400, 1.3267, 1.2193, 1.9171, 4.5002,\n",
              "                                    2.2647, 1.3461, 2.7267, 0.6411, 0.9371, 2.5581, 1.7124,\n",
              "                                    1.7580, 0.9049, 1.1155, 1.4257, 3.4763, 0.8679, 1.8893,\n",
              "                                    1.3490, 1.8444, 2.4958, 1.6697, 1.8277, 1.4210, 1.7539,\n",
              "                                    3.4078, 3.1998, 1.3614, 2.5496, 1.3958, 2.1308, 1.7214,\n",
              "                                    1.3070, 1.0357, 1.4546, 1.7945, 3.1521, 1.8312, 1.8888,\n",
              "                                    1.9104]),\n",
              "                     size=(64,), nnz=64, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   1,   2,  ...,  61,  62,  63],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.0344, -0.1461, -0.1676,  ..., -0.0037,  0.0142,\n",
              "                                    -0.1135]),\n",
              "                     size=(256, 64, 1, 1), nnz=16384, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9852, 0.9939, 1.0055, 1.0034, 0.9810, 0.9803, 1.0119,\n",
              "                                    0.9736, 1.0039, 0.9861, 0.9965, 0.9990, 0.9938, 0.9940,\n",
              "                                    1.0178, 0.9665, 0.9864, 0.9987, 0.9942, 1.0014, 1.0202,\n",
              "                                    0.9697, 0.9833, 1.0060, 0.9905, 0.9975, 1.0153, 1.0015,\n",
              "                                    0.9740, 0.9914, 0.9993, 0.9868, 0.9869, 0.9984, 1.0072,\n",
              "                                    1.0088, 0.9961, 1.0118, 1.0085, 0.9981, 0.9843, 0.9960,\n",
              "                                    1.0060, 0.9992, 1.0072, 0.9932, 0.9990, 0.9727, 1.0050,\n",
              "                                    0.9952, 0.9948, 0.9983, 0.9919, 0.9723, 1.0111, 0.9835,\n",
              "                                    0.9812, 1.0057, 0.9915, 0.9885, 0.9881, 1.0095, 0.9766,\n",
              "                                    1.0000, 1.0044, 0.9890, 0.9793, 0.9989, 0.9795, 0.9984,\n",
              "                                    0.9961, 1.0116, 1.0044, 1.0036, 0.9920, 0.9866, 0.9940,\n",
              "                                    0.9977, 0.9985, 1.0071, 0.9946, 0.9865, 0.9713, 0.9981,\n",
              "                                    0.9793, 0.9995, 1.0211, 0.9945, 1.0138, 1.0114, 1.0144,\n",
              "                                    1.0239, 0.9917, 0.9834, 1.0040, 1.0148, 0.9870, 0.9904,\n",
              "                                    0.9868, 0.9966, 0.9977, 0.9861, 0.9947, 1.0188, 0.9960,\n",
              "                                    0.9818, 0.9890, 1.0045, 1.0080, 1.0027, 1.0049, 0.9997,\n",
              "                                    0.9964, 1.0167, 0.9815, 1.0060, 0.9904, 1.0050, 1.0073,\n",
              "                                    0.9922, 1.0039, 1.0073, 1.0009, 1.0022, 1.0174, 1.0003,\n",
              "                                    0.9876, 0.9820, 0.9915, 0.9946, 1.0188, 0.9775, 0.9841,\n",
              "                                    1.0025, 0.9839, 0.9894, 0.9939, 0.9979, 0.9973, 0.9886,\n",
              "                                    0.9649, 0.9967, 0.9902, 1.0000, 0.9917, 1.0091, 0.9767,\n",
              "                                    0.9944, 0.9986, 1.0164, 0.9940, 0.9984, 1.0118, 1.0027,\n",
              "                                    0.9935, 1.0014, 0.9882, 1.0025, 0.9952, 1.0043, 0.9895,\n",
              "                                    1.0006, 0.9838, 0.9793, 0.9975, 1.0066, 0.9817, 0.9910,\n",
              "                                    1.0103, 1.0050, 0.9852, 0.9838, 0.9963, 0.9941, 0.9975,\n",
              "                                    0.9860, 1.0004, 0.9865, 0.9858, 0.9903, 0.9757, 1.0028,\n",
              "                                    0.9971, 0.9869, 1.0081, 0.9836, 0.9925, 1.0246, 1.0325,\n",
              "                                    0.9729, 0.9948, 1.0070, 0.9883, 0.9984, 0.9978, 0.9950,\n",
              "                                    1.0226, 0.9982, 1.0197, 0.9956, 0.9981, 1.0031, 1.0082,\n",
              "                                    0.9914, 0.9883, 0.9845, 0.9823, 1.0041, 1.0160, 0.9767,\n",
              "                                    0.9855, 1.0012, 1.0031, 0.9990, 1.0173, 1.0112, 0.9851,\n",
              "                                    0.9856, 1.0077, 0.9843, 0.9994, 1.0167, 0.9971, 0.9839,\n",
              "                                    0.9875, 0.9833, 0.9929, 0.9754, 1.0060, 0.9871, 1.0025,\n",
              "                                    0.9906, 0.9970, 0.9972, 1.0136, 0.9958, 0.9719, 0.9966,\n",
              "                                    1.0088, 0.9940, 1.0190, 0.9956, 1.0028, 1.0116, 0.9815,\n",
              "                                    0.9648, 0.9917, 0.9942, 0.9916, 0.9840, 1.0110, 0.9941,\n",
              "                                    1.0141, 0.9799, 1.0056, 1.0001]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 1.0231e-02, -3.8495e-03,  2.1005e-02,  3.5854e-02,\n",
              "                                     5.4227e-03,  9.6789e-03,  2.7528e-03, -4.6607e-03,\n",
              "                                    -8.8116e-04,  1.7515e-02, -1.0726e-03,  8.0619e-03,\n",
              "                                    -2.7143e-03,  9.2282e-03, -6.4565e-03,  4.8623e-03,\n",
              "                                     2.2972e-03,  4.6120e-03, -6.8863e-03,  9.3364e-04,\n",
              "                                    -1.8613e-02, -1.5359e-02, -3.3059e-02,  3.8384e-03,\n",
              "                                    -1.7083e-03,  1.1857e-02,  5.5265e-03,  3.6448e-03,\n",
              "                                    -1.0260e-02, -8.6008e-03,  1.1491e-02,  5.7394e-03,\n",
              "                                     1.0147e-02, -2.2700e-02,  1.5754e-03, -4.1826e-03,\n",
              "                                     7.7116e-03,  4.6330e-03,  9.0513e-03, -1.7674e-02,\n",
              "                                    -2.6408e-03,  7.5665e-03,  1.3121e-02, -1.0927e-02,\n",
              "                                     6.0436e-03,  4.2079e-03, -9.4945e-04,  1.8609e-02,\n",
              "                                     9.4511e-03, -2.8910e-03,  3.6177e-03, -8.1907e-05,\n",
              "                                    -1.1036e-02,  8.5537e-03, -3.3241e-03,  2.5498e-03,\n",
              "                                     3.7635e-03,  1.0159e-02, -1.1763e-02,  8.4509e-03,\n",
              "                                     2.0592e-02, -1.2991e-02, -7.0545e-03,  2.4161e-02,\n",
              "                                     7.9800e-04, -8.3713e-03,  3.3944e-02,  5.2200e-03,\n",
              "                                     1.4490e-02, -1.7372e-02, -2.0267e-02,  6.0518e-03,\n",
              "                                     1.3469e-02, -8.7350e-03, -7.8102e-03,  1.1075e-02,\n",
              "                                    -8.5574e-03,  9.4983e-03, -2.7226e-03, -9.3908e-03,\n",
              "                                    -1.1803e-02, -1.8438e-02,  5.0786e-03,  1.7715e-04,\n",
              "                                     1.0467e-02,  3.7400e-03, -2.8736e-03, -1.2876e-02,\n",
              "                                    -1.2896e-02,  3.1003e-04,  6.4336e-03,  2.4726e-02,\n",
              "                                     1.3576e-02, -5.2831e-03,  6.2627e-04, -1.3917e-02,\n",
              "                                    -1.2184e-02,  1.1580e-02,  6.1539e-03,  6.3000e-03,\n",
              "                                    -1.9023e-03, -2.3275e-03,  7.8848e-03,  1.3716e-02,\n",
              "                                     1.3027e-02, -2.1506e-03,  4.0217e-03,  1.5600e-02,\n",
              "                                    -4.2728e-03, -3.9802e-03,  5.5525e-03, -1.5176e-02,\n",
              "                                    -1.5436e-02,  8.0413e-03, -4.2358e-03,  8.5813e-03,\n",
              "                                     2.0897e-02, -7.0477e-03,  4.0126e-03, -4.8094e-03,\n",
              "                                     3.9847e-04,  3.1023e-03,  1.2406e-02, -7.8790e-03,\n",
              "                                     6.1554e-03, -7.6777e-03,  8.0426e-03, -1.9798e-02,\n",
              "                                     2.1680e-03,  7.1692e-03,  4.1044e-03,  8.4157e-03,\n",
              "                                     1.5390e-03,  1.3282e-02, -2.7845e-04, -1.8438e-02,\n",
              "                                    -1.9918e-02, -1.8994e-02,  4.3294e-03, -1.1598e-03,\n",
              "                                     1.5237e-03, -1.6528e-02, -2.2912e-02,  7.9737e-03,\n",
              "                                     5.3148e-03, -1.4168e-02, -1.5176e-02,  4.0574e-03,\n",
              "                                     2.3362e-02, -1.6487e-03, -1.0090e-02, -2.7466e-02,\n",
              "                                    -8.4717e-03,  1.8703e-02,  8.8236e-03,  2.1787e-02,\n",
              "                                    -1.5914e-02,  2.9918e-03,  1.3816e-02, -1.6052e-02,\n",
              "                                     7.5096e-03, -9.8795e-03, -7.5666e-03, -1.4112e-03,\n",
              "                                    -4.7488e-04,  5.0739e-03, -1.3291e-02,  9.1242e-03,\n",
              "                                     1.0936e-02,  1.6286e-02, -8.8217e-04,  2.0975e-02,\n",
              "                                    -9.9992e-03,  8.0101e-03, -7.8471e-03, -6.6968e-03,\n",
              "                                     4.1338e-03, -3.1680e-03,  5.7579e-02, -1.6284e-03,\n",
              "                                    -2.3006e-03, -5.1839e-03, -5.4234e-03, -3.0714e-03,\n",
              "                                    -7.7060e-03,  1.3513e-02, -6.1724e-03,  3.5665e-03,\n",
              "                                    -1.2145e-04, -8.3867e-03, -1.0433e-02, -2.2120e-02,\n",
              "                                     8.9510e-03,  2.0059e-02, -5.1064e-03, -1.7724e-02,\n",
              "                                     1.7713e-02,  1.0151e-03, -1.4986e-02, -7.1967e-03,\n",
              "                                     9.8923e-03, -6.7591e-03,  1.1495e-03,  5.4644e-03,\n",
              "                                     8.7612e-03, -1.2357e-03,  1.4045e-03,  1.5000e-02,\n",
              "                                     1.4740e-02, -1.6823e-02,  7.3050e-03, -2.0304e-03,\n",
              "                                     2.3952e-03, -1.5678e-02, -3.0383e-02, -5.2158e-03,\n",
              "                                     1.5017e-02, -1.6241e-02, -1.4801e-02,  1.1788e-03,\n",
              "                                     1.3371e-03,  1.0097e-02,  2.4670e-03,  3.8357e-03,\n",
              "                                    -7.6566e-03,  7.2347e-03,  7.2076e-03, -1.8212e-02,\n",
              "                                    -2.6175e-02, -1.9945e-02, -2.2099e-03,  1.1006e-02,\n",
              "                                    -1.5765e-02,  3.0585e-03, -5.7428e-03,  4.6566e-04,\n",
              "                                     1.5002e-02,  8.1202e-03,  2.7630e-02,  1.0255e-02,\n",
              "                                    -1.1143e-02,  1.2293e-02,  8.9976e-03, -1.6618e-02,\n",
              "                                     3.4793e-03, -5.1325e-03, -1.0020e-02, -9.1594e-03,\n",
              "                                     1.4648e-02,  7.7535e-03,  2.1978e-02,  1.3116e-02,\n",
              "                                     1.8323e-02, -8.4019e-04, -9.1079e-04, -1.6652e-04]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-1.3976e-01,  1.0606e-01, -1.0154e-01,  1.2210e-01,\n",
              "                                     2.3780e-01, -1.0084e-01, -1.5667e-01,  3.4419e-01,\n",
              "                                    -7.0362e-02, -1.3617e-01, -3.3249e-02, -8.7171e-02,\n",
              "                                    -1.0569e-01, -1.7492e-01,  1.6241e-01,  1.8886e-01,\n",
              "                                     7.9028e-02,  1.6153e-01,  1.2713e-01, -3.8587e-01,\n",
              "                                     1.5787e-01, -2.9745e-01,  1.2257e-01, -1.0152e-01,\n",
              "                                     2.4917e-01, -6.6948e-02, -1.0832e-01,  4.8684e-02,\n",
              "                                    -1.6100e-02,  1.4070e-03,  5.0583e-01,  2.2324e-01,\n",
              "                                    -3.4323e-02,  1.9241e-01,  4.5377e-01, -1.2872e-01,\n",
              "                                     1.5932e-01, -1.6085e-01, -3.9461e-03, -1.4047e-02,\n",
              "                                     2.9014e-02,  8.6795e-02, -1.6556e-01,  2.0256e-01,\n",
              "                                     2.8844e-01, -6.9113e-02,  6.1121e-02, -1.5695e-03,\n",
              "                                    -1.9517e-01, -3.8295e-01, -2.3323e-02,  1.2239e-02,\n",
              "                                    -1.2106e-01,  1.7935e-02, -1.5109e-01, -7.7948e-02,\n",
              "                                    -3.7277e-01, -1.0978e-01, -2.1540e-01, -2.6705e-02,\n",
              "                                    -2.4064e-01, -5.7242e-01, -2.2581e-05, -2.7298e-01,\n",
              "                                    -4.4832e-01,  4.0090e-03, -2.8666e-01, -1.8677e-01,\n",
              "                                    -3.1398e-01, -3.5983e-01,  2.2233e-03,  2.0387e-02,\n",
              "                                     3.9511e-01, -5.1666e-02, -4.6259e-01,  1.9034e-01,\n",
              "                                    -2.6611e-01, -3.7431e-01,  4.8489e-02,  2.5876e-01,\n",
              "                                    -1.8042e-01, -2.2438e-01,  1.9985e-01, -4.3152e-01,\n",
              "                                     1.2882e-01, -3.6283e-01, -1.7567e-01,  4.3237e-01,\n",
              "                                    -3.3285e-01, -4.1054e-01, -1.0282e-01, -4.3822e-01,\n",
              "                                    -6.7660e-02,  2.6602e-01, -2.3048e-01,  1.2908e-01,\n",
              "                                     3.0374e-01, -1.5040e-03, -5.0041e-01, -3.6206e-03,\n",
              "                                     2.9497e-01, -3.4558e-02,  5.9247e-02,  2.0495e-01,\n",
              "                                     2.8215e-01,  1.9865e-01,  1.9882e-01,  4.1606e-01,\n",
              "                                    -3.4763e-01, -3.2438e-01, -1.2685e-01,  4.0515e-02,\n",
              "                                     1.7683e-01, -2.3031e-01, -4.7281e-03,  5.1418e-01,\n",
              "                                    -1.6053e-01, -8.2955e-02, -2.4208e-02, -8.5601e-02,\n",
              "                                     2.5207e-01,  6.1718e-01,  1.6927e-01, -1.4049e-01,\n",
              "                                     5.9555e-02, -8.6525e-02, -7.4089e-02, -1.9429e-03,\n",
              "                                    -1.3968e-01, -7.9411e-01, -1.0719e-01,  4.4183e-01,\n",
              "                                    -6.3524e-01, -2.0444e-01, -2.7617e-01,  9.1860e-02,\n",
              "                                    -8.4221e-02, -1.8914e-01, -5.3446e-02, -3.7615e-01,\n",
              "                                    -7.0227e-01,  1.6442e-01,  1.6008e-01, -8.6809e-02,\n",
              "                                    -2.4686e-01, -5.7264e-02,  4.3613e-02, -4.6584e-01,\n",
              "                                    -1.5773e-01,  4.1770e-02, -3.1331e-01, -2.3663e-01,\n",
              "                                    -3.3133e-01, -3.5759e-01, -2.2912e-02,  3.1848e-02,\n",
              "                                     2.1751e-01,  6.3406e-01,  1.0009e-01, -4.4761e-01,\n",
              "                                    -2.3897e-01, -3.3121e-01, -1.7349e-01,  1.6957e-01,\n",
              "                                    -5.8417e-01, -3.5274e-01, -1.4462e-01,  2.7799e-01,\n",
              "                                     1.1039e-01, -1.8792e-01, -2.4919e-01, -4.2268e-02,\n",
              "                                     7.3172e-02,  4.8159e-02, -3.7293e-01,  3.2950e-01,\n",
              "                                    -2.0243e-01, -8.1283e-02,  9.3959e-02,  3.2551e-01,\n",
              "                                     7.5422e-03, -2.2474e-01, -7.8722e-02,  1.5270e-01,\n",
              "                                    -1.6461e-01,  6.2826e-03, -5.5200e-02,  1.2377e-01,\n",
              "                                    -8.0139e-02,  2.0876e-02, -5.8916e-02, -1.6697e-01,\n",
              "                                    -3.1915e-01, -3.6056e-01, -3.2748e-02, -1.0742e-01,\n",
              "                                     8.1814e-02, -1.1558e-01, -1.7768e-01, -4.7824e-02,\n",
              "                                    -2.1629e-01,  3.4131e-01,  2.3542e-01,  1.3057e-01,\n",
              "                                    -1.1625e-01,  4.1666e-02,  1.0227e-01,  1.2666e-01,\n",
              "                                    -4.2973e-01, -8.0485e-02, -3.2539e-02,  5.5272e-03,\n",
              "                                    -1.1760e-02,  1.6961e-01, -3.5944e-01, -1.4126e-01,\n",
              "                                    -7.6928e-02, -1.5794e-01, -2.4227e-01,  3.2027e-01,\n",
              "                                    -9.6114e-02,  8.7501e-02,  3.5944e-01,  1.0124e-03,\n",
              "                                     3.7868e-01,  3.5163e-03,  3.5188e-01,  4.0838e-02,\n",
              "                                    -3.2061e-01, -2.9776e-01,  1.0657e-01, -2.0784e-01,\n",
              "                                     6.0149e-02, -3.9290e-01, -1.2705e-01,  2.7952e-01,\n",
              "                                    -6.4687e-02, -1.2639e-01,  1.2668e-01, -2.7949e-01,\n",
              "                                     8.3795e-02, -1.9475e-01, -3.6318e-01,  2.0615e-01,\n",
              "                                    -6.0492e-03,  1.0157e-01, -1.4411e-01, -3.0667e-01,\n",
              "                                    -8.5470e-02, -5.5875e-01, -5.6470e-02, -8.7054e-02,\n",
              "                                    -1.5039e-01, -1.6562e-01,  4.4705e-01,  1.7389e-01]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.1780, 0.1146, 0.0908, 0.2301, 0.1736, 0.3075, 0.1549,\n",
              "                                    0.0948, 0.1513, 0.2328, 0.3005, 0.2193, 0.1585, 0.1912,\n",
              "                                    0.2543, 0.1953, 0.2702, 0.2100, 0.1133, 0.3677, 0.2565,\n",
              "                                    0.2943, 0.1019, 0.2561, 0.2512, 0.2711, 0.4407, 0.4384,\n",
              "                                    0.3102, 0.1579, 0.3036, 0.1138, 0.2052, 0.1081, 0.1712,\n",
              "                                    0.2227, 0.2568, 0.1187, 0.1648, 0.3390, 0.1719, 0.3223,\n",
              "                                    0.3030, 0.2496, 0.1346, 0.1370, 0.0924, 0.1771, 0.2524,\n",
              "                                    0.1456, 0.2143, 0.2213, 0.1662, 0.1195, 0.2090, 0.3082,\n",
              "                                    0.0980, 0.2234, 0.2301, 0.1246, 0.1397, 0.6552, 0.1712,\n",
              "                                    0.2284, 0.2911, 0.2152, 0.2169, 0.1011, 0.1804, 0.4763,\n",
              "                                    0.1880, 0.5160, 0.5029, 0.1782, 0.2764, 0.1975, 0.3884,\n",
              "                                    0.0675, 0.3746, 0.2146, 0.0605, 0.1765, 0.1641, 0.3863,\n",
              "                                    0.1828, 0.2823, 0.1230, 0.3645, 0.1810, 0.2456, 0.3807,\n",
              "                                    0.8595, 0.3387, 0.4785, 0.2688, 0.1225, 0.2793, 0.2253,\n",
              "                                    0.4856, 0.2177, 0.1344, 0.3165, 0.2067, 0.3432, 0.4686,\n",
              "                                    0.1808, 0.3783, 0.3555, 0.3678, 0.3397, 0.2789, 0.1437,\n",
              "                                    0.2350, 0.1774, 0.2092, 0.3596, 0.2726, 0.1708, 0.1251,\n",
              "                                    0.1732, 0.1935, 0.3204, 0.2900, 0.2158, 0.3030, 0.3772,\n",
              "                                    0.3535, 0.1373, 0.2447, 0.8990, 0.3408, 0.7163, 0.1152,\n",
              "                                    0.3855, 0.1893, 0.1069, 0.2636, 0.2352, 0.2660, 0.3918,\n",
              "                                    0.8448, 0.2552, 0.2182, 0.3154, 0.2351, 0.6817, 0.1102,\n",
              "                                    0.6047, 0.2079, 0.1867, 0.1615, 0.2289, 0.1503, 0.2351,\n",
              "                                    0.1774, 0.1140, 0.2016, 0.1777, 0.2832, 0.2950, 0.2739,\n",
              "                                    0.3331, 0.5779, 0.3066, 0.1589, 0.1993, 0.4280, 0.4919,\n",
              "                                    0.5231, 0.1914, 0.3568, 0.2270, 0.3140, 0.3842, 0.4495,\n",
              "                                    0.2752, 0.2612, 0.1833, 0.2544, 0.1306, 0.1470, 0.2618,\n",
              "                                    0.2041, 0.2082, 0.0859, 0.2895, 0.1683, 0.2030, 0.3590,\n",
              "                                    0.2127, 0.4681, 0.1679, 0.2481, 0.1123, 0.3365, 0.2261,\n",
              "                                    0.2189, 0.1575, 0.2282, 0.2741, 0.1341, 0.3866, 0.2142,\n",
              "                                    0.1539, 0.1164, 0.1452, 0.1714, 0.4133, 0.7674, 0.3436,\n",
              "                                    0.2434, 0.1746, 0.1557, 0.3220, 0.1746, 0.1026, 0.2090,\n",
              "                                    0.1654, 0.6439, 0.4216, 0.2739, 0.1695, 0.3650, 0.2032,\n",
              "                                    0.5131, 0.1138, 0.4491, 0.2004, 0.1345, 0.4222, 0.1932,\n",
              "                                    0.1776, 0.2358, 0.4502, 0.0922, 0.1296, 0.2488, 0.2760,\n",
              "                                    0.2183, 0.3410, 0.3470, 0.3015, 0.1727, 0.1395, 0.1134,\n",
              "                                    0.2236, 0.3196, 0.1697, 0.2365, 0.3589, 0.5054, 0.4181,\n",
              "                                    0.2366, 0.1905, 0.1376, 0.2846]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer1.2.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   1,   2,  ..., 253, 254, 255],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.0843,  0.0473, -0.0786,  ..., -0.0169,  0.0397,\n",
              "                                     0.0367]),\n",
              "                     size=(128, 256, 1, 1), nnz=32768, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([0.9897, 1.0044, 1.0025, 1.0057, 1.0268, 0.9935, 1.0230,\n",
              "                                    0.9839, 1.0081, 0.9907, 0.9939, 1.0335, 0.9927, 1.0132,\n",
              "                                    1.0098, 0.9969, 1.0155, 0.9996, 1.0002, 0.9716, 0.9901,\n",
              "                                    0.9998, 0.9995, 0.9870, 0.9931, 1.0030, 1.0191, 1.0145,\n",
              "                                    1.0170, 0.9800, 0.9929, 1.0023, 1.0082, 1.0081, 1.0151,\n",
              "                                    1.0167, 0.9893, 1.0221, 1.0022, 1.0061, 0.9932, 0.9930,\n",
              "                                    1.0088, 0.9970, 0.9977, 0.9938, 0.9894, 1.0039, 1.0051,\n",
              "                                    0.9998, 0.9899, 0.9993, 0.9874, 0.9887, 1.0210, 1.0019,\n",
              "                                    0.9998, 0.9865, 1.0036, 0.9638, 0.9855, 1.0018, 0.9911,\n",
              "                                    0.9960, 0.9864, 1.0172, 0.9926, 0.9968, 1.0193, 1.0007,\n",
              "                                    1.0167, 0.9997, 1.0041, 1.0010, 1.0027, 1.0040, 0.9943,\n",
              "                                    0.9839, 0.9842, 0.9811, 1.0187, 0.9873, 0.9978, 1.0005,\n",
              "                                    1.0090, 0.9982, 0.9962, 0.9989, 1.0187, 0.9940, 0.9864,\n",
              "                                    0.9854, 1.0329, 1.0018, 0.9982, 1.0177, 1.0122, 0.9845,\n",
              "                                    0.9938, 0.9779, 0.9999, 1.0226, 0.9965, 0.9949, 0.9992,\n",
              "                                    0.9957, 0.9942, 0.9950, 0.9953, 1.0063, 0.9919, 0.9773,\n",
              "                                    0.9911, 0.9850, 0.9979, 0.9804, 1.0176, 1.0068, 1.0132,\n",
              "                                    0.9960, 0.9920, 1.0134, 1.0162, 1.0066, 1.0326, 0.9859,\n",
              "                                    0.9827, 0.9944]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([-1.6076e-02,  4.6617e-03,  3.3806e-03, -3.8042e-03,\n",
              "                                     2.4187e-02,  1.5089e-02,  1.4680e-02,  2.2302e-03,\n",
              "                                     1.0508e-02, -3.5442e-03, -4.8631e-03, -2.2004e-03,\n",
              "                                     5.6951e-04,  8.5876e-03, -2.7148e-03,  1.8443e-03,\n",
              "                                     1.4431e-04, -4.8590e-03, -6.2387e-03,  6.9432e-03,\n",
              "                                     9.0934e-03,  9.3928e-03,  3.3690e-03, -8.9625e-03,\n",
              "                                    -1.2349e-02,  8.0010e-03,  2.3413e-02, -6.0240e-03,\n",
              "                                     1.1741e-02, -2.1387e-03, -1.2863e-02,  8.2696e-03,\n",
              "                                     1.1159e-02, -2.2661e-03,  1.1583e-02,  7.0886e-03,\n",
              "                                     4.3328e-03,  1.9411e-02, -8.9458e-03,  1.4366e-02,\n",
              "                                    -6.2507e-03,  1.2174e-03, -4.8635e-03,  1.9548e-02,\n",
              "                                     2.0187e-03, -1.1320e-03, -2.7439e-03, -1.5934e-03,\n",
              "                                     4.6524e-03,  9.3417e-03, -5.1168e-03, -1.2377e-02,\n",
              "                                    -4.1140e-03, -1.5960e-02,  1.3473e-02,  1.0303e-02,\n",
              "                                     8.3677e-03, -1.6130e-03,  1.5549e-03,  8.2011e-03,\n",
              "                                    -8.9676e-03,  2.9520e-02,  1.0208e-02, -1.8442e-02,\n",
              "                                    -4.0456e-03,  1.0923e-03, -2.3703e-03, -3.6668e-05,\n",
              "                                     3.4988e-02,  4.2006e-03,  1.0593e-02,  2.4328e-03,\n",
              "                                     2.2224e-03,  1.5036e-02,  2.4298e-02,  8.6490e-03,\n",
              "                                    -2.4697e-03, -1.5265e-02, -2.1720e-03,  9.3274e-04,\n",
              "                                    -4.8581e-03,  4.6705e-03,  1.6675e-02, -1.5937e-03,\n",
              "                                     7.8333e-03, -4.9553e-03,  5.1526e-03,  6.4933e-03,\n",
              "                                     2.9956e-02,  8.8545e-03, -1.3543e-02, -2.0817e-02,\n",
              "                                     6.9018e-03,  9.1590e-03, -4.7155e-03,  1.7067e-02,\n",
              "                                     9.2044e-03, -8.9320e-04,  1.2934e-03, -9.1819e-03,\n",
              "                                     5.6837e-03,  3.1575e-03,  1.6061e-03,  1.8150e-03,\n",
              "                                     1.1611e-02,  1.2286e-02, -1.5398e-02, -9.7946e-03,\n",
              "                                    -1.9516e-02, -7.8541e-03,  1.1683e-02,  4.4903e-03,\n",
              "                                    -1.3189e-02, -7.5057e-03,  8.6822e-03,  3.8396e-03,\n",
              "                                    -2.0435e-03,  2.3134e-02,  8.4350e-03,  1.6133e-02,\n",
              "                                    -8.6423e-03,  1.5249e-02,  1.7296e-02,  4.4499e-04,\n",
              "                                    -3.4932e-03, -1.2821e-02, -3.4944e-04, -2.6866e-03]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([-2.2391,  0.3838, -0.4664, -0.7712,  1.2766,  2.1631,\n",
              "                                    -1.9937,  1.5717, -3.7675, -3.6500, -2.7232,  1.4555,\n",
              "                                    -2.0727, -1.5937,  0.8434, -0.1903, -1.1583,  0.0839,\n",
              "                                    -5.9662, -1.3223, -2.7063, -0.6613, -2.3331, -3.1904,\n",
              "                                    -4.7523, -1.6659, -1.4838,  0.7863,  0.1569,  0.6679,\n",
              "                                     0.7420,  0.2036, -1.7768, -0.5377, -0.7128,  1.7146,\n",
              "                                    -1.1373,  0.1987,  1.0484,  3.4491, -0.6640,  1.3722,\n",
              "                                     1.4782,  1.3565, -1.1095, -2.1937,  1.3307, -3.4292,\n",
              "                                    -2.5430,  1.6703, -1.0895, -0.6739, -2.4685, -1.1489,\n",
              "                                     0.5398,  0.5317, -0.6012, -2.0079, -1.8569,  0.5676,\n",
              "                                     2.3210, -4.0255,  0.3857,  0.1430, -1.9784,  1.0032,\n",
              "                                    -0.3777,  0.3398, -0.8182, -4.5561, -1.6905, -1.6674,\n",
              "                                    -2.2865,  1.8883,  0.3805, -3.1107, -0.1094,  1.4636,\n",
              "                                    -2.0843, -0.2064, -0.1880, -1.0420,  0.2002,  1.2950,\n",
              "                                     0.6103,  0.4241, -1.4928, -1.7926,  1.0225, -0.4402,\n",
              "                                    -2.8254,  0.3202,  0.1146, -5.7702,  0.7116,  2.5292,\n",
              "                                     0.6877,  3.4285, -1.2393, -0.1271,  0.6247, -0.4556,\n",
              "                                     0.8721, -2.5973, -0.7633, -0.3776, -3.0348, -4.0831,\n",
              "                                     1.1905,  0.9295, -1.8962, -0.4065, -3.3990,  1.3149,\n",
              "                                     1.6907,  0.7209,  0.8973,  2.8932, -3.0951,  2.3266,\n",
              "                                     3.2178,  1.1876, -0.4138,  3.6566, -0.7357, -0.4366,\n",
              "                                    -2.9195, -0.9468]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([16.5298, 27.9185,  7.7295,  7.4467,  5.2894, 12.4541,\n",
              "                                    18.1761,  5.0723, 16.3704, 19.1721,  9.3409, 12.7784,\n",
              "                                    21.0623, 13.4579, 18.7732,  7.5621,  8.6868,  7.3623,\n",
              "                                    27.4758, 12.0349,  5.3203, 11.1043, 10.1411,  6.8032,\n",
              "                                     5.6743, 15.7129, 21.5434,  8.4463,  6.9407, 13.5109,\n",
              "                                     5.1115,  8.7495,  9.8886,  5.1361,  8.2170,  7.3548,\n",
              "                                     6.4028,  7.8786, 17.0433, 12.2376,  5.1713,  7.2114,\n",
              "                                    22.3832, 15.2462,  7.1010,  8.4259, 11.1429, 11.6855,\n",
              "                                    10.2840,  9.8961, 14.2776,  8.5784, 12.8681, 11.8398,\n",
              "                                     8.8060, 17.7017, 11.2228,  8.9833, 11.0166,  8.8223,\n",
              "                                    30.2563, 28.9174,  5.9404, 25.4864,  8.7003, 12.9530,\n",
              "                                     3.4386,  8.3563,  9.6192, 13.9462,  7.9215,  8.9430,\n",
              "                                     5.1644, 14.4293, 16.5022, 12.0881,  8.2881,  6.5504,\n",
              "                                     6.2762, 13.0935,  4.1459,  8.2413,  8.4864,  9.3555,\n",
              "                                     9.8606,  9.4986, 11.0922,  9.6023, 12.0738,  9.1595,\n",
              "                                    15.4262, 15.5402, 13.9286, 19.9082, 14.1752,  8.8937,\n",
              "                                     5.3403, 19.8869, 10.0595,  4.3437,  3.7484,  8.6888,\n",
              "                                     4.4344, 32.1616,  4.9023,  6.6518,  3.6516,  6.7510,\n",
              "                                    11.1383,  6.2121,  5.8017,  6.3044, 11.8155,  8.4966,\n",
              "                                    12.6012,  4.2934,  9.6100, 27.3313, 14.1966,  7.7253,\n",
              "                                     6.0958,  9.8521, 16.9778, 12.6383,  9.8913,  7.5573,\n",
              "                                    18.8924,  6.6332]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0963, -0.0111,  0.0280,  ...,  0.0579, -0.0410,\n",
              "                                     0.0431]),\n",
              "                     size=(128, 128, 3, 3), nnz=147456, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([0.9973, 1.0008, 1.0302, 1.0037, 0.9758, 0.9922, 1.0058,\n",
              "                                    0.9890, 1.0080, 1.0079, 1.0040, 0.9975, 0.9841, 1.0213,\n",
              "                                    1.0235, 0.9912, 1.0029, 1.0016, 1.0185, 1.0137, 1.0048,\n",
              "                                    1.0143, 0.9929, 0.9956, 1.0185, 1.0107, 1.0104, 1.0082,\n",
              "                                    0.9982, 1.0026, 0.9905, 1.0002, 1.0052, 0.9724, 0.9899,\n",
              "                                    0.9823, 1.0128, 1.0039, 1.0078, 0.9919, 1.0085, 1.0048,\n",
              "                                    1.0200, 0.9896, 0.9981, 1.0198, 0.9773, 0.9942, 1.0001,\n",
              "                                    1.0032, 0.9915, 0.9845, 0.9962, 0.9793, 0.9987, 1.0059,\n",
              "                                    0.9833, 0.9920, 0.9539, 0.9968, 0.9847, 0.9861, 0.9905,\n",
              "                                    0.9786, 0.9895, 1.0066, 0.9868, 0.9889, 0.9947, 0.9964,\n",
              "                                    1.0219, 0.9879, 1.0091, 1.0064, 1.0158, 0.9851, 0.9884,\n",
              "                                    1.0119, 1.0018, 1.0120, 1.0015, 1.0066, 1.0024, 0.9671,\n",
              "                                    1.0007, 1.0164, 1.0056, 1.0097, 0.9982, 1.0181, 0.9950,\n",
              "                                    0.9907, 1.0006, 0.9956, 1.0098, 1.0171, 0.9932, 0.9894,\n",
              "                                    1.0281, 0.9918, 0.9907, 1.0261, 1.0086, 0.9935, 0.9950,\n",
              "                                    0.9939, 0.9924, 1.0015, 0.9912, 1.0275, 1.0132, 1.0008,\n",
              "                                    1.0054, 1.0077, 0.9868, 1.0111, 0.9905, 1.0065, 1.0087,\n",
              "                                    0.9986, 0.9920, 1.0299, 1.0135, 1.0147, 0.9998, 1.0026,\n",
              "                                    1.0147, 1.0009]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 3.9720e-03, -2.5018e-03,  2.2856e-02,  1.4905e-03,\n",
              "                                    -3.5151e-03, -6.8381e-05,  4.7608e-03, -1.1740e-02,\n",
              "                                     1.8743e-02,  4.0519e-03,  9.4705e-03,  3.5287e-02,\n",
              "                                     1.2608e-02,  1.7865e-02,  2.3188e-02, -2.6823e-03,\n",
              "                                     8.3414e-03,  7.0333e-03,  2.0007e-02,  2.4695e-02,\n",
              "                                     1.8766e-02,  3.1169e-04, -1.6106e-02,  1.3474e-02,\n",
              "                                     1.9727e-02,  9.5023e-03,  1.1602e-02,  2.7372e-02,\n",
              "                                    -1.0958e-02,  5.8541e-03, -5.6498e-03, -4.4726e-03,\n",
              "                                    -2.1654e-03, -5.3545e-03,  1.4317e-02, -1.6350e-03,\n",
              "                                     3.1196e-02, -3.4463e-03,  1.2202e-02, -9.7118e-03,\n",
              "                                    -6.2625e-03,  5.6589e-03,  2.3979e-02, -6.4011e-03,\n",
              "                                     3.6579e-03, -2.6130e-02, -5.3450e-03, -7.6431e-03,\n",
              "                                     8.5995e-03,  1.2268e-04, -8.7458e-03, -2.3960e-02,\n",
              "                                     5.8554e-03, -1.4771e-02,  7.5271e-03,  1.7217e-02,\n",
              "                                    -2.3425e-02,  1.4960e-03, -1.7744e-02, -5.6572e-03,\n",
              "                                     1.2980e-03, -8.8112e-03, -1.1113e-02, -1.7262e-02,\n",
              "                                    -1.6399e-03,  9.3985e-03, -3.1455e-02, -5.7444e-03,\n",
              "                                    -5.2409e-04,  8.9774e-04,  2.9004e-02, -6.8462e-03,\n",
              "                                     1.1117e-02,  7.6298e-03,  1.6135e-02, -5.8866e-03,\n",
              "                                     9.5438e-03,  3.6058e-03,  4.1789e-03,  1.7476e-02,\n",
              "                                     7.6063e-03, -9.8528e-04,  8.2641e-03, -1.3708e-02,\n",
              "                                     1.1951e-02,  1.2193e-02,  2.0110e-03, -2.7400e-03,\n",
              "                                     6.5592e-03,  2.1170e-02,  4.7460e-03,  1.1943e-02,\n",
              "                                     1.0882e-02, -1.6558e-02,  1.9856e-02,  7.8766e-03,\n",
              "                                     3.3735e-03,  1.9060e-02,  1.8771e-02, -1.7478e-02,\n",
              "                                     9.6405e-03,  1.6754e-02,  6.4811e-03,  7.7587e-03,\n",
              "                                    -3.9690e-03, -2.3333e-03, -1.9425e-02,  9.6353e-03,\n",
              "                                    -4.5535e-03, -5.8958e-03, -1.0229e-02,  1.9080e-02,\n",
              "                                     1.2431e-02,  1.0558e-02, -9.1696e-03,  2.2072e-03,\n",
              "                                     7.7410e-03, -1.3072e-03,  1.1613e-02, -1.6162e-02,\n",
              "                                    -8.5671e-03, -7.2210e-03,  1.8296e-02,  1.1540e-02,\n",
              "                                     6.2483e-03, -2.8337e-03,  4.6856e-03,  1.2456e-02]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 3.7171e-01,  3.4435e-01, -8.9334e-01, -6.2526e-01,\n",
              "                                     1.0016e+00, -3.2543e-01, -1.0550e+00, -1.0623e+00,\n",
              "                                    -9.0783e-01, -7.1535e-01,  3.2949e-01, -3.9033e-01,\n",
              "                                     7.0223e-01,  2.5255e-03, -5.8786e-01, -8.6542e-01,\n",
              "                                     1.4354e-01, -1.1964e+00,  7.6672e-01, -1.5911e-01,\n",
              "                                    -4.4736e-01, -2.0942e-01, -3.4395e-03, -5.1257e-01,\n",
              "                                     1.5190e-02, -5.1598e-01, -3.2458e-02,  2.3816e-01,\n",
              "                                    -5.8493e-02,  2.8606e-01,  5.2886e-01,  3.1122e-01,\n",
              "                                     6.9646e-01,  7.4712e-01, -8.4991e-02,  6.0848e-01,\n",
              "                                     3.0753e-02, -3.4170e-01, -3.1733e-01, -1.2650e+00,\n",
              "                                    -2.4073e-01,  8.1205e-01, -8.8807e-01, -2.5046e-01,\n",
              "                                     7.9025e-02, -4.7889e-01,  6.8337e-02, -7.5459e-01,\n",
              "                                    -1.6236e+00, -9.8096e-01, -2.3094e-01,  4.5255e-01,\n",
              "                                    -1.8187e-01, -3.0943e-01,  5.7079e-01, -3.6687e-01,\n",
              "                                     7.1227e-01, -3.4728e-01,  6.5153e-01, -4.0027e-03,\n",
              "                                    -5.0249e-01, -6.3263e-02, -6.7567e-01, -4.8218e-01,\n",
              "                                    -1.4235e+00, -1.3947e+00, -2.4444e-01,  5.0797e-01,\n",
              "                                     1.9204e-01,  1.3669e+00, -9.4770e-01, -1.0132e+00,\n",
              "                                    -1.4502e-01, -5.2555e-01, -1.5306e-03, -6.7002e-01,\n",
              "                                    -6.3364e-01, -6.4418e-01, -1.1740e+00, -3.0424e-02,\n",
              "                                     7.3645e-01,  1.1060e-01, -3.8233e-01, -2.7470e-01,\n",
              "                                    -5.2055e-01,  8.0648e-01, -8.1944e-01,  8.5765e-01,\n",
              "                                    -3.5750e-01,  3.0007e-02,  5.2903e-01,  1.4775e+00,\n",
              "                                    -1.4066e+00, -6.5312e-01,  3.1251e-02,  8.0855e-01,\n",
              "                                    -7.7900e-02, -1.2981e+00, -1.0307e+00, -4.6862e-01,\n",
              "                                    -8.5553e-01, -1.8652e-01, -5.2015e-01, -5.9633e-02,\n",
              "                                    -8.0082e-01, -2.1128e-01, -4.0146e-01, -1.5447e-01,\n",
              "                                     2.7431e-01, -1.1744e+00,  8.8416e-02,  3.1245e-01,\n",
              "                                     7.3095e-01, -7.5411e-01,  8.4412e-01,  3.3277e-01,\n",
              "                                    -7.8217e-01, -1.3998e-01, -2.3652e-01,  3.2523e-02,\n",
              "                                     8.4913e-01,  2.6160e-01, -8.2545e-01, -1.9983e-01,\n",
              "                                    -6.1832e-01, -4.0635e-01, -1.2693e+00,  8.0300e-02]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([2.6998, 2.6131, 2.2198, 3.0227, 2.6444, 1.9161, 1.6952,\n",
              "                                    3.3182, 4.3160, 6.4259, 4.2958, 3.8182, 3.1785, 1.5413,\n",
              "                                    2.4069, 7.4471, 2.7546, 4.4359, 6.1251, 2.7022, 3.3999,\n",
              "                                    2.2278, 3.1345, 2.5774, 5.8342, 2.0871, 6.0780, 2.1259,\n",
              "                                    3.5699, 4.2948, 5.1987, 2.7531, 3.5457, 3.3323, 3.9233,\n",
              "                                    4.3290, 7.7353, 3.8266, 8.4103, 3.5576, 2.1740, 2.2867,\n",
              "                                    3.7154, 2.1253, 3.8661, 2.5059, 3.2107, 2.2715, 4.3878,\n",
              "                                    1.4632, 4.2395, 3.5560, 4.6063, 1.8197, 4.6766, 4.7044,\n",
              "                                    4.0249, 1.4345, 3.2720, 2.6076, 2.9294, 2.6648, 2.1356,\n",
              "                                    2.1049, 2.1108, 4.1488, 2.1215, 3.5924, 2.0052, 2.8187,\n",
              "                                    5.2387, 4.2240, 2.9031, 1.7325, 2.9323, 3.2465, 2.6741,\n",
              "                                    5.3774, 3.1299, 3.2813, 5.0495, 1.5148, 4.4270, 3.2384,\n",
              "                                    4.0669, 2.5841, 2.1118, 1.2234, 1.6056, 4.8115, 4.8144,\n",
              "                                    7.7432, 7.4328, 1.8488, 2.1832, 2.2779, 3.3343, 2.0118,\n",
              "                                    2.6680, 1.5803, 2.1946, 2.8577, 2.1267, 3.1267, 3.2036,\n",
              "                                    3.1936, 2.2452, 1.9528, 1.3660, 2.7679, 2.0634, 3.4580,\n",
              "                                    3.6091, 3.6475, 1.3395, 1.6227, 3.7349, 2.5065, 3.0203,\n",
              "                                    2.6397, 3.7960, 3.7971, 3.1027, 1.9776, 4.5690, 1.6300,\n",
              "                                    5.6782, 2.5373]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   1,   2,  ..., 125, 126, 127],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.0008, -0.0290, -0.0893,  ...,  0.0421, -0.0010,\n",
              "                                     0.0533]),\n",
              "                     size=(512, 128, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9927, 0.9917, 0.9955, 0.9893, 1.0108, 0.9918, 1.0053,\n",
              "                                    1.0166, 1.0090, 0.9780, 0.9962, 1.0019, 0.9917, 0.9940,\n",
              "                                    0.9878, 1.0021, 0.9943, 0.9940, 0.9906, 0.9937, 0.9958,\n",
              "                                    0.9898, 1.0014, 0.9969, 0.9978, 1.0021, 0.9804, 0.9896,\n",
              "                                    0.9835, 0.9835, 1.0072, 1.0220, 0.9971, 1.0069, 0.9970,\n",
              "                                    1.0220, 0.9904, 1.0123, 1.0122, 0.9919, 0.9911, 1.0013,\n",
              "                                    1.0057, 0.9932, 0.9876, 1.0196, 1.0401, 0.9980, 1.0044,\n",
              "                                    0.9956, 1.0189, 1.0112, 0.9920, 1.0029, 0.9963, 1.0301,\n",
              "                                    0.9833, 1.0197, 0.9869, 1.0082, 1.0143, 0.9991, 0.9869,\n",
              "                                    1.0075, 1.0011, 1.0080, 0.9996, 1.0010, 0.9860, 0.9965,\n",
              "                                    1.0000, 0.9896, 1.0111, 0.9920, 1.0061, 1.0078, 0.9818,\n",
              "                                    0.9965, 1.0088, 0.9920, 1.0048, 0.9910, 0.9998, 0.9932,\n",
              "                                    0.9990, 1.0205, 0.9784, 0.9877, 0.9991, 0.9887, 1.0052,\n",
              "                                    0.9996, 0.9998, 0.9959, 1.0090, 1.0229, 0.9944, 0.9829,\n",
              "                                    0.9969, 0.9978, 1.0162, 0.9972, 0.9999, 0.9991, 0.9958,\n",
              "                                    0.9994, 0.9817, 0.9917, 1.0090, 1.0005, 1.0117, 1.0131,\n",
              "                                    0.9738, 0.9656, 1.0126, 0.9919, 0.9780, 1.0206, 1.0220,\n",
              "                                    0.9983, 0.9839, 0.9911, 1.0053, 0.9992, 0.9983, 0.9935,\n",
              "                                    1.0133, 0.9911, 1.0053, 1.0038, 0.9935, 0.9967, 0.9909,\n",
              "                                    1.0165, 0.9892, 1.0125, 1.0119, 1.0181, 1.0011, 0.9964,\n",
              "                                    0.9971, 0.9846, 1.0021, 0.9866, 1.0009, 1.0191, 0.9991,\n",
              "                                    1.0069, 0.9785, 0.9940, 0.9852, 0.9916, 1.0161, 0.9825,\n",
              "                                    1.0043, 1.0038, 1.0193, 0.9893, 1.0192, 0.9983, 0.9929,\n",
              "                                    0.9958, 1.0076, 1.0223, 1.0093, 0.9888, 0.9982, 0.9853,\n",
              "                                    0.9762, 1.0043, 1.0067, 1.0036, 0.9957, 0.9878, 1.0167,\n",
              "                                    1.0046, 1.0004, 0.9980, 0.9936, 1.0092, 0.9844, 0.9934,\n",
              "                                    0.9956, 0.9969, 0.9908, 0.9945, 1.0191, 0.9889, 0.9983,\n",
              "                                    0.9965, 1.0025, 1.0088, 1.0031, 0.9944, 0.9998, 0.9834,\n",
              "                                    1.0010, 1.0153, 0.9992, 0.9799, 0.9876, 0.9975, 0.9802,\n",
              "                                    1.0108, 0.9979, 0.9874, 0.9984, 0.9998, 0.9938, 1.0055,\n",
              "                                    0.9913, 0.9941, 1.0029, 0.9979, 0.9914, 1.0071, 0.9917,\n",
              "                                    0.9995, 1.0055, 1.0027, 0.9844, 0.9982, 0.9929, 0.9904,\n",
              "                                    1.0074, 0.9936, 0.9941, 0.9946, 0.9779, 0.9993, 0.9892,\n",
              "                                    0.9944, 0.9969, 1.0043, 1.0097, 1.0172, 1.0061, 0.9912,\n",
              "                                    1.0057, 0.9893, 1.0040, 0.9812, 0.9996, 1.0038, 0.9871,\n",
              "                                    0.9785, 0.9888, 0.9935, 1.0007, 0.9924, 1.0168, 1.0063,\n",
              "                                    0.9829, 1.0149, 0.9933, 1.0128, 1.0035, 1.0132, 1.0036,\n",
              "                                    1.0014, 1.0074, 0.9862, 1.0062, 1.0026, 0.9938, 0.9821,\n",
              "                                    1.0143, 1.0018, 0.9876, 0.9846, 1.0100, 0.9885, 1.0065,\n",
              "                                    1.0112, 0.9957, 1.0029, 0.9877, 1.0105, 0.9824, 0.9921,\n",
              "                                    0.9935, 1.0021, 1.0001, 1.0099, 0.9916, 1.0041, 0.9956,\n",
              "                                    0.9892, 0.9814, 0.9999, 0.9818, 1.0253, 0.9933, 1.0037,\n",
              "                                    0.9918, 0.9908, 0.9963, 1.0008, 0.9963, 1.0043, 0.9913,\n",
              "                                    1.0075, 1.0025, 0.9745, 0.9693, 0.9841, 0.9919, 1.0134,\n",
              "                                    1.0205, 1.0121, 0.9900, 1.0067, 1.0052, 0.9956, 0.9988,\n",
              "                                    1.0032, 1.0184, 0.9960, 0.9986, 1.0102, 0.9944, 1.0149,\n",
              "                                    0.9999, 1.0106, 1.0094, 0.9993, 0.9734, 1.0130, 0.9883,\n",
              "                                    1.0157, 1.0013, 1.0243, 0.9907, 0.9880, 1.0138, 0.9832,\n",
              "                                    0.9864, 1.0073, 0.9972, 0.9960, 0.9923, 1.0097, 1.0194,\n",
              "                                    0.9930, 1.0242, 0.9902, 1.0176, 0.9986, 1.0031, 1.0027,\n",
              "                                    0.9846, 1.0260, 0.9718, 1.0059, 0.9916, 0.9849, 0.9851,\n",
              "                                    1.0057, 0.9910, 1.0189, 0.9768, 1.0042, 1.0117, 1.0034,\n",
              "                                    1.0122, 0.9986, 1.0149, 1.0172, 0.9980, 1.0030, 1.0210,\n",
              "                                    0.9989, 0.9933, 1.0070, 1.0052, 1.0006, 1.0024, 1.0172,\n",
              "                                    0.9977, 1.0078, 0.9882, 1.0026, 1.0003, 0.9881, 1.0057,\n",
              "                                    0.9939, 1.0165, 1.0115, 1.0057, 0.9986, 1.0009, 1.0136,\n",
              "                                    0.9863, 1.0019, 1.0246, 1.0061, 1.0143, 0.9957, 0.9922,\n",
              "                                    1.0280, 0.9994, 0.9994, 1.0163, 1.0079, 0.9974, 0.9881,\n",
              "                                    0.9899, 0.9884, 1.0056, 0.9726, 1.0136, 0.9802, 0.9879,\n",
              "                                    0.9958, 0.9940, 0.9852, 1.0136, 1.0392, 1.0079, 0.9921,\n",
              "                                    0.9907, 0.9995, 0.9816, 0.9912, 0.9932, 0.9921, 1.0163,\n",
              "                                    0.9959, 1.0066, 0.9928, 1.0068, 0.9937, 1.0119, 0.9892,\n",
              "                                    0.9978, 0.9933, 1.0067, 0.9986, 0.9939, 1.0089, 0.9703,\n",
              "                                    0.9693, 0.9952, 0.9940, 0.9821, 0.9970, 1.0189, 0.9943,\n",
              "                                    1.0013, 0.9887, 1.0126, 1.0251, 0.9761, 0.9992, 1.0097,\n",
              "                                    1.0096, 0.9923, 1.0114, 0.9944, 0.9834, 0.9991, 0.9983,\n",
              "                                    0.9894, 0.9995, 0.9905, 1.0252, 1.0005, 1.0057, 0.9998,\n",
              "                                    0.9947, 1.0110, 1.0096, 0.9994, 0.9966, 0.9715, 0.9974,\n",
              "                                    0.9925, 0.9979, 1.0336, 1.0057, 1.0103, 0.9968, 1.0293,\n",
              "                                    1.0046, 0.9826, 1.0004, 1.0070, 1.0072, 1.0002, 1.0144,\n",
              "                                    1.0280, 1.0010, 0.9955, 1.0173, 1.0018, 0.9836, 0.9849,\n",
              "                                    0.9864, 0.9806, 1.0214, 1.0094, 1.0042, 1.0279, 1.0053,\n",
              "                                    0.9928, 0.9968, 0.9961, 1.0005, 0.9898, 0.9984, 1.0051,\n",
              "                                    0.9833]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-7.3420e-03,  1.5829e-02, -1.3353e-02, -1.1658e-02,\n",
              "                                    -6.9758e-04,  1.2418e-02, -1.2773e-02,  2.5673e-02,\n",
              "                                     2.9907e-03, -1.3205e-02, -6.2191e-03, -9.5866e-03,\n",
              "                                     2.1872e-02,  1.2216e-03, -1.7084e-02,  5.2572e-03,\n",
              "                                     2.6255e-03,  1.0711e-02, -1.9560e-02, -1.2403e-02,\n",
              "                                     1.1032e-02,  1.0007e-02, -4.7055e-03, -1.5552e-03,\n",
              "                                     2.0940e-02,  1.7341e-02,  2.0948e-03,  1.8797e-03,\n",
              "                                     2.3401e-03,  6.0417e-04,  1.0599e-02, -6.2446e-04,\n",
              "                                    -6.0347e-03, -2.9868e-04,  1.2423e-02,  1.2252e-02,\n",
              "                                     3.5509e-03, -1.5003e-02,  1.5090e-02, -4.0764e-03,\n",
              "                                    -1.0944e-02,  3.1614e-02,  1.2330e-02, -1.4882e-03,\n",
              "                                    -1.6233e-03,  2.3307e-02,  4.8785e-02,  3.6352e-02,\n",
              "                                     2.0514e-02,  7.2525e-04,  4.4711e-03,  7.0527e-03,\n",
              "                                    -3.3220e-02,  6.6863e-03,  1.1024e-02,  1.8470e-02,\n",
              "                                     1.3374e-02,  6.4393e-03,  1.8022e-02,  1.9742e-03,\n",
              "                                     1.0698e-02, -1.2626e-02,  8.1055e-03, -5.8934e-03,\n",
              "                                    -1.5493e-02,  2.1457e-02,  1.4878e-02, -9.3813e-03,\n",
              "                                     6.2736e-03, -5.3990e-03,  4.6348e-03, -6.3436e-03,\n",
              "                                     1.9665e-02,  3.3003e-04,  2.1056e-02,  2.2008e-02,\n",
              "                                     1.3743e-02, -8.1048e-03,  1.2999e-02, -7.9422e-03,\n",
              "                                     1.4670e-02, -6.9992e-03, -2.4269e-02,  2.1707e-02,\n",
              "                                     1.3319e-02,  4.1267e-03, -1.2008e-02, -1.6808e-02,\n",
              "                                     2.2190e-02,  8.2639e-03,  1.2577e-03, -1.6602e-03,\n",
              "                                    -5.4648e-03, -1.4477e-02,  5.4223e-03,  2.1349e-02,\n",
              "                                    -1.4796e-02,  4.8511e-03, -1.2864e-02,  5.5273e-03,\n",
              "                                     3.7755e-02,  1.7002e-02,  3.7077e-04,  5.4918e-02,\n",
              "                                     4.5643e-03, -1.6637e-02,  1.4633e-02,  6.8790e-03,\n",
              "                                     2.9969e-03,  1.1925e-03,  2.2547e-03,  2.3877e-03,\n",
              "                                    -1.2048e-02, -4.7566e-05, -2.9319e-03, -6.9269e-03,\n",
              "                                    -2.1037e-02,  3.5112e-02,  5.2086e-03,  2.4531e-03,\n",
              "                                     1.4743e-03, -8.1653e-04, -2.8224e-04, -8.3904e-03,\n",
              "                                     3.0428e-03,  1.3439e-02,  3.3868e-02,  1.4457e-02,\n",
              "                                     6.7484e-05, -2.5670e-03,  8.1041e-03,  8.4984e-03,\n",
              "                                     5.3505e-03,  6.4761e-03, -4.5120e-03,  2.3435e-03,\n",
              "                                     1.2621e-02,  1.0075e-02,  1.8983e-02, -1.7654e-02,\n",
              "                                    -1.2681e-02,  2.4306e-02, -4.9227e-04,  6.7040e-03,\n",
              "                                    -2.1241e-02, -9.6869e-03,  4.8961e-03,  4.7716e-03,\n",
              "                                    -1.0669e-02,  1.7838e-02, -1.2109e-02,  7.5567e-03,\n",
              "                                     1.4946e-02, -5.7108e-03,  3.9381e-03, -8.3012e-03,\n",
              "                                    -5.5947e-04, -3.0626e-03, -9.9089e-03,  3.0942e-02,\n",
              "                                    -4.4332e-03, -1.1405e-02,  4.1937e-03,  2.9669e-02,\n",
              "                                    -1.7673e-03, -1.3964e-03, -3.5497e-03, -2.5651e-03,\n",
              "                                    -7.0994e-03, -2.7325e-03, -7.6035e-03,  2.1520e-02,\n",
              "                                     2.9094e-02,  7.0162e-03,  2.0216e-02, -5.8935e-03,\n",
              "                                    -9.7931e-04,  5.6520e-03, -8.8973e-03,  3.5748e-02,\n",
              "                                    -1.5345e-02,  4.7388e-03,  4.0003e-03, -1.3396e-02,\n",
              "                                     1.0611e-02, -1.4769e-02,  3.0760e-02, -2.8757e-03,\n",
              "                                     1.6395e-03, -3.3011e-03, -1.2607e-02, -2.3510e-04,\n",
              "                                     5.9626e-03,  2.4161e-02, -1.5697e-03, -1.9223e-02,\n",
              "                                     9.5713e-03,  1.7313e-02,  1.6593e-02,  3.6466e-03,\n",
              "                                     7.8828e-03,  1.6880e-02, -9.6234e-03, -8.6595e-03,\n",
              "                                     2.1123e-02,  1.3363e-02, -6.4540e-03,  2.7568e-03,\n",
              "                                    -4.7229e-03,  2.7430e-02,  9.8517e-03,  8.0810e-04,\n",
              "                                     1.7922e-03,  4.5046e-03, -8.6062e-03,  9.9669e-03,\n",
              "                                    -6.7919e-03,  1.3580e-02, -2.8260e-02,  9.3391e-03,\n",
              "                                     9.6368e-03, -5.8605e-03,  2.6609e-02,  1.5243e-02,\n",
              "                                     1.5500e-03, -2.2261e-02, -1.1164e-03, -2.3216e-02,\n",
              "                                     5.1233e-03, -3.5174e-03, -8.1151e-04,  2.3524e-04,\n",
              "                                    -7.0456e-03, -3.7211e-03,  1.1169e-02,  1.3406e-02,\n",
              "                                     7.5314e-03, -1.4691e-02,  2.0409e-02, -6.4041e-03,\n",
              "                                    -1.0678e-02,  6.7104e-04, -6.2731e-03,  6.1420e-03,\n",
              "                                     6.7533e-03, -3.9473e-03,  1.1990e-02, -9.7771e-03,\n",
              "                                    -9.4688e-03,  7.0661e-03,  1.9506e-02,  3.5927e-03,\n",
              "                                     2.3563e-02,  1.1683e-02, -8.4393e-03,  5.8344e-03,\n",
              "                                     3.1793e-02,  7.5802e-03, -4.1134e-03,  7.0568e-03,\n",
              "                                     6.9101e-03, -4.9845e-04,  2.4591e-03,  1.8775e-02,\n",
              "                                     2.6359e-02, -2.2554e-03,  1.7916e-03, -1.9061e-02,\n",
              "                                    -1.1813e-03,  1.1498e-02, -1.5413e-02, -2.7060e-02,\n",
              "                                    -1.6616e-03, -1.1471e-02,  2.2324e-02,  1.3545e-02,\n",
              "                                     1.8870e-02,  1.3532e-02, -2.0675e-02, -2.5223e-02,\n",
              "                                    -6.3017e-03,  5.7834e-03,  6.3913e-03, -7.2516e-03,\n",
              "                                    -1.7813e-04,  1.0894e-02,  4.2072e-03,  1.5194e-02,\n",
              "                                    -1.0124e-02,  2.4339e-03,  1.4852e-02,  1.9755e-02,\n",
              "                                    -3.6937e-03, -1.5914e-02,  3.1758e-03, -2.9417e-03,\n",
              "                                     5.2829e-03,  3.8191e-03,  2.9085e-02, -1.0962e-02,\n",
              "                                     1.6613e-02,  7.3852e-03,  9.9595e-03, -1.4518e-02,\n",
              "                                     6.6218e-03,  1.3456e-02,  1.8210e-02, -6.5940e-03,\n",
              "                                     1.3814e-02,  2.7119e-03, -7.4716e-03,  5.0981e-03,\n",
              "                                     8.6716e-03, -2.2612e-03,  2.0755e-02,  1.3596e-02,\n",
              "                                     1.0079e-02, -1.6182e-02, -8.1829e-03,  1.3350e-02,\n",
              "                                     8.6024e-03,  6.3807e-03, -8.2524e-03,  4.7418e-02,\n",
              "                                     1.4168e-02,  1.0206e-02, -2.6856e-02,  2.0198e-02,\n",
              "                                     7.3275e-03,  2.1363e-02, -1.4258e-03,  6.3668e-02,\n",
              "                                     5.5674e-03, -1.5288e-02,  8.7831e-03, -1.5548e-02,\n",
              "                                     2.0380e-03, -6.3860e-04,  2.1574e-02, -2.1758e-03,\n",
              "                                     1.0095e-02,  1.2607e-02,  2.2328e-02,  7.6587e-03,\n",
              "                                     2.6392e-02, -1.1077e-03,  1.8686e-02,  1.1797e-03,\n",
              "                                     8.3762e-03,  1.6497e-02,  3.8726e-04,  1.8386e-02,\n",
              "                                    -9.7500e-03,  1.4893e-02, -1.1076e-02, -6.3756e-03,\n",
              "                                    -1.3638e-02,  3.0844e-03,  5.1841e-04,  2.4988e-02,\n",
              "                                     9.7099e-04,  1.6899e-02,  8.0157e-03,  9.1297e-03,\n",
              "                                     1.3663e-02,  7.9862e-04, -2.6684e-04, -1.3488e-03,\n",
              "                                     1.9885e-02,  2.9527e-03,  1.4844e-02, -6.3569e-03,\n",
              "                                     4.4369e-03,  3.3878e-02,  5.2448e-03,  2.2781e-03,\n",
              "                                     1.2104e-02,  7.2619e-03,  4.2152e-03, -8.4997e-03,\n",
              "                                     5.9676e-03,  1.6968e-02,  4.5429e-03, -5.4194e-03,\n",
              "                                    -8.4456e-03, -1.1900e-02, -6.8071e-03,  1.1867e-03,\n",
              "                                    -7.7309e-03,  9.7701e-03, -1.2234e-02,  5.8339e-02,\n",
              "                                     5.5262e-03,  4.5966e-03,  1.3489e-02, -2.3432e-02,\n",
              "                                     2.0794e-02,  9.0588e-03,  1.2525e-02,  1.4257e-02,\n",
              "                                     9.5067e-05,  1.0882e-02,  6.2375e-03,  9.2954e-03,\n",
              "                                     1.3175e-02, -1.2174e-02, -1.9550e-02,  2.9069e-02,\n",
              "                                     2.3549e-02,  8.9992e-04,  1.1667e-02, -6.1100e-03,\n",
              "                                    -1.1643e-02,  2.7193e-02,  3.5518e-03, -1.4889e-02,\n",
              "                                     1.5619e-02,  6.6867e-04,  1.1228e-02,  4.0002e-03,\n",
              "                                     9.8135e-03, -8.6253e-03,  1.3300e-02,  8.2248e-03,\n",
              "                                     2.1166e-02,  2.6036e-02,  4.5261e-03,  8.8262e-03,\n",
              "                                    -1.5600e-03, -1.3753e-02,  6.9826e-03, -7.8066e-04,\n",
              "                                    -4.2286e-03, -1.8624e-02,  3.5226e-02,  1.1513e-02,\n",
              "                                    -2.3341e-02,  1.1408e-02, -3.2299e-03,  1.7419e-02,\n",
              "                                    -3.2432e-03, -1.8755e-02,  2.1268e-03, -1.8727e-03,\n",
              "                                    -4.6743e-03, -8.6940e-03,  9.0945e-03,  3.5870e-03,\n",
              "                                     1.4249e-02, -5.3388e-03, -6.8062e-03,  3.4985e-02,\n",
              "                                    -5.1499e-03, -1.8929e-03,  9.4134e-03,  7.6301e-03,\n",
              "                                     2.0445e-02,  2.6292e-02, -6.4649e-03,  2.1201e-02,\n",
              "                                     7.5673e-03,  7.7357e-03, -1.1645e-02,  7.1298e-03,\n",
              "                                    -1.1496e-02,  1.9517e-02, -3.9329e-03, -2.6074e-03,\n",
              "                                     6.5233e-03,  4.1501e-03,  1.2945e-02,  9.8707e-04,\n",
              "                                     9.6383e-03,  9.1639e-03,  6.0479e-03,  6.5222e-03,\n",
              "                                    -4.8405e-03,  2.4522e-03, -2.4588e-03, -1.9205e-03,\n",
              "                                     3.2258e-02, -5.0829e-03,  2.0129e-02,  3.1682e-03,\n",
              "                                     2.3181e-02,  7.9641e-03,  2.2519e-02,  1.2250e-02,\n",
              "                                    -1.7356e-02, -2.1772e-03,  3.9567e-02, -1.3167e-02,\n",
              "                                    -1.1699e-03, -3.5785e-03,  5.5433e-03, -2.4103e-04,\n",
              "                                    -8.1706e-03, -2.9913e-02, -3.6982e-03,  1.6842e-02,\n",
              "                                     9.1549e-03,  8.8854e-03,  2.4169e-02,  1.0040e-02,\n",
              "                                    -8.0329e-03,  1.2653e-02,  1.9025e-03,  7.8929e-04,\n",
              "                                    -1.9888e-02,  1.3294e-02, -6.2359e-03,  4.7654e-03]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-3.6113e-01, -6.9227e-01, -3.0370e-01, -1.0060e-02,\n",
              "                                    -4.1753e-01, -1.9808e-01, -2.5633e-02, -4.3837e-01,\n",
              "                                     2.2472e-01,  1.4157e-01,  4.1362e-02, -5.1145e-02,\n",
              "                                     1.3261e-01, -4.5617e-01,  3.1920e-01,  9.5876e-02,\n",
              "                                    -6.2858e-02, -5.2942e-02, -3.4918e-01, -2.9277e-01,\n",
              "                                    -9.0004e-02,  1.3168e-01,  2.9904e-01,  2.3644e-01,\n",
              "                                    -1.7338e-01,  2.4774e-03, -3.3739e-01,  1.6370e-01,\n",
              "                                     1.5557e-01, -1.3675e-01, -2.5254e-02,  2.2883e-01,\n",
              "                                    -4.1166e-01, -3.2735e-01,  2.6039e-02, -8.3851e-02,\n",
              "                                    -7.8484e-02,  3.1858e-01,  1.2239e-01, -2.8580e-01,\n",
              "                                    -4.5866e-01, -1.1175e-01,  6.8880e-02, -1.1299e-01,\n",
              "                                     1.2003e-01,  1.6733e-02, -5.4314e-02, -7.7555e-02,\n",
              "                                    -8.0438e-03, -2.2636e-01, -1.4101e-01,  8.8746e-02,\n",
              "                                     1.9846e-01,  1.5238e-01, -3.2789e-02,  3.1283e-01,\n",
              "                                    -3.5947e-01,  1.1907e-01,  5.2234e-02,  1.9041e-02,\n",
              "                                    -2.3546e-01, -2.0529e-01,  2.5368e-02, -1.9577e-01,\n",
              "                                    -5.4026e-02, -1.4202e-02,  3.0882e-01,  8.0291e-01,\n",
              "                                     2.3363e-01,  7.4252e-02,  3.8631e-01,  3.1628e-01,\n",
              "                                     1.6352e-01,  4.0521e-01, -8.8266e-02,  1.9413e-01,\n",
              "                                    -2.5215e-01, -1.7166e-01, -5.9763e-02,  2.8170e-01,\n",
              "                                     1.4896e-01, -1.4128e-01, -1.0905e-01,  1.3624e-01,\n",
              "                                    -5.8710e-01,  5.5813e-02,  4.9963e-02, -1.8490e-01,\n",
              "                                    -7.5910e-01, -3.1583e-01,  1.5142e-01, -3.2476e-01,\n",
              "                                     1.5083e-02, -3.9012e-01,  4.0929e-03, -1.7615e-01,\n",
              "                                    -5.0701e-01,  1.5632e-02, -3.8451e-01,  6.5633e-02,\n",
              "                                    -2.5324e-01, -1.7848e-01, -1.1286e-01, -2.5261e-02,\n",
              "                                    -3.3958e-01, -2.4622e-01, -1.4285e-01,  3.0698e-01,\n",
              "                                    -2.0566e-01, -6.7362e-02, -1.1937e-01,  1.0662e-01,\n",
              "                                     3.1108e-01,  3.6632e-02, -5.8151e-02, -1.9169e-02,\n",
              "                                     7.9646e-02,  2.9515e-02, -2.9681e-01,  1.0572e-01,\n",
              "                                     2.7163e-01, -3.4649e-01, -1.0030e-01,  2.2877e-01,\n",
              "                                    -2.9957e-01, -5.3023e-01, -1.5929e-01,  2.1019e-01,\n",
              "                                    -6.6485e-02,  9.6378e-02, -8.2224e-02,  3.4709e-01,\n",
              "                                    -1.1522e-01,  1.5699e-01, -3.9395e-01, -2.9666e-01,\n",
              "                                     4.5432e-01,  3.2126e-01, -4.4906e-01,  2.3782e-01,\n",
              "                                    -1.7139e-01, -1.9697e-01, -2.0960e-01,  4.4566e-01,\n",
              "                                    -8.3969e-03, -1.0117e-01,  3.8770e-01, -7.8327e-02,\n",
              "                                    -2.7340e-02, -2.6670e-01, -4.6298e-01, -2.3213e-01,\n",
              "                                    -2.0685e-01, -2.7152e-01, -2.2163e-01,  2.3413e-02,\n",
              "                                    -1.1497e-01, -6.3036e-02, -4.4570e-01, -1.0947e-01,\n",
              "                                    -3.8008e-01, -4.7346e-01,  7.2807e-02,  1.8764e-01,\n",
              "                                    -2.1672e-02,  2.3339e-01, -5.3435e-01, -3.0257e-01,\n",
              "                                    -7.6468e-02, -9.4021e-02,  6.7526e-01,  2.7642e-01,\n",
              "                                    -6.3302e-03,  5.0382e-02,  2.0974e-02, -4.4214e-01,\n",
              "                                    -4.5286e-01,  1.5285e-01,  1.1732e-02, -1.6248e-01,\n",
              "                                     8.9975e-02,  1.9402e-03,  5.3380e-02,  1.6199e-01,\n",
              "                                     3.4762e-02,  1.5978e-01,  2.0048e-01,  3.7925e-02,\n",
              "                                    -1.1707e-01, -4.6670e-02, -1.9630e-01, -4.0382e-01,\n",
              "                                     1.8811e-01, -8.8416e-03, -2.1290e-01,  9.7905e-02,\n",
              "                                     2.1805e-01, -1.5130e-01, -2.5395e-02, -3.7702e-01,\n",
              "                                    -6.9548e-03, -1.4963e-01,  1.4991e-01,  8.4435e-02,\n",
              "                                     9.1958e-02, -9.6667e-02, -3.2764e-01, -1.8007e-01,\n",
              "                                    -3.5887e-01, -1.9223e-01,  1.0132e-01, -1.8500e-01,\n",
              "                                     2.8397e-02, -2.0797e-01, -3.3865e-02,  1.3398e-01,\n",
              "                                    -9.4519e-02, -6.4876e-01, -8.3226e-02,  2.4038e-01,\n",
              "                                    -1.0879e-01, -2.8818e-01, -1.2316e-02, -5.8808e-02,\n",
              "                                    -1.7516e-01, -4.0012e-01, -1.7928e-01,  2.5357e-01,\n",
              "                                    -2.7115e-01,  9.5669e-02, -3.7952e-01, -2.9242e-01,\n",
              "                                    -1.5848e-02, -1.8898e-01,  3.8552e-02,  2.3443e-01,\n",
              "                                     4.7572e-01, -1.5856e-01,  5.5761e-02,  5.4037e-02,\n",
              "                                     9.3634e-02,  1.5137e-01, -2.8519e-01,  1.0495e-01,\n",
              "                                    -3.2946e-01, -3.8808e-02, -1.1166e-01,  1.9076e-01,\n",
              "                                    -1.2800e-01,  1.0859e-02, -2.5613e-01, -5.0585e-03,\n",
              "                                    -5.3741e-01, -1.5763e-01, -1.4090e-01,  3.9665e-01,\n",
              "                                     3.4814e-01, -2.4589e-01,  3.0275e-01, -4.1479e-01,\n",
              "                                     9.4524e-02,  3.1008e-02, -1.2003e-01,  1.2465e-02,\n",
              "                                    -2.9657e-02, -4.8297e-01,  4.4690e-01, -2.3284e-01,\n",
              "                                    -1.0994e-01,  5.7837e-01, -8.8167e-02, -2.9769e-02,\n",
              "                                     3.5763e-01,  5.2835e-01,  1.2372e-01,  1.1057e-01,\n",
              "                                     6.0737e-01,  7.6855e-02,  2.9716e-01, -3.6342e-01,\n",
              "                                    -2.7942e-01, -2.7869e-01,  2.6410e-01, -1.7106e-01,\n",
              "                                    -4.5373e-01,  1.0229e-01,  4.2189e-01,  8.7352e-02,\n",
              "                                     1.6902e-02, -1.9838e-01, -1.2977e-01,  1.4126e-01,\n",
              "                                    -6.7890e-02,  5.1703e-02,  2.3796e-03, -1.4844e-02,\n",
              "                                     2.6612e-01,  2.3883e-01, -4.5060e-01, -4.7368e-01,\n",
              "                                     9.8854e-02, -1.8586e-02,  3.5758e-01, -6.3771e-01,\n",
              "                                    -1.6006e-01, -1.9003e-01, -3.1975e-01,  2.5124e-01,\n",
              "                                     4.0649e-01, -7.4449e-03, -5.3347e-02, -5.5500e-02,\n",
              "                                    -6.7999e-02,  1.8989e-01, -1.5989e-01, -1.5555e-01,\n",
              "                                    -7.0586e-01, -7.6422e-02, -2.3034e-01, -3.0182e-01,\n",
              "                                     1.0266e-01,  1.7019e-01, -1.2405e-01, -2.7361e-01,\n",
              "                                     4.1615e-02,  6.7301e-02,  1.1630e-01, -1.1639e-01,\n",
              "                                     2.2450e-02,  2.6585e-01,  3.7187e-01, -2.0685e-01,\n",
              "                                    -6.3977e-03, -1.4040e-01,  1.1011e-01, -6.6630e-02,\n",
              "                                    -5.3376e-01,  1.7119e-02, -4.7327e-01, -4.7576e-01,\n",
              "                                    -1.3457e-01, -2.6195e-01,  7.0499e-02, -2.8500e-01,\n",
              "                                     4.0058e-02, -2.0937e-01, -1.3871e-01,  4.8185e-04,\n",
              "                                     2.9278e-01,  4.4838e-02,  1.4325e-01, -4.4577e-01,\n",
              "                                     3.9450e-02, -9.9606e-02, -3.3915e-01, -8.9876e-02,\n",
              "                                    -2.8823e-01,  1.2509e-02, -2.4065e-01, -1.0038e-01,\n",
              "                                    -3.1159e-01, -1.8909e-01, -2.4005e-01,  3.8565e-01,\n",
              "                                     2.5518e-02, -3.0728e-01,  3.3086e-01, -1.8473e-01,\n",
              "                                    -2.7112e-01, -2.5194e-01,  4.3355e-01,  2.1997e-01,\n",
              "                                     3.6189e-01, -1.6372e-01, -4.8109e-01, -4.0792e-02,\n",
              "                                     1.2358e-01, -4.0958e-02, -2.4268e-01, -3.0897e-01,\n",
              "                                    -8.6960e-01, -8.9421e-02,  8.8330e-02, -4.9643e-01,\n",
              "                                     1.1708e-01, -3.6483e-01, -4.7745e-02, -4.0064e-01,\n",
              "                                     1.0303e-01, -1.0781e-01, -2.8074e-01, -6.4960e-02,\n",
              "                                     6.5779e-02,  2.3917e-01, -2.6055e-01, -1.0380e-01,\n",
              "                                     4.7933e-01,  2.1016e-03,  1.0789e-01, -5.3775e-01,\n",
              "                                    -1.1211e-01, -1.8793e-02, -7.0023e-02,  4.4100e-02,\n",
              "                                    -3.0288e-02, -3.3527e-01, -3.1895e-01,  2.8478e-01,\n",
              "                                    -1.7396e-02, -8.8876e-02,  4.4695e-01,  1.8801e-01,\n",
              "                                     8.1332e-02, -1.2626e-01,  1.3311e-01, -3.7408e-01,\n",
              "                                     3.0797e-01, -1.8070e-01,  1.7585e-01, -4.6594e-03,\n",
              "                                    -2.2322e-01, -1.0391e-01, -1.6532e-01, -1.9342e-01,\n",
              "                                    -2.1735e-01, -5.1379e-01,  1.8711e-01,  7.9680e-02,\n",
              "                                    -2.9455e-01, -2.5979e-01, -1.6496e-01, -3.9222e-02,\n",
              "                                    -1.2005e-02,  3.3969e-03, -7.1439e-01,  7.3295e-02,\n",
              "                                     4.4960e-02,  3.6550e-01,  7.5031e-03,  2.6498e-01,\n",
              "                                    -2.3139e-01, -4.4868e-02, -3.6710e-02, -3.1484e-01,\n",
              "                                     1.1134e-01, -3.8308e-01, -1.0310e-02, -2.3446e-01,\n",
              "                                     4.0282e-02, -2.1394e-01, -4.5875e-01, -2.3731e-01,\n",
              "                                    -4.8909e-01,  3.3356e-01,  1.5646e-02, -2.0211e-01,\n",
              "                                    -5.6899e-02, -7.7286e-02,  8.7202e-02, -1.8158e-01,\n",
              "                                    -1.5102e-01,  3.1778e-04, -1.3660e-01, -1.8140e-01,\n",
              "                                    -3.6489e-01, -1.6018e-01, -2.3192e-01, -2.2330e-01,\n",
              "                                    -1.6277e-01, -7.3073e-01,  2.5874e-01,  7.2198e-02,\n",
              "                                    -1.3178e-01,  3.8340e-01, -5.4822e-01, -3.7008e-02,\n",
              "                                    -2.3895e-01, -2.8410e-01,  4.3417e-01, -2.7121e-01,\n",
              "                                     9.7629e-02, -6.1886e-01, -1.7210e-01,  9.4564e-02,\n",
              "                                    -1.0408e-01,  2.4663e-01, -1.6271e-01, -1.5465e-01,\n",
              "                                    -9.4481e-03,  1.6346e-02, -3.1557e-01, -5.7762e-01,\n",
              "                                    -4.2407e-01, -1.7372e-01,  1.0741e-01,  2.5442e-01,\n",
              "                                    -1.4249e-01, -7.6238e-02, -1.3117e-02, -2.3970e-01,\n",
              "                                     1.0835e-01,  2.4355e-01,  1.8466e-01, -5.1184e-02,\n",
              "                                    -5.0311e-01, -3.9217e-01, -1.1800e-01,  3.0623e-01,\n",
              "                                     1.0648e-01,  1.0191e-01, -7.1873e-02, -3.0640e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.2829, 0.3244, 0.8219, 0.2713, 0.2324, 0.4623, 0.6848,\n",
              "                                    0.3748, 0.2009, 0.2580, 0.2186, 0.5331, 0.9544, 0.2211,\n",
              "                                    0.1522, 0.2464, 0.2513, 0.2044, 0.3891, 0.1953, 0.3574,\n",
              "                                    0.5537, 0.3974, 0.3380, 0.3519, 0.1661, 0.1972, 0.5616,\n",
              "                                    0.3559, 0.2827, 0.3019, 0.1744, 0.2336, 0.2267, 0.3147,\n",
              "                                    0.4796, 0.1595, 0.1799, 0.3028, 0.2736, 0.2781, 0.5120,\n",
              "                                    0.3707, 0.3040, 0.1959, 0.3651, 0.4043, 0.6992, 0.1959,\n",
              "                                    0.3494, 0.3020, 0.3780, 0.1310, 0.3385, 0.4934, 0.4879,\n",
              "                                    0.1596, 0.2596, 0.4478, 0.1900, 0.8066, 0.2552, 0.2820,\n",
              "                                    0.2046, 0.4822, 0.5567, 0.5210, 0.9722, 0.1056, 0.1586,\n",
              "                                    0.3998, 0.3592, 0.3436, 0.9403, 0.5370, 0.1965, 0.2620,\n",
              "                                    0.1889, 0.3019, 0.5949, 0.7997, 0.4597, 0.2782, 0.1520,\n",
              "                                    1.0504, 0.1925, 0.2969, 0.3517, 0.5663, 0.2965, 0.2177,\n",
              "                                    0.7045, 0.4095, 0.3135, 0.3262, 0.4893, 0.4517, 0.2507,\n",
              "                                    0.5935, 0.4846, 0.5283, 0.4068, 0.2657, 0.3338, 0.3945,\n",
              "                                    0.5151, 0.3809, 0.2135, 0.2528, 0.6127, 0.5983, 0.3306,\n",
              "                                    0.1275, 0.3039, 0.1686, 0.3815, 0.2795, 0.2922, 0.3100,\n",
              "                                    0.4916, 0.1680, 0.4473, 0.5304, 0.4774, 0.7717, 0.3827,\n",
              "                                    0.2844, 0.2997, 0.4627, 0.3215, 0.3787, 0.3513, 0.2678,\n",
              "                                    0.4011, 0.4735, 0.2109, 0.4445, 0.4424, 0.2147, 0.1667,\n",
              "                                    0.1916, 0.2384, 0.3340, 0.4791, 0.3976, 0.4397, 0.2045,\n",
              "                                    0.1574, 0.2682, 0.1936, 0.5672, 0.7935, 0.3114, 0.2058,\n",
              "                                    0.3612, 0.1798, 0.3138, 0.3240, 0.4962, 0.2731, 0.4224,\n",
              "                                    0.4221, 0.2700, 0.5388, 0.2425, 0.6349, 0.1468, 0.1444,\n",
              "                                    0.2493, 0.4106, 0.5999, 0.1850, 0.2917, 0.6472, 0.2835,\n",
              "                                    0.4406, 0.4708, 0.2944, 0.2801, 0.4500, 0.2108, 0.2545,\n",
              "                                    0.2357, 0.2007, 0.6016, 0.1780, 0.4633, 0.1540, 0.6643,\n",
              "                                    0.1723, 0.2260, 0.3518, 0.2123, 0.2989, 0.3910, 0.2661,\n",
              "                                    0.2879, 0.2087, 0.2833, 0.6044, 0.4422, 0.5408, 0.1540,\n",
              "                                    0.2232, 0.3615, 0.3855, 0.3572, 0.2992, 0.4294, 0.2758,\n",
              "                                    0.7238, 0.2275, 0.3611, 0.5002, 0.3112, 0.2527, 0.3786,\n",
              "                                    1.2671, 0.1923, 1.1380, 0.5639, 0.2288, 0.3802, 0.3697,\n",
              "                                    0.3814, 0.6194, 0.2011, 0.2044, 0.3371, 0.4186, 0.5605,\n",
              "                                    0.2236, 0.6695, 0.7659, 0.2968, 0.3669, 0.4029, 0.3073,\n",
              "                                    0.5659, 0.2897, 0.2737, 0.3553, 0.4843, 0.6278, 0.2483,\n",
              "                                    0.9508, 0.4801, 0.3928, 0.4564, 0.6736, 0.2621, 0.3612,\n",
              "                                    0.1335, 0.3839, 0.4757, 0.5662, 0.3507, 0.3096, 0.3110,\n",
              "                                    0.2046, 0.1757, 0.3877, 0.2526, 0.2928, 0.7943, 0.2624,\n",
              "                                    0.2022, 0.3777, 0.5368, 0.1563, 0.2321, 0.3637, 0.2420,\n",
              "                                    0.1863, 0.2331, 0.3650, 0.4137, 0.5459, 0.2054, 0.1824,\n",
              "                                    0.3172, 0.5227, 0.2977, 0.6328, 0.4430, 0.4313, 0.4141,\n",
              "                                    0.8940, 0.3440, 0.1862, 0.7600, 0.4075, 0.2369, 0.4161,\n",
              "                                    0.3086, 0.3052, 0.1496, 0.5328, 0.3368, 0.7081, 0.5102,\n",
              "                                    0.3823, 0.6033, 0.4670, 0.2044, 0.6933, 0.1499, 0.4934,\n",
              "                                    0.6414, 0.2540, 0.5621, 0.3830, 0.4067, 0.2987, 0.4236,\n",
              "                                    0.2037, 0.3281, 0.2319, 0.5959, 0.3983, 0.2845, 0.2140,\n",
              "                                    0.4768, 0.1673, 0.5900, 0.2982, 0.2342, 0.3089, 0.3908,\n",
              "                                    0.7078, 0.2780, 0.6385, 0.3119, 0.2141, 0.6866, 0.5205,\n",
              "                                    0.3101, 0.2424, 0.2944, 0.3088, 0.1942, 0.4468, 0.2976,\n",
              "                                    0.4967, 0.3717, 0.2413, 0.1773, 0.6483, 0.7489, 0.3365,\n",
              "                                    0.4539, 0.1604, 0.2488, 0.4020, 0.1692, 0.1755, 0.4342,\n",
              "                                    0.3227, 0.2599, 0.3872, 0.3807, 0.4968, 0.6999, 0.4603,\n",
              "                                    0.1950, 0.5982, 0.3500, 0.3508, 0.4932, 0.2658, 0.6922,\n",
              "                                    0.5187, 0.6685, 0.4196, 0.4277, 0.1249, 0.2981, 0.2309,\n",
              "                                    0.9006, 0.3551, 0.8029, 0.2352, 0.1896, 0.6541, 0.3934,\n",
              "                                    0.4558, 0.2348, 0.6491, 0.3946, 0.4030, 0.3586, 0.5836,\n",
              "                                    0.1283, 0.2651, 0.4984, 0.3515, 1.1787, 0.2258, 0.2878,\n",
              "                                    0.3658, 0.3426, 0.2881, 0.3355, 0.7073, 0.2851, 0.5257,\n",
              "                                    0.3617, 0.5323, 0.2552, 0.3531, 0.2843, 0.1725, 0.4782,\n",
              "                                    0.8203, 0.6919, 0.5738, 0.2407, 0.4394, 0.3251, 0.2732,\n",
              "                                    0.3239, 0.1882, 0.3167, 0.1328, 0.6277, 0.2107, 0.2937,\n",
              "                                    0.2924, 0.5288, 0.2643, 0.3265, 0.2864, 0.2942, 0.3046,\n",
              "                                    0.2189, 0.3761, 0.1822, 0.3210, 0.3180, 0.3521, 0.3404,\n",
              "                                    0.3814, 0.2271, 0.2964, 0.2217, 0.5326, 0.6709, 0.5024,\n",
              "                                    0.3301, 0.9238, 0.2806, 0.2027, 0.3796, 0.1874, 0.6647,\n",
              "                                    0.1415, 0.1720, 0.2630, 0.1812, 0.3368, 0.3300, 0.2059,\n",
              "                                    0.1884, 1.0585, 0.7866, 0.2726, 0.3617, 0.2153, 0.2621,\n",
              "                                    0.3967, 0.8280, 0.1856, 0.3173, 0.3736, 0.7662, 0.1602,\n",
              "                                    0.4104, 0.5005, 0.4589, 0.1193, 0.2434, 0.8464, 0.5519,\n",
              "                                    0.1819, 0.4537, 0.5364, 0.6324, 0.2058, 0.5005, 0.4256,\n",
              "                                    0.4450, 0.6204, 0.1637, 0.5318, 0.1762, 0.4215, 0.4129,\n",
              "                                    0.2277, 0.2301, 0.3510, 0.1883, 0.1722, 0.1599, 0.5770,\n",
              "                                    0.2927, 0.4818, 0.6472, 0.3859, 0.3616, 0.5239, 0.1600,\n",
              "                                    0.2683]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.downsample.0.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   1,   2,  ..., 253, 254, 255],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.0916,  0.0200,  0.1456,  ..., -0.1263,  0.0527,\n",
              "                                    -0.1308]),\n",
              "                     size=(512, 256, 1, 1), nnz=131072, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.downsample.1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9981, 1.0353, 0.9865, 1.0055, 0.9862, 1.0328, 0.9723,\n",
              "                                    1.0267, 0.9978, 1.0066, 0.9981, 1.0041, 1.0038, 1.0008,\n",
              "                                    0.9980, 1.0173, 0.9983, 1.0018, 0.9871, 0.9828, 1.0319,\n",
              "                                    1.0086, 0.9972, 1.0012, 0.9936, 0.9978, 0.9898, 1.0256,\n",
              "                                    0.9844, 0.9970, 0.9770, 0.9884, 0.9908, 0.9875, 0.9979,\n",
              "                                    0.9934, 0.9921, 0.9946, 1.0249, 0.9905, 1.0049, 1.0144,\n",
              "                                    1.0104, 1.0054, 0.9813, 1.0008, 1.0381, 0.9996, 0.9973,\n",
              "                                    1.0045, 1.0176, 1.0024, 0.9729, 0.9933, 1.0163, 1.0322,\n",
              "                                    1.0089, 0.9950, 1.0058, 0.9919, 0.9979, 0.9947, 1.0188,\n",
              "                                    0.9759, 0.9857, 1.0031, 1.0066, 0.9768, 1.0071, 0.9733,\n",
              "                                    0.9971, 0.9951, 1.0327, 0.9915, 0.9948, 1.0091, 1.0080,\n",
              "                                    1.0071, 1.0097, 0.9950, 0.9986, 0.9975, 0.9951, 1.0121,\n",
              "                                    0.9927, 0.9892, 0.9952, 1.0314, 1.0136, 1.0117, 0.9998,\n",
              "                                    1.0030, 0.9837, 0.9961, 1.0079, 1.0095, 1.0098, 1.0080,\n",
              "                                    0.9747, 1.0011, 1.0331, 1.0039, 1.0033, 1.0123, 0.9854,\n",
              "                                    0.9973, 1.0021, 0.9982, 1.0087, 0.9911, 1.0037, 0.9872,\n",
              "                                    0.9952, 1.0157, 0.9823, 1.0036, 0.9973, 1.0173, 1.0485,\n",
              "                                    0.9953, 1.0150, 0.9910, 1.0018, 1.0010, 0.9988, 1.0098,\n",
              "                                    1.0146, 1.0114, 0.9900, 0.9998, 1.0016, 1.0083, 0.9964,\n",
              "                                    1.0043, 0.9837, 1.0034, 1.0198, 0.9830, 1.0024, 0.9892,\n",
              "                                    0.9925, 1.0190, 1.0011, 1.0056, 0.9948, 0.9777, 1.0208,\n",
              "                                    0.9786, 0.9921, 1.0092, 1.0043, 0.9970, 1.0037, 1.0004,\n",
              "                                    1.0042, 0.9846, 0.9937, 1.0019, 0.9961, 1.0101, 0.9988,\n",
              "                                    1.0038, 1.0151, 1.0316, 1.0008, 0.9967, 0.9913, 0.9905,\n",
              "                                    1.0100, 0.9986, 1.0073, 1.0146, 1.0336, 1.0251, 1.0172,\n",
              "                                    1.0038, 0.9961, 1.0197, 0.9960, 1.0343, 0.9918, 1.0019,\n",
              "                                    1.0206, 0.9860, 1.0041, 1.0014, 1.0296, 0.9826, 0.9942,\n",
              "                                    1.0004, 1.0351, 1.0106, 1.0247, 1.0007, 0.9995, 1.0022,\n",
              "                                    0.9958, 0.9796, 1.0082, 0.9968, 1.0061, 1.0102, 0.9762,\n",
              "                                    0.9995, 1.0176, 1.0005, 1.0000, 1.0048, 0.9972, 1.0206,\n",
              "                                    1.0244, 0.9982, 1.0055, 0.9958, 0.9960, 1.0373, 1.0086,\n",
              "                                    1.0186, 0.9713, 0.9943, 1.0070, 1.0052, 1.0298, 1.0259,\n",
              "                                    0.9894, 1.0005, 0.9953, 0.9904, 1.0226, 0.9909, 1.0103,\n",
              "                                    0.9970, 1.0073, 0.9810, 1.0047, 1.0197, 1.0025, 1.0044,\n",
              "                                    1.0137, 0.9968, 0.9895, 0.9911, 0.9745, 1.0331, 0.9945,\n",
              "                                    1.0136, 0.9978, 1.0058, 1.0005, 1.0078, 1.0249, 1.0082,\n",
              "                                    1.0130, 1.0022, 0.9930, 0.9818, 1.0246, 0.9964, 0.9973,\n",
              "                                    1.0107, 1.0036, 1.0028, 0.9909, 0.9799, 0.9977, 1.0097,\n",
              "                                    0.9789, 0.9773, 1.0028, 1.0042, 0.9990, 0.9965, 1.0002,\n",
              "                                    0.9908, 1.0235, 1.0145, 1.0467, 1.0428, 0.9881, 0.9915,\n",
              "                                    0.9979, 0.9942, 1.0065, 0.9910, 1.0029, 1.0146, 1.0068,\n",
              "                                    1.0016, 0.9962, 0.9957, 1.0065, 1.0240, 0.9900, 0.9807,\n",
              "                                    1.0187, 0.9843, 1.0028, 0.9971, 1.0337, 0.9829, 1.0140,\n",
              "                                    1.0060, 0.9862, 1.0241, 0.9935, 1.0049, 1.0127, 1.0186,\n",
              "                                    1.0252, 1.0116, 1.0045, 0.9949, 0.9907, 1.0163, 1.0126,\n",
              "                                    1.0062, 0.9867, 1.0073, 1.0066, 1.0242, 1.0152, 1.0160,\n",
              "                                    0.9965, 0.9963, 1.0339, 1.0127, 0.9935, 0.9965, 0.9815,\n",
              "                                    1.0066, 0.9867, 1.0238, 1.0087, 0.9896, 1.0242, 1.0107,\n",
              "                                    1.0078, 0.9874, 1.0249, 1.0047, 1.0220, 0.9995, 1.0190,\n",
              "                                    1.0177, 1.0140, 0.9953, 1.0055, 0.9978, 1.0106, 1.0006,\n",
              "                                    1.0095, 0.9948, 0.9919, 1.0195, 0.9925, 0.9910, 0.9918,\n",
              "                                    1.0099, 0.9911, 1.0253, 0.9981, 1.0122, 1.0023, 0.9841,\n",
              "                                    0.9901, 1.0041, 1.0021, 1.0030, 1.0369, 0.9982, 1.0043,\n",
              "                                    0.9920, 0.9993, 1.0149, 0.9862, 0.9927, 0.9961, 1.0424,\n",
              "                                    0.9985, 0.9906, 1.0067, 1.0131, 0.9957, 0.9911, 0.9935,\n",
              "                                    0.9986, 0.9954, 0.9835, 1.0316, 1.0188, 0.9877, 1.0317,\n",
              "                                    1.0168, 1.0002, 0.9765, 1.0163, 1.0105, 1.0208, 1.0193,\n",
              "                                    1.0035, 0.9957, 0.9954, 0.9867, 1.0059, 1.0181, 0.9936,\n",
              "                                    0.9920, 1.0208, 1.0268, 1.0043, 0.9772, 1.0038, 1.0071,\n",
              "                                    1.0104, 0.9979, 1.0003, 0.9745, 0.9958, 1.0378, 1.0150,\n",
              "                                    0.9979, 0.9945, 1.0048, 1.0080, 1.0031, 1.0075, 1.0270,\n",
              "                                    0.9975, 0.9890, 0.9812, 1.0005, 0.9944, 1.0108, 0.9693,\n",
              "                                    1.0120, 0.9918, 0.9893, 1.0022, 0.9981, 1.0041, 1.0339,\n",
              "                                    1.0200, 1.0238, 1.0019, 1.0157, 0.9995, 0.9991, 1.0098,\n",
              "                                    0.9944, 0.9910, 0.9604, 1.0183, 0.9986, 0.9879, 1.0161,\n",
              "                                    1.0029, 1.0125, 1.0065, 1.0134, 1.0092, 1.0014, 1.0145,\n",
              "                                    1.0036, 1.0048, 1.0072, 1.0049, 0.9899, 1.0049, 1.0001,\n",
              "                                    1.0006, 1.0006, 1.0150, 1.0014, 1.0118, 1.0329, 1.0167,\n",
              "                                    1.0076, 1.0035, 1.0229, 0.9860, 1.0225, 0.9996, 1.0137,\n",
              "                                    1.0314, 1.0069, 0.9963, 1.0210, 0.9936, 0.9862, 1.0147,\n",
              "                                    1.0230, 0.9938, 1.0116, 0.9817, 1.0042, 1.0057, 1.0015,\n",
              "                                    0.9761, 1.0000, 1.0195, 1.0102, 0.9933, 1.0173, 1.0152,\n",
              "                                    1.0035, 1.0214, 0.9956, 0.9983, 1.0086, 1.0050, 0.9766,\n",
              "                                    0.9990]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.downsample.1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-7.3420e-03,  1.5829e-02, -1.3353e-02, -1.1658e-02,\n",
              "                                    -6.9758e-04,  1.2418e-02, -1.2773e-02,  2.5673e-02,\n",
              "                                     2.9907e-03, -1.3205e-02, -6.2191e-03, -9.5866e-03,\n",
              "                                     2.1872e-02,  1.2216e-03, -1.7084e-02,  5.2572e-03,\n",
              "                                     2.6255e-03,  1.0711e-02, -1.9560e-02, -1.2403e-02,\n",
              "                                     1.1032e-02,  1.0007e-02, -4.7055e-03, -1.5552e-03,\n",
              "                                     2.0940e-02,  1.7341e-02,  2.0948e-03,  1.8797e-03,\n",
              "                                     2.3401e-03,  6.0417e-04,  1.0599e-02, -6.2446e-04,\n",
              "                                    -6.0347e-03, -2.9868e-04,  1.2423e-02,  1.2252e-02,\n",
              "                                     3.5509e-03, -1.5003e-02,  1.5090e-02, -4.0764e-03,\n",
              "                                    -1.0944e-02,  3.1614e-02,  1.2330e-02, -1.4882e-03,\n",
              "                                    -1.6233e-03,  2.3307e-02,  4.8785e-02,  3.6352e-02,\n",
              "                                     2.0514e-02,  7.2525e-04,  4.4711e-03,  7.0527e-03,\n",
              "                                    -3.3220e-02,  6.6863e-03,  1.1024e-02,  1.8470e-02,\n",
              "                                     1.3374e-02,  6.4393e-03,  1.8022e-02,  1.9742e-03,\n",
              "                                     1.0698e-02, -1.2626e-02,  8.1055e-03, -5.8934e-03,\n",
              "                                    -1.5493e-02,  2.1457e-02,  1.4878e-02, -9.3813e-03,\n",
              "                                     6.2736e-03, -5.3990e-03,  4.6348e-03, -6.3436e-03,\n",
              "                                     1.9665e-02,  3.3003e-04,  2.1056e-02,  2.2008e-02,\n",
              "                                     1.3743e-02, -8.1048e-03,  1.2999e-02, -7.9422e-03,\n",
              "                                     1.4670e-02, -6.9992e-03, -2.4269e-02,  2.1707e-02,\n",
              "                                     1.3319e-02,  4.1267e-03, -1.2008e-02, -1.6808e-02,\n",
              "                                     2.2190e-02,  8.2639e-03,  1.2577e-03, -1.6602e-03,\n",
              "                                    -5.4648e-03, -1.4477e-02,  5.4223e-03,  2.1349e-02,\n",
              "                                    -1.4796e-02,  4.8511e-03, -1.2864e-02,  5.5273e-03,\n",
              "                                     3.7755e-02,  1.7002e-02,  3.7077e-04,  5.4918e-02,\n",
              "                                     4.5643e-03, -1.6637e-02,  1.4633e-02,  6.8790e-03,\n",
              "                                     2.9969e-03,  1.1925e-03,  2.2547e-03,  2.3877e-03,\n",
              "                                    -1.2048e-02, -4.7566e-05, -2.9319e-03, -6.9269e-03,\n",
              "                                    -2.1037e-02,  3.5112e-02,  5.2086e-03,  2.4531e-03,\n",
              "                                     1.4743e-03, -8.1653e-04, -2.8224e-04, -8.3904e-03,\n",
              "                                     3.0428e-03,  1.3439e-02,  3.3868e-02,  1.4457e-02,\n",
              "                                     6.7484e-05, -2.5670e-03,  8.1041e-03,  8.4984e-03,\n",
              "                                     5.3505e-03,  6.4761e-03, -4.5120e-03,  2.3435e-03,\n",
              "                                     1.2621e-02,  1.0075e-02,  1.8983e-02, -1.7654e-02,\n",
              "                                    -1.2681e-02,  2.4306e-02, -4.9227e-04,  6.7040e-03,\n",
              "                                    -2.1241e-02, -9.6869e-03,  4.8961e-03,  4.7716e-03,\n",
              "                                    -1.0669e-02,  1.7838e-02, -1.2109e-02,  7.5567e-03,\n",
              "                                     1.4946e-02, -5.7108e-03,  3.9381e-03, -8.3012e-03,\n",
              "                                    -5.5947e-04, -3.0626e-03, -9.9089e-03,  3.0942e-02,\n",
              "                                    -4.4332e-03, -1.1405e-02,  4.1937e-03,  2.9669e-02,\n",
              "                                    -1.7673e-03, -1.3964e-03, -3.5497e-03, -2.5651e-03,\n",
              "                                    -7.0994e-03, -2.7325e-03, -7.6035e-03,  2.1520e-02,\n",
              "                                     2.9094e-02,  7.0162e-03,  2.0216e-02, -5.8935e-03,\n",
              "                                    -9.7931e-04,  5.6520e-03, -8.8973e-03,  3.5748e-02,\n",
              "                                    -1.5345e-02,  4.7388e-03,  4.0003e-03, -1.3396e-02,\n",
              "                                     1.0611e-02, -1.4769e-02,  3.0760e-02, -2.8757e-03,\n",
              "                                     1.6395e-03, -3.3011e-03, -1.2607e-02, -2.3510e-04,\n",
              "                                     5.9626e-03,  2.4161e-02, -1.5697e-03, -1.9223e-02,\n",
              "                                     9.5713e-03,  1.7313e-02,  1.6593e-02,  3.6466e-03,\n",
              "                                     7.8828e-03,  1.6880e-02, -9.6234e-03, -8.6595e-03,\n",
              "                                     2.1123e-02,  1.3363e-02, -6.4540e-03,  2.7568e-03,\n",
              "                                    -4.7229e-03,  2.7430e-02,  9.8517e-03,  8.0810e-04,\n",
              "                                     1.7922e-03,  4.5046e-03, -8.6062e-03,  9.9669e-03,\n",
              "                                    -6.7919e-03,  1.3580e-02, -2.8260e-02,  9.3391e-03,\n",
              "                                     9.6368e-03, -5.8605e-03,  2.6609e-02,  1.5243e-02,\n",
              "                                     1.5500e-03, -2.2261e-02, -1.1164e-03, -2.3216e-02,\n",
              "                                     5.1233e-03, -3.5174e-03, -8.1151e-04,  2.3524e-04,\n",
              "                                    -7.0456e-03, -3.7211e-03,  1.1169e-02,  1.3406e-02,\n",
              "                                     7.5314e-03, -1.4691e-02,  2.0409e-02, -6.4041e-03,\n",
              "                                    -1.0678e-02,  6.7104e-04, -6.2731e-03,  6.1420e-03,\n",
              "                                     6.7533e-03, -3.9473e-03,  1.1990e-02, -9.7771e-03,\n",
              "                                    -9.4688e-03,  7.0661e-03,  1.9506e-02,  3.5927e-03,\n",
              "                                     2.3563e-02,  1.1683e-02, -8.4393e-03,  5.8344e-03,\n",
              "                                     3.1793e-02,  7.5802e-03, -4.1134e-03,  7.0568e-03,\n",
              "                                     6.9101e-03, -4.9845e-04,  2.4591e-03,  1.8775e-02,\n",
              "                                     2.6359e-02, -2.2554e-03,  1.7916e-03, -1.9061e-02,\n",
              "                                    -1.1813e-03,  1.1498e-02, -1.5413e-02, -2.7060e-02,\n",
              "                                    -1.6616e-03, -1.1471e-02,  2.2324e-02,  1.3545e-02,\n",
              "                                     1.8870e-02,  1.3532e-02, -2.0675e-02, -2.5223e-02,\n",
              "                                    -6.3017e-03,  5.7834e-03,  6.3913e-03, -7.2516e-03,\n",
              "                                    -1.7813e-04,  1.0894e-02,  4.2072e-03,  1.5194e-02,\n",
              "                                    -1.0124e-02,  2.4339e-03,  1.4852e-02,  1.9755e-02,\n",
              "                                    -3.6937e-03, -1.5914e-02,  3.1758e-03, -2.9417e-03,\n",
              "                                     5.2829e-03,  3.8191e-03,  2.9085e-02, -1.0962e-02,\n",
              "                                     1.6613e-02,  7.3852e-03,  9.9595e-03, -1.4518e-02,\n",
              "                                     6.6218e-03,  1.3456e-02,  1.8210e-02, -6.5940e-03,\n",
              "                                     1.3814e-02,  2.7119e-03, -7.4716e-03,  5.0981e-03,\n",
              "                                     8.6716e-03, -2.2612e-03,  2.0755e-02,  1.3596e-02,\n",
              "                                     1.0079e-02, -1.6182e-02, -8.1829e-03,  1.3350e-02,\n",
              "                                     8.6024e-03,  6.3807e-03, -8.2524e-03,  4.7418e-02,\n",
              "                                     1.4168e-02,  1.0206e-02, -2.6856e-02,  2.0198e-02,\n",
              "                                     7.3275e-03,  2.1363e-02, -1.4258e-03,  6.3668e-02,\n",
              "                                     5.5674e-03, -1.5288e-02,  8.7831e-03, -1.5548e-02,\n",
              "                                     2.0380e-03, -6.3860e-04,  2.1574e-02, -2.1758e-03,\n",
              "                                     1.0095e-02,  1.2607e-02,  2.2328e-02,  7.6587e-03,\n",
              "                                     2.6392e-02, -1.1077e-03,  1.8686e-02,  1.1797e-03,\n",
              "                                     8.3762e-03,  1.6497e-02,  3.8726e-04,  1.8386e-02,\n",
              "                                    -9.7500e-03,  1.4893e-02, -1.1076e-02, -6.3756e-03,\n",
              "                                    -1.3638e-02,  3.0844e-03,  5.1841e-04,  2.4988e-02,\n",
              "                                     9.7099e-04,  1.6899e-02,  8.0157e-03,  9.1297e-03,\n",
              "                                     1.3663e-02,  7.9862e-04, -2.6684e-04, -1.3488e-03,\n",
              "                                     1.9885e-02,  2.9527e-03,  1.4844e-02, -6.3569e-03,\n",
              "                                     4.4369e-03,  3.3878e-02,  5.2448e-03,  2.2781e-03,\n",
              "                                     1.2104e-02,  7.2619e-03,  4.2152e-03, -8.4997e-03,\n",
              "                                     5.9676e-03,  1.6968e-02,  4.5429e-03, -5.4194e-03,\n",
              "                                    -8.4456e-03, -1.1900e-02, -6.8071e-03,  1.1867e-03,\n",
              "                                    -7.7309e-03,  9.7701e-03, -1.2234e-02,  5.8339e-02,\n",
              "                                     5.5262e-03,  4.5966e-03,  1.3489e-02, -2.3432e-02,\n",
              "                                     2.0794e-02,  9.0588e-03,  1.2525e-02,  1.4257e-02,\n",
              "                                     9.5067e-05,  1.0882e-02,  6.2375e-03,  9.2954e-03,\n",
              "                                     1.3175e-02, -1.2174e-02, -1.9550e-02,  2.9069e-02,\n",
              "                                     2.3549e-02,  8.9992e-04,  1.1667e-02, -6.1100e-03,\n",
              "                                    -1.1643e-02,  2.7193e-02,  3.5518e-03, -1.4889e-02,\n",
              "                                     1.5619e-02,  6.6867e-04,  1.1228e-02,  4.0002e-03,\n",
              "                                     9.8135e-03, -8.6253e-03,  1.3300e-02,  8.2248e-03,\n",
              "                                     2.1166e-02,  2.6036e-02,  4.5261e-03,  8.8262e-03,\n",
              "                                    -1.5600e-03, -1.3753e-02,  6.9826e-03, -7.8066e-04,\n",
              "                                    -4.2286e-03, -1.8624e-02,  3.5226e-02,  1.1513e-02,\n",
              "                                    -2.3341e-02,  1.1408e-02, -3.2299e-03,  1.7419e-02,\n",
              "                                    -3.2432e-03, -1.8755e-02,  2.1268e-03, -1.8727e-03,\n",
              "                                    -4.6743e-03, -8.6940e-03,  9.0945e-03,  3.5870e-03,\n",
              "                                     1.4249e-02, -5.3388e-03, -6.8062e-03,  3.4985e-02,\n",
              "                                    -5.1499e-03, -1.8929e-03,  9.4134e-03,  7.6301e-03,\n",
              "                                     2.0445e-02,  2.6292e-02, -6.4649e-03,  2.1201e-02,\n",
              "                                     7.5673e-03,  7.7357e-03, -1.1645e-02,  7.1298e-03,\n",
              "                                    -1.1496e-02,  1.9517e-02, -3.9329e-03, -2.6074e-03,\n",
              "                                     6.5233e-03,  4.1501e-03,  1.2945e-02,  9.8707e-04,\n",
              "                                     9.6383e-03,  9.1639e-03,  6.0479e-03,  6.5222e-03,\n",
              "                                    -4.8405e-03,  2.4522e-03, -2.4588e-03, -1.9205e-03,\n",
              "                                     3.2258e-02, -5.0829e-03,  2.0129e-02,  3.1682e-03,\n",
              "                                     2.3181e-02,  7.9641e-03,  2.2519e-02,  1.2250e-02,\n",
              "                                    -1.7356e-02, -2.1772e-03,  3.9567e-02, -1.3167e-02,\n",
              "                                    -1.1699e-03, -3.5785e-03,  5.5433e-03, -2.4103e-04,\n",
              "                                    -8.1706e-03, -2.9913e-02, -3.6982e-03,  1.6842e-02,\n",
              "                                     9.1549e-03,  8.8854e-03,  2.4169e-02,  1.0040e-02,\n",
              "                                    -8.0329e-03,  1.2653e-02,  1.9025e-03,  7.8929e-04,\n",
              "                                    -1.9888e-02,  1.3294e-02, -6.2359e-03,  4.7654e-03]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.downsample.1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-1.6738e+00,  1.9722e-01, -1.4032e+00, -1.0190e+00,\n",
              "                                     8.4970e-01, -1.4136e+00, -1.6026e+00,  1.1634e+00,\n",
              "                                    -3.2161e-01, -2.5652e-01,  3.5169e-01,  5.2043e-01,\n",
              "                                     8.8562e-02, -1.0821e+00, -1.6991e+00,  1.0176e+00,\n",
              "                                    -2.3500e+00,  6.1447e-01,  7.6931e-01, -2.1054e+00,\n",
              "                                     4.4133e-01, -6.6644e-01, -6.5390e-01, -1.4442e+00,\n",
              "                                    -1.3412e-01,  2.6844e+00,  1.3002e+00, -7.7668e-01,\n",
              "                                     2.1886e+00,  9.4045e-01,  2.6714e+00, -1.4460e+00,\n",
              "                                     9.4208e-01,  1.7017e+00,  1.3727e+00, -1.7540e+00,\n",
              "                                    -1.4280e+00, -1.4342e+00,  1.6334e-01,  1.6199e+00,\n",
              "                                    -7.2355e-01,  6.8513e-01,  1.4815e+00, -1.5441e-01,\n",
              "                                    -3.3721e-01,  1.9177e+00, -7.0357e-01, -6.6283e-02,\n",
              "                                     1.3446e-02,  6.2419e-01, -4.0686e-02,  1.8805e+00,\n",
              "                                     2.6758e-01,  2.9325e+00,  4.0577e-01,  3.6281e-01,\n",
              "                                     8.0334e-01,  3.0560e-01, -3.7133e-01, -7.8379e-01,\n",
              "                                    -5.6518e-01, -1.4626e+00,  3.5797e-01,  3.7347e-02,\n",
              "                                    -7.3672e-01, -2.9659e-01, -4.2162e-01,  1.0528e+00,\n",
              "                                    -2.1193e+00, -2.3141e+00, -8.7185e-01, -1.9166e+00,\n",
              "                                     3.5098e-01,  1.1298e+00,  1.4081e+00, -1.8649e+00,\n",
              "                                    -1.3922e-01,  8.4023e-01,  1.4751e+00, -5.5819e-01,\n",
              "                                     8.8244e-01, -1.2754e-01,  6.9864e-01, -9.2895e-01,\n",
              "                                    -2.2350e+00, -2.4479e-01,  1.7962e+00, -8.8788e-01,\n",
              "                                     4.1924e-01,  5.0084e-01,  7.7632e-01, -1.1722e-01,\n",
              "                                     1.6815e-01, -5.5140e-01,  7.2932e-01,  1.0092e+00,\n",
              "                                     1.2618e-01, -2.1549e+00,  2.1604e-01,  1.0710e+00,\n",
              "                                     6.7212e-01,  6.8708e-01,  1.1091e+00,  1.5962e+00,\n",
              "                                     1.0222e+00, -1.6552e+00,  5.5887e-01, -8.2774e-01,\n",
              "                                    -1.0282e+00, -8.6023e-01,  1.2245e-01, -4.5082e-01,\n",
              "                                    -1.0265e+00,  5.0338e-01, -7.1859e-01,  9.8365e-01,\n",
              "                                    -9.6508e-01,  1.8169e+00, -2.2791e-01,  1.8568e+00,\n",
              "                                     3.4863e-01, -5.8585e-01,  3.1274e-01, -8.6674e-01,\n",
              "                                     9.1466e-01, -1.9180e+00, -1.9365e-01,  1.0220e+00,\n",
              "                                    -1.6025e+00, -1.6713e+00,  6.2022e-01,  4.3775e-01,\n",
              "                                     1.1844e+00,  9.6711e-01,  7.2986e-01,  1.9491e+00,\n",
              "                                    -2.0809e-01,  2.9367e+00, -1.0273e+00, -4.8932e-01,\n",
              "                                     6.2299e-01, -4.5622e-01, -5.3479e-01,  2.9131e-01,\n",
              "                                    -1.9373e-01,  8.4746e-01, -7.5509e-01,  1.4491e+00,\n",
              "                                     2.2171e-01, -2.7717e-01,  3.5781e-01,  8.2823e-01,\n",
              "                                    -2.2576e+00, -1.0645e+00, -1.6936e+00, -7.4174e-01,\n",
              "                                    -1.2802e+00, -3.4680e-01, -9.9135e-03,  1.7796e+00,\n",
              "                                    -6.8058e-01, -7.7807e-01, -7.1539e-01,  1.4289e-01,\n",
              "                                    -7.6323e-01,  6.8149e-01, -1.2085e+00, -2.2835e+00,\n",
              "                                    -8.7792e-01,  5.6313e-01,  1.0533e+00, -1.4184e+00,\n",
              "                                    -8.2542e-01, -3.9213e-01,  8.0656e-02,  6.2709e-01,\n",
              "                                    -1.6944e+00, -1.0405e+00, -1.2856e-01,  9.8882e-01,\n",
              "                                     1.2251e-01,  3.0111e-02,  9.0081e-01,  7.1628e-01,\n",
              "                                    -1.4501e+00,  1.2836e-02,  2.0279e-01,  1.6299e+00,\n",
              "                                    -8.5905e-01, -8.9947e-01, -1.0229e+00,  1.8660e+00,\n",
              "                                     1.1191e+00,  7.2217e-01,  2.3638e-01, -1.3030e+00,\n",
              "                                    -5.5282e-01, -7.3104e-01, -3.0618e-01,  1.8991e+00,\n",
              "                                    -1.3097e-01,  1.8376e+00, -1.4661e+00,  2.1297e-01,\n",
              "                                     9.1882e-01,  2.8739e-01,  5.8877e-01, -1.0245e+00,\n",
              "                                     1.3085e+00, -6.9923e-01, -9.8511e-02,  2.7443e-01,\n",
              "                                     2.1690e-01, -5.0147e-01, -6.1337e-01, -4.4170e-01,\n",
              "                                     2.5813e-01, -4.5048e-01,  1.6703e+00,  7.9230e-03,\n",
              "                                     3.8109e-01, -1.7190e+00,  1.1628e+00, -9.2693e-02,\n",
              "                                     1.8665e+00, -3.6231e-01,  2.6892e-01, -8.5382e-01,\n",
              "                                    -6.5501e-01, -1.2072e+00, -1.6288e-01, -8.9870e-01,\n",
              "                                    -9.7198e-02, -5.1662e-01, -1.2980e+00, -1.6982e-01,\n",
              "                                     1.0363e+00,  1.3699e+00,  1.6817e+00,  8.8705e-01,\n",
              "                                    -1.3379e+00,  1.7534e-01, -2.0042e+00,  6.2503e-01,\n",
              "                                    -2.1707e+00,  1.3994e+00,  1.5014e+00, -2.8034e+00,\n",
              "                                     1.1243e+00, -3.8323e-01,  1.3465e+00, -6.8059e-01,\n",
              "                                     2.6953e-02, -3.8105e-02, -1.2742e+00, -2.3246e+00,\n",
              "                                     5.1355e-01,  6.4724e-01,  1.3615e+00, -1.6281e-01,\n",
              "                                    -1.9347e+00,  8.9101e-01, -9.2338e-02, -1.2493e+00,\n",
              "                                     6.9990e-01,  5.9776e-01, -7.4583e-02, -7.6691e-01,\n",
              "                                     4.8758e-01, -1.0246e+00,  1.1004e+00,  1.8126e+00,\n",
              "                                    -1.8015e+00, -4.9205e-01,  9.6602e-01,  1.2365e+00,\n",
              "                                    -2.4855e-01,  9.2745e-01, -3.0810e-01, -6.6343e-02,\n",
              "                                    -7.5349e-01,  7.7310e-02,  4.5023e-01,  1.1565e+00,\n",
              "                                     9.6295e-01,  6.4390e-01, -1.1213e+00, -9.0911e-01,\n",
              "                                     1.2212e+00, -8.2706e-02,  4.3432e-01, -2.4929e-01,\n",
              "                                    -5.3310e-01, -1.7294e+00,  1.5481e+00, -2.0428e+00,\n",
              "                                    -1.4524e+00, -1.0535e+00,  1.8361e-01,  5.1587e-01,\n",
              "                                     9.2283e-01,  1.2288e+00, -9.7919e-01,  1.9393e+00,\n",
              "                                    -4.0709e-01,  1.1719e+00, -4.7218e-01,  8.4377e-01,\n",
              "                                     1.1417e+00,  2.0520e-01,  6.5606e-01,  2.0219e-01,\n",
              "                                    -6.4006e-01, -1.6848e+00,  2.8907e-01,  7.3892e-01,\n",
              "                                     8.9581e-01, -1.2626e+00, -1.3352e-03,  1.4166e+00,\n",
              "                                     6.2718e-01,  1.2166e+00,  8.2393e-01,  1.3617e+00,\n",
              "                                    -6.0939e-01,  1.5513e-01,  5.4596e-01,  1.5297e+00,\n",
              "                                    -9.9253e-01, -1.6032e+00,  1.6289e+00,  1.4820e+00,\n",
              "                                    -2.2827e-01, -2.2070e+00, -5.4144e-01, -2.2538e+00,\n",
              "                                    -7.4471e-02, -1.2308e+00,  7.3073e-01,  1.7941e+00,\n",
              "                                     5.5528e-02,  3.2578e-02,  1.8167e+00, -2.7187e+00,\n",
              "                                     1.3897e+00, -9.7302e-01,  9.4557e-01, -3.5756e-01,\n",
              "                                     2.6998e-01,  1.5194e+00, -3.0071e-01, -1.3354e+00,\n",
              "                                    -1.8158e-01,  7.5108e-01, -3.7589e-01, -3.5362e-02,\n",
              "                                    -1.2589e+00,  1.5051e-01,  2.0721e+00, -2.7798e-01,\n",
              "                                     7.8403e-01,  3.1860e-01,  1.1143e+00, -4.9654e-02,\n",
              "                                     9.3270e-01, -2.2283e-01, -3.7804e-01, -1.2861e+00,\n",
              "                                     3.5647e-01, -1.1917e+00, -3.7064e-01, -1.3971e+00,\n",
              "                                     1.5218e-01,  2.0415e+00, -1.4451e-01, -1.2259e+00,\n",
              "                                    -3.1833e-01,  6.0934e-01,  8.8009e-01,  1.1390e+00,\n",
              "                                     6.5163e-01,  1.6055e+00, -2.3158e+00,  1.3770e+00,\n",
              "                                    -1.2980e+00, -6.0301e-01, -1.3687e-01,  1.7321e+00,\n",
              "                                    -7.7262e-02,  8.3553e-01, -4.2305e-01, -2.5659e-01,\n",
              "                                     4.4436e-01, -9.1448e-01,  4.3878e-02,  6.3692e-01,\n",
              "                                     7.9514e-01,  9.7614e-01,  1.4682e+00, -3.6144e-01,\n",
              "                                    -4.6518e-01,  1.4654e-01, -2.6660e-01,  2.2998e+00,\n",
              "                                     1.7070e+00, -2.6535e-01, -7.6686e-01,  1.0835e-01,\n",
              "                                     1.0185e+00,  3.3347e-01, -3.1610e+00,  4.8577e-01,\n",
              "                                     4.7406e-03,  1.0549e+00,  1.8121e-01,  1.8215e-01,\n",
              "                                    -8.3481e-02,  3.5090e-01,  3.5665e-01, -7.7002e-01,\n",
              "                                     8.2767e-01, -1.5840e+00,  1.4312e+00, -5.2551e-01,\n",
              "                                    -1.1431e-01, -5.5195e-01, -5.1038e-01, -1.5930e+00,\n",
              "                                     1.6977e+00, -1.7730e+00, -1.4284e+00, -1.1157e-02,\n",
              "                                     1.0905e+00,  8.1632e-01, -8.4568e-01,  8.5285e-01,\n",
              "                                    -2.7311e+00, -7.8379e-02,  2.0907e-01,  3.9237e-01,\n",
              "                                    -1.7107e-01, -6.6942e-01,  3.4896e-01, -5.6176e-01,\n",
              "                                    -5.5338e-01, -1.5238e-01, -1.7274e-01, -6.1086e-01,\n",
              "                                     3.2487e-01, -1.1746e+00, -1.0248e+00,  1.0426e+00,\n",
              "                                     9.5224e-01,  4.7669e-02, -2.4829e-01,  6.6598e-01,\n",
              "                                     2.8501e-01, -1.3334e+00, -1.0766e+00, -6.4792e-01,\n",
              "                                    -4.8533e-01,  8.5803e-01, -3.4537e-01, -1.2100e+00,\n",
              "                                    -2.3943e+00,  6.4893e-01, -5.3168e-01, -1.1383e+00,\n",
              "                                    -1.4306e+00, -2.2440e+00, -4.5321e-01, -3.5828e-01,\n",
              "                                    -1.7921e+00,  3.8999e-01,  3.9489e-01, -1.3173e-01,\n",
              "                                     3.5528e-01,  6.0723e-01,  3.7473e-01, -1.7431e+00,\n",
              "                                     4.7451e-02, -1.8045e-01, -1.2617e+00,  5.6933e-01,\n",
              "                                     7.1888e-01,  5.5804e-02, -1.9129e-01, -1.7769e+00,\n",
              "                                    -9.5765e-01, -2.6079e-01,  1.0419e+00,  7.6426e-01,\n",
              "                                    -3.5882e-01,  1.0168e+00,  1.9032e+00, -1.6140e+00,\n",
              "                                    -1.3242e+00, -9.2634e-01, -8.1541e-01,  4.5359e-01,\n",
              "                                     1.6244e+00,  4.9651e-01,  1.4266e+00,  1.1331e+00,\n",
              "                                    -1.8460e-01,  8.8810e-01, -1.0772e+00, -9.8517e-01,\n",
              "                                    -2.6584e-01,  1.7640e+00, -1.4205e+00, -1.9648e+00]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.downsample.1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 4.0785,  1.3760,  4.5566,  2.2770,  1.7981,  5.4206,\n",
              "                                     4.5403,  2.1196,  3.4357,  3.5206,  1.9933,  3.0678,\n",
              "                                     3.0121,  3.0972,  6.7839,  3.1941,  6.4552,  5.1355,\n",
              "                                     2.5831,  5.1374,  2.5870,  2.6386,  1.4409,  1.8606,\n",
              "                                     1.0745, 11.9826,  6.0022,  3.4743,  6.7591,  2.4137,\n",
              "                                     8.1652,  2.4084,  1.9931,  6.2559,  5.5446,  2.8315,\n",
              "                                     2.1439,  3.0892,  4.6885,  5.5149,  2.1757,  4.5721,\n",
              "                                     5.1312,  2.0221,  4.6687,  7.8262,  4.5389,  1.3772,\n",
              "                                     3.6725,  3.3578,  2.0407, 10.1463,  2.2575,  5.7254,\n",
              "                                     3.4635,  7.4297,  5.3981,  1.8464,  1.4963,  6.6845,\n",
              "                                     2.0026,  2.7179,  2.4624,  2.2817,  3.2372,  3.0799,\n",
              "                                     1.7648,  3.0614,  6.8977,  3.5885,  2.4184,  3.2714,\n",
              "                                     3.9315,  2.8896,  6.7217, 11.3197,  4.1699,  1.5181,\n",
              "                                     4.1029,  7.7033,  2.4447,  2.6081,  4.1019,  6.9661,\n",
              "                                     2.3278,  2.3076,  7.8037,  1.0920,  3.7295,  2.1711,\n",
              "                                     4.2923,  3.2397,  1.7405,  3.4093,  3.5574,  5.6963,\n",
              "                                     1.4877,  7.2696,  5.1011,  4.5818,  2.2853,  5.5507,\n",
              "                                     1.2317,  5.6451,  4.4885,  2.7162,  2.2594,  3.6124,\n",
              "                                     2.5013,  1.8982,  1.7346,  2.1841,  6.4935,  2.7211,\n",
              "                                     2.8190,  2.3671,  3.2900,  5.1526,  2.1489,  3.5381,\n",
              "                                     1.7469,  4.6283,  6.7320,  4.3730,  0.7248,  9.1074,\n",
              "                                     3.1788,  2.8296,  2.6546,  7.7486,  4.5734,  2.5487,\n",
              "                                     2.5808,  6.3087,  3.5019,  2.8554,  1.7518, 11.2714,\n",
              "                                     3.3857,  1.7427,  1.8512,  2.4633,  3.8685,  2.0969,\n",
              "                                     4.6685,  4.5116,  4.2643,  4.6652,  3.7399,  2.7832,\n",
              "                                     2.8175,  2.9059,  5.4640,  4.0624,  6.5883,  5.5054,\n",
              "                                     4.0458,  2.7578,  1.5538,  9.3661,  1.5426,  6.6049,\n",
              "                                     2.7537,  4.3585,  3.6058,  7.5925,  1.0752,  3.0561,\n",
              "                                     1.6245,  3.1729,  2.4346,  3.6739,  2.5962,  2.5644,\n",
              "                                     5.0680,  1.8971,  3.8298,  5.5227,  2.5822,  3.7314,\n",
              "                                     1.2064,  3.6965,  4.4052,  2.2777,  2.4333,  4.3648,\n",
              "                                     2.4128,  2.6556,  1.0573,  6.3346,  2.7991,  2.1686,\n",
              "                                     3.0029,  2.0470,  2.9343,  2.7471,  4.1586,  3.4441,\n",
              "                                     1.6672,  4.4479,  3.2079,  5.1368,  5.5537,  1.8539,\n",
              "                                     2.6862,  4.3086,  2.8919,  1.8736,  3.6193,  3.5890,\n",
              "                                     3.7425,  2.5502,  4.5774,  3.0544,  1.9020,  1.8227,\n",
              "                                     2.4557,  1.3868,  6.6701,  3.7065,  4.3232,  5.0805,\n",
              "                                     1.8111,  2.2964,  2.3606,  0.8053,  3.9448,  2.6792,\n",
              "                                     2.5002,  4.0207,  2.1621,  3.2728,  2.7431,  2.9416,\n",
              "                                     2.1281,  4.1225,  2.9550,  3.0605,  3.2074,  4.7489,\n",
              "                                     4.0173,  1.0699,  8.0590,  3.3018,  2.8155,  2.5220,\n",
              "                                     6.9849,  5.9944,  2.2931,  4.7487,  5.5048,  5.0572,\n",
              "                                     1.7788,  1.7672,  4.6835,  3.2013,  1.5422,  1.3944,\n",
              "                                     3.6843,  3.0638,  5.4251,  3.5041,  5.2807,  3.2851,\n",
              "                                     3.8476,  1.9192,  1.0031,  1.1428,  5.0433,  2.5128,\n",
              "                                     2.2966,  2.3607,  3.1340,  1.7385,  4.3379,  3.3369,\n",
              "                                     3.8367,  1.8420,  2.7384,  2.4415,  2.4384,  1.8802,\n",
              "                                     2.0995,  4.6491,  3.5900,  1.8044,  3.5870,  2.3485,\n",
              "                                     4.0855,  1.9884,  4.4621,  4.1479,  3.0361,  1.3403,\n",
              "                                     1.3863,  6.5135,  8.4790,  4.3496,  2.4263,  4.1806,\n",
              "                                     3.5332,  1.2739,  2.9057,  2.5190,  2.1574,  3.5566,\n",
              "                                     4.5992,  3.0623,  2.4880,  2.3174,  3.2832,  3.4086,\n",
              "                                     4.5924,  2.0159,  2.9922,  2.0312,  2.2041,  2.1486,\n",
              "                                     2.8598,  2.3087,  2.5249,  2.7318,  2.8314,  4.3608,\n",
              "                                     3.4772,  0.9637,  4.0936,  5.3309,  3.8014, 11.1924,\n",
              "                                     3.0849,  7.4407,  2.4765,  2.6428,  2.1697,  5.4203,\n",
              "                                     2.7506,  4.0306,  4.6387,  2.5361,  3.4501,  2.3570,\n",
              "                                     6.5380, 13.1718,  3.6972,  3.7161,  7.2556,  4.4154,\n",
              "                                     2.4981,  4.4502,  3.6917,  8.6175,  1.6089,  1.8515,\n",
              "                                     2.1146,  1.5256,  3.5318,  1.3795,  8.7361,  3.2789,\n",
              "                                     3.1035,  5.4178,  3.2094,  2.2874,  5.8849,  2.5070,\n",
              "                                     2.7341,  4.2541,  5.5568,  2.5888,  1.3457,  2.1974,\n",
              "                                     2.5825,  4.6132,  2.3176,  9.5175,  1.6131,  3.4761,\n",
              "                                     3.1885,  2.4839,  7.6759,  1.9515,  6.1963,  6.3504,\n",
              "                                     3.4191,  4.6356,  1.9417,  3.1517,  1.9713,  1.2321,\n",
              "                                     2.4842,  4.2999,  1.0271,  1.3365,  5.9513,  3.3433,\n",
              "                                     6.4920,  2.2206,  2.5729,  3.6695,  1.1725,  3.4146,\n",
              "                                     6.0450,  5.8115,  5.5467,  2.5218,  2.0595,  1.8556,\n",
              "                                     4.8132,  1.5255,  5.5149,  2.0914,  5.2328,  8.6902,\n",
              "                                     2.9729,  4.2356,  2.8491,  3.0739,  4.1026,  2.2094,\n",
              "                                     2.8026,  5.1521,  6.1613,  2.5939,  2.0513,  2.0866,\n",
              "                                     3.2086,  6.4350,  8.6797,  6.3478,  6.3062,  2.1993,\n",
              "                                     2.8986,  3.3998,  1.9654,  1.3997,  4.5443,  1.0730,\n",
              "                                     2.7326,  1.1583,  2.0614,  2.9020,  1.5610,  3.3599,\n",
              "                                     2.1696,  1.3064,  7.4567,  3.1435,  2.0793,  4.3333,\n",
              "                                     2.0048,  3.8404,  5.0201,  1.4993,  3.9678,  2.3124,\n",
              "                                     2.7829,  1.7207,  1.6660,  2.9153,  1.3016,  4.4147,\n",
              "                                     2.5128,  3.4675,  4.2303,  1.9673,  6.3038,  4.5185,\n",
              "                                     2.2793,  3.9119,  1.9062,  2.3652,  3.2132,  3.0918,\n",
              "                                     3.3931,  1.8415,  1.5196,  2.2768,  2.7908,  3.4130,\n",
              "                                     4.0205,  3.7151,  3.9108,  2.1466,  2.8363,  2.2928,\n",
              "                                     2.9907,  3.2528,  2.7653,  6.0760,  6.5182,  1.2298,\n",
              "                                     4.8485,  2.6454,  3.8738,  4.4103,  2.3222,  1.1549,\n",
              "                                     2.8962,  4.2992,  2.1114,  3.8261,  3.5783,  2.9532,\n",
              "                                     1.6049,  2.2742,  5.1441,  6.2408,  4.4903,  4.0346,\n",
              "                                     3.0526,  2.9217]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.0.downsample.1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   1,   2,  ..., 509, 510, 511],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.1925,  0.0855,  0.0108,  ...,  0.0012, -0.0004,\n",
              "                                    -0.0807]),\n",
              "                     size=(128, 512, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([0.9899, 0.9823, 1.0318, 1.0095, 1.0113, 0.9802, 0.9874,\n",
              "                                    1.0040, 0.9806, 1.0265, 0.9955, 0.9919, 0.9880, 1.0066,\n",
              "                                    1.0109, 1.0136, 1.0001, 0.9851, 0.9824, 0.9632, 1.0168,\n",
              "                                    1.0204, 1.0028, 1.0173, 0.9888, 1.0205, 1.0119, 1.0231,\n",
              "                                    0.9992, 1.0119, 0.9852, 1.0590, 1.0152, 0.9895, 0.9843,\n",
              "                                    0.9875, 0.9906, 1.0249, 0.9901, 1.0143, 1.0006, 0.9978,\n",
              "                                    1.0265, 0.9871, 1.0165, 1.0093, 0.9797, 0.9965, 1.0172,\n",
              "                                    1.0037, 1.0009, 1.0035, 1.0055, 1.0002, 0.9797, 1.0063,\n",
              "                                    0.9977, 0.9846, 0.9965, 0.9863, 1.0073, 1.0065, 0.9819,\n",
              "                                    1.0069, 1.0041, 0.9844, 1.0071, 0.9956, 0.9902, 0.9904,\n",
              "                                    0.9939, 0.9925, 0.9788, 0.9950, 0.9976, 1.0185, 1.0106,\n",
              "                                    0.9677, 1.0351, 1.0062, 0.9966, 0.9944, 1.0042, 1.0054,\n",
              "                                    1.0074, 0.9986, 1.0042, 1.0052, 0.9844, 0.9983, 1.0106,\n",
              "                                    0.9856, 1.0103, 0.9876, 1.0224, 0.9853, 1.0001, 0.9823,\n",
              "                                    1.0064, 0.9902, 1.0137, 1.0069, 1.0096, 0.9917, 0.9930,\n",
              "                                    0.9869, 0.9989, 0.9729, 0.9830, 1.0228, 1.0148, 0.9924,\n",
              "                                    0.9981, 1.0005, 1.0121, 0.9874, 0.9858, 0.9861, 0.9906,\n",
              "                                    0.9991, 1.0209, 1.0040, 1.0227, 0.9941, 1.0277, 0.9813,\n",
              "                                    0.9922, 0.9927]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 6.3754e-03,  6.9154e-05, -1.3830e-02,  5.8373e-03,\n",
              "                                     7.4319e-03, -2.4777e-02, -6.5849e-03, -2.2086e-03,\n",
              "                                     7.5502e-03,  7.6460e-03, -5.5184e-04,  1.5494e-02,\n",
              "                                     6.8301e-03, -6.5356e-03,  2.5458e-02,  2.7237e-02,\n",
              "                                     3.9857e-03, -7.2849e-03, -8.2828e-03, -1.1374e-02,\n",
              "                                    -3.3409e-04,  1.7194e-02, -2.3605e-03,  1.0814e-02,\n",
              "                                    -2.4095e-02, -1.0452e-02,  1.0483e-02,  8.4852e-03,\n",
              "                                     5.1362e-03, -1.3294e-02, -8.9487e-03,  2.0505e-02,\n",
              "                                     1.6939e-02,  1.0321e-02, -2.1536e-02, -6.1815e-03,\n",
              "                                    -1.3654e-02,  1.5714e-02,  8.1029e-03,  2.1346e-02,\n",
              "                                     1.4243e-02,  2.7253e-03,  1.9821e-02, -1.7297e-02,\n",
              "                                     2.0639e-02,  2.7077e-02,  3.1073e-03,  1.1750e-02,\n",
              "                                     7.2721e-03,  9.6957e-03,  8.2233e-03,  3.7925e-03,\n",
              "                                     5.6649e-03,  8.6610e-03, -7.6289e-03, -7.0505e-03,\n",
              "                                    -1.6095e-03, -4.6560e-03,  4.2804e-02, -1.5962e-02,\n",
              "                                    -1.1685e-03,  1.0069e-02,  1.4325e-02,  7.0440e-03,\n",
              "                                     1.1828e-02, -1.4065e-02,  1.2591e-02, -5.9249e-05,\n",
              "                                    -3.1031e-03, -1.0168e-02,  2.2686e-03,  1.1100e-02,\n",
              "                                    -5.7291e-03,  3.1697e-03,  2.1474e-02,  2.6157e-02,\n",
              "                                     7.8314e-03, -8.7984e-03,  1.2105e-02,  3.2963e-03,\n",
              "                                     4.0954e-03, -3.3771e-03, -2.4492e-03, -1.1377e-03,\n",
              "                                    -1.7456e-02,  1.3713e-02,  2.8228e-02,  8.8193e-03,\n",
              "                                    -1.3266e-02,  2.1076e-03,  2.8049e-02, -2.9623e-02,\n",
              "                                    -2.0449e-03,  7.7550e-04,  3.5403e-02, -6.8849e-03,\n",
              "                                    -1.0797e-03, -2.4320e-02, -1.4633e-03, -4.9586e-03,\n",
              "                                     1.2115e-02,  7.1904e-03,  2.0469e-02, -1.5611e-05,\n",
              "                                     1.7986e-02, -1.3428e-03, -1.3386e-03, -2.0099e-02,\n",
              "                                    -6.9989e-03,  2.8843e-02,  1.7115e-02, -3.5777e-03,\n",
              "                                     7.4769e-03, -5.4852e-03,  1.5223e-02, -1.4038e-02,\n",
              "                                     2.1077e-03, -3.8778e-03,  1.7460e-03,  4.0938e-05,\n",
              "                                     2.4384e-02,  1.6862e-02,  3.1985e-02,  3.3192e-03,\n",
              "                                     3.6737e-02, -3.7911e-03,  7.0960e-03, -5.3930e-04]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 1.2632, -0.5308,  1.8189, -0.8554, -1.6432, -1.5928,\n",
              "                                    -2.5076, -1.1944, -0.8727, -0.6982, -0.9475,  0.5712,\n",
              "                                    -3.9106,  1.6635,  0.3776, -2.7628, -1.1351, -2.0419,\n",
              "                                     0.8603,  1.9506,  2.1820,  2.4058,  0.2691, -0.3594,\n",
              "                                    -1.2019, -0.4414,  0.0776,  0.5027, -0.2590,  2.1777,\n",
              "                                    -2.5342,  1.1829, -0.1392,  0.2649, -0.3887, -1.1098,\n",
              "                                    -0.4647,  1.2524, -0.0712,  0.9031,  2.4048, -0.7620,\n",
              "                                     3.2279,  1.0895, -1.0771, -0.8106, -0.6127,  1.6897,\n",
              "                                     0.2131,  1.5389, -0.8599, -2.8464, -0.1785,  1.3337,\n",
              "                                    -2.6389, -2.5622, -0.4404,  0.2425,  1.3023, -0.4194,\n",
              "                                    -1.4497, -3.1135,  0.0937,  0.7679, -0.0663, -2.6866,\n",
              "                                    -0.6973,  0.4515, -6.3578, -2.5157,  2.2614,  1.9701,\n",
              "                                     3.9354, -0.1627, -1.4875, -1.5035, -1.5905,  1.7953,\n",
              "                                    -0.7671,  4.0957,  0.4356, -1.5684, -0.8725, -1.5477,\n",
              "                                    -0.5952, -2.7487, -1.1289, -2.1125, -1.7673, -3.0735,\n",
              "                                    -1.2909, -1.2110,  1.0049,  3.4102, -1.3075,  0.4177,\n",
              "                                    -3.3049, -0.0871,  1.0453,  1.0659, -5.4943,  1.3600,\n",
              "                                     1.6198,  1.5160, -0.6978,  0.0295,  0.7214, -1.4021,\n",
              "                                     1.6407, -0.0857, -2.0716,  1.1457,  0.4010, -0.0631,\n",
              "                                     1.2234,  1.3613,  1.6186, -0.3498, -2.0926, -2.0728,\n",
              "                                    -1.0532,  3.2585,  2.6118,  4.0595, -3.8264, -0.1190,\n",
              "                                     1.2720, -1.8571]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([23.5685,  7.0379, 18.5586, 14.3929, 22.4380, 15.1551,\n",
              "                                    18.4943, 30.4231, 15.6366, 14.9034, 13.2228, 26.0629,\n",
              "                                    18.1355, 21.8258, 11.2269, 35.0368, 24.9197, 13.0427,\n",
              "                                    12.7844, 23.0090, 23.9001, 30.4573, 32.2753, 11.9881,\n",
              "                                    11.8684, 14.7836, 12.0059, 17.0663, 32.7716, 17.1320,\n",
              "                                    14.7180, 37.1614, 19.9786, 32.1500, 11.2014, 20.1159,\n",
              "                                    20.1065, 14.2461, 19.5447, 16.3310, 26.8883,  5.9315,\n",
              "                                    33.6441, 19.2318, 19.1541, 15.4116, 18.3134, 27.4463,\n",
              "                                    13.8231, 42.0502, 19.9925, 24.6593, 24.1149, 26.0034,\n",
              "                                    25.6802, 12.6901, 13.3382, 14.0524, 11.7768, 12.5760,\n",
              "                                    11.4866,  7.6757, 32.9534, 31.9048, 17.4716, 15.5100,\n",
              "                                    20.9443, 16.8217, 45.6061, 17.1168, 34.8883, 29.2735,\n",
              "                                    11.8858, 16.8827, 21.1289, 19.5859, 13.2152, 20.5120,\n",
              "                                    21.0187, 24.3535, 21.0104, 17.3296, 12.5561, 27.9620,\n",
              "                                    16.6652, 18.5114, 19.4608, 22.9583, 13.3420, 20.9489,\n",
              "                                    15.5673, 18.2468, 21.5314, 31.8668, 17.9891, 21.6215,\n",
              "                                    41.2626,  8.2532,  9.2275, 24.0010, 25.9356, 12.7105,\n",
              "                                    43.0538, 23.5128, 20.4758, 25.8713, 24.9339, 23.0067,\n",
              "                                    23.1466, 16.7979, 24.9400, 30.0744, 21.4083, 24.5499,\n",
              "                                    20.3993, 25.4938, 16.1859, 18.1153, 25.2570,  6.2828,\n",
              "                                    14.5227, 18.7792, 23.0417, 44.8550, 47.6363, 15.7537,\n",
              "                                    21.4935, 28.4217]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0169,  0.0576, -0.0703,  ...,  0.0115, -0.0669,\n",
              "                                     0.0101]),\n",
              "                     size=(128, 128, 3, 3), nnz=147456, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([1.0405, 1.0015, 0.9553, 0.9899, 0.9830, 1.0107, 1.0228,\n",
              "                                    0.9965, 0.9855, 0.9834, 0.9989, 1.0070, 0.9687, 0.9905,\n",
              "                                    0.9998, 1.0091, 0.9888, 1.0052, 0.9918, 0.9774, 1.0013,\n",
              "                                    1.0003, 0.9899, 1.0235, 0.9845, 0.9888, 1.0070, 1.0113,\n",
              "                                    1.0083, 1.0014, 0.9958, 1.0383, 0.9976, 0.9952, 0.9928,\n",
              "                                    1.0176, 1.0153, 1.0329, 0.9876, 1.0147, 1.0059, 1.0113,\n",
              "                                    0.9930, 0.9751, 1.0135, 1.0050, 1.0082, 0.9937, 1.0016,\n",
              "                                    1.0064, 0.9982, 0.9855, 0.9961, 1.0319, 1.0209, 1.0019,\n",
              "                                    1.0051, 0.9906, 0.9985, 1.0101, 0.9821, 1.0103, 0.9969,\n",
              "                                    0.9967, 1.0213, 1.0109, 1.0003, 1.0025, 1.0078, 1.0206,\n",
              "                                    1.0045, 0.9947, 0.9990, 0.9979, 0.9896, 0.9877, 1.0042,\n",
              "                                    0.9767, 0.9999, 0.9842, 1.0123, 1.0212, 0.9897, 1.0034,\n",
              "                                    0.9979, 0.9905, 0.9845, 0.9878, 1.0163, 1.0157, 0.9984,\n",
              "                                    0.9941, 1.0059, 1.0002, 1.0143, 0.9841, 1.0163, 1.0043,\n",
              "                                    0.9906, 0.9916, 1.0028, 1.0119, 1.0008, 1.0205, 0.9982,\n",
              "                                    0.9791, 1.0009, 0.9917, 1.0344, 0.9858, 0.9922, 0.9965,\n",
              "                                    0.9917, 1.0074, 0.9847, 0.9756, 1.0130, 0.9965, 1.0053,\n",
              "                                    0.9886, 0.9859, 0.9897, 1.0038, 0.9863, 1.0078, 0.9904,\n",
              "                                    0.9881, 1.0053]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 0.0120, -0.0064,  0.0148,  0.0216,  0.0023, -0.0201,\n",
              "                                     0.0066,  0.0047, -0.0004, -0.0118, -0.0102,  0.0050,\n",
              "                                    -0.0103,  0.0276, -0.0158,  0.0125, -0.0139,  0.0026,\n",
              "                                    -0.0051, -0.0157,  0.0138, -0.0160,  0.0053, -0.0059,\n",
              "                                    -0.0117,  0.0128, -0.0002,  0.0083,  0.0239, -0.0201,\n",
              "                                     0.0015,  0.0055,  0.0167,  0.0037, -0.0143,  0.0115,\n",
              "                                     0.0169,  0.0255, -0.0007, -0.0081,  0.0104,  0.0139,\n",
              "                                     0.0065, -0.0297, -0.0184, -0.0102,  0.0321, -0.0187,\n",
              "                                    -0.0090, -0.0049,  0.0100, -0.0221,  0.0024, -0.0144,\n",
              "                                     0.0243,  0.0023, -0.0015,  0.0037,  0.0089,  0.0082,\n",
              "                                    -0.0045,  0.0189,  0.0073,  0.0005,  0.0153,  0.0159,\n",
              "                                     0.0041,  0.0139,  0.0011, -0.0011,  0.0203, -0.0074,\n",
              "                                     0.0124, -0.0057, -0.0119, -0.0083, -0.0184, -0.0113,\n",
              "                                    -0.0163, -0.0121,  0.0195,  0.0087, -0.0081, -0.0083,\n",
              "                                    -0.0043, -0.0024, -0.0124, -0.0020,  0.0364,  0.0037,\n",
              "                                     0.0126, -0.0038,  0.0072, -0.0084,  0.0284, -0.0012,\n",
              "                                     0.0107,  0.0092,  0.0108,  0.0087, -0.0058,  0.0299,\n",
              "                                     0.0163,  0.0111, -0.0035, -0.0177,  0.0150,  0.0041,\n",
              "                                     0.0305,  0.0131, -0.0066, -0.0170, -0.0106,  0.0181,\n",
              "                                    -0.0166, -0.0114,  0.0237,  0.0031, -0.0196, -0.0134,\n",
              "                                    -0.0080, -0.0087, -0.0079, -0.0042, -0.0009, -0.0017,\n",
              "                                    -0.0097,  0.0132]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 2.2716,  0.4334,  0.9932,  0.5092,  0.2703,  0.1036,\n",
              "                                     0.9990, -0.8728, -0.8662,  0.2738, -0.0245, -0.4005,\n",
              "                                    -0.2804,  0.9980,  0.3256,  0.1271, -0.0885,  0.4751,\n",
              "                                    -0.5237, -1.0580, -0.8852, -0.4580, -0.9167,  0.5138,\n",
              "                                     0.0231, -1.0584, -0.2583, -1.4074, -0.9040, -0.9201,\n",
              "                                    -1.7373,  0.6039, -0.5034, -0.9188, -1.0661,  1.5395,\n",
              "                                    -0.9264,  0.0234, -0.4236, -1.0413, -0.4230,  0.4958,\n",
              "                                    -0.0128,  0.9171,  0.8978,  0.0526,  0.5575,  0.0055,\n",
              "                                    -0.3928,  1.3412, -0.4436,  0.2013, -0.0379,  0.7590,\n",
              "                                    -0.7559,  0.5871, -0.2571, -0.9582, -1.4016, -1.1218,\n",
              "                                    -1.0964,  0.0273,  0.3974, -0.7041, -1.0737, -0.1847,\n",
              "                                     1.6145,  0.3849, -1.7300, -0.0649, -0.8154, -0.2980,\n",
              "                                    -1.6859,  1.3921, -1.4324, -0.6343,  0.0453,  0.3893,\n",
              "                                     0.7365, -0.1090, -0.7682, -0.9254, -0.6652, -0.9782,\n",
              "                                    -0.6478, -1.3937, -1.3198, -0.4771,  0.0594, -0.3839,\n",
              "                                    -0.7769,  0.9698,  0.3682, -0.4224, -0.0563, -0.0417,\n",
              "                                    -0.7969,  0.8500, -0.3867,  0.1393, -0.0500, -1.2588,\n",
              "                                    -0.5947, -0.1983,  0.3908,  0.4021,  0.2013, -1.5538,\n",
              "                                    -0.9288, -0.4627,  1.0170,  1.6797, -0.3435,  0.1609,\n",
              "                                    -1.2060, -0.5183, -0.6759, -0.5170, -0.2954, -0.0937,\n",
              "                                    -0.6341, -0.6338, -0.0848, -0.2103, -0.8393, -0.9157,\n",
              "                                     1.1811, -0.8595]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 7.8726,  2.6182,  8.0073,  2.9445,  5.6235,  3.1188,\n",
              "                                     4.4944,  2.7293,  3.3563,  6.3786,  2.8770,  1.6267,\n",
              "                                     3.7769,  5.5676,  1.9044,  3.1554,  4.5316,  3.1695,\n",
              "                                     3.2609,  2.5307,  4.0826,  3.2080,  5.4286,  2.9908,\n",
              "                                     2.2027,  5.5144,  3.0938,  2.0149,  3.6663,  1.8765,\n",
              "                                     4.7897,  6.2972,  8.5298,  3.9973,  2.8108,  5.8746,\n",
              "                                     6.4826,  5.0898,  3.1656,  3.3762,  5.2738,  3.4597,\n",
              "                                     4.4019,  3.1628,  3.2220,  3.6134,  7.9124,  2.1162,\n",
              "                                     3.1345,  3.5134,  4.1830,  3.9500,  4.0865,  6.1834,\n",
              "                                     3.0216,  3.3056,  3.9217,  2.8191,  7.0637,  6.7818,\n",
              "                                     3.9605,  4.7496,  3.4987,  2.2770,  6.5564,  5.4881,\n",
              "                                     5.2496,  7.5714, 10.0939,  6.7249,  4.1544,  3.9720,\n",
              "                                     3.7071,  4.9149,  7.1898,  3.6710,  3.3171,  6.9748,\n",
              "                                     3.1413,  3.7057,  4.8569,  9.3535,  6.0983,  3.3569,\n",
              "                                     3.4970,  3.4130,  2.3160,  5.6121,  2.9776,  3.9026,\n",
              "                                     2.2621,  6.1317,  3.9323,  3.9211,  4.1458,  5.0038,\n",
              "                                     5.5661,  8.5169,  3.4226,  4.2710,  2.4451,  3.2834,\n",
              "                                     4.1887,  3.6072,  2.8135,  3.2374,  2.3929,  6.5497,\n",
              "                                     4.1806,  3.2467,  5.3746,  3.8154,  1.9519,  7.4075,\n",
              "                                     4.9493,  2.4607,  6.2843,  4.9681,  2.6624,  3.5022,\n",
              "                                     4.8159,  2.8997,  4.4760,  2.2630,  4.6719,  3.1929,\n",
              "                                     4.8874,  5.0851]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   1,   2,  ..., 125, 126, 127],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.0468, -0.0213,  0.1086,  ...,  0.0100,  0.1140,\n",
              "                                     0.0900]),\n",
              "                     size=(512, 128, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([1.0026, 1.0089, 0.9835, 0.9945, 0.9900, 1.0007, 0.9839,\n",
              "                                    1.0034, 1.0015, 0.9934, 0.9970, 1.0094, 0.9794, 1.0018,\n",
              "                                    1.0049, 1.0056, 0.9827, 0.9993, 1.0248, 1.0095, 1.0059,\n",
              "                                    1.0047, 0.9753, 1.0177, 1.0171, 0.9914, 0.9900, 0.9866,\n",
              "                                    1.0121, 0.9959, 0.9968, 0.9933, 1.0111, 1.0013, 1.0029,\n",
              "                                    0.9937, 0.9993, 1.0379, 0.9965, 0.9802, 0.9938, 1.0003,\n",
              "                                    0.9864, 0.9933, 0.9768, 1.0122, 1.0062, 0.9955, 1.0034,\n",
              "                                    0.9942, 1.0329, 1.0075, 0.9906, 0.9849, 1.0041, 1.0058,\n",
              "                                    0.9714, 1.0000, 0.9969, 1.0262, 1.0049, 0.9876, 0.9738,\n",
              "                                    0.9971, 0.9865, 1.0045, 1.0105, 0.9964, 0.9932, 0.9978,\n",
              "                                    1.0009, 0.9868, 1.0011, 1.0243, 1.0034, 1.0027, 1.0000,\n",
              "                                    1.0144, 1.0037, 0.9962, 0.9956, 1.0013, 1.0173, 1.0058,\n",
              "                                    0.9976, 1.0272, 0.9987, 0.9862, 1.0212, 0.9939, 1.0035,\n",
              "                                    1.0092, 1.0157, 0.9832, 1.0119, 1.0181, 0.9842, 1.0096,\n",
              "                                    1.0213, 0.9918, 1.0071, 0.9875, 0.9914, 0.9876, 1.0034,\n",
              "                                    0.9968, 1.0012, 0.9845, 0.9845, 0.9807, 1.0109, 0.9864,\n",
              "                                    1.0072, 1.0014, 1.0026, 1.0343, 1.0092, 0.9916, 0.9810,\n",
              "                                    1.0001, 1.0047, 1.0301, 0.9984, 1.0121, 1.0078, 1.0033,\n",
              "                                    0.9883, 0.9841, 1.0037, 0.9969, 1.0100, 0.9975, 0.9959,\n",
              "                                    1.0068, 0.9943, 0.9758, 0.9861, 0.9848, 1.0040, 0.9970,\n",
              "                                    0.9904, 0.9895, 0.9810, 1.0101, 0.9937, 0.9945, 1.0031,\n",
              "                                    0.9924, 0.9948, 1.0057, 0.9980, 1.0044, 0.9971, 1.0034,\n",
              "                                    1.0064, 0.9905, 0.9902, 0.9893, 0.9994, 0.9786, 0.9997,\n",
              "                                    1.0090, 1.0142, 0.9999, 1.0143, 0.9918, 0.9822, 0.9918,\n",
              "                                    1.0018, 0.9921, 0.9903, 1.0024, 1.0119, 1.0015, 0.9692,\n",
              "                                    0.9903, 1.0106, 1.0008, 1.0231, 1.0089, 0.9985, 0.9969,\n",
              "                                    0.9855, 0.9888, 0.9949, 0.9818, 1.0278, 0.9952, 0.9858,\n",
              "                                    1.0063, 1.0023, 0.9879, 0.9898, 0.9739, 1.0075, 1.0137,\n",
              "                                    0.9964, 0.9936, 1.0030, 1.0303, 1.0107, 1.0124, 0.9910,\n",
              "                                    0.9915, 0.9699, 0.9750, 0.9931, 1.0061, 0.9807, 0.9768,\n",
              "                                    1.0089, 1.0047, 1.0091, 1.0019, 1.0289, 1.0000, 0.9869,\n",
              "                                    1.0008, 1.0171, 0.9909, 1.0097, 1.0017, 1.0025, 0.9913,\n",
              "                                    0.9903, 0.9985, 0.9974, 1.0268, 0.9888, 1.0032, 1.0153,\n",
              "                                    0.9780, 0.9894, 0.9965, 1.0233, 0.9924, 0.9833, 0.9972,\n",
              "                                    0.9788, 1.0001, 0.9838, 1.0150, 0.9972, 0.9892, 1.0234,\n",
              "                                    0.9938, 1.0031, 0.9844, 1.0014, 0.9983, 0.9896, 0.9935,\n",
              "                                    1.0173, 0.9990, 0.9930, 1.0123, 0.9831, 1.0192, 1.0081,\n",
              "                                    1.0293, 1.0077, 1.0040, 1.0215, 0.9965, 1.0017, 0.9909,\n",
              "                                    1.0116, 1.0353, 1.0081, 1.0110, 0.9869, 1.0178, 1.0000,\n",
              "                                    0.9929, 1.0053, 1.0161, 0.9963, 1.0074, 1.0133, 0.9882,\n",
              "                                    1.0016, 1.0101, 0.9978, 1.0047, 0.9880, 0.9934, 1.0040,\n",
              "                                    1.0090, 0.9990, 1.0265, 1.0069, 0.9906, 1.0053, 0.9990,\n",
              "                                    0.9925, 1.0229, 0.9976, 0.9876, 1.0403, 1.0016, 1.0170,\n",
              "                                    0.9789, 0.9929, 0.9890, 1.0284, 0.9970, 0.9930, 1.0198,\n",
              "                                    0.9769, 1.0086, 0.9980, 1.0155, 0.9907, 1.0012, 0.9925,\n",
              "                                    1.0190, 1.0095, 1.0047, 1.0032, 1.0231, 0.9856, 0.9940,\n",
              "                                    1.0133, 0.9772, 0.9755, 0.9982, 1.0017, 0.9973, 1.0106,\n",
              "                                    1.0374, 1.0250, 1.0119, 0.9806, 0.9823, 1.0119, 0.9971,\n",
              "                                    1.0169, 1.0064, 1.0167, 0.9903, 1.0059, 0.9884, 1.0052,\n",
              "                                    0.9884, 1.0078, 0.9993, 1.0159, 1.0199, 1.0020, 1.0291,\n",
              "                                    1.0089, 1.0018, 1.0029, 1.0242, 0.9911, 1.0106, 1.0077,\n",
              "                                    1.0147, 0.9939, 0.9948, 1.0162, 1.0132, 1.0002, 0.9913,\n",
              "                                    0.9884, 1.0069, 0.9835, 0.9966, 1.0159, 1.0140, 0.9923,\n",
              "                                    1.0220, 0.9942, 1.0134, 0.9918, 1.0055, 1.0031, 0.9893,\n",
              "                                    0.9967, 1.0058, 1.0072, 0.9993, 1.0164, 1.0069, 0.9786,\n",
              "                                    1.0131, 0.9936, 0.9997, 1.0040, 1.0131, 0.9960, 0.9774,\n",
              "                                    1.0099, 0.9866, 1.0084, 0.9933, 0.9952, 0.9826, 0.9916,\n",
              "                                    1.0076, 1.0012, 1.0196, 0.9914, 0.9668, 1.0080, 0.9976,\n",
              "                                    1.0008, 1.0090, 0.9867, 1.0113, 1.0030, 1.0123, 0.9916,\n",
              "                                    0.9981, 1.0058, 1.0301, 1.0388, 0.9727, 0.9792, 1.0025,\n",
              "                                    0.9930, 0.9936, 1.0117, 1.0422, 1.0025, 0.9922, 0.9973,\n",
              "                                    1.0179, 0.9889, 0.9913, 0.9928, 0.9874, 0.9989, 1.0128,\n",
              "                                    0.9961, 1.0159, 1.0023, 0.9845, 1.0191, 1.0121, 0.9982,\n",
              "                                    0.9991, 0.9918, 1.0094, 1.0031, 1.0089, 1.0167, 1.0026,\n",
              "                                    0.9987, 1.0009, 1.0021, 1.0139, 0.9945, 0.9970, 1.0119,\n",
              "                                    0.9968, 0.9913, 1.0054, 0.9906, 1.0224, 1.0007, 1.0090,\n",
              "                                    0.9989, 1.0122, 0.9860, 1.0106, 1.0089, 1.0229, 1.0170,\n",
              "                                    0.9847, 0.9966, 0.9990, 0.9841, 1.0145, 0.9848, 0.9987,\n",
              "                                    0.9841, 0.9926, 1.0121, 0.9975, 0.9909, 1.0047, 0.9992,\n",
              "                                    0.9732, 1.0192, 1.0016, 0.9895, 0.9916, 1.0026, 1.0157,\n",
              "                                    1.0192, 0.9858, 0.9893, 1.0120, 0.9860, 0.9887, 0.9966,\n",
              "                                    1.0030, 0.9947, 1.0017, 0.9914, 0.9761, 0.9778, 1.0199,\n",
              "                                    0.9915, 0.9901, 0.9960, 1.0056, 1.0146, 1.0055, 0.9950,\n",
              "                                    1.0104]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 6.3493e-03,  3.4465e-02, -8.9781e-03, -1.3652e-02,\n",
              "                                    -1.0566e-02,  1.4845e-02, -1.5853e-02,  2.1972e-02,\n",
              "                                     6.6244e-03, -2.5802e-03, -2.0792e-02, -5.7393e-03,\n",
              "                                     3.4757e-02,  6.9029e-03, -3.2676e-02,  4.1391e-03,\n",
              "                                     5.7196e-04, -5.6976e-03,  1.4509e-02, -7.5240e-03,\n",
              "                                     7.1573e-03, -1.1735e-02, -1.4018e-02,  1.1427e-02,\n",
              "                                     5.9148e-03,  7.6831e-03, -1.8083e-02,  2.9374e-03,\n",
              "                                     2.7810e-02, -1.0343e-02,  2.0344e-02, -2.9366e-03,\n",
              "                                    -4.8562e-03, -4.9359e-03,  2.5158e-02,  4.1393e-03,\n",
              "                                     1.5037e-02, -4.6225e-03,  1.3356e-02, -7.6568e-03,\n",
              "                                    -9.0777e-03, -1.1362e-03,  3.5007e-03,  9.5457e-04,\n",
              "                                    -7.0504e-03,  2.0639e-02,  4.0502e-02,  8.4614e-03,\n",
              "                                     7.2566e-03,  6.8306e-03, -1.2786e-02,  7.5148e-03,\n",
              "                                    -1.3573e-02,  5.0934e-03,  1.5623e-02,  2.1603e-02,\n",
              "                                    -2.2477e-03, -3.2682e-03, -7.2320e-03, -3.1280e-03,\n",
              "                                     4.5948e-03, -1.4970e-02, -1.3878e-03, -6.8978e-03,\n",
              "                                    -1.7707e-02,  3.1110e-03,  3.3623e-03, -2.2340e-02,\n",
              "                                    -4.9497e-04,  6.0754e-03, -1.0159e-02,  2.2100e-03,\n",
              "                                     9.2617e-03, -1.1026e-02,  1.6083e-02,  2.4059e-02,\n",
              "                                     1.5277e-02,  1.7238e-02,  1.1525e-02,  1.2305e-02,\n",
              "                                     2.7023e-02, -4.5459e-03, -2.1130e-02,  2.3032e-02,\n",
              "                                    -1.5090e-02, -1.5389e-02, -9.8794e-03,  3.1466e-03,\n",
              "                                     1.8238e-02,  1.1602e-02,  2.5490e-05, -1.0773e-03,\n",
              "                                    -4.7128e-03, -5.5742e-03, -2.8309e-03,  7.2237e-03,\n",
              "                                    -6.7595e-03,  9.6153e-03,  2.0132e-02,  1.6244e-02,\n",
              "                                     1.7086e-02,  1.3049e-03,  6.4361e-03,  6.4214e-03,\n",
              "                                     1.3570e-03,  6.1060e-03, -9.8932e-03, -3.3934e-03,\n",
              "                                    -9.8119e-04, -1.0633e-02,  4.1457e-03,  7.6680e-03,\n",
              "                                     1.4044e-02, -7.9955e-03,  1.0666e-02,  5.5040e-04,\n",
              "                                    -1.6534e-03,  1.4766e-02,  1.1147e-02, -8.0394e-03,\n",
              "                                     1.2380e-02,  1.6804e-03, -1.9051e-03,  2.1907e-03,\n",
              "                                    -9.9825e-03,  4.8183e-03,  4.0363e-03,  1.7294e-03,\n",
              "                                     5.9679e-03, -5.3735e-03,  7.8354e-03,  4.0893e-03,\n",
              "                                    -6.8875e-03,  1.1630e-02,  2.8779e-03, -8.3139e-03,\n",
              "                                     1.2796e-02,  1.4718e-02,  2.9892e-02,  5.5325e-03,\n",
              "                                    -1.3218e-02, -9.6262e-03,  2.8488e-02, -2.0938e-03,\n",
              "                                    -7.7983e-03, -5.8459e-03,  9.1892e-03,  2.0226e-02,\n",
              "                                    -3.7036e-03, -1.4233e-02, -1.0492e-02, -2.3365e-03,\n",
              "                                     1.4949e-02, -5.2623e-03,  1.8708e-02, -2.6248e-03,\n",
              "                                    -4.4433e-03, -7.9360e-03, -9.2014e-03, -9.3237e-04,\n",
              "                                    -3.7491e-02,  3.8397e-03,  1.2710e-02, -6.6149e-03,\n",
              "                                    -1.9521e-02, -1.6861e-03, -1.2777e-02, -1.0977e-02,\n",
              "                                    -4.9265e-04,  3.6771e-03, -4.9880e-03,  1.9276e-02,\n",
              "                                     2.3245e-02, -6.5646e-03,  1.2382e-04,  1.0226e-02,\n",
              "                                     1.4758e-02,  2.4638e-02, -5.8851e-04,  5.7901e-02,\n",
              "                                    -3.0121e-03,  6.3420e-03, -8.6013e-03,  1.0969e-02,\n",
              "                                    -7.6648e-03,  2.1722e-03,  1.1604e-02, -2.4676e-02,\n",
              "                                    -1.7061e-02, -2.0967e-03, -6.8803e-03,  4.3373e-03,\n",
              "                                    -2.6792e-02,  2.2433e-02, -3.1711e-03, -4.7492e-03,\n",
              "                                     8.2216e-03,  3.8230e-04,  8.6384e-03,  1.6890e-02,\n",
              "                                     1.8217e-02,  1.8698e-02, -7.0546e-03,  2.0812e-03,\n",
              "                                     2.3140e-02,  2.4586e-04,  8.3207e-03, -2.1545e-03,\n",
              "                                    -2.7865e-03,  1.8987e-02,  2.9815e-02, -8.3366e-03,\n",
              "                                     4.1056e-04, -2.7137e-03,  1.0711e-02, -2.1474e-02,\n",
              "                                    -5.1588e-03, -6.0242e-04, -1.0904e-02,  2.2305e-02,\n",
              "                                    -1.3559e-02,  4.2304e-03,  4.2586e-03,  2.6063e-02,\n",
              "                                     4.0772e-03, -1.4892e-02, -2.3603e-02,  1.0349e-02,\n",
              "                                    -2.3320e-03, -2.2719e-03,  1.5229e-02,  3.2696e-03,\n",
              "                                     4.3571e-03, -2.0756e-02,  2.7407e-03, -5.7703e-03,\n",
              "                                     1.4684e-02, -2.9939e-03,  5.5978e-03, -1.7219e-02,\n",
              "                                    -1.6451e-02,  1.7876e-02,  2.5637e-03,  2.2747e-03,\n",
              "                                     1.0287e-02, -4.6033e-03, -2.5775e-03,  1.9857e-03,\n",
              "                                     4.4580e-03,  4.9485e-03,  9.2276e-03,  3.6306e-03,\n",
              "                                     3.9124e-03,  4.2597e-03, -1.6748e-02, -3.2298e-03,\n",
              "                                     1.4282e-02,  3.3238e-03, -3.9600e-03, -5.8352e-03,\n",
              "                                     3.1169e-03,  5.3583e-03,  2.3355e-02,  1.3284e-04,\n",
              "                                     3.4946e-02, -1.5486e-02,  1.1753e-02, -1.1453e-03,\n",
              "                                    -2.1115e-02,  3.5849e-04, -2.4399e-02,  3.0769e-04,\n",
              "                                     2.7743e-03,  4.6920e-03,  8.5961e-03,  1.8447e-02,\n",
              "                                    -1.6036e-03,  3.0226e-02,  5.4641e-03, -3.5107e-02,\n",
              "                                    -3.7898e-03, -8.9925e-04,  1.2823e-02, -8.8703e-03,\n",
              "                                    -4.0262e-03, -7.3754e-03,  1.0346e-02,  1.0911e-02,\n",
              "                                    -1.4445e-03,  1.2950e-02,  2.4043e-02, -9.3663e-03,\n",
              "                                     1.1602e-03,  5.7013e-03,  3.3654e-03,  2.6862e-02,\n",
              "                                    -7.2791e-03, -9.0957e-03,  2.8185e-02, -1.6621e-02,\n",
              "                                     3.2082e-02, -5.9321e-03,  3.4902e-03, -2.9183e-02,\n",
              "                                     1.0559e-02,  2.4115e-02,  8.8548e-03, -4.6707e-04,\n",
              "                                     1.3756e-02, -1.1468e-02,  5.9563e-04,  2.0429e-04,\n",
              "                                     3.3540e-02,  6.6835e-03,  1.6235e-02,  1.8330e-02,\n",
              "                                     1.8635e-02, -2.7495e-02,  6.6686e-03,  1.6069e-02,\n",
              "                                    -1.5976e-02,  1.0321e-02, -2.1210e-02,  2.7516e-02,\n",
              "                                     1.2939e-02,  1.8232e-02, -3.3430e-02,  1.1733e-02,\n",
              "                                     1.4734e-03,  5.0293e-03,  9.3335e-03,  3.8813e-02,\n",
              "                                     5.4064e-03, -3.4149e-03,  9.7665e-03,  6.0557e-03,\n",
              "                                    -4.8981e-03,  2.2592e-02,  2.8530e-02, -1.3274e-02,\n",
              "                                     1.1328e-02,  6.1474e-03, -2.2674e-04, -6.3834e-03,\n",
              "                                     2.6576e-03,  7.6328e-03,  2.1222e-02, -7.1324e-03,\n",
              "                                     1.9421e-02, -3.6111e-03,  7.4946e-03,  1.2129e-02,\n",
              "                                    -9.7473e-03,  2.5421e-02, -2.0337e-02, -9.6271e-03,\n",
              "                                    -3.0775e-03,  1.0046e-02,  7.7559e-03,  2.3911e-02,\n",
              "                                     1.5190e-03,  5.6167e-03,  3.1963e-02,  1.0424e-02,\n",
              "                                     3.6990e-02,  1.3249e-03,  8.4363e-03,  7.4330e-03,\n",
              "                                     1.1419e-03,  1.9348e-02,  5.4961e-03,  1.3486e-02,\n",
              "                                    -7.9701e-03,  5.5613e-02, -6.3224e-03,  6.5980e-04,\n",
              "                                     1.8953e-02, -6.0768e-03,  2.1468e-02, -2.0145e-02,\n",
              "                                     1.7420e-03,  1.3832e-02,  6.9668e-03,  1.2691e-03,\n",
              "                                     1.0405e-02,  1.4110e-03,  5.0552e-03,  3.3402e-03,\n",
              "                                    -1.3764e-02, -1.3964e-02, -7.8391e-03,  3.7945e-02,\n",
              "                                    -1.1004e-02,  1.3404e-02,  3.1776e-03, -2.1461e-02,\n",
              "                                     2.5161e-02, -2.8430e-03,  6.4177e-03,  1.9827e-02,\n",
              "                                    -3.2851e-03,  2.0875e-02,  8.4300e-03,  8.2927e-03,\n",
              "                                     2.2287e-02, -9.3309e-03,  7.4989e-04,  1.7857e-02,\n",
              "                                     1.6327e-02, -1.1941e-02,  2.5772e-02,  7.7026e-04,\n",
              "                                    -5.7508e-03, -3.4064e-03, -9.1016e-03,  1.6612e-02,\n",
              "                                     2.2228e-02, -1.9689e-02, -4.8260e-03,  3.2397e-03,\n",
              "                                     2.3082e-02, -6.7241e-03,  1.8846e-02,  2.9420e-02,\n",
              "                                     9.4443e-03,  1.5716e-02,  2.1236e-02,  7.4576e-03,\n",
              "                                    -4.2182e-03, -1.2824e-02, -1.7626e-03, -3.1078e-03,\n",
              "                                    -5.0190e-03,  2.7292e-03,  4.7003e-02,  1.0895e-03,\n",
              "                                    -3.5002e-03,  8.2449e-04, -6.6621e-03, -7.4860e-03,\n",
              "                                     4.5423e-04, -1.4341e-02, -6.9604e-03, -1.2476e-04,\n",
              "                                     7.2913e-03, -2.0575e-02, -1.0978e-02,  1.6700e-02,\n",
              "                                     1.6764e-02,  1.2670e-02, -2.0446e-02,  2.6462e-02,\n",
              "                                    -1.6650e-02,  1.4780e-04,  1.5546e-03, -1.4074e-02,\n",
              "                                    -5.4337e-03,  1.5109e-02, -1.1769e-02, -2.0176e-02,\n",
              "                                     2.2448e-02,  5.7599e-03, -1.8165e-03,  2.0693e-02,\n",
              "                                     1.2495e-03,  2.0492e-02, -5.9699e-03,  5.2721e-03,\n",
              "                                    -6.7862e-03,  5.1012e-03, -7.3162e-04, -1.5690e-02,\n",
              "                                     1.8164e-02,  1.8123e-02,  1.5616e-02,  1.3747e-02,\n",
              "                                     1.0937e-02, -5.2461e-04,  1.1779e-02, -1.8088e-02,\n",
              "                                     3.5500e-02, -3.5783e-03,  1.8893e-02, -2.1958e-04,\n",
              "                                     9.5284e-03,  1.6502e-02,  3.7566e-02,  3.6291e-03,\n",
              "                                    -6.7766e-03, -2.0206e-02,  2.0881e-02, -6.2613e-03,\n",
              "                                    -9.1248e-03,  8.4918e-03,  1.4165e-02, -1.2470e-02,\n",
              "                                    -1.4116e-02, -2.8537e-02, -2.5942e-02,  6.7253e-03,\n",
              "                                    -6.1427e-03,  1.4194e-03,  3.5683e-02,  1.0592e-02,\n",
              "                                    -1.7103e-02, -1.2764e-02, -7.6367e-04,  2.6973e-02,\n",
              "                                    -3.8071e-03,  1.0744e-03, -1.4885e-02,  3.5340e-03]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-3.2617e-01, -3.3846e-01, -6.7760e-02, -9.6997e-02,\n",
              "                                    -3.0814e-01, -3.8274e-01, -3.0906e-01,  1.8497e-01,\n",
              "                                    -1.3704e-01, -2.5419e-01,  3.5113e-01,  2.3361e-02,\n",
              "                                    -2.6418e-01, -2.4414e-01,  5.5555e-02,  2.1753e-02,\n",
              "                                    -1.2102e-01,  2.5105e-01,  9.8009e-02, -1.8261e-01,\n",
              "                                    -5.4913e-01, -6.7725e-01, -1.6301e-01, -8.7185e-02,\n",
              "                                     3.1899e-03, -4.0357e-01,  1.2092e-01,  3.9582e-02,\n",
              "                                     1.4963e-01,  3.9996e-01,  4.0724e-01,  3.3503e-01,\n",
              "                                    -2.2952e-01, -5.4109e-01, -4.0317e-01, -3.1010e-03,\n",
              "                                    -2.8695e-01,  1.1633e-01, -2.9875e-01,  4.1213e-01,\n",
              "                                    -1.4463e-01, -2.5473e-01, -1.5551e-01,  4.6715e-01,\n",
              "                                     2.7194e-01, -1.3607e-01, -3.2159e-01,  3.8224e-02,\n",
              "                                    -7.4674e-02, -2.3150e-01,  2.4911e-01,  6.8920e-02,\n",
              "                                    -1.1817e-01,  3.5536e-01, -2.3728e-01,  1.6861e-01,\n",
              "                                     2.5411e-01, -1.1211e-01,  9.8039e-02,  1.3969e-02,\n",
              "                                    -5.4247e-02, -1.7526e-01, -3.6690e-01, -2.6923e-01,\n",
              "                                    -4.0895e-01, -1.4656e-01, -1.1079e-01,  2.3923e-01,\n",
              "                                    -4.1919e-02, -1.5696e-01, -1.4122e-01, -5.3009e-01,\n",
              "                                     1.2970e-01, -1.5146e-01,  1.6038e-01,  4.0718e-01,\n",
              "                                    -5.1874e-01,  1.6523e-02, -1.5278e-01, -8.7416e-02,\n",
              "                                     4.8322e-01, -5.5203e-02, -1.8193e-01, -1.0252e-01,\n",
              "                                     1.6471e-01, -1.6646e-02, -3.8525e-02,  1.3762e-01,\n",
              "                                    -3.8921e-01, -2.8417e-02, -1.5474e-01, -7.2489e-01,\n",
              "                                     9.7358e-02, -6.7946e-01,  4.8234e-02, -7.3062e-02,\n",
              "                                     1.5782e-01,  4.5442e-02, -1.1657e-01,  1.1096e-01,\n",
              "                                    -5.2447e-01,  1.1801e-01, -5.3361e-01, -1.1356e-01,\n",
              "                                     1.9394e-01,  1.3560e-01, -5.3790e-01,  3.3814e-01,\n",
              "                                    -3.1180e-01,  2.5669e-01, -5.7371e-01,  1.8497e-01,\n",
              "                                     4.9418e-02,  2.8823e-01, -1.3235e-02,  5.6073e-02,\n",
              "                                     3.2827e-02,  4.7170e-01, -1.8529e-01, -5.9959e-02,\n",
              "                                    -3.1713e-02,  5.7951e-02, -2.5575e-01, -1.5699e-01,\n",
              "                                    -3.9707e-01,  5.3447e-02, -1.3234e-02,  6.7941e-01,\n",
              "                                     1.1002e-01,  2.0670e-01, -3.6379e-02, -4.2246e-01,\n",
              "                                    -4.3871e-02, -4.0440e-01,  1.5330e-01,  4.7619e-01,\n",
              "                                    -2.0354e-01, -1.8591e-01,  8.2769e-02, -8.9510e-03,\n",
              "                                    -3.2605e-01, -2.1936e-01, -2.2962e-01, -1.5241e-02,\n",
              "                                    -2.1961e-01,  4.1528e-01,  6.6651e-01, -2.9310e-01,\n",
              "                                    -3.0563e-01, -9.7597e-02,  5.6050e-01, -3.8500e-01,\n",
              "                                    -1.0298e-01,  2.3365e-01,  3.0749e-01,  6.8474e-02,\n",
              "                                    -4.8600e-01,  8.6295e-02, -7.7347e-02,  6.1620e-01,\n",
              "                                     4.1769e-01, -1.2521e-01, -2.6484e-01,  1.8491e-02,\n",
              "                                    -3.5973e-02, -4.9001e-01,  2.6527e-02, -5.0708e-02,\n",
              "                                    -1.6208e-01,  9.8900e-03, -1.0133e-01, -3.5004e-01,\n",
              "                                     1.4053e-01, -1.5543e-02,  6.7057e-02,  2.0844e-01,\n",
              "                                     7.8062e-02,  3.1433e-01,  5.0395e-03,  8.0240e-02,\n",
              "                                    -2.4305e-01,  8.7949e-02, -9.5675e-02,  2.5523e-02,\n",
              "                                    -3.2910e-01,  4.9231e-01, -3.7324e-02,  1.8507e-01,\n",
              "                                    -1.2493e-01,  3.4433e-01, -3.0800e-02,  1.8533e-01,\n",
              "                                     8.0749e-01, -5.9573e-01,  3.9899e-02, -3.7502e-01,\n",
              "                                    -5.2500e-01, -3.9312e-02, -2.6357e-01,  3.2252e-01,\n",
              "                                    -2.4888e-01, -2.6145e-01,  3.8175e-01,  3.7083e-01,\n",
              "                                    -4.4864e-01,  2.4970e-01, -1.1738e-01, -1.9658e-01,\n",
              "                                    -2.4948e-01,  2.1882e-01, -1.6783e-01, -3.8178e-01,\n",
              "                                    -2.8021e-01,  4.3019e-01, -1.3169e-01,  2.2676e-01,\n",
              "                                     3.6393e-01, -3.2342e-01, -2.5380e-02,  1.4830e-01,\n",
              "                                    -1.5555e-01,  3.2145e-01, -4.5447e-01,  5.6986e-02,\n",
              "                                    -2.6305e-01,  1.7011e-01,  9.3810e-02, -2.4150e-01,\n",
              "                                    -5.0702e-01,  9.4481e-02,  3.5070e-02,  7.4922e-02,\n",
              "                                    -5.2854e-01,  2.5123e-01,  2.4873e-01,  1.1191e-01,\n",
              "                                     4.6377e-02, -1.3571e-01,  2.7867e-01, -3.7361e-01,\n",
              "                                     9.2454e-03, -1.6631e-01, -4.6861e-01, -1.6848e-02,\n",
              "                                     8.4508e-02,  9.2897e-02, -2.5642e-01,  1.7215e-03,\n",
              "                                     3.0210e-02, -1.3057e-02, -5.3006e-01, -2.5430e-01,\n",
              "                                    -2.6368e-01, -5.3335e-03, -7.2481e-02, -8.4339e-02,\n",
              "                                    -4.1624e-01, -3.6405e-01, -9.0825e-02,  1.7618e-01,\n",
              "                                     1.3799e-01, -2.0674e-02,  2.7196e-02, -3.9300e-01,\n",
              "                                     8.4901e-02, -4.4571e-01,  8.4175e-02, -5.9164e-03,\n",
              "                                    -3.7527e-01,  4.0829e-02,  5.2620e-01, -2.1905e-01,\n",
              "                                     4.5176e-01,  8.0060e-02,  2.0573e-02,  2.2258e-01,\n",
              "                                    -2.3579e-01, -4.2331e-01, -3.3010e-01, -5.4312e-01,\n",
              "                                    -5.1395e-01, -1.5940e-01, -4.4611e-01,  1.9012e-01,\n",
              "                                    -1.7604e-01, -3.6276e-01,  1.4176e-01, -5.9738e-01,\n",
              "                                    -6.3353e-01, -4.7889e-01,  3.1732e-01,  2.5419e-02,\n",
              "                                     2.4868e-02,  1.4169e-01,  1.3937e-01,  2.2405e-02,\n",
              "                                    -3.0659e-01, -1.4639e-01, -7.1936e-02, -5.3330e-01,\n",
              "                                    -3.5692e-01, -3.5631e-01, -1.2323e-01, -5.3471e-02,\n",
              "                                    -4.4718e-02,  2.0944e-01, -8.2864e-02,  1.7075e-01,\n",
              "                                     3.3784e-02, -1.8544e-01,  5.4561e-01, -4.3295e-01,\n",
              "                                    -3.4679e-01,  1.6518e-01, -1.4601e-01, -4.2887e-02,\n",
              "                                    -6.8163e-01, -1.7201e-01, -1.7446e-01, -1.1061e-01,\n",
              "                                    -5.0179e-01, -4.2152e-01, -1.5878e-01,  2.8711e-01,\n",
              "                                    -3.3795e-01,  7.3803e-02, -2.3813e-01, -1.6472e-01,\n",
              "                                    -8.7508e-02,  1.4480e-01, -3.3336e-02,  3.6992e-02,\n",
              "                                    -7.9157e-02, -6.8895e-02,  1.9367e-01, -9.7423e-02,\n",
              "                                     3.6318e-01,  6.7083e-02, -1.6537e-01,  5.5477e-01,\n",
              "                                     4.6847e-01, -2.9457e-01,  2.7438e-01,  2.3278e-01,\n",
              "                                     1.0635e-01, -1.0185e-01, -3.8253e-01, -2.9704e-01,\n",
              "                                    -4.9570e-02, -4.4633e-01,  2.6038e-03,  2.1554e-02,\n",
              "                                    -2.3179e-01,  3.0754e-01, -1.1954e-01, -3.0872e-01,\n",
              "                                    -3.2183e-01, -2.7791e-01, -5.0450e-01, -3.9082e-01,\n",
              "                                    -3.7362e-02, -4.3411e-01,  6.5498e-02, -5.7526e-02,\n",
              "                                    -2.0945e-01, -2.0533e-01, -3.9335e-01,  2.4758e-01,\n",
              "                                     1.5990e-01, -1.4853e-01, -1.3980e-01,  2.0914e-01,\n",
              "                                     1.7246e-01,  6.5053e-02, -3.2843e-02,  1.3149e-01,\n",
              "                                    -2.4971e-01,  2.6152e-01, -4.7157e-01,  1.0275e-02,\n",
              "                                     1.1306e-01, -3.6145e-02, -5.3307e-01, -1.5195e-01,\n",
              "                                    -7.5139e-02, -6.0640e-03, -3.4545e-01, -7.2228e-02,\n",
              "                                    -2.2405e-01,  5.3081e-02, -1.9210e-01, -3.0610e-02,\n",
              "                                     1.6888e-01,  7.9120e-02, -1.6057e-02,  4.8251e-02,\n",
              "                                     3.3143e-01,  6.7557e-02,  1.1763e-01, -3.3918e-01,\n",
              "                                    -5.4756e-02, -1.1380e-01, -1.6717e-01, -6.6830e-01,\n",
              "                                    -5.0170e-01, -1.0854e-01, -1.5670e-01,  1.2202e-01,\n",
              "                                    -5.5895e-02,  2.5395e-04, -4.4530e-02, -2.1941e-01,\n",
              "                                    -3.4426e-01, -2.9651e-01, -3.5412e-01, -1.4391e-02,\n",
              "                                    -3.7476e-01,  2.6701e-01,  7.8669e-02, -1.4689e-01,\n",
              "                                    -3.0751e-01, -2.6800e-01,  5.5589e-01, -6.2674e-02,\n",
              "                                     5.6139e-02,  2.7381e-01,  3.3305e-01,  2.6514e-01,\n",
              "                                    -3.0300e-01, -3.7893e-01,  3.1653e-01,  1.5169e-02,\n",
              "                                     8.9149e-02, -1.1887e-01, -2.6301e-01, -3.7687e-01,\n",
              "                                    -1.6249e-01,  1.7865e-02, -2.9122e-01, -2.1251e-01,\n",
              "                                    -8.1003e-02, -2.5401e-02, -2.7202e-01, -1.4102e-01,\n",
              "                                     2.5381e-01, -3.1667e-01, -2.0320e-01,  4.5670e-02,\n",
              "                                    -3.6112e-01,  4.9364e-02, -2.4323e-01,  2.6796e-02,\n",
              "                                    -8.8429e-02, -1.4593e-01, -1.4394e-01, -2.5045e-01,\n",
              "                                    -3.8574e-01,  4.3809e-01, -1.9402e-01, -3.0448e-01,\n",
              "                                    -3.7618e-01,  1.5684e-01, -2.2149e-01, -2.5545e-01,\n",
              "                                    -3.4976e-02,  9.6459e-02, -1.6440e-01,  2.0957e-02,\n",
              "                                     2.7374e-01, -3.8790e-01, -2.1366e-01, -1.0206e-01,\n",
              "                                     1.8859e-01,  8.9712e-02, -9.8800e-02, -2.0298e-01,\n",
              "                                    -1.4309e-01, -1.8362e-01, -4.8396e-01, -2.0040e-01,\n",
              "                                     1.3994e-01,  5.6530e-01,  5.9050e-02,  6.9929e-02,\n",
              "                                     1.2609e-01, -1.7263e-01,  4.9130e-02, -2.6384e-01,\n",
              "                                    -2.8481e-01, -2.9157e-03,  6.7307e-02,  2.1496e-01,\n",
              "                                     3.6619e-02,  8.8969e-02, -2.3799e-01, -5.1055e-01,\n",
              "                                     1.8713e-01,  1.1260e-01, -7.0272e-03, -1.9518e-01,\n",
              "                                     3.4192e-01,  1.0151e-02, -1.7646e-01, -1.0949e-01,\n",
              "                                    -2.2585e-01,  3.5725e-01,  5.8565e-03,  1.3347e-01,\n",
              "                                    -7.2532e-02, -1.5914e-01,  1.6424e-01,  2.7039e-01]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.3596, 0.3640, 0.2050, 0.5709, 0.3996, 0.1439, 0.5391,\n",
              "                                    0.5631, 0.2208, 0.2342, 0.2005, 0.2021, 0.2593, 0.2313,\n",
              "                                    0.3681, 0.2281, 0.2781, 0.2344, 0.1597, 0.1803, 0.2007,\n",
              "                                    0.8631, 0.4038, 0.2349, 0.1926, 0.2504, 0.3258, 0.3922,\n",
              "                                    0.1824, 0.1807, 0.3140, 0.5874, 0.1133, 0.1817, 0.3032,\n",
              "                                    0.3277, 0.4467, 0.2323, 0.2361, 0.2158, 0.3427, 0.2342,\n",
              "                                    0.2965, 0.6083, 0.2566, 0.2410, 0.3832, 0.1510, 0.4977,\n",
              "                                    0.3639, 0.2705, 0.3820, 0.3230, 0.2804, 0.4760, 0.4841,\n",
              "                                    0.6185, 0.1750, 0.1887, 0.2746, 0.2594, 0.1855, 0.1750,\n",
              "                                    0.1879, 0.4464, 0.5755, 0.3271, 0.2249, 0.1894, 0.2841,\n",
              "                                    0.3553, 0.3932, 0.2297, 0.1696, 0.2865, 0.1743, 0.7465,\n",
              "                                    0.1688, 0.2016, 0.1386, 0.8790, 0.3727, 0.6146, 0.2224,\n",
              "                                    0.4689, 0.4154, 0.1741, 0.4329, 0.2165, 0.1981, 0.3517,\n",
              "                                    0.3979, 0.2087, 0.2081, 0.2978, 0.3744, 0.2004, 0.2493,\n",
              "                                    0.3280, 0.5839, 0.2346, 0.2764, 0.1470, 0.1512, 0.1451,\n",
              "                                    0.1856, 0.5215, 0.3717, 0.3239, 0.2431, 0.2961, 0.1409,\n",
              "                                    0.1508, 1.0275, 0.1692, 0.1937, 0.2336, 0.6339, 0.5225,\n",
              "                                    0.2437, 0.3231, 0.2186, 0.6388, 0.1952, 0.5282, 0.4860,\n",
              "                                    0.4015, 1.4710, 0.2586, 0.4362, 0.1794, 0.1660, 0.1322,\n",
              "                                    0.1844, 0.1469, 0.3069, 0.4227, 0.2132, 0.2162, 0.1531,\n",
              "                                    0.4776, 0.4192, 0.2757, 0.1621, 0.1969, 0.7525, 0.3074,\n",
              "                                    0.1484, 0.1789, 0.4407, 0.7110, 0.2947, 0.2890, 0.3389,\n",
              "                                    0.4272, 0.1730, 0.5450, 0.2660, 0.3379, 0.4704, 0.2971,\n",
              "                                    0.2098, 0.1659, 0.3032, 0.3403, 0.4599, 0.3261, 0.3952,\n",
              "                                    0.4050, 0.2554, 0.4126, 0.7784, 0.2420, 0.3462, 0.1947,\n",
              "                                    0.3395, 0.2446, 0.0975, 0.2377, 0.7200, 0.3932, 0.3610,\n",
              "                                    0.1316, 0.1878, 0.7002, 0.7215, 0.3091, 0.1615, 0.0884,\n",
              "                                    0.2009, 0.3734, 0.2735, 0.8020, 0.2640, 0.2868, 0.1694,\n",
              "                                    0.5469, 0.1906, 0.6189, 0.3560, 0.1642, 0.2788, 0.6856,\n",
              "                                    0.6279, 0.5763, 0.5479, 0.2461, 0.2396, 0.3282, 0.2744,\n",
              "                                    0.1687, 0.2711, 0.5363, 0.1559, 0.2884, 0.2112, 0.1309,\n",
              "                                    0.2590, 0.2706, 0.8510, 0.1967, 0.2613, 0.2013, 0.3060,\n",
              "                                    0.2498, 0.7050, 0.2893, 0.2716, 0.2265, 0.2342, 0.2852,\n",
              "                                    0.3163, 0.5177, 0.1719, 0.3908, 0.3235, 0.3066, 0.1953,\n",
              "                                    0.2259, 0.1812, 0.4328, 0.2380, 0.3531, 0.6836, 0.2997,\n",
              "                                    0.4793, 0.1463, 0.4542, 0.2415, 0.2469, 0.3867, 0.1387,\n",
              "                                    0.1615, 0.2489, 0.2115, 0.1764, 0.6874, 0.1908, 0.2517,\n",
              "                                    0.2311, 0.2697, 0.1214, 0.1921, 0.3243, 0.3358, 0.3888,\n",
              "                                    0.5806, 0.2593, 0.1577, 0.2302, 0.8164, 0.3009, 0.7615,\n",
              "                                    0.2936, 0.2768, 0.3990, 0.2897, 0.3462, 0.2890, 0.3339,\n",
              "                                    0.4986, 0.2364, 0.2334, 0.2880, 0.4124, 0.6630, 0.2966,\n",
              "                                    0.5490, 0.3987, 0.1538, 0.3089, 0.3628, 0.2526, 0.1816,\n",
              "                                    0.3657, 0.3779, 0.3974, 0.2244, 0.3288, 0.5545, 0.3367,\n",
              "                                    0.4376, 0.1750, 0.2384, 0.2428, 0.5236, 0.1278, 0.2886,\n",
              "                                    0.3285, 0.3618, 0.4451, 0.4651, 0.2032, 0.2790, 0.3972,\n",
              "                                    0.2255, 0.6377, 0.3750, 0.2080, 0.1714, 0.5110, 0.2109,\n",
              "                                    0.1365, 0.3551, 0.3738, 0.2335, 0.4246, 0.1735, 0.3822,\n",
              "                                    0.2466, 0.2181, 0.4554, 0.4255, 0.2181, 0.1340, 0.3384,\n",
              "                                    0.2329, 0.4070, 0.2227, 0.5008, 0.5143, 0.2683, 0.5122,\n",
              "                                    0.4284, 0.3493, 0.7610, 0.1726, 0.1678, 0.5924, 0.3118,\n",
              "                                    0.4797, 0.1304, 0.3956, 0.1832, 0.3044, 0.6631, 0.2070,\n",
              "                                    0.1361, 0.6225, 0.3466, 0.2168, 0.1938, 0.2840, 0.1685,\n",
              "                                    0.3288, 0.2870, 0.5989, 0.5957, 0.3196, 0.1978, 0.1736,\n",
              "                                    0.2424, 0.1976, 0.3398, 0.5540, 0.3019, 0.3174, 0.4101,\n",
              "                                    0.2467, 0.1107, 0.5436, 0.2577, 0.2138, 0.5325, 0.4058,\n",
              "                                    0.2738, 0.2437, 0.5646, 0.2634, 0.3544, 0.2743, 0.3077,\n",
              "                                    0.1271, 0.4666, 0.4421, 0.1128, 0.3446, 0.5470, 0.2148,\n",
              "                                    0.2357, 0.5206, 0.2433, 0.1990, 0.5513, 0.4260, 0.2453,\n",
              "                                    0.2811, 0.3046, 0.2085, 0.2454, 0.2832, 0.1720, 0.3561,\n",
              "                                    0.3188, 0.1754, 0.2739, 0.1429, 0.6036, 0.1528, 0.1536,\n",
              "                                    0.4319, 0.2941, 0.1130, 0.3065, 0.2669, 0.6309, 0.2457,\n",
              "                                    0.3989, 0.8142, 0.1895, 0.1337, 0.1768, 0.4470, 0.2228,\n",
              "                                    0.5699, 0.3943, 0.1839, 0.2051, 0.2029, 0.2523, 0.2229,\n",
              "                                    0.2144, 0.3952, 0.2259, 0.6092, 0.4251, 0.1919, 0.1891,\n",
              "                                    0.2997, 0.3773, 0.2130, 0.3266, 0.1878, 0.3379, 0.1913,\n",
              "                                    0.8804, 0.4632, 0.5950, 0.2213, 0.4718, 0.2829, 0.1767,\n",
              "                                    0.1794, 0.2772, 0.2190, 0.1954, 0.3012, 0.3384, 0.2169,\n",
              "                                    0.5289, 0.2091, 0.4501, 0.4734, 0.8857, 0.5062, 0.3027,\n",
              "                                    0.2306, 0.1764, 0.1735, 0.2048, 0.4907, 0.4804, 0.3887,\n",
              "                                    0.4837, 0.1838, 0.1953, 0.5607, 0.3103, 0.1558, 0.1516,\n",
              "                                    0.2203, 0.1981, 0.2919, 0.1907, 0.3089, 0.4115, 0.1641,\n",
              "                                    0.5438, 0.2365, 0.1586, 0.5518, 0.3131, 0.2115, 0.2901,\n",
              "                                    0.3518, 0.6019, 0.1788, 0.2592, 0.1980, 0.2382, 0.1530,\n",
              "                                    0.1618]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.1.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   1,   2,  ..., 509, 510, 511],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.0886,  0.0307, -0.0447,  ..., -0.0046, -0.0046,\n",
              "                                    -0.0893]),\n",
              "                     size=(128, 512, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([1.0059, 1.0064, 0.9891, 0.9897, 1.0058, 0.9912, 1.0068,\n",
              "                                    1.0021, 0.9671, 0.9843, 1.0083, 0.9935, 1.0061, 1.0154,\n",
              "                                    1.0021, 1.0027, 1.0211, 0.9969, 0.9984, 1.0154, 1.0011,\n",
              "                                    1.0038, 1.0315, 1.0208, 0.9917, 0.9748, 1.0146, 1.0179,\n",
              "                                    0.9906, 0.9973, 0.9873, 0.9996, 0.9986, 0.9840, 0.9605,\n",
              "                                    1.0263, 0.9985, 0.9968, 1.0001, 0.9873, 0.9961, 0.9919,\n",
              "                                    1.0049, 0.9890, 0.9856, 1.0253, 0.9831, 0.9935, 0.9874,\n",
              "                                    0.9815, 1.0049, 0.9890, 0.9820, 1.0234, 1.0034, 1.0102,\n",
              "                                    0.9838, 0.9961, 0.9880, 0.9908, 0.9521, 1.0119, 1.0448,\n",
              "                                    1.0044, 0.9880, 0.9678, 1.0079, 1.0165, 0.9849, 1.0023,\n",
              "                                    0.9954, 0.9807, 1.0087, 1.0148, 1.0055, 1.0029, 0.9933,\n",
              "                                    0.9899, 0.9930, 0.9770, 0.9957, 1.0077, 1.0051, 0.9791,\n",
              "                                    0.9846, 1.0276, 0.9952, 0.9901, 0.9899, 1.0003, 1.0256,\n",
              "                                    0.9936, 1.0145, 0.9987, 0.9876, 1.0014, 0.9967, 1.0089,\n",
              "                                    1.0030, 0.9932, 1.0044, 0.9922, 0.9959, 1.0095, 1.0071,\n",
              "                                    0.9960, 1.0099, 1.0144, 0.9904, 1.0010, 0.9983, 0.9969,\n",
              "                                    0.9758, 0.9967, 0.9861, 0.9995, 1.0051, 1.0024, 1.0251,\n",
              "                                    1.0305, 1.0067, 0.9881, 1.0314, 1.0231, 1.0264, 0.9987,\n",
              "                                    1.0077, 0.9848]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([-0.0015,  0.0098,  0.0137, -0.0053,  0.0040,  0.0003,\n",
              "                                    -0.0201,  0.0228, -0.0178, -0.0032,  0.0277, -0.0191,\n",
              "                                    -0.0036,  0.0091,  0.0086,  0.0143,  0.0214,  0.0066,\n",
              "                                     0.0122, -0.0115, -0.0075,  0.0043,  0.0140,  0.0297,\n",
              "                                     0.0048, -0.0183,  0.0003, -0.0032,  0.0065, -0.0035,\n",
              "                                    -0.0121,  0.0106,  0.0011, -0.0090, -0.0260, -0.0054,\n",
              "                                    -0.0030,  0.0072,  0.0188,  0.0056, -0.0074, -0.0071,\n",
              "                                     0.0187, -0.0021, -0.0177,  0.0045, -0.0023, -0.0066,\n",
              "                                     0.0099,  0.0115, -0.0110,  0.0060, -0.0020, -0.0011,\n",
              "                                    -0.0112, -0.0089,  0.0094,  0.0125, -0.0003, -0.0047,\n",
              "                                    -0.0184, -0.0144,  0.0278,  0.0185, -0.0139, -0.0046,\n",
              "                                     0.0051, -0.0018, -0.0056, -0.0132,  0.0093, -0.0139,\n",
              "                                     0.0236,  0.0086,  0.0032,  0.0120, -0.0137,  0.0008,\n",
              "                                    -0.0079,  0.0129,  0.0012,  0.0006,  0.0140,  0.0068,\n",
              "                                    -0.0040,  0.0296,  0.0053, -0.0163,  0.0001, -0.0103,\n",
              "                                     0.0258, -0.0025,  0.0022,  0.0208,  0.0007,  0.0093,\n",
              "                                     0.0042,  0.0171,  0.0100, -0.0045,  0.0125, -0.0160,\n",
              "                                    -0.0093,  0.0289,  0.0016,  0.0119,  0.0130,  0.0113,\n",
              "                                    -0.0085, -0.0019,  0.0020,  0.0101, -0.0149,  0.0047,\n",
              "                                    -0.0246,  0.0140,  0.0048,  0.0250,  0.0121,  0.0195,\n",
              "                                     0.0161, -0.0010, -0.0057,  0.0071,  0.0506,  0.0040,\n",
              "                                    -0.0090, -0.0082]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 1.9575, -0.6334, -0.2252,  5.4054, -2.5370,  0.8895,\n",
              "                                     0.1685, -2.9999, -2.8732,  2.0572, -5.0299,  0.5789,\n",
              "                                     0.8941, -1.7618, -3.7298, -4.6249, -4.3361,  1.2818,\n",
              "                                    -1.6018,  4.2712, -3.1729, -4.5097,  0.6462, -3.5292,\n",
              "                                    -1.1203, -3.4674,  1.8788,  3.2868,  0.1959, -1.8053,\n",
              "                                     4.1838, -0.7286, -2.9588, -4.4255,  2.4874,  1.1617,\n",
              "                                    -5.1893, -4.3360,  1.8661, -1.2217, -2.3143,  2.9527,\n",
              "                                     0.8576, -2.4521,  1.1357,  1.1181, -0.4936, -4.1175,\n",
              "                                    -1.3179,  5.2792, -1.3359,  1.4370,  2.9071, -2.9367,\n",
              "                                     1.9363, -0.1784, -1.8193, -3.4129,  0.4449,  2.3641,\n",
              "                                    -3.3107,  2.1353, -0.1681, -2.1300, -3.6311,  1.0291,\n",
              "                                     3.5830, -1.6815, -2.0551,  1.6628,  0.6145,  3.3282,\n",
              "                                    -0.6704, -1.9003,  1.8580,  0.6347,  2.6214, -2.4602,\n",
              "                                    -3.3007,  0.3910, -0.1983, -1.2976,  1.8696,  1.9492,\n",
              "                                     2.9187, -0.2071, -5.8556, -0.5658, -3.7911, -0.7165,\n",
              "                                    -0.4014,  0.0328,  1.4050,  2.1943, -2.5652,  0.2321,\n",
              "                                    -3.4553,  4.5378,  2.9189, -1.8101, -1.2680, -2.2605,\n",
              "                                     5.6285,  3.5853,  1.2075,  0.8239,  2.8000, -0.1078,\n",
              "                                    -2.2993, -0.5726,  0.6474, -1.7274, -2.6546, -6.1198,\n",
              "                                    -1.8250,  0.9628, -0.5572, -3.6343, -2.7416,  0.4376,\n",
              "                                     1.3410, -1.7354,  0.8727, -2.2880,  2.0233, -1.6967,\n",
              "                                     6.0324,  3.0574]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([34.8060, 35.4936, 23.7239, 46.2131, 27.9847, 18.3835,\n",
              "                                    12.5091, 35.7613, 15.8965, 24.2508, 21.1353, 25.9446,\n",
              "                                    17.1428, 28.8751, 38.9010, 29.1332, 36.9335, 27.0658,\n",
              "                                    20.8193, 23.0239, 34.0112, 31.4274, 19.7931, 31.0859,\n",
              "                                    12.9351, 29.4114, 29.0466, 26.8631, 25.0972, 23.1346,\n",
              "                                    36.6146, 19.0504, 33.7334, 27.7489, 17.7473, 16.0022,\n",
              "                                    31.0255, 38.6142, 29.4492, 17.2814, 20.3676, 29.0463,\n",
              "                                    23.6781, 37.9415, 29.3343, 17.5317, 25.6737, 47.8678,\n",
              "                                    35.3272, 30.9706, 27.7584, 30.3548, 60.8419, 29.1498,\n",
              "                                    19.6721, 19.1443, 49.9395, 35.3864, 21.1564, 48.8340,\n",
              "                                    35.2047, 25.8133, 30.0835, 26.2891, 31.6800, 36.4725,\n",
              "                                    34.9566, 36.9468, 18.8112, 34.4736, 15.4147, 34.7142,\n",
              "                                    35.2714, 19.4530, 37.0102, 30.0615, 35.5255, 27.0830,\n",
              "                                    14.5205, 33.7090, 40.4221, 17.9664, 31.9368, 55.1417,\n",
              "                                    41.0385, 28.3760, 58.4705, 19.0935, 47.4013, 21.6284,\n",
              "                                    46.9519, 22.6293, 21.5433, 31.7101, 30.5683, 16.4265,\n",
              "                                    39.1738, 46.4935, 27.2108, 40.1610, 35.8909, 51.7649,\n",
              "                                    65.2889, 66.7798, 25.7799, 31.4896, 39.5983, 20.7219,\n",
              "                                    23.9648, 12.0513, 22.2454, 19.7310, 19.2312, 49.9987,\n",
              "                                    36.9220, 35.6735, 22.9266, 28.8552, 23.3407, 47.5051,\n",
              "                                    19.9961, 38.5257, 16.7866, 50.7155, 48.4430, 63.6964,\n",
              "                                    53.0902, 20.6675]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([-0.0022,  0.0285, -0.0088,  ..., -0.0222,  0.0152,\n",
              "                                     0.0139]),\n",
              "                     size=(128, 128, 3, 3), nnz=147456, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([1.0091, 1.0084, 0.9758, 0.9896, 1.0177, 1.0033, 1.0076,\n",
              "                                    0.9864, 0.9994, 1.0013, 0.9869, 1.0070, 0.9959, 0.9777,\n",
              "                                    1.0074, 1.0205, 1.0096, 0.9827, 0.9855, 0.9950, 0.9964,\n",
              "                                    0.9976, 0.9974, 0.9964, 1.0173, 1.0042, 0.9847, 1.0137,\n",
              "                                    1.0013, 0.9896, 0.9871, 0.9805, 1.0193, 1.0006, 1.0016,\n",
              "                                    0.9967, 0.9806, 0.9884, 1.0022, 1.0042, 1.0010, 0.9850,\n",
              "                                    0.9901, 0.9983, 1.0112, 1.0242, 0.9650, 0.9778, 1.0132,\n",
              "                                    1.0410, 1.0091, 0.9800, 0.9750, 1.0369, 0.9934, 1.0065,\n",
              "                                    1.0015, 0.9866, 1.0165, 0.9869, 1.0079, 1.0195, 1.0071,\n",
              "                                    1.0002, 0.9876, 1.0026, 1.0020, 0.9891, 1.0051, 0.9930,\n",
              "                                    1.0095, 0.9816, 0.9996, 0.9935, 1.0031, 1.0167, 0.9715,\n",
              "                                    1.0073, 0.9985, 1.0009, 0.9998, 0.9850, 0.9873, 0.9890,\n",
              "                                    0.9895, 1.0046, 1.0096, 0.9875, 1.0010, 1.0179, 0.9963,\n",
              "                                    1.0250, 1.0034, 1.0154, 0.9854, 0.9737, 0.9977, 0.9868,\n",
              "                                    1.0052, 0.9815, 0.9940, 0.9971, 1.0137, 0.9917, 1.0080,\n",
              "                                    0.9976, 1.0181, 1.0097, 1.0046, 0.9935, 0.9978, 0.9902,\n",
              "                                    1.0190, 1.0114, 0.9886, 1.0128, 1.0040, 1.0181, 0.9868,\n",
              "                                    0.9892, 1.0302, 0.9884, 0.9847, 1.0306, 0.9936, 0.9981,\n",
              "                                    0.9939, 0.9982]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 0.0042, -0.0030,  0.0261, -0.0197,  0.0009, -0.0115,\n",
              "                                     0.0236, -0.0055, -0.0158, -0.0016, -0.0217,  0.0063,\n",
              "                                    -0.0013, -0.0083, -0.0291,  0.0155,  0.0205, -0.0095,\n",
              "                                    -0.0163, -0.0044, -0.0337,  0.0083, -0.0036, -0.0054,\n",
              "                                    -0.0109, -0.0093,  0.0069,  0.0086,  0.0090, -0.0206,\n",
              "                                    -0.0067, -0.0123,  0.0161, -0.0424,  0.0192,  0.0105,\n",
              "                                     0.0016, -0.0149, -0.0056,  0.0024, -0.0077, -0.0019,\n",
              "                                     0.0018,  0.0141,  0.0061,  0.0153, -0.0040, -0.0223,\n",
              "                                    -0.0087, -0.0094, -0.0099, -0.0149, -0.0093,  0.0064,\n",
              "                                    -0.0016,  0.0088,  0.0119, -0.0192, -0.0268,  0.0183,\n",
              "                                     0.0177,  0.0051,  0.0141, -0.0078, -0.0095,  0.0278,\n",
              "                                     0.0213,  0.0061, -0.0232, -0.0218, -0.0195, -0.0026,\n",
              "                                    -0.0015,  0.0101, -0.0156,  0.0128, -0.0165, -0.0019,\n",
              "                                    -0.0114,  0.0050, -0.0172, -0.0026,  0.0039, -0.0025,\n",
              "                                     0.0018, -0.0008, -0.0378, -0.0146, -0.0122,  0.0109,\n",
              "                                     0.0130,  0.0120,  0.0298, -0.0059, -0.0055, -0.0117,\n",
              "                                     0.0089, -0.0047,  0.0050, -0.0219,  0.0091, -0.0119,\n",
              "                                     0.0229,  0.0096,  0.0243, -0.0039, -0.0028, -0.0086,\n",
              "                                     0.0102, -0.0038, -0.0017, -0.0039,  0.0183,  0.0302,\n",
              "                                     0.0148, -0.0094, -0.0115,  0.0020, -0.0178, -0.0090,\n",
              "                                    -0.0084, -0.0056,  0.0017,  0.0099,  0.0049, -0.0022,\n",
              "                                    -0.0013,  0.0059]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([-0.8572,  1.4129, -0.2494,  0.0588,  0.0938,  0.0085,\n",
              "                                    -1.9036, -1.8435,  1.3341, -0.4330, -0.7385, -1.5215,\n",
              "                                    -1.4858, -0.1922,  1.0988,  0.7469,  0.1641,  1.5795,\n",
              "                                    -1.0343,  0.9474, -1.0451,  0.3063, -0.5585,  0.4425,\n",
              "                                     0.0504,  0.1988, -0.0186,  0.3377,  0.2482,  0.3153,\n",
              "                                     0.0554, -0.5777, -1.3554,  0.3616,  0.0957, -0.7903,\n",
              "                                     0.1663, -1.4105, -0.0898,  0.2261,  0.1128, -0.4564,\n",
              "                                     0.6751, -0.1609, -0.3031,  0.2541, -0.2259, -0.5840,\n",
              "                                    -0.6200, -0.2177,  0.4107, -1.4675, -1.0997, -0.5405,\n",
              "                                    -0.8212,  0.4047, -0.5837, -0.6660, -0.5936, -1.3146,\n",
              "                                    -0.7332,  0.0633,  0.7228, -0.6153, -1.0131,  0.2399,\n",
              "                                     0.0037,  0.7497, -0.0776,  0.4247,  1.0291,  1.0173,\n",
              "                                     0.2324, -0.6733, -0.3312,  0.7070, -0.2704, -2.4153,\n",
              "                                     1.3176, -0.7460, -0.0669,  0.1935, -0.9943, -0.6777,\n",
              "                                     0.0697, -0.2005,  0.7223, -1.0813, -0.2515,  0.3849,\n",
              "                                     0.0484,  0.2036,  0.1831,  0.4590, -1.4060, -0.1283,\n",
              "                                    -0.8052,  0.8386, -0.2261, -1.2125, -0.7986,  0.6718,\n",
              "                                     0.0662, -1.3975, -0.2653,  0.1607,  0.5518,  1.4955,\n",
              "                                    -0.6698, -0.1980, -0.1995,  1.5165,  0.2653, -1.1589,\n",
              "                                     0.7174, -0.4246,  0.4441, -0.4605,  0.5588, -0.3834,\n",
              "                                     0.9002,  0.1794,  0.2913,  0.5561, -0.7240, -0.0462,\n",
              "                                    -0.7632, -1.2740]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([3.1023, 5.2377, 3.0723, 3.0649, 4.7479, 4.7798, 7.7455,\n",
              "                                    7.2973, 7.1366, 3.0328, 3.3795, 6.9705, 5.5316, 3.8779,\n",
              "                                    4.5888, 5.0637, 3.2549, 4.0865, 3.4584, 6.4416, 3.6048,\n",
              "                                    2.8692, 4.5660, 6.0088, 4.4765, 4.2958, 3.4139, 2.8596,\n",
              "                                    3.9416, 4.8791, 4.4362, 2.3085, 7.0241, 2.1887, 3.3907,\n",
              "                                    4.1599, 5.1379, 2.9351, 3.1980, 5.7811, 5.6468, 2.1697,\n",
              "                                    5.7416, 4.7993, 3.2286, 3.2646, 3.4831, 4.0637, 4.6857,\n",
              "                                    2.3845, 2.3209, 5.0519, 4.7720, 3.1872, 4.5583, 1.7377,\n",
              "                                    3.5810, 2.4526, 3.1741, 2.6612, 2.1413, 8.0368, 2.1695,\n",
              "                                    1.7624, 4.8138, 3.4193, 5.0193, 3.3627, 2.4173, 3.0162,\n",
              "                                    3.8627, 5.1776, 6.0140, 7.6848, 1.9838, 8.3258, 3.7040,\n",
              "                                    4.2889, 4.2836, 3.3012, 2.4686, 3.5749, 3.5092, 5.2555,\n",
              "                                    3.0477, 3.1378, 3.0547, 5.5241, 5.5917, 5.8409, 2.6073,\n",
              "                                    5.1492, 3.7969, 2.9248, 1.6924, 3.1998, 3.3886, 6.0312,\n",
              "                                    2.6065, 4.1326, 3.6508, 3.9656, 2.4865, 5.4672, 4.1129,\n",
              "                                    3.0927, 6.8521, 6.3148, 3.6165, 2.4658, 3.2079, 6.2714,\n",
              "                                    8.5694, 7.3977, 6.0194, 7.4891, 3.9911, 3.8358, 3.9628,\n",
              "                                    2.7259, 3.7524, 4.7868, 2.3241, 5.4898, 4.8547, 4.7097,\n",
              "                                    6.0299, 3.4291]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   1,   2,  ..., 125, 126, 127],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.0210,  0.0311,  0.0252,  ..., -0.0886, -0.0146,\n",
              "                                     0.0054]),\n",
              "                     size=(512, 128, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([1.0028, 0.9809, 0.9647, 0.9985, 0.9979, 1.0091, 0.9781,\n",
              "                                    0.9828, 1.0149, 1.0109, 1.0526, 0.9980, 1.0065, 0.9946,\n",
              "                                    0.9903, 1.0005, 0.9990, 0.9825, 1.0014, 0.9755, 0.9699,\n",
              "                                    0.9935, 1.0021, 0.9809, 1.0158, 0.9372, 1.0173, 1.0056,\n",
              "                                    0.9896, 1.0132, 1.0210, 0.9886, 0.9869, 1.0035, 0.9807,\n",
              "                                    1.0026, 1.0030, 1.0144, 1.0001, 1.0013, 1.0095, 1.0002,\n",
              "                                    0.9929, 0.9801, 1.0064, 0.9682, 0.9968, 0.9989, 0.9846,\n",
              "                                    1.0145, 1.0126, 0.9989, 1.0070, 0.9977, 0.9818, 1.0134,\n",
              "                                    0.9904, 1.0007, 0.9803, 0.9914, 0.9951, 0.9933, 0.9892,\n",
              "                                    0.9958, 0.9869, 0.9862, 0.9843, 0.9853, 0.9833, 1.0068,\n",
              "                                    0.9973, 1.0031, 1.0200, 1.0101, 1.0179, 1.0001, 0.9916,\n",
              "                                    1.0086, 0.9917, 0.9951, 0.9940, 0.9998, 0.9921, 1.0042,\n",
              "                                    0.9866, 0.9931, 1.0080, 0.9911, 1.0123, 1.0047, 0.9925,\n",
              "                                    0.9928, 0.9970, 1.0014, 1.0138, 0.9788, 0.9956, 0.9774,\n",
              "                                    0.9883, 1.0062, 0.9806, 1.0000, 0.9586, 1.0132, 1.0056,\n",
              "                                    1.0064, 0.9863, 1.0095, 0.9906, 0.9897, 0.9862, 0.9906,\n",
              "                                    0.9940, 1.0048, 0.9880, 1.0116, 1.0012, 0.9891, 0.9842,\n",
              "                                    0.9646, 0.9980, 0.9708, 0.9931, 0.9755, 1.0087, 0.9975,\n",
              "                                    0.9934, 0.9902, 1.0031, 0.9958, 0.9907, 1.0094, 1.0089,\n",
              "                                    1.0031, 1.0147, 1.0122, 0.9958, 0.9915, 0.9836, 0.9983,\n",
              "                                    1.0023, 0.9917, 0.9639, 0.9777, 0.9968, 1.0033, 0.9702,\n",
              "                                    0.9970, 1.0124, 0.9952, 0.9733, 0.9979, 1.0052, 0.9963,\n",
              "                                    1.0128, 1.0231, 1.0056, 0.9982, 0.9868, 0.9835, 0.9766,\n",
              "                                    0.9764, 1.0243, 0.9972, 1.0063, 1.0127, 0.9827, 0.9888,\n",
              "                                    0.9665, 0.9982, 0.9929, 0.9802, 0.9846, 1.0017, 1.0106,\n",
              "                                    0.9713, 0.9853, 1.0097, 1.0060, 1.0081, 0.9942, 1.0050,\n",
              "                                    0.9894, 1.0177, 0.9869, 0.9645, 1.0049, 1.0046, 1.0091,\n",
              "                                    0.9982, 0.9768, 0.9994, 0.9762, 1.0061, 1.0171, 0.9968,\n",
              "                                    0.9995, 0.9794, 0.9858, 1.0198, 1.0058, 0.9925, 0.9688,\n",
              "                                    0.9914, 1.0170, 1.0021, 0.9916, 0.9951, 1.0058, 1.0124,\n",
              "                                    0.9837, 1.0038, 1.0030, 0.9727, 1.0134, 1.0041, 0.9918,\n",
              "                                    0.9989, 1.0109, 0.9953, 0.9940, 0.9825, 0.9989, 0.9972,\n",
              "                                    1.0147, 1.0011, 0.9900, 1.0043, 0.9926, 0.9970, 1.0068,\n",
              "                                    0.9830, 1.0003, 0.9999, 0.9620, 0.9989, 1.0020, 1.0095,\n",
              "                                    0.9746, 0.9955, 1.0017, 0.9931, 1.0024, 0.9888, 0.9989,\n",
              "                                    0.9751, 0.9901, 0.9874, 0.9967, 0.9895, 0.9901, 0.9920,\n",
              "                                    0.9990, 0.9875, 1.0247, 0.9993, 0.9915, 0.9972, 1.0158,\n",
              "                                    0.9936, 1.0221, 1.0000, 1.0007, 0.9774, 1.0105, 0.9905,\n",
              "                                    0.9836, 1.0049, 1.0080, 0.9831, 1.0091, 1.0235, 0.9885,\n",
              "                                    1.0085, 1.0065, 1.0160, 1.0076, 1.0053, 0.9970, 1.0046,\n",
              "                                    0.9940, 1.0001, 1.0045, 1.0075, 0.9963, 1.0044, 1.0199,\n",
              "                                    0.9840, 0.9994, 1.0063, 0.9897, 1.0096, 1.0021, 1.0162,\n",
              "                                    0.9707, 0.9932, 1.0060, 0.9910, 1.0281, 0.9950, 0.9751,\n",
              "                                    1.0094, 0.9832, 1.0152, 0.9915, 0.9879, 0.9999, 1.0029,\n",
              "                                    0.9786, 1.0083, 0.9924, 0.9969, 1.0191, 0.9868, 0.9881,\n",
              "                                    0.9792, 0.9848, 0.9961, 1.0176, 1.0200, 1.0001, 0.9653,\n",
              "                                    0.9980, 0.9828, 1.0112, 0.9866, 0.9857, 0.9935, 0.9934,\n",
              "                                    0.9809, 0.9849, 0.9753, 1.0163, 0.9993, 1.0257, 1.0173,\n",
              "                                    1.0083, 1.0012, 0.9968, 1.0001, 1.0083, 1.0025, 0.9780,\n",
              "                                    1.0001, 0.9949, 1.0034, 1.0133, 0.9875, 0.9921, 1.0155,\n",
              "                                    1.0326, 0.9909, 0.9967, 0.9982, 0.9825, 0.9998, 0.9849,\n",
              "                                    0.9846, 0.9920, 0.9832, 1.0100, 1.0191, 0.9791, 0.9844,\n",
              "                                    1.0015, 0.9514, 1.0073, 0.9832, 0.9941, 0.9835, 0.9946,\n",
              "                                    1.0299, 1.0103, 0.9952, 1.0148, 1.0140, 0.9872, 1.0010,\n",
              "                                    0.9852, 0.9945, 1.0022, 0.9930, 0.9863, 0.9919, 0.9729,\n",
              "                                    1.0000, 1.0082, 1.0017, 1.0159, 0.9666, 1.0082, 0.9816,\n",
              "                                    0.9815, 1.0136, 0.9686, 0.9814, 0.9831, 1.0210, 0.9996,\n",
              "                                    0.9844, 0.9968, 1.0051, 0.9887, 1.0012, 1.0257, 0.9890,\n",
              "                                    1.0144, 0.9912, 1.0147, 0.9845, 1.0131, 1.0323, 0.9994,\n",
              "                                    0.9945, 1.0017, 1.0134, 0.9716, 0.9879, 0.9825, 1.0136,\n",
              "                                    0.9849, 0.9868, 0.9915, 0.9896, 1.0086, 1.0027, 0.9891,\n",
              "                                    0.9867, 0.9997, 0.9713, 1.0317, 0.9963, 1.0119, 1.0178,\n",
              "                                    0.9949, 0.9832, 1.0130, 0.9902, 1.0135, 0.9848, 0.9794,\n",
              "                                    0.9879, 0.9946, 1.0124, 0.9878, 0.9837, 1.0052, 0.9949,\n",
              "                                    1.0013, 0.9889, 1.0026, 0.9892, 0.9800, 0.9950, 1.0321,\n",
              "                                    1.0089, 0.9849, 0.9843, 1.0061, 0.9969, 0.9922, 0.9805,\n",
              "                                    0.9960, 1.0041, 0.9950, 1.0049, 1.0019, 1.0222, 0.9833,\n",
              "                                    0.9955, 0.9702, 1.0125, 1.0002, 0.9869, 0.9703, 0.9835,\n",
              "                                    1.0037, 1.0092, 0.9652, 0.9870, 1.0014, 1.0070, 0.9998,\n",
              "                                    0.9990, 0.9924, 1.0117, 0.9967, 1.0172, 0.9869, 0.9997,\n",
              "                                    1.0159, 0.9897, 0.9814, 1.0083, 0.9790, 0.9799, 1.0212,\n",
              "                                    0.9969, 0.9932, 0.9922, 1.0138, 0.9833, 0.9859, 0.9778,\n",
              "                                    0.9915, 0.9880, 0.9916, 1.0239, 1.0251, 0.9815, 0.9946,\n",
              "                                    0.9929]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 8.9013e-03,  2.7273e-02, -2.1376e-02, -1.6739e-02,\n",
              "                                    -1.9240e-02,  3.3326e-02, -2.2757e-02,  6.6976e-03,\n",
              "                                     1.1641e-02,  1.5194e-03, -6.0035e-03,  2.8913e-02,\n",
              "                                     1.8699e-02,  2.5406e-02, -2.8286e-03,  7.5412e-03,\n",
              "                                    -5.5338e-04, -2.0017e-03, -2.7883e-03, -3.2897e-02,\n",
              "                                     9.8664e-03, -1.1667e-02,  1.2477e-02, -1.0417e-02,\n",
              "                                     9.2030e-03,  2.6552e-02, -1.8570e-03, -2.7705e-03,\n",
              "                                     1.8175e-02,  6.8026e-03,  7.8600e-03,  1.7861e-02,\n",
              "                                    -3.0798e-03,  4.1872e-03,  2.3213e-02,  6.4988e-03,\n",
              "                                     1.5523e-02, -1.1162e-02,  2.6735e-02,  2.5958e-03,\n",
              "                                     1.9472e-02,  3.4493e-03,  8.1437e-03, -1.7209e-02,\n",
              "                                     3.0213e-03,  1.4553e-02,  1.8784e-02,  1.0702e-02,\n",
              "                                    -3.8079e-03,  7.0871e-03, -3.0257e-02,  1.2329e-02,\n",
              "                                    -6.6914e-03,  1.1999e-03,  2.6328e-02,  5.3199e-03,\n",
              "                                    -2.1854e-03,  6.1212e-03,  9.3527e-04,  1.5317e-02,\n",
              "                                    -3.7535e-03, -2.4294e-02,  1.3017e-03,  5.6293e-03,\n",
              "                                     2.9415e-03,  4.3591e-03, -2.6269e-03, -1.8431e-02,\n",
              "                                     8.5546e-03, -8.1328e-03,  4.3855e-03, -5.9693e-03,\n",
              "                                     2.2609e-02, -6.7008e-03,  3.3747e-02,  1.8184e-02,\n",
              "                                     5.1866e-03, -1.4408e-04, -1.2870e-02,  4.6840e-03,\n",
              "                                     7.4189e-03, -1.9682e-02, -3.2577e-02,  3.6970e-02,\n",
              "                                    -9.6341e-03, -1.7488e-02, -7.3876e-03, -5.6182e-03,\n",
              "                                     1.8220e-03,  1.4533e-02, -5.3424e-03,  3.3128e-03,\n",
              "                                     2.7907e-03, -1.0914e-02, -1.3141e-02,  2.2893e-03,\n",
              "                                     5.1405e-03,  4.6578e-03,  1.3434e-02, -6.6227e-03,\n",
              "                                     5.5227e-03,  1.0471e-02, -1.7056e-02,  5.6818e-03,\n",
              "                                     9.4331e-03, -4.2527e-03, -6.8017e-03,  6.1742e-03,\n",
              "                                     1.2330e-03, -9.0598e-03, -1.3702e-03,  2.1811e-03,\n",
              "                                     4.9343e-03, -6.4178e-03, -5.8358e-04,  9.6804e-03,\n",
              "                                     6.1818e-03,  3.5698e-02,  1.8777e-02,  5.3593e-05,\n",
              "                                     3.5019e-03, -1.8620e-02, -8.6722e-03,  2.4602e-02,\n",
              "                                    -1.7629e-02, -9.4339e-03,  1.8547e-02,  1.1031e-02,\n",
              "                                     5.9779e-04,  6.4330e-03,  9.0802e-03,  1.3828e-02,\n",
              "                                    -1.1218e-02,  8.6952e-03,  7.7558e-03, -1.5694e-02,\n",
              "                                     5.0162e-03,  1.4246e-02,  1.9021e-02,  1.4141e-02,\n",
              "                                    -1.3835e-02,  9.1355e-04,  3.8345e-02, -1.1346e-02,\n",
              "                                    -3.1944e-03,  9.7392e-03, -4.1055e-04,  1.1521e-02,\n",
              "                                    -1.1905e-02, -1.9732e-03, -1.7003e-02,  1.2598e-02,\n",
              "                                     2.2167e-02,  1.0051e-02,  1.8614e-02, -1.2220e-02,\n",
              "                                     2.6323e-02,  1.0963e-02,  3.1611e-03, -2.1905e-02,\n",
              "                                    -2.2708e-02, -5.5875e-03, -1.6459e-03,  1.4602e-02,\n",
              "                                    -1.6840e-02,  3.5189e-03, -2.0405e-02, -1.9280e-02,\n",
              "                                    -1.5506e-02, -1.2050e-02, -1.1544e-02, -6.7643e-03,\n",
              "                                     2.0328e-02,  1.0407e-03, -1.6375e-03,  1.5138e-03,\n",
              "                                     2.1049e-02,  3.0298e-02, -2.0262e-02,  4.7298e-02,\n",
              "                                    -1.9191e-02,  4.7031e-03, -4.5653e-03,  2.1715e-02,\n",
              "                                    -2.1852e-02, -3.0562e-02,  1.1670e-02, -2.4163e-02,\n",
              "                                    -1.6175e-03, -5.1239e-03,  5.8790e-03,  1.9683e-02,\n",
              "                                    -1.0697e-02,  1.4494e-02, -1.6993e-02, -1.7169e-02,\n",
              "                                     6.1956e-04, -7.6318e-03,  1.3695e-02, -4.0660e-03,\n",
              "                                     1.3455e-02,  1.3687e-02, -1.7882e-03, -1.0649e-02,\n",
              "                                     9.4276e-03,  6.4107e-03,  5.9511e-03,  3.2896e-03,\n",
              "                                    -7.4461e-03,  3.4422e-02,  2.5719e-02, -2.1881e-02,\n",
              "                                     1.1164e-02, -2.3335e-02,  2.4807e-02, -3.4278e-02,\n",
              "                                    -3.1035e-03, -5.2539e-03, -1.8561e-03,  3.0098e-02,\n",
              "                                     4.6667e-03, -3.2073e-03,  4.3637e-03,  2.2159e-02,\n",
              "                                    -3.3812e-03,  6.3465e-03, -2.6232e-02,  1.5830e-02,\n",
              "                                    -8.3083e-03, -1.7793e-02,  8.2901e-03, -7.7736e-03,\n",
              "                                    -1.0454e-02, -1.2438e-02, -1.8341e-02, -1.9730e-02,\n",
              "                                     1.3196e-02, -3.5260e-03, -1.4551e-02, -1.1806e-02,\n",
              "                                    -4.8637e-03,  1.7460e-02, -7.3115e-03, -5.1803e-04,\n",
              "                                     1.2924e-02, -1.8330e-02, -3.1664e-03,  7.4964e-04,\n",
              "                                     7.0078e-03, -5.4826e-03,  1.0348e-02,  6.8302e-03,\n",
              "                                    -1.0453e-02, -6.8791e-03,  1.1538e-02, -9.5879e-03,\n",
              "                                     4.4502e-03, -8.2976e-03, -1.3139e-02, -2.0975e-03,\n",
              "                                     3.2487e-03,  1.0068e-02, -7.0698e-03, -2.3038e-03,\n",
              "                                     1.9729e-02, -1.2146e-02, -1.5320e-02,  5.7541e-04,\n",
              "                                    -4.2009e-02, -1.6058e-02, -7.6839e-03, -4.8673e-03,\n",
              "                                     1.8159e-02, -9.0475e-03,  3.1269e-02,  3.3559e-02,\n",
              "                                     6.9046e-03,  2.7331e-02,  5.3428e-03, -7.8241e-03,\n",
              "                                    -3.1549e-03,  2.8533e-03, -7.8418e-03, -9.7917e-03,\n",
              "                                    -6.1674e-03,  5.0722e-03,  3.5588e-03, -1.1361e-05,\n",
              "                                    -1.3487e-02,  1.3135e-02,  1.1826e-02, -2.0598e-03,\n",
              "                                     8.6033e-03, -1.8951e-02,  1.0601e-03,  2.9624e-02,\n",
              "                                     1.7969e-03,  1.0714e-02,  1.4872e-02, -1.3148e-02,\n",
              "                                     3.9313e-02,  2.8749e-03,  9.2007e-03, -3.8308e-03,\n",
              "                                     8.2468e-03,  5.5839e-04,  2.8968e-03, -8.0353e-04,\n",
              "                                     2.4709e-03, -4.2710e-04,  2.4119e-03,  3.2168e-03,\n",
              "                                     2.2320e-02,  2.7882e-02,  4.2337e-03,  5.9626e-03,\n",
              "                                     8.7339e-03,  4.4360e-03,  8.6347e-03,  5.6086e-03,\n",
              "                                    -2.5656e-02,  1.7011e-02,  9.5695e-05,  8.7197e-03,\n",
              "                                     3.0168e-03,  2.6434e-02, -2.2260e-02,  1.5678e-02,\n",
              "                                    -4.9639e-03, -1.3145e-02,  1.3030e-02,  3.0989e-02,\n",
              "                                     6.0481e-03,  1.5342e-02, -1.1595e-02,  1.6073e-02,\n",
              "                                     9.1000e-03,  2.6973e-02,  1.7752e-02, -1.1294e-02,\n",
              "                                     2.5018e-02, -2.2238e-03,  9.1819e-03, -5.4119e-03,\n",
              "                                    -1.7322e-02,  7.4940e-03,  2.0214e-02, -4.6955e-03,\n",
              "                                     1.5248e-02,  1.2996e-02,  1.4791e-04,  1.4662e-02,\n",
              "                                     7.2977e-03,  1.2145e-02, -1.9770e-02, -4.3601e-04,\n",
              "                                    -8.4237e-03, -5.8362e-04,  2.2874e-02, -1.2624e-03,\n",
              "                                     1.9231e-02,  7.1653e-04,  8.2234e-03,  8.8117e-04,\n",
              "                                     1.6104e-02,  5.4596e-03,  8.5753e-03,  1.7293e-02,\n",
              "                                    -9.0982e-04,  7.9866e-03, -1.1794e-02,  1.7149e-02,\n",
              "                                     3.0907e-03,  2.9618e-02,  2.6705e-03, -7.6429e-03,\n",
              "                                     2.1889e-02, -1.0436e-02,  2.4851e-02, -9.6054e-04,\n",
              "                                    -4.6106e-03,  2.3098e-02, -8.4157e-03,  2.0148e-02,\n",
              "                                     1.3926e-02,  4.8099e-03, -6.2702e-04, -3.2337e-03,\n",
              "                                     6.9804e-03,  9.4890e-03,  6.6971e-03,  2.1538e-02,\n",
              "                                     1.1754e-02,  1.8328e-02,  1.6163e-02, -1.6118e-02,\n",
              "                                     1.5846e-02, -2.0355e-02,  1.5254e-02,  1.4677e-02,\n",
              "                                     1.7667e-03,  2.8117e-03, -4.7413e-03,  3.7444e-03,\n",
              "                                     2.1532e-02, -3.1177e-03,  1.6095e-02,  2.5904e-03,\n",
              "                                     1.1228e-02, -2.8457e-03,  3.3720e-03,  3.6317e-03,\n",
              "                                     2.4128e-03, -4.7267e-03, -3.8432e-04, -1.2180e-03,\n",
              "                                     5.6714e-03, -2.7900e-02, -2.3414e-02, -1.4743e-02,\n",
              "                                     1.9717e-02, -1.0518e-02, -1.7434e-02,  9.5771e-03,\n",
              "                                     9.2244e-03, -2.0707e-02,  2.2624e-02,  1.4411e-02,\n",
              "                                    -1.1209e-02, -9.8184e-03, -1.5832e-02,  1.3735e-02,\n",
              "                                     3.4969e-03, -1.0393e-02,  1.4212e-02, -1.6887e-03,\n",
              "                                    -4.2447e-03, -2.7650e-02, -9.5755e-03, -1.7249e-02,\n",
              "                                    -3.5411e-03, -1.8019e-02, -1.9512e-02, -3.5821e-04,\n",
              "                                     1.2211e-02, -8.3715e-03,  1.0804e-03,  1.5026e-02,\n",
              "                                     1.1454e-02,  1.0237e-02, -1.0644e-02,  3.4541e-02,\n",
              "                                     4.8916e-03,  1.2489e-02,  7.1891e-03,  2.3383e-02,\n",
              "                                     2.8751e-03,  2.8964e-02, -2.1773e-02, -9.6237e-03,\n",
              "                                     8.7448e-03, -1.5844e-02, -1.3020e-02,  4.6055e-02,\n",
              "                                    -2.4563e-03,  1.6879e-02, -9.4744e-03,  5.8593e-03,\n",
              "                                     1.2625e-03, -1.7862e-03, -1.8902e-02, -6.7559e-03,\n",
              "                                     1.0563e-02,  8.0383e-03,  2.1697e-02,  6.8546e-03,\n",
              "                                    -4.6455e-03,  6.8661e-03,  1.7773e-02, -2.4743e-02,\n",
              "                                     5.9315e-03,  4.3661e-03,  1.6652e-02, -9.6393e-03,\n",
              "                                     3.4671e-02,  6.5898e-03,  1.9315e-02,  1.5393e-02,\n",
              "                                     7.1701e-05, -2.2250e-03,  2.6054e-02,  1.5017e-02,\n",
              "                                     5.5878e-03,  2.8926e-03,  2.4119e-02, -1.2667e-03,\n",
              "                                    -2.9977e-02, -2.6060e-02, -6.9540e-03,  1.0339e-02,\n",
              "                                     8.9150e-03,  4.6212e-04,  2.5255e-02,  7.8040e-03,\n",
              "                                    -2.8499e-02, -1.0845e-02, -6.6145e-03,  2.9928e-02,\n",
              "                                    -8.5355e-03,  1.6592e-02, -2.3413e-02, -1.0294e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 0.3167, -0.0234, -0.0838,  0.1500, -0.5161, -0.2184,\n",
              "                                     0.0445, -0.0298,  0.1689,  0.3473, -0.4116, -0.2301,\n",
              "                                     0.2973, -0.0539, -0.2422, -0.2671, -0.1009,  0.0041,\n",
              "                                    -0.0233, -0.0885, -0.0289, -0.1838, -0.0230,  0.0301,\n",
              "                                    -0.0858, -0.3872, -0.4047, -0.0529, -0.0701,  0.0533,\n",
              "                                    -0.4403, -0.0850, -0.0889, -0.3012,  0.0097, -0.0529,\n",
              "                                    -0.2074,  0.0466, -0.4696, -0.1656,  0.0830, -0.7583,\n",
              "                                    -0.3527,  0.0723, -0.1746,  0.1340, -0.2149,  0.2061,\n",
              "                                    -0.2022, -0.3360,  0.2777,  0.2685, -0.0776,  0.0867,\n",
              "                                    -0.3656, -0.1756,  0.3819, -0.1026, -0.1777, -0.5483,\n",
              "                                    -0.1223, -0.5102,  0.4104, -0.3881, -0.0719,  0.0449,\n",
              "                                     0.5246, -0.1386, -0.1024,  0.3200,  0.0641, -0.2116,\n",
              "                                    -0.3864,  0.2470, -0.3278, -0.1616,  0.1500, -0.1181,\n",
              "                                    -0.3471, -0.4247, -0.2302,  0.1224,  0.1130, -0.2132,\n",
              "                                    -0.0879, -0.1444,  0.0583, -0.2918, -0.2292, -0.0865,\n",
              "                                     0.4588, -0.4834, -0.1795, -0.2661,  0.1427,  0.1105,\n",
              "                                     0.1984,  0.4020, -0.1823,  0.3990, -0.0558,  0.1568,\n",
              "                                    -0.2289, -0.0840, -0.1586, -0.1061,  0.2272,  0.3128,\n",
              "                                     0.0176, -0.0051, -0.2451, -0.3256, -0.0359, -0.2603,\n",
              "                                     0.2597, -0.0571,  0.1925, -0.6768,  0.0134,  0.0405,\n",
              "                                    -0.2905,  0.6099, -0.0436,  0.3571,  0.3425,  0.0336,\n",
              "                                    -0.2818,  0.2591,  0.5053, -0.3469,  0.0877,  0.0360,\n",
              "                                     0.0827, -0.2301, -0.1012, -0.1225,  0.4825, -0.1002,\n",
              "                                     0.0266, -0.1460,  0.2270, -0.0816,  0.0043,  0.4885,\n",
              "                                     0.5258, -0.3801, -0.1132, -0.2747,  0.0047,  0.3094,\n",
              "                                     0.1095,  0.2480,  0.1364,  0.6538, -0.0906, -0.4314,\n",
              "                                     0.0952, -0.4432, -0.4575, -0.0842, -0.3725, -0.1665,\n",
              "                                    -0.2072, -0.3159, -0.1603, -0.0624, -0.0765,  0.0765,\n",
              "                                    -0.0296, -0.7546, -0.3248, -0.5250,  0.6289,  0.1467,\n",
              "                                    -0.7728,  0.2586,  0.4425,  0.0905, -0.1869, -0.1669,\n",
              "                                    -0.0322, -0.1167,  0.2890, -0.0725, -0.2319, -0.0274,\n",
              "                                     0.3528,  0.3666,  0.0954,  0.0231, -0.1002, -0.3156,\n",
              "                                     0.2766, -0.0358, -0.1053,  0.1237, -0.0859, -0.0828,\n",
              "                                     0.5232,  0.1700, -0.0657, -0.4601,  0.2389, -0.7753,\n",
              "                                    -0.1603,  0.1700, -0.3239, -0.0333, -0.2375, -0.4473,\n",
              "                                    -0.3097, -0.3758,  0.2013, -0.4475,  0.0665, -0.2131,\n",
              "                                     0.0031, -0.2320, -0.1052, -0.0894, -0.1797,  0.0763,\n",
              "                                     0.2890, -0.3636, -0.0429,  0.2228, -0.4561, -0.1974,\n",
              "                                     0.0873,  0.2836,  0.2002,  0.0794, -0.2507,  0.0928,\n",
              "                                    -0.1432, -0.1389, -0.2333, -0.2331, -0.1828, -0.3798,\n",
              "                                    -0.2856,  0.0997,  0.3311, -0.3767, -0.0487, -0.4234,\n",
              "                                    -0.2093,  0.2376,  0.0739, -0.3728,  0.3660, -0.0702,\n",
              "                                     0.0481, -0.3821, -0.0967,  0.2730,  0.2588,  0.1933,\n",
              "                                    -0.1978, -0.2827, -0.2742,  0.4498,  0.3087,  0.1946,\n",
              "                                    -0.2755, -0.1389, -0.0882,  0.1869,  0.1560, -0.2301,\n",
              "                                    -0.2439, -0.1384, -0.1071, -0.5281, -0.0634, -0.2374,\n",
              "                                    -0.4902,  0.3528, -0.2567,  0.2480,  0.2126,  0.0397,\n",
              "                                    -0.2822, -0.3492, -0.0717, -0.2371, -0.0461, -0.2675,\n",
              "                                    -0.6821, -0.4374, -0.5171, -0.0808, -0.0265,  0.0682,\n",
              "                                     0.0832,  0.5289,  0.0204, -0.3142, -0.2515, -0.1734,\n",
              "                                    -0.6741, -0.2593, -0.2342, -0.0970,  0.1283, -0.3567,\n",
              "                                    -0.3670,  0.3606, -0.3243, -0.3727, -0.0248,  0.2023,\n",
              "                                     0.0721, -0.0105, -0.0729, -0.0490,  0.3930,  0.3161,\n",
              "                                     0.0809,  0.0845, -0.1255, -0.6221, -0.1197,  0.2072,\n",
              "                                     0.2176, -0.1553, -0.2051, -0.2076, -0.2797, -0.0402,\n",
              "                                     0.2342, -0.3871, -0.2343, -0.3241, -0.2118, -0.0712,\n",
              "                                    -0.1739, -0.0098,  0.0687, -0.3350, -0.1554, -0.4862,\n",
              "                                    -0.2105,  0.3152,  0.1641,  0.1677, -0.3342,  0.0833,\n",
              "                                    -0.0305, -0.1684, -0.3489, -0.6166, -0.2478,  0.1701,\n",
              "                                    -0.0342, -0.2479,  0.3275, -0.0343,  0.0338, -0.1676,\n",
              "                                    -0.1244, -0.0136, -0.2691,  0.0626, -0.2282, -0.0679,\n",
              "                                    -0.1901, -0.2170, -0.4607,  0.3092, -0.2389, -0.1810,\n",
              "                                     0.4713, -0.0551, -0.1956, -0.2841, -0.2833, -0.1378,\n",
              "                                    -0.1719, -0.3539,  0.1513,  0.0396,  0.0438,  0.2028,\n",
              "                                    -0.2586, -0.0958,  0.1048, -0.2066, -0.4403,  0.2286,\n",
              "                                    -0.2239, -0.2428, -0.1542, -0.2973,  0.0490,  0.1199,\n",
              "                                    -0.7186, -0.0233, -0.3482, -0.6903,  0.2335, -0.3190,\n",
              "                                    -0.0533, -0.0991, -0.2003,  0.1886, -0.1640, -0.2585,\n",
              "                                    -0.0810, -0.5842, -0.2832, -0.1634,  0.6427, -0.0110,\n",
              "                                    -0.6986, -0.1538,  0.3100, -0.0440, -0.2004, -0.6585,\n",
              "                                     0.2842, -0.1503, -0.0503,  0.1779,  0.3737, -0.2403,\n",
              "                                    -0.1474, -0.3336, -0.3430,  0.2715, -0.0355, -0.0247,\n",
              "                                    -0.0890, -0.0576, -0.5023, -0.2141, -0.4661,  0.1018,\n",
              "                                    -0.3611, -0.1982, -0.0956,  0.0174, -0.0451, -0.3082,\n",
              "                                     0.0254,  0.1253, -0.1633, -0.4546,  0.0330, -0.2948,\n",
              "                                    -0.2393,  0.1596, -0.1330, -0.1264,  0.0944, -0.4526,\n",
              "                                    -0.1038,  0.2231, -0.0674,  0.3607,  0.2469, -0.1545,\n",
              "                                    -0.1572, -0.1327, -0.5961,  0.0724, -0.0569, -0.0905,\n",
              "                                    -0.2690, -0.0560,  0.1279, -0.1456,  0.2083, -0.0582,\n",
              "                                    -0.0155,  0.0799, -0.5139, -0.4924, -0.1719,  0.2929,\n",
              "                                    -0.5224,  0.4591,  0.2385, -0.4029,  0.0177, -0.2553,\n",
              "                                    -0.5168, -0.4635,  0.2512,  0.1109, -0.1313, -0.0378,\n",
              "                                    -0.0399,  0.0262, -0.2686,  0.0620,  0.3263, -0.0748,\n",
              "                                     0.1492, -0.1309, -0.3569, -0.2433, -0.4816,  0.3202,\n",
              "                                    -0.3091,  0.2006, -0.2485, -0.1771, -0.2159,  0.0993,\n",
              "                                     0.3737, -0.2566]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.1108, 0.1802, 0.1732, 0.2261, 1.5870, 0.2458, 0.2290,\n",
              "                                    0.3862, 0.1603, 0.6504, 0.1693, 0.4526, 0.2453, 0.3226,\n",
              "                                    0.2308, 0.2958, 0.1422, 0.4166, 0.2610, 0.3308, 0.3218,\n",
              "                                    0.4604, 0.2570, 0.2122, 0.6157, 0.2468, 0.4654, 0.2530,\n",
              "                                    0.3880, 0.4733, 0.2651, 0.5387, 0.2080, 0.2563, 0.2799,\n",
              "                                    0.1960, 0.3442, 0.2639, 0.2274, 0.3270, 0.2301, 0.2613,\n",
              "                                    0.3324, 0.2396, 0.2862, 0.7284, 0.3009, 0.5379, 0.3168,\n",
              "                                    0.1527, 0.3114, 0.5391, 0.4042, 0.3841, 0.1561, 0.4174,\n",
              "                                    0.4744, 0.2103, 0.1918, 0.6057, 0.2126, 0.2321, 0.4806,\n",
              "                                    0.3722, 0.1420, 0.2767, 0.6846, 0.2387, 0.2308, 0.1856,\n",
              "                                    0.2531, 0.3029, 0.3025, 0.4600, 0.4036, 0.1696, 0.2477,\n",
              "                                    0.3791, 0.7907, 0.2318, 0.2344, 0.2497, 0.2286, 0.1692,\n",
              "                                    0.1840, 0.1233, 0.1179, 0.2165, 0.1885, 0.1597, 0.3897,\n",
              "                                    0.8342, 0.3645, 0.4806, 0.2154, 0.5485, 0.4066, 0.2909,\n",
              "                                    0.3755, 0.1936, 0.1735, 0.3514, 0.2526, 0.4910, 0.1859,\n",
              "                                    0.1205, 0.1860, 0.2089, 0.7779, 0.3013, 0.2562, 0.4692,\n",
              "                                    0.2647, 0.5548, 0.3393, 0.2804, 0.3664, 0.3803, 0.3232,\n",
              "                                    0.1546, 0.4453, 0.6690, 0.2726, 0.4386, 0.1759, 0.2606,\n",
              "                                    0.3367, 0.2220, 0.2424, 0.3604, 0.1738, 0.2367, 0.3096,\n",
              "                                    0.3143, 0.1998, 0.2740, 0.7674, 0.3090, 0.2312, 0.4341,\n",
              "                                    0.1966, 0.3486, 0.5073, 0.3717, 0.2754, 0.8374, 0.3573,\n",
              "                                    0.1405, 0.2321, 0.5512, 0.3193, 0.4420, 0.1790, 0.3567,\n",
              "                                    0.5628, 0.3928, 0.4420, 0.3247, 0.6911, 0.2732, 0.2632,\n",
              "                                    0.3082, 0.1585, 0.2322, 0.2758, 0.3204, 0.2308, 0.2585,\n",
              "                                    0.2765, 0.7504, 0.6285, 0.2637, 0.3876, 0.3331, 0.5464,\n",
              "                                    1.3152, 0.3067, 0.6116, 0.2037, 0.4911, 0.3485, 0.2840,\n",
              "                                    0.2496, 0.3181, 0.2320, 0.6695, 0.2668, 0.1647, 0.4874,\n",
              "                                    0.2498, 0.4453, 0.3930, 0.4706, 0.2268, 0.1990, 0.2480,\n",
              "                                    0.6312, 0.2129, 0.3944, 0.2564, 0.4920, 0.1790, 0.5093,\n",
              "                                    0.3722, 0.2210, 0.6833, 0.4304, 0.2035, 0.1884, 0.2261,\n",
              "                                    0.2155, 0.2102, 0.3240, 0.3671, 0.2140, 0.2646, 0.6615,\n",
              "                                    0.4946, 0.2964, 0.2795, 0.3171, 0.1771, 0.3855, 0.4020,\n",
              "                                    0.1899, 0.8532, 0.1398, 0.3142, 1.1832, 0.2973, 0.4101,\n",
              "                                    0.5417, 0.5370, 0.4423, 0.5046, 0.2192, 0.4344, 0.5593,\n",
              "                                    0.1416, 0.1377, 0.4532, 0.4481, 0.5573, 0.3668, 0.2341,\n",
              "                                    0.4674, 0.1748, 0.1993, 0.2949, 0.2008, 0.4370, 0.2823,\n",
              "                                    0.1712, 0.3594, 0.2321, 0.3298, 0.5534, 0.2527, 0.4184,\n",
              "                                    0.1987, 0.2117, 0.4317, 0.3013, 0.4839, 0.2322, 0.2469,\n",
              "                                    0.2574, 0.1989, 0.2262, 0.1491, 0.2734, 0.1707, 0.2062,\n",
              "                                    0.5066, 0.6806, 0.1935, 0.1270, 0.5951, 0.6882, 0.5611,\n",
              "                                    0.3093, 0.3414, 1.0177, 0.3288, 0.3794, 0.3229, 0.1847,\n",
              "                                    0.3787, 0.3019, 0.5027, 0.2783, 0.2121, 0.1789, 0.4835,\n",
              "                                    0.5179, 1.4394, 0.6398, 0.3596, 0.2187, 0.3335, 0.2392,\n",
              "                                    0.4335, 0.3613, 0.1223, 0.5072, 0.2972, 0.1218, 0.4407,\n",
              "                                    0.3509, 0.4079, 0.3860, 0.2738, 0.3563, 0.5069, 0.5360,\n",
              "                                    0.3671, 0.2736, 0.4182, 0.2424, 0.3681, 0.1919, 0.4888,\n",
              "                                    0.3398, 0.3302, 0.2724, 0.1205, 0.1907, 0.3266, 0.2780,\n",
              "                                    0.3539, 0.2911, 0.5453, 0.1219, 0.1892, 0.2937, 0.2125,\n",
              "                                    0.2848, 0.2678, 0.3584, 0.7067, 0.4240, 0.5416, 0.2992,\n",
              "                                    0.3403, 0.1514, 0.2930, 0.3530, 0.3744, 0.2944, 0.5364,\n",
              "                                    0.3151, 0.6909, 0.1430, 0.4161, 0.1554, 0.2219, 0.2371,\n",
              "                                    0.1790, 0.2991, 0.3419, 0.2818, 0.1192, 0.2919, 0.2497,\n",
              "                                    0.2234, 0.2836, 0.4743, 0.1945, 0.3783, 0.1471, 0.1779,\n",
              "                                    0.2248, 0.2679, 0.4753, 0.2323, 0.2504, 0.4196, 0.4351,\n",
              "                                    0.3011, 0.2932, 0.3320, 0.2765, 0.4157, 0.3078, 0.4047,\n",
              "                                    0.2300, 0.3241, 0.3790, 0.1895, 0.5241, 0.2393, 0.2346,\n",
              "                                    0.3151, 0.2638, 0.3619, 0.2074, 0.7294, 0.4493, 0.2906,\n",
              "                                    0.6775, 0.1712, 0.7092, 0.6503, 0.1807, 0.2391, 0.4635,\n",
              "                                    0.2312, 0.3414, 0.2124, 0.2539, 0.3086, 0.2300, 0.3767,\n",
              "                                    0.2427, 0.7256, 0.1430, 0.6349, 0.2689, 0.2428, 0.2288,\n",
              "                                    0.1803, 0.3361, 0.2282, 0.4680, 0.1337, 0.1783, 0.2407,\n",
              "                                    0.2490, 0.6386, 0.3012, 0.4178, 0.2055, 0.3305, 0.1627,\n",
              "                                    0.3007, 0.2286, 0.1659, 0.2656, 0.6973, 0.1557, 0.2752,\n",
              "                                    0.2816, 0.6756, 0.1562, 0.5482, 0.5813, 0.3917, 0.4012,\n",
              "                                    0.3439, 0.9254, 0.3614, 0.5875, 0.2269, 0.6775, 0.3183,\n",
              "                                    0.1744, 0.1450, 0.3838, 0.1810, 0.4106, 0.2211, 0.2513,\n",
              "                                    0.2363, 0.3642, 0.3837, 0.1272, 0.2123, 0.3497, 0.2182,\n",
              "                                    0.7253, 0.5904, 0.2167, 0.2916, 0.4173, 0.2747, 0.3571,\n",
              "                                    0.7705, 0.5906, 0.1845, 0.5262, 0.3256, 0.3317, 0.5245,\n",
              "                                    0.3877, 0.1651, 0.4642, 0.2925, 1.0308, 0.1654, 0.4836,\n",
              "                                    0.3403, 0.2031, 0.1943, 0.3404, 0.7828, 0.4778, 0.3182,\n",
              "                                    0.3050, 0.2419, 0.2473, 0.1968, 0.3470, 0.3485, 0.5522,\n",
              "                                    0.1696, 0.3093, 0.4624, 0.4532, 0.2759, 0.2173, 1.0304,\n",
              "                                    0.3413]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.2.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   1,   2,  ..., 509, 510, 511],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.0928, -0.0118,  0.0174,  ..., -0.0169, -0.0152,\n",
              "                                     0.0192]),\n",
              "                     size=(128, 512, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([0.9793, 0.9924, 0.9863, 0.9844, 0.9828, 1.0170, 0.9906,\n",
              "                                    0.9849, 1.0048, 0.9892, 0.9990, 1.0021, 0.9884, 0.9757,\n",
              "                                    1.0056, 0.9958, 0.9979, 1.0008, 0.9991, 1.0077, 1.0073,\n",
              "                                    0.9863, 0.9768, 0.9944, 1.0053, 0.9952, 1.0068, 0.9809,\n",
              "                                    0.9922, 1.0192, 0.9970, 0.9786, 1.0302, 0.9885, 0.9809,\n",
              "                                    0.9816, 1.0029, 1.0042, 0.9902, 0.9846, 0.9909, 1.0074,\n",
              "                                    0.9860, 1.0076, 1.0309, 0.9903, 0.9986, 1.0008, 1.0006,\n",
              "                                    0.9912, 0.9996, 0.9705, 0.9838, 0.9979, 1.0346, 0.9993,\n",
              "                                    0.9954, 0.9874, 0.9926, 0.9971, 0.9853, 0.9880, 1.0070,\n",
              "                                    1.0324, 0.9731, 1.0031, 1.0060, 0.9950, 0.9980, 1.0137,\n",
              "                                    1.0243, 1.0032, 1.0057, 0.9960, 1.0367, 0.9978, 0.9822,\n",
              "                                    0.9941, 0.9956, 1.0044, 1.0064, 0.9863, 0.9659, 1.0067,\n",
              "                                    0.9878, 1.0244, 0.9718, 1.0427, 0.9901, 1.0070, 0.9893,\n",
              "                                    0.9843, 0.9945, 1.0147, 1.0177, 0.9914, 1.0192, 1.0670,\n",
              "                                    0.9771, 1.0095, 0.9937, 1.0041, 1.0078, 0.9957, 1.0004,\n",
              "                                    0.9850, 1.0005, 0.9899, 0.9771, 0.9922, 0.9827, 1.0325,\n",
              "                                    1.0006, 0.9780, 0.9995, 0.9842, 1.0309, 0.9799, 0.9967,\n",
              "                                    1.0173, 1.0130, 1.0119, 1.0140, 1.0159, 1.0005, 0.9849,\n",
              "                                    0.9880, 1.0007]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([-0.0135, -0.0211, -0.0153, -0.0132,  0.0063,  0.0245,\n",
              "                                    -0.0070, -0.0206,  0.0036,  0.0088, -0.0024, -0.0087,\n",
              "                                    -0.0125, -0.0238,  0.0074,  0.0055,  0.0050,  0.0046,\n",
              "                                     0.0057,  0.0119,  0.0544, -0.0036, -0.0151, -0.0048,\n",
              "                                     0.0191, -0.0133,  0.0147, -0.0082, -0.0109,  0.0162,\n",
              "                                    -0.0153, -0.0154,  0.0059, -0.0093,  0.0124,  0.0004,\n",
              "                                     0.0106, -0.0036, -0.0050, -0.0195, -0.0032,  0.0192,\n",
              "                                    -0.0177,  0.0160,  0.0425, -0.0257, -0.0401, -0.0033,\n",
              "                                    -0.0120, -0.0117,  0.0216, -0.0076, -0.0087,  0.0110,\n",
              "                                     0.0413,  0.0165,  0.0108,  0.0215,  0.0045,  0.0095,\n",
              "                                    -0.0143,  0.0127, -0.0168,  0.0084, -0.0184, -0.0075,\n",
              "                                    -0.0070, -0.0256,  0.0124,  0.0141, -0.0144, -0.0095,\n",
              "                                     0.0164,  0.0031, -0.0145, -0.0016,  0.0009,  0.0045,\n",
              "                                     0.0020, -0.0025,  0.0184,  0.0049, -0.0157, -0.0031,\n",
              "                                    -0.0068,  0.0106, -0.0082,  0.0548, -0.0145,  0.0023,\n",
              "                                    -0.0278, -0.0074, -0.0063, -0.0019,  0.0009,  0.0170,\n",
              "                                     0.0030,  0.0576, -0.0149, -0.0072, -0.0169,  0.0160,\n",
              "                                     0.0306, -0.0021,  0.0051, -0.0166, -0.0006,  0.0089,\n",
              "                                    -0.0159,  0.0039, -0.0146,  0.0349,  0.0043, -0.0088,\n",
              "                                    -0.0062, -0.0073,  0.0503,  0.0281, -0.0156,  0.0040,\n",
              "                                     0.0217, -0.0053,  0.0148,  0.0046,  0.0123, -0.0145,\n",
              "                                    -0.0181, -0.0009]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 1.6241e+00,  1.0903e+00,  7.7069e-01,  2.1201e+00,\n",
              "                                     3.7821e+00,  3.0405e+00, -5.7240e-01,  5.0323e-01,\n",
              "                                     5.3574e+00,  3.1811e+00, -6.9273e-01, -2.9321e+00,\n",
              "                                    -5.5792e+00,  5.6235e-03,  6.6989e-01,  1.5255e+00,\n",
              "                                    -1.8575e+00, -3.0018e+00, -2.0362e+00, -4.7341e+00,\n",
              "                                     3.8907e+00, -3.5234e+00, -7.2378e+00,  1.9904e-01,\n",
              "                                    -2.0496e+00,  3.0766e+00,  8.1644e-01, -7.8711e+00,\n",
              "                                    -1.5516e+00, -1.0140e+00,  4.2266e+00,  4.9947e+00,\n",
              "                                     2.1888e+00,  1.9960e+00, -2.4319e+00, -1.0698e+00,\n",
              "                                     1.5071e+00, -4.0416e+00, -5.0851e+00,  1.1862e+00,\n",
              "                                    -5.9810e+00, -6.6730e-01,  5.4103e-01,  8.1627e-01,\n",
              "                                     1.9435e-03,  9.8886e-01,  1.8842e+00,  4.0874e+00,\n",
              "                                    -4.5132e+00,  9.7539e-02,  2.2805e+00, -4.5746e-01,\n",
              "                                     2.0221e+00,  5.7318e+00, -9.3353e-01,  1.6320e+00,\n",
              "                                    -3.0553e+00,  1.2163e+00, -6.5698e+00,  4.5998e+00,\n",
              "                                     1.6413e+00, -2.1474e+00, -1.6046e+00,  2.9017e+00,\n",
              "                                    -1.4594e+00,  3.8665e+00,  4.2253e+00, -2.7325e+00,\n",
              "                                     7.7977e-01,  1.9514e+00, -6.0117e-01, -4.4734e+00,\n",
              "                                     1.0604e+00,  1.0681e+00, -6.1165e-02, -3.1908e+00,\n",
              "                                    -1.5582e+00,  4.0885e+00, -6.4472e-01,  2.2387e+00,\n",
              "                                    -1.7252e+00, -1.7811e+00,  3.3065e-01, -7.1823e-01,\n",
              "                                     6.8570e-01,  2.1226e+00,  2.4485e+00,  1.9222e-01,\n",
              "                                    -2.8799e+00, -1.9645e+00, -9.8347e-01, -4.2916e+00,\n",
              "                                    -1.4374e+00, -1.4252e-01, -2.4841e+00,  3.4198e-01,\n",
              "                                     3.2610e-02,  4.7328e-01, -3.9018e+00,  4.0561e+00,\n",
              "                                    -1.1514e+00, -1.7589e+00, -6.7491e-02, -1.8006e+00,\n",
              "                                    -4.8607e-01,  3.7897e+00,  3.1614e+00, -2.9668e+00,\n",
              "                                    -1.5134e+00, -5.5835e-01,  3.8957e+00,  3.1374e+00,\n",
              "                                     6.3726e+00,  1.5638e+00, -4.9478e+00, -2.9563e+00,\n",
              "                                     3.4198e+00, -6.0080e+00, -4.3817e+00,  5.8871e-01,\n",
              "                                     2.4005e+00,  1.3451e+00, -1.6364e+00, -6.8313e-01,\n",
              "                                     4.7009e+00, -6.2683e+00, -7.2034e+00,  2.8141e+00]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 35.1801,  44.0105,  45.9555,  21.7052,  63.3990,\n",
              "                                     96.0178,  71.0044,  36.6346, 101.5405,  41.9680,\n",
              "                                     45.3252,  17.8634,  89.6599,  34.3193,  34.2592,\n",
              "                                     34.0686,  54.2376,  39.9220,  49.3534,  17.1902,\n",
              "                                     58.6151,  29.3921,  65.9751,  38.9730,  22.4585,\n",
              "                                     24.8989,  25.8949,  68.0015,  37.2027,  58.6175,\n",
              "                                     53.1916,  63.4376,  38.4136,  50.6400,  58.6808,\n",
              "                                     16.6041,  36.1521,  41.4360,  43.4238,  32.8467,\n",
              "                                     70.8001,  56.9354,  25.0916,  25.2906,  49.5426,\n",
              "                                     35.9671,  36.6121,  33.6646,  52.1225,  49.3021,\n",
              "                                     25.1006,  28.0181,  43.9161,  86.5269,  71.4825,\n",
              "                                     55.8105,  35.0439,  12.1927,  43.7002,  86.6345,\n",
              "                                     21.9632,  41.0478,  41.2731,  67.8623,  28.6402,\n",
              "                                     40.2257,  16.9225,  24.3320,  43.3333,  61.0327,\n",
              "                                     47.0772,  48.1668,  42.1267,  22.7744,  45.3845,\n",
              "                                     22.7154,  28.3395,  44.6748,  43.1420,  80.6660,\n",
              "                                     23.8443,  29.5411,  13.8652,  36.9460,  52.7402,\n",
              "                                     29.5634,  28.0348,  64.5542,  37.9819,  35.0940,\n",
              "                                     22.6632,  70.4152,  31.9526,  33.2354,  60.7032,\n",
              "                                     20.1251,  26.0097,  75.3352,  23.7358,  49.4786,\n",
              "                                     24.7515,  58.8595,  35.4472,  56.5373,  15.5560,\n",
              "                                     62.8109,  61.3927,  45.0175,  27.5825,  69.0131,\n",
              "                                     69.1224,  79.4882,  49.9475,  31.2766,  36.2668,\n",
              "                                     26.9714,  69.3013,  71.7770,  55.5792,  49.7866,\n",
              "                                     54.4288,  40.0498,  35.9555,  19.0420,  55.0399,\n",
              "                                     72.1945,  56.9138,  40.2954]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ..., 127, 127, 127],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0180, -0.0807, -0.0768,  ...,  0.0915,  0.0493,\n",
              "                                     0.0330]),\n",
              "                     size=(128, 128, 3, 3), nnz=147456, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([1.0047, 1.0069, 1.0107, 1.0154, 1.0021, 1.0029, 1.0287,\n",
              "                                    0.9842, 1.0251, 0.9931, 1.0013, 0.9767, 1.0049, 1.0011,\n",
              "                                    0.9885, 0.9942, 0.9860, 0.9995, 1.0052, 1.0021, 1.0216,\n",
              "                                    1.0100, 1.0206, 1.0118, 0.9822, 1.0136, 1.0323, 1.0191,\n",
              "                                    0.9826, 0.9945, 0.9771, 0.9749, 1.0006, 0.9998, 0.9944,\n",
              "                                    0.9875, 1.0043, 0.9967, 1.0054, 1.0084, 1.0130, 0.9974,\n",
              "                                    1.0091, 0.9863, 1.0054, 1.0248, 1.0163, 1.0213, 0.9843,\n",
              "                                    1.0268, 0.9978, 0.9772, 1.0415, 1.0075, 0.9565, 0.9877,\n",
              "                                    1.0061, 1.0115, 0.9986, 0.9900, 0.9729, 1.0010, 0.9934,\n",
              "                                    0.9920, 0.9739, 0.9806, 0.9916, 0.9956, 0.9798, 0.9825,\n",
              "                                    0.9925, 0.9965, 1.0151, 1.0195, 0.9836, 0.9999, 1.0107,\n",
              "                                    0.9769, 0.9989, 0.9946, 1.0258, 0.9953, 1.0008, 0.9770,\n",
              "                                    0.9938, 0.9588, 0.9845, 0.9920, 1.0340, 0.9801, 0.9813,\n",
              "                                    0.9971, 1.0126, 1.0138, 0.9826, 0.9876, 0.9716, 1.0058,\n",
              "                                    1.0129, 1.0014, 0.9755, 0.9910, 1.0199, 0.9867, 0.9850,\n",
              "                                    1.0085, 0.9853, 0.9987, 0.9937, 1.0442, 1.0093, 0.9932,\n",
              "                                    0.9841, 1.0027, 0.9676, 0.9804, 0.9983, 1.0022, 1.0008,\n",
              "                                    1.0263, 1.0134, 1.0479, 1.0283, 0.9955, 0.9884, 1.0104,\n",
              "                                    1.0021, 1.0136]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 2.3402e-02, -3.0485e-02,  2.1626e-02, -2.4957e-02,\n",
              "                                     4.2625e-03, -2.0806e-02, -9.2344e-03,  1.3508e-02,\n",
              "                                     5.1094e-03,  2.4137e-02, -2.5603e-02, -9.7843e-03,\n",
              "                                    -2.6564e-02, -1.6956e-02, -1.0484e-02,  3.5845e-02,\n",
              "                                     9.0661e-03, -3.1295e-03, -1.0288e-02,  6.2337e-03,\n",
              "                                     1.9074e-02, -6.9970e-03,  2.1781e-02,  1.6822e-02,\n",
              "                                     1.7662e-02,  2.7668e-02,  2.9667e-02, -5.5182e-03,\n",
              "                                    -2.1314e-02, -2.3354e-03,  9.7738e-04, -1.7740e-02,\n",
              "                                     1.1828e-02, -4.0283e-03,  1.3217e-02, -1.2892e-03,\n",
              "                                    -1.0796e-02,  1.9889e-02,  6.1896e-03, -3.0426e-03,\n",
              "                                    -3.5989e-03, -1.8070e-02,  6.2391e-05, -1.5266e-02,\n",
              "                                    -6.7629e-03, -2.2249e-02, -8.4001e-03,  2.6650e-03,\n",
              "                                    -1.3634e-02,  2.1869e-02,  9.2021e-03, -1.3102e-02,\n",
              "                                    -1.9661e-02,  1.2293e-04, -2.2086e-02, -1.5157e-02,\n",
              "                                     7.6616e-03,  1.1533e-02, -3.7181e-02, -2.1136e-02,\n",
              "                                    -8.7400e-03, -2.2870e-03, -9.3809e-03, -9.9175e-03,\n",
              "                                    -8.0709e-03, -2.8415e-02, -6.0554e-03, -2.8368e-03,\n",
              "                                    -1.6673e-02,  1.3740e-02, -8.7217e-03, -5.0232e-03,\n",
              "                                    -1.5332e-02, -1.4645e-02,  1.8334e-02,  4.4837e-03,\n",
              "                                     2.3140e-02,  3.6984e-03, -3.8651e-03, -1.7785e-03,\n",
              "                                    -1.7783e-02, -1.2108e-02,  6.5200e-03, -1.7652e-02,\n",
              "                                     1.4047e-02, -5.9088e-04, -4.3812e-02, -1.1671e-02,\n",
              "                                     1.1590e-02,  2.6452e-03, -4.3094e-02,  1.8996e-02,\n",
              "                                    -2.2398e-03, -1.4496e-02,  6.9219e-03,  3.8709e-02,\n",
              "                                    -3.3499e-02, -1.6319e-02,  9.1028e-03,  1.1675e-02,\n",
              "                                    -1.7833e-02,  9.0972e-03,  1.2028e-02, -8.1619e-04,\n",
              "                                    -4.4350e-03, -2.5257e-03, -2.0360e-02, -8.1750e-03,\n",
              "                                     1.0452e-02,  1.1017e-02,  2.0958e-02,  6.0815e-03,\n",
              "                                    -3.3231e-02, -1.3555e-03, -2.0214e-02, -6.5427e-03,\n",
              "                                     4.9844e-03,  1.6395e-02, -2.1367e-02, -1.0293e-02,\n",
              "                                     1.5146e-02,  2.8420e-02, -1.3667e-02, -2.1975e-02,\n",
              "                                    -1.7041e-02,  1.9544e-02, -3.0285e-02, -3.0203e-03]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([-0.5405,  2.1653, -0.5449,  1.0793, -1.6995, -0.8202,\n",
              "                                    -0.1783,  0.5795,  0.9372, -1.6525,  0.2530, -0.9270,\n",
              "                                     0.5385,  0.4374,  0.5291,  1.0276, -0.9450,  0.3289,\n",
              "                                    -0.4355,  0.3544, -1.1133, -0.1114,  0.0400,  0.7373,\n",
              "                                    -0.8758, -0.9500,  0.2917, -1.2409,  0.2710, -0.2454,\n",
              "                                     0.0602,  0.3976, -0.8797,  0.9813, -0.6917,  0.8896,\n",
              "                                    -0.1841, -1.5655,  0.7831,  0.1906, -0.7213,  0.9829,\n",
              "                                    -0.1160, -0.7365,  1.0243,  0.1745,  0.9972,  0.7475,\n",
              "                                    -0.9237, -1.0108,  0.7141, -0.6625,  0.4448,  0.5290,\n",
              "                                     0.1095,  0.0216,  0.9619,  0.5880,  0.7368,  0.1287,\n",
              "                                     1.2178, -0.7696, -0.3553, -0.9513, -0.3451,  1.0216,\n",
              "                                    -0.4371,  0.3454,  0.6387,  1.2698, -0.0332,  0.0074,\n",
              "                                     0.4816,  1.4332, -0.8745, -0.8198, -0.4900, -2.0984,\n",
              "                                     1.1421, -1.3339, -0.5702,  0.5899,  0.3633, -0.3726,\n",
              "                                     0.5354,  0.5282, -0.0367, -0.4619, -0.2123, -1.7594,\n",
              "                                     2.1422, -0.4214,  0.8564,  1.9672, -0.6638,  1.0978,\n",
              "                                    -0.3525,  1.2336, -0.1362, -1.4193, -1.3990, -1.5493,\n",
              "                                    -0.1744, -1.6928, -1.0018,  0.1746,  0.6834, -1.7918,\n",
              "                                    -0.0856,  1.3748,  1.6760, -1.0853,  0.0713, -0.7645,\n",
              "                                     0.5468, -1.9143, -1.1272, -1.5818,  0.0805, -0.6400,\n",
              "                                    -0.0442, -0.4287, -0.4254,  0.0081, -1.1965, -1.4261,\n",
              "                                    -0.1990, -0.3580]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127]]),\n",
              "                     values=tensor([ 5.9536,  5.8557,  4.0234,  4.9574,  4.9183,  5.4579,\n",
              "                                     3.5810,  7.3502,  4.5216,  6.2423,  3.9204,  3.4743,\n",
              "                                     5.0344,  3.3056,  4.5720,  6.6260,  4.9068,  2.4319,\n",
              "                                     2.8552,  4.3810,  7.1843,  5.8512,  3.8515,  6.6801,\n",
              "                                     5.9552,  8.8304,  3.4324,  4.8651,  4.0156,  5.3977,\n",
              "                                     5.7877,  4.9599,  7.8645,  4.0807,  4.5550,  5.5042,\n",
              "                                     3.2861, 11.2592,  5.1669,  4.8274,  4.1730,  5.6479,\n",
              "                                     5.1225,  4.2281,  4.4310,  4.6111,  3.5416,  5.7749,\n",
              "                                     3.9107,  7.3206,  7.1026,  4.4619,  6.1627,  5.1244,\n",
              "                                     6.4629,  2.5887,  7.7650,  5.3155,  4.7712,  3.7759,\n",
              "                                     5.8294,  4.2274,  5.8728,  3.5962,  3.8465,  3.0736,\n",
              "                                     4.6221,  5.2222,  5.0939,  7.4588,  6.8151,  5.7721,\n",
              "                                     3.1986,  5.0726,  6.1710,  5.3926,  5.6903,  8.9333,\n",
              "                                     5.8416,  6.0152,  5.4182,  3.5242,  4.6813,  3.8680,\n",
              "                                     4.5404,  4.6828,  4.2830,  5.3002,  4.8371,  7.0217,\n",
              "                                     8.2136,  7.3312,  6.2192,  8.5426,  6.4207,  4.9871,\n",
              "                                     5.1646,  4.5441,  3.3993, 10.4570,  8.7780,  6.0842,\n",
              "                                     5.0584,  3.4007,  5.9776,  3.9635,  4.7924,  8.8764,\n",
              "                                     2.9048,  7.4410,  7.8653, 10.3737,  1.9764,  2.8068,\n",
              "                                     4.7604, 12.4674,  5.7460, 11.6500,  7.9758,  4.9791,\n",
              "                                     4.0757,  8.6921,  5.0472,  3.1840,  5.4911,  8.9157,\n",
              "                                     4.8992,  7.1374]),\n",
              "                     size=(128,), nnz=128, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.conv3.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   1,   2,  ..., 125, 126, 127],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([ 0.0474,  0.0667, -0.0619,  ...,  0.0494, -0.1473,\n",
              "                                     0.0316]),\n",
              "                     size=(512, 128, 1, 1), nnz=65536, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn3.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9736, 0.9847, 1.0026, 1.0042, 0.9877, 0.9903, 1.0160,\n",
              "                                    0.9995, 0.9932, 0.9937, 0.9932, 0.9834, 0.9973, 1.0080,\n",
              "                                    1.0048, 1.0024, 0.9946, 1.0076, 0.9749, 1.0031, 0.9786,\n",
              "                                    0.9881, 1.0149, 0.9770, 0.9886, 0.9867, 1.0141, 0.9783,\n",
              "                                    0.9959, 1.0008, 0.9889, 0.9900, 0.9986, 0.9824, 1.0158,\n",
              "                                    1.0009, 1.0068, 1.0070, 0.9886, 0.9737, 0.9841, 0.9878,\n",
              "                                    0.9835, 1.0010, 0.9982, 1.0041, 0.9891, 1.0074, 0.9787,\n",
              "                                    0.9728, 1.0055, 0.9972, 1.0019, 1.0065, 0.9889, 1.0147,\n",
              "                                    0.9980, 0.9883, 0.9660, 1.0093, 0.9977, 0.9910, 0.9987,\n",
              "                                    0.9962, 0.9987, 0.9983, 1.0007, 1.0154, 0.9883, 1.0006,\n",
              "                                    0.9981, 1.0020, 0.9895, 0.9877, 0.9630, 0.9977, 0.9920,\n",
              "                                    0.9956, 0.9710, 0.9999, 0.9733, 0.9915, 1.0087, 0.9935,\n",
              "                                    1.0015, 0.9896, 1.0051, 1.0171, 0.9910, 0.9976, 0.9713,\n",
              "                                    0.9812, 0.9888, 1.0148, 1.0088, 0.9861, 1.0103, 0.9859,\n",
              "                                    1.0113, 0.9945, 0.9732, 0.9722, 1.0058, 0.9788, 0.9933,\n",
              "                                    1.0008, 1.0154, 1.0106, 1.0015, 0.9875, 0.9777, 0.9677,\n",
              "                                    0.9940, 0.9965, 0.9979, 1.0275, 0.9895, 1.0047, 0.9944,\n",
              "                                    0.9907, 1.0056, 0.9921, 1.0126, 1.0027, 0.9977, 0.9792,\n",
              "                                    0.9881, 0.9729, 1.0108, 1.0001, 0.9828, 0.9837, 1.0050,\n",
              "                                    0.9901, 0.9905, 1.0053, 0.9799, 1.0095, 1.0048, 1.0152,\n",
              "                                    0.9925, 0.9929, 0.9941, 1.0077, 0.9943, 1.0227, 1.0043,\n",
              "                                    0.9966, 0.9773, 0.9840, 0.9796, 1.0134, 0.9804, 0.9962,\n",
              "                                    0.9930, 0.9882, 0.9826, 1.0077, 0.9976, 0.9736, 0.9965,\n",
              "                                    0.9772, 0.9881, 0.9925, 0.9686, 0.9791, 0.9842, 1.0135,\n",
              "                                    0.9997, 0.9965, 0.9826, 0.9915, 0.9881, 1.0228, 1.0261,\n",
              "                                    1.0091, 1.0059, 0.9826, 1.0024, 0.9728, 0.9969, 0.9771,\n",
              "                                    0.9742, 0.9718, 1.0103, 1.0160, 0.9951, 1.0015, 0.9981,\n",
              "                                    0.9953, 0.9938, 1.0048, 0.9884, 0.9914, 0.9966, 1.0018,\n",
              "                                    0.9914, 0.9864, 0.9829, 1.0069, 0.9639, 0.9946, 1.0013,\n",
              "                                    1.0010, 0.9865, 0.9803, 1.0001, 1.0020, 1.0217, 0.9831,\n",
              "                                    1.0085, 0.9963, 0.9766, 1.0125, 0.9844, 0.9935, 1.0150,\n",
              "                                    0.9829, 0.9983, 0.9671, 0.9987, 0.9929, 0.9976, 0.9928,\n",
              "                                    0.9722, 0.9812, 0.9897, 0.9886, 0.9894, 1.0108, 1.0019,\n",
              "                                    0.9903, 0.9897, 0.9893, 1.0310, 0.9822, 0.9906, 0.9929,\n",
              "                                    0.9960, 1.0040, 1.0077, 0.9995, 1.0248, 0.9829, 1.0011,\n",
              "                                    1.0171, 1.0059, 0.9740, 0.9910, 0.9954, 0.9693, 0.9972,\n",
              "                                    1.0035, 0.9736, 1.0048, 0.9936, 0.9906, 0.9897, 0.9950,\n",
              "                                    0.9925, 0.9964, 0.9786, 0.9995, 1.0234, 0.9730, 0.9946,\n",
              "                                    1.0092, 0.9963, 0.9856, 1.0002, 1.0002, 0.9996, 1.0021,\n",
              "                                    0.9897, 0.9553, 1.0116, 0.9878, 1.0089, 0.9784, 1.0175,\n",
              "                                    0.9877, 0.9799, 0.9910, 1.0293, 0.9863, 1.0024, 0.9952,\n",
              "                                    0.9938, 0.9789, 1.0097, 0.9934, 1.0047, 0.9960, 1.0001,\n",
              "                                    0.9950, 1.0008, 0.9990, 0.9709, 0.9827, 0.9965, 0.9742,\n",
              "                                    0.9937, 1.0023, 1.0087, 0.9893, 0.9908, 0.9914, 0.9789,\n",
              "                                    0.9907, 1.0026, 1.0095, 0.9888, 1.0071, 0.9988, 0.9909,\n",
              "                                    1.0113, 0.9729, 1.0297, 0.9785, 0.9735, 0.9983, 0.9847,\n",
              "                                    0.9902, 0.9811, 0.9902, 0.9935, 0.9879, 0.9914, 1.0135,\n",
              "                                    1.0173, 0.9874, 0.9917, 1.0133, 0.9854, 0.9865, 0.9918,\n",
              "                                    0.9915, 0.9838, 0.9758, 1.0224, 0.9987, 0.9822, 0.9977,\n",
              "                                    0.9954, 1.0071, 1.0174, 0.9860, 1.0087, 0.9665, 0.9846,\n",
              "                                    0.9977, 0.9742, 0.9940, 0.9865, 1.0198, 0.9702, 1.0126,\n",
              "                                    0.9995, 0.9793, 0.9781, 0.9905, 0.9994, 0.9980, 1.0216,\n",
              "                                    0.9993, 1.0038, 0.9845, 1.0076, 0.9930, 0.9901, 1.0105,\n",
              "                                    1.0054, 1.0244, 0.9588, 0.9894, 0.9967, 0.9904, 0.9878,\n",
              "                                    1.0436, 1.0174, 0.9909, 0.9841, 0.9908, 1.0050, 1.0136,\n",
              "                                    0.9833, 0.9895, 1.0002, 0.9812, 1.0051, 0.9766, 1.0129,\n",
              "                                    1.0118, 0.9781, 0.9878, 0.9921, 0.9848, 0.9661, 0.9900,\n",
              "                                    0.9753, 0.9857, 1.0048, 0.9986, 0.9855, 0.9968, 0.9814,\n",
              "                                    1.0320, 0.9873, 1.0005, 1.0029, 1.0094, 0.9987, 1.0040,\n",
              "                                    1.0126, 1.0048, 0.9893, 0.9807, 1.0019, 0.9953, 1.0133,\n",
              "                                    1.0176, 0.9944, 1.0017, 0.9857, 0.9867, 0.9762, 0.9776,\n",
              "                                    1.0026, 1.0000, 1.0098, 0.9857, 0.9854, 0.9926, 1.0460,\n",
              "                                    0.9762, 1.0033, 1.0023, 0.9905, 1.0177, 1.0094, 1.0014,\n",
              "                                    0.9641, 0.9783, 1.0013, 0.9932, 0.9864, 1.0077, 0.9810,\n",
              "                                    0.9940, 0.9963, 1.0066, 0.9863, 1.0045, 0.9791, 1.0057,\n",
              "                                    0.9891, 1.0279, 0.9906, 1.0104, 1.0237, 0.9993, 1.0001,\n",
              "                                    1.0089, 1.0135, 0.9991, 1.0082, 1.0214, 0.9903, 1.0128,\n",
              "                                    1.0017, 1.0092, 0.9812, 0.9951, 0.9827, 1.0007, 0.9878,\n",
              "                                    0.9813, 0.9957, 0.9905, 0.9797, 0.9715, 0.9999, 0.9868,\n",
              "                                    0.9773, 0.9747, 0.9924, 0.9929, 1.0028, 0.9972, 1.0207,\n",
              "                                    0.9727, 0.9862, 0.9818, 1.0073, 1.0076, 1.0075, 1.0084,\n",
              "                                    0.9884, 1.0060, 0.9672, 0.9957, 0.9795, 1.0164, 0.9667,\n",
              "                                    1.0050, 1.0012, 1.0178, 1.0052, 0.9808, 0.9862, 1.0002,\n",
              "                                    0.9897]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn3.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-1.3914e-02,  2.7789e-02, -2.0782e-02, -9.9357e-03,\n",
              "                                    -7.1757e-03,  2.4416e-02, -3.1655e-02,  1.1741e-02,\n",
              "                                    -5.1437e-03, -1.1369e-02, -1.3484e-02,  2.1472e-02,\n",
              "                                    -1.6842e-02,  2.0512e-02, -1.7892e-02, -5.4129e-03,\n",
              "                                     9.8028e-03, -9.4922e-03,  9.5044e-03, -2.8823e-02,\n",
              "                                     1.7069e-02, -1.4636e-02, -2.6573e-03, -3.1078e-02,\n",
              "                                     4.9180e-03,  9.4359e-03, -2.4622e-03, -8.9749e-03,\n",
              "                                     1.0573e-02, -7.1473e-03,  9.1739e-03,  3.2410e-02,\n",
              "                                     2.6237e-02,  4.5912e-03,  1.1222e-03,  1.3089e-02,\n",
              "                                     1.2468e-02, -1.1126e-02,  1.2439e-02, -3.7222e-03,\n",
              "                                     1.7963e-02, -9.8114e-03,  6.2767e-03, -1.5379e-02,\n",
              "                                    -7.8932e-03,  1.2832e-02,  2.0912e-02,  4.2368e-03,\n",
              "                                     1.5149e-02, -9.0446e-03, -1.9204e-02,  2.1262e-02,\n",
              "                                    -1.1132e-03,  1.2370e-02,  3.4610e-02,  3.0723e-02,\n",
              "                                     1.5714e-02,  2.1248e-03,  1.5662e-02,  3.7548e-02,\n",
              "                                     1.1055e-02, -1.3790e-02, -4.5666e-03,  2.8789e-02,\n",
              "                                    -2.2453e-02,  3.6254e-03,  1.9303e-02, -1.8150e-02,\n",
              "                                     3.8280e-03,  3.4143e-03,  1.5647e-02, -8.2798e-03,\n",
              "                                    -5.7658e-03, -4.8103e-03,  2.5430e-02, -3.8168e-03,\n",
              "                                    -4.4544e-03, -9.1957e-04, -3.4683e-02, -6.5926e-03,\n",
              "                                    -2.8658e-03,  4.3030e-03, -2.2294e-02,  1.9374e-02,\n",
              "                                    -1.4781e-02, -1.7201e-02,  1.3183e-02, -5.4615e-04,\n",
              "                                     1.5399e-02,  1.6671e-02, -1.2432e-02,  8.9039e-04,\n",
              "                                    -1.0020e-02, -5.5146e-03, -1.1227e-02, -3.1629e-02,\n",
              "                                     1.1554e-02,  1.6441e-02,  2.2303e-03, -1.1955e-02,\n",
              "                                     1.0905e-02,  1.5600e-02, -2.9490e-02,  6.6245e-05,\n",
              "                                    -1.0034e-02, -8.5330e-03,  3.7967e-03,  8.0497e-03,\n",
              "                                     7.9923e-03,  9.1827e-03, -5.1252e-03,  1.0589e-02,\n",
              "                                    -1.6647e-02,  1.6935e-03, -3.1077e-03, -1.1030e-02,\n",
              "                                    -1.4547e-02,  2.4789e-02,  3.1985e-02, -8.2207e-03,\n",
              "                                     1.0581e-03, -3.4777e-02, -8.4155e-03,  1.4167e-02,\n",
              "                                    -1.6981e-02, -5.2738e-03,  1.0001e-02, -8.3118e-03,\n",
              "                                    -3.7109e-03,  2.8827e-02,  4.8053e-03,  1.3712e-02,\n",
              "                                    -7.1038e-03,  1.1176e-02,  8.0184e-03, -4.4978e-03,\n",
              "                                    -1.3767e-03,  1.9622e-02, -6.6025e-03,  1.9518e-02,\n",
              "                                    -1.5570e-02,  1.6068e-02,  2.8876e-02, -1.6905e-02,\n",
              "                                    -1.7797e-03,  1.4617e-02, -1.2596e-02,  8.7070e-03,\n",
              "                                     2.4020e-03, -1.0555e-02, -1.7201e-02,  8.1698e-03,\n",
              "                                     1.1732e-02,  7.1138e-03,  5.1721e-03, -7.7661e-03,\n",
              "                                     2.4733e-02,  1.1183e-02, -3.2616e-02, -1.4417e-02,\n",
              "                                    -2.9862e-02, -9.7770e-03, -4.7391e-04, -1.4413e-03,\n",
              "                                    -2.6002e-02,  3.7805e-03, -1.5545e-02,  2.5036e-02,\n",
              "                                    -2.8331e-02, -1.4062e-02, -9.6021e-03, -4.6233e-03,\n",
              "                                     2.7104e-02,  1.2195e-02,  7.3951e-03,  2.1360e-04,\n",
              "                                     2.1431e-03,  1.5411e-02, -1.4672e-02,  4.9599e-02,\n",
              "                                    -2.3367e-02,  1.1944e-02,  4.7782e-03,  1.3775e-02,\n",
              "                                    -2.3048e-02,  9.2684e-03,  9.3267e-03, -1.3919e-02,\n",
              "                                    -3.4953e-03,  4.2212e-03, -1.0963e-02, -9.6783e-03,\n",
              "                                    -1.8170e-02,  2.8627e-02, -5.1684e-02, -1.6476e-02,\n",
              "                                    -1.7223e-02,  1.1392e-02,  1.8300e-02,  5.4616e-03,\n",
              "                                     4.1371e-02,  1.6997e-02,  4.0854e-03, -1.6262e-02,\n",
              "                                    -1.5615e-02,  1.6610e-02,  1.6876e-03,  1.5049e-02,\n",
              "                                    -3.5140e-02,  2.4174e-02,  5.6079e-03, -1.9597e-02,\n",
              "                                     3.0954e-03, -8.1929e-05,  2.0844e-02, -1.4901e-02,\n",
              "                                     5.9404e-03, -5.7283e-03,  1.6010e-03,  2.4502e-02,\n",
              "                                     3.8167e-02, -2.7344e-04,  8.2906e-03, -8.8801e-03,\n",
              "                                    -1.8575e-02,  1.8692e-03, -3.0336e-02,  1.2763e-02,\n",
              "                                    -1.1956e-02, -1.1854e-02,  2.9509e-02, -1.5747e-02,\n",
              "                                    -7.1912e-03, -2.1255e-02, -1.2450e-02, -5.9540e-03,\n",
              "                                     2.7216e-02, -1.5917e-02, -1.7986e-02, -1.8161e-02,\n",
              "                                     5.8382e-03,  3.2873e-02, -1.6731e-02, -1.7229e-02,\n",
              "                                    -7.0622e-03, -4.7227e-03,  2.1802e-02,  1.7041e-03,\n",
              "                                     2.1376e-02, -1.8471e-02,  1.0547e-02,  1.3135e-02,\n",
              "                                     7.9429e-03, -1.4271e-02, -7.3637e-03, -7.3543e-03,\n",
              "                                     2.6137e-02,  9.1503e-03, -8.1502e-03,  2.7114e-02,\n",
              "                                     6.1877e-03, -1.0756e-02,  5.3064e-03, -1.6653e-02,\n",
              "                                     9.8882e-03,  2.4354e-03, -1.9370e-02,  4.0170e-03,\n",
              "                                    -1.5780e-02, -1.4284e-02, -6.9714e-04, -1.9430e-02,\n",
              "                                     2.0803e-02, -2.9685e-02,  7.2839e-03,  1.7648e-02,\n",
              "                                     2.6272e-02,  4.0085e-03,  3.1891e-03, -1.5270e-02,\n",
              "                                     9.9985e-04,  1.4378e-02, -1.0046e-02,  8.4330e-03,\n",
              "                                    -1.0182e-02,  1.9038e-02,  3.0457e-02, -4.2344e-03,\n",
              "                                    -3.1773e-02,  5.5134e-03,  2.1009e-02, -1.0520e-02,\n",
              "                                     1.7334e-02, -7.4269e-03,  2.9358e-03,  1.0487e-02,\n",
              "                                    -1.4997e-02, -1.0469e-02,  1.8626e-02,  5.8173e-03,\n",
              "                                     1.8903e-02,  3.6814e-03,  4.8419e-03,  3.7592e-03,\n",
              "                                     3.3475e-02, -3.1880e-03, -4.7291e-03,  2.2810e-02,\n",
              "                                    -3.2037e-02,  4.7287e-03,  3.4066e-04, -8.2321e-03,\n",
              "                                     1.8516e-02,  3.6367e-02,  1.9756e-02,  1.3072e-02,\n",
              "                                    -4.8395e-03, -1.3530e-02, -9.4227e-03, -1.5388e-02,\n",
              "                                    -2.2902e-02, -8.2791e-03, -2.3831e-02,  5.8452e-03,\n",
              "                                     6.4090e-03,  8.5053e-03, -4.9151e-03, -1.4539e-02,\n",
              "                                     1.0502e-02,  1.3499e-03,  6.5650e-03,  2.6400e-02,\n",
              "                                     1.0012e-03,  8.5918e-03, -2.6156e-02,  8.8251e-03,\n",
              "                                     8.3782e-03,  1.7633e-02,  3.9686e-04,  6.3011e-03,\n",
              "                                     2.4300e-02,  5.8703e-03,  5.2649e-04, -1.7459e-02,\n",
              "                                    -1.0669e-02,  4.7979e-03,  1.9743e-02, -4.1495e-03,\n",
              "                                     9.1137e-03,  1.2566e-02,  4.5881e-03,  1.9725e-02,\n",
              "                                     1.0280e-02,  3.5997e-03, -2.0095e-02, -7.6753e-03,\n",
              "                                     4.5380e-03, -6.7822e-03,  6.3148e-03, -9.8048e-03,\n",
              "                                     1.0437e-02,  8.9595e-03, -2.5091e-03, -2.9661e-02,\n",
              "                                    -3.9469e-03,  9.4115e-03, -8.4909e-03,  3.2935e-02,\n",
              "                                     5.9169e-03,  3.3832e-02,  1.9763e-02,  2.9514e-02,\n",
              "                                    -1.9515e-02, -8.3267e-03, -6.7331e-03,  5.3698e-03,\n",
              "                                     2.3698e-02,  2.1233e-03,  3.1600e-02,  1.0616e-02,\n",
              "                                     9.3564e-03,  1.8975e-02, -1.6861e-02,  6.0342e-02,\n",
              "                                     2.4215e-02,  3.7869e-03,  3.8067e-03, -1.0045e-02,\n",
              "                                     2.2881e-03,  1.6433e-02,  2.4125e-02, -9.2459e-04,\n",
              "                                     1.8012e-03,  2.7474e-02,  1.4341e-02, -2.5411e-02,\n",
              "                                     2.2995e-02, -1.3623e-02,  2.1958e-02,  8.2655e-03,\n",
              "                                     7.6729e-03,  1.3624e-03,  1.3117e-02,  3.5777e-03,\n",
              "                                     1.4405e-02,  8.0204e-04,  1.3870e-02,  6.1263e-03,\n",
              "                                    -3.1272e-03, -1.5162e-04,  6.2996e-03,  9.2092e-03,\n",
              "                                    -2.7331e-02,  4.2182e-04,  1.5335e-02, -1.2407e-03,\n",
              "                                     1.1415e-02, -1.5153e-02, -2.9848e-02, -2.9600e-02,\n",
              "                                     4.4021e-03, -2.0933e-02, -3.1561e-02,  1.0755e-02,\n",
              "                                     1.2895e-02, -4.8260e-03,  2.8931e-02,  2.2590e-02,\n",
              "                                     5.0514e-03,  1.4524e-02,  4.7705e-03,  3.3118e-03,\n",
              "                                     1.6994e-02, -1.7687e-02,  6.0252e-03,  4.5700e-03,\n",
              "                                     2.2042e-02, -1.2337e-02, -6.1852e-03, -2.2188e-02,\n",
              "                                     5.4576e-03, -3.0602e-02,  4.1679e-03, -1.3429e-02,\n",
              "                                     6.1126e-03, -1.4656e-02,  1.4520e-03,  8.0807e-05,\n",
              "                                     2.0327e-02, -5.2644e-03, -9.4009e-03, -3.5295e-02,\n",
              "                                    -1.5652e-03,  6.9587e-03,  1.4912e-02,  2.4647e-02,\n",
              "                                     2.9118e-03,  1.5081e-02, -1.0806e-02,  4.7589e-03,\n",
              "                                     3.7707e-03,  3.1451e-03, -4.0012e-02, -6.7277e-04,\n",
              "                                    -1.2611e-02,  4.8779e-03, -2.0996e-02, -7.1901e-03,\n",
              "                                     1.6684e-02,  9.7811e-03, -1.5405e-02, -2.8639e-02,\n",
              "                                    -3.5974e-03,  1.0067e-02,  2.3572e-02, -8.7808e-03,\n",
              "                                    -4.4386e-03,  2.1994e-02,  3.6289e-03, -3.2579e-02,\n",
              "                                     2.0238e-02, -3.1490e-03,  3.9987e-03, -6.7679e-03,\n",
              "                                     8.5954e-03,  1.8395e-02,  9.4447e-03,  4.7918e-03,\n",
              "                                    -3.0942e-03, -4.6855e-03,  3.5324e-02,  5.6692e-03,\n",
              "                                     1.6855e-03,  8.5497e-03,  2.1586e-02, -6.7628e-03,\n",
              "                                    -3.7773e-02, -2.4875e-02, -1.8151e-02,  4.0596e-03,\n",
              "                                    -1.7139e-02,  1.8118e-03,  1.7930e-02,  6.1003e-03,\n",
              "                                    -2.6621e-02,  1.5109e-04,  3.5297e-03,  2.6085e-02,\n",
              "                                    -1.3309e-02,  1.5693e-02, -1.1428e-02, -6.1734e-03]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn3.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 3.2756e-01,  2.0855e-01,  1.3689e-01,  1.1118e-01,\n",
              "                                     2.2276e-01, -1.1870e-01,  6.3383e-02,  5.7221e-02,\n",
              "                                     1.5662e-01, -1.3480e-01, -2.8346e-01,  4.8558e-02,\n",
              "                                     1.2857e-01, -1.7650e-01,  5.0106e-02, -2.9547e-01,\n",
              "                                     2.6913e-01, -2.9504e-01, -1.4624e-01, -4.4844e-01,\n",
              "                                     5.0841e-02,  3.1879e-02, -2.3535e-01, -5.6117e-01,\n",
              "                                    -1.9358e-01, -7.1000e-02,  2.4813e-01, -1.1013e-02,\n",
              "                                    -5.3728e-01,  3.5908e-02, -3.2724e-02, -1.3586e-01,\n",
              "                                     7.4261e-02,  1.2111e-01, -6.2513e-01, -4.2515e-01,\n",
              "                                    -3.2072e-02,  6.7354e-02,  3.4353e-01, -1.7609e-01,\n",
              "                                     3.3921e-01, -4.4827e-02,  1.0808e-01, -1.7433e-01,\n",
              "                                    -5.7183e-01, -6.6320e-01, -1.8622e-01, -4.5149e-02,\n",
              "                                     4.8939e-01, -4.2350e-01,  2.2978e-01, -4.0200e-01,\n",
              "                                    -3.0098e-01, -1.0735e-01,  3.9793e-02,  1.1610e-01,\n",
              "                                    -1.0280e-02,  1.5965e-01, -9.9845e-03, -8.9727e-02,\n",
              "                                     7.5044e-02, -2.5770e-01,  1.6963e-01, -1.9276e-01,\n",
              "                                     2.4632e-02, -2.6657e-01, -3.4817e-01, -3.1030e-01,\n",
              "                                     2.2504e-01,  8.1459e-02,  1.3358e-02,  3.2743e-02,\n",
              "                                    -3.1956e-01,  5.9336e-02, -7.2571e-02,  3.4641e-01,\n",
              "                                     8.9158e-02, -5.5922e-01,  1.1289e-01, -1.4424e-01,\n",
              "                                     2.5384e-01, -1.0860e-01, -6.2243e-02,  2.0696e-01,\n",
              "                                    -3.3026e-01, -2.3677e-01, -2.9032e-01,  1.2398e-01,\n",
              "                                    -3.1656e-01,  2.1993e-01, -1.1428e-01,  2.6673e-01,\n",
              "                                    -2.3467e-01,  1.2740e-01,  1.0357e-01,  6.6397e-02,\n",
              "                                     1.6110e-01, -3.9134e-01,  2.2882e-01, -2.0142e-01,\n",
              "                                    -5.5507e-02,  2.9785e-01, -2.8559e-01, -2.2271e-03,\n",
              "                                    -3.4369e-01, -2.4975e-01, -3.4436e-01, -2.8585e-01,\n",
              "                                     5.3454e-01, -3.0573e-01, -2.3582e-01,  2.6542e-01,\n",
              "                                     3.5499e-01,  4.4192e-02, -5.0805e-02, -3.0651e-01,\n",
              "                                    -1.2041e-01, -3.5525e-01,  5.8691e-03, -6.1702e-01,\n",
              "                                    -1.7257e-01, -4.3250e-01, -1.8150e-01, -9.4022e-02,\n",
              "                                    -1.1684e-01,  1.4652e-01, -2.0974e-01, -5.8417e-02,\n",
              "                                     5.7210e-02, -2.5828e-02, -1.2966e-01, -2.6592e-01,\n",
              "                                     2.2050e-02, -2.6034e-01,  2.8230e-01, -9.3241e-02,\n",
              "                                    -1.6535e-01, -2.2105e-01, -3.1096e-01,  6.6666e-02,\n",
              "                                    -1.2467e-01, -2.4255e-01, -2.1187e-01, -3.1572e-02,\n",
              "                                    -4.0035e-01, -1.5259e-01, -1.1401e-01, -4.4766e-01,\n",
              "                                    -4.6386e-02, -6.2563e-02,  1.4611e-01, -3.8350e-01,\n",
              "                                    -3.4088e-01,  1.0646e-01, -4.7099e-03,  5.3295e-02,\n",
              "                                     5.6448e-02, -2.0535e-01, -1.2471e-01, -9.1657e-02,\n",
              "                                    -9.3352e-02, -3.6757e-01, -2.6128e-01, -6.3437e-01,\n",
              "                                     1.1253e-01, -3.6233e-01, -1.2528e-01, -1.0057e-01,\n",
              "                                     1.6860e-01, -3.6445e-01,  2.9935e-01,  3.7974e-01,\n",
              "                                     1.4812e-01,  2.1416e-01, -8.2550e-02, -1.0754e-01,\n",
              "                                    -1.2471e-01,  6.4685e-01,  3.6995e-03, -9.1094e-02,\n",
              "                                     2.6840e-02, -2.8336e-01, -8.9527e-02, -3.5947e-01,\n",
              "                                    -1.5616e-01, -4.7175e-01, -1.3114e-01,  2.0441e-02,\n",
              "                                    -1.0494e-02,  4.0060e-01, -1.2904e-01, -7.1236e-01,\n",
              "                                     2.0319e-01, -3.1589e-01, -2.7138e-01,  2.1514e-01,\n",
              "                                     4.4668e-01,  1.8776e-02,  3.3254e-01,  1.0975e-01,\n",
              "                                     1.5787e-02, -2.8959e-01,  1.4519e-01, -1.5420e-01,\n",
              "                                     2.4768e-01,  6.1673e-02, -4.4513e-01,  1.0343e-01,\n",
              "                                     2.1000e-03, -2.4109e-01, -6.8171e-02,  4.7434e-02,\n",
              "                                    -4.7332e-01, -2.4258e-01, -2.1920e-01, -1.7055e-01,\n",
              "                                    -1.8273e-01,  1.1851e-01, -1.0017e-01, -7.3634e-02,\n",
              "                                     2.9688e-01, -3.7185e-01, -9.7395e-02, -1.0988e-01,\n",
              "                                     5.2470e-01,  7.5880e-02, -5.4549e-03, -5.4728e-02,\n",
              "                                    -2.5168e-01, -4.8407e-01, -3.0883e-01,  8.5508e-02,\n",
              "                                    -5.0446e-01, -1.2568e-01, -1.2046e-01, -3.6939e-01,\n",
              "                                    -5.5689e-01, -1.1992e-01, -1.1957e-01,  5.2625e-01,\n",
              "                                    -7.5648e-02, -7.1816e-02, -1.4644e-01, -5.7333e-01,\n",
              "                                    -3.0811e-01, -3.9209e-02, -2.4801e-01, -4.4928e-02,\n",
              "                                    -2.6381e-01, -8.4613e-02, -2.7582e-01, -5.7833e-01,\n",
              "                                     2.6671e-01, -2.0651e-01, -8.5225e-02, -2.8106e-01,\n",
              "                                    -3.2119e-01, -1.0404e-01,  7.7946e-01, -3.1024e-01,\n",
              "                                    -9.5015e-02,  3.0835e-01,  4.2894e-02, -1.3675e-01,\n",
              "                                     5.3320e-01, -1.8160e-01, -4.4535e-01,  3.7779e-01,\n",
              "                                    -3.0347e-01, -2.2097e-01,  1.9478e-01,  4.9652e-03,\n",
              "                                    -2.4527e-01, -4.0428e-01, -4.6827e-02,  5.2157e-02,\n",
              "                                    -3.8133e-01, -2.7728e-02, -2.6350e-01, -1.1304e-01,\n",
              "                                    -1.1836e-02,  5.2671e-01,  1.9758e-02, -8.5201e-02,\n",
              "                                     8.0881e-03, -3.8888e-01, -2.7813e-01, -1.0952e-01,\n",
              "                                    -1.4551e-01,  5.2959e-02, -2.8550e-01, -6.8594e-02,\n",
              "                                    -2.6953e-01,  1.2347e-01, -8.5472e-02, -1.5205e-01,\n",
              "                                    -2.5605e-01, -6.9674e-02, -7.0755e-02, -9.8460e-02,\n",
              "                                    -4.1422e-01,  2.5979e-01, -4.6921e-01, -7.7370e-01,\n",
              "                                    -4.3050e-01, -2.4374e-01,  5.2531e-02, -2.4957e-01,\n",
              "                                     3.9696e-01, -3.2497e-03, -4.0000e-02,  4.0052e-01,\n",
              "                                    -2.6010e-01, -4.7354e-01, -2.1120e-01, -1.2125e-01,\n",
              "                                     1.8898e-02, -5.4302e-02,  1.1251e-01,  7.3719e-02,\n",
              "                                    -1.1639e-01,  1.8376e-01, -3.0155e-01,  4.0432e-01,\n",
              "                                     1.6344e-01, -6.6859e-01, -8.3847e-04,  2.1025e-01,\n",
              "                                    -4.6753e-01, -1.2932e-01, -2.5209e-01,  8.5325e-02,\n",
              "                                    -1.0524e-01,  1.1929e-01,  3.1114e-01, -2.3690e-02,\n",
              "                                    -5.1933e-01, -1.7994e-01,  9.2587e-02,  3.1558e-01,\n",
              "                                     1.4661e-01,  4.6582e-02, -1.4181e-01,  1.2814e-01,\n",
              "                                    -2.5910e-01, -1.6895e-01,  4.2466e-02, -2.3460e-02,\n",
              "                                    -8.8963e-02,  1.3882e-01, -3.5891e-01,  3.5251e-01,\n",
              "                                    -3.4686e-01, -4.4004e-02, -1.2923e-01,  4.4836e-01,\n",
              "                                    -9.2607e-02,  2.2986e-01, -9.1006e-02,  3.6475e-01,\n",
              "                                    -8.6834e-01, -1.6838e-01,  1.3519e-01, -6.8679e-02,\n",
              "                                    -3.5956e-01, -2.4333e-01, -7.0046e-02, -3.0044e-01,\n",
              "                                    -4.5163e-02,  7.3940e-02,  2.3440e-01, -1.7722e-01,\n",
              "                                    -5.8068e-01, -2.6392e-01, -5.7556e-02,  2.5728e-01,\n",
              "                                    -6.4550e-01, -8.0526e-02, -1.6696e-01, -2.9032e-01,\n",
              "                                    -4.0360e-02,  2.3295e-02,  3.3592e-01, -2.3376e-01,\n",
              "                                    -2.5637e-01, -3.2784e-01,  4.2197e-01, -3.7191e-02,\n",
              "                                    -2.1366e-01, -2.6688e-01, -5.9539e-02, -4.8948e-01,\n",
              "                                    -4.0191e-01, -9.4893e-02,  3.3611e-01,  8.5843e-01,\n",
              "                                    -6.6491e-01, -1.0341e-01, -5.4804e-01, -2.2755e-01,\n",
              "                                    -3.0952e-01,  1.1398e-01, -3.8184e-02, -3.4771e-01,\n",
              "                                    -2.2666e-02,  5.5452e-02, -2.4080e-01, -1.2352e-01,\n",
              "                                     1.1250e-02, -2.1128e-01, -4.1748e-01, -1.7248e-01,\n",
              "                                    -4.4161e-01, -1.3622e-01, -2.8942e-01,  9.8341e-02,\n",
              "                                     5.4684e-01, -4.5021e-01, -9.6903e-02, -1.4189e-01,\n",
              "                                    -2.8437e-01, -2.2685e-01, -4.1162e-02,  1.6738e-01,\n",
              "                                    -4.0763e-02, -1.4105e-01, -2.9056e-01,  8.6580e-02,\n",
              "                                     2.9919e-02, -4.8468e-01, -2.7671e-01, -3.7896e-01,\n",
              "                                    -3.8874e-02, -7.5909e-02, -3.5096e-01,  7.4285e-02,\n",
              "                                     1.0886e-01, -2.8566e-01, -2.5399e-01, -4.2880e-01,\n",
              "                                    -4.6873e-01,  2.5323e-01, -1.9005e-01, -4.1071e-01,\n",
              "                                    -5.2252e-01,  4.7813e-01,  1.2379e-01, -6.6461e-02,\n",
              "                                    -6.1893e-02, -1.8759e-01,  1.4783e-01,  2.1976e-03,\n",
              "                                    -9.2049e-02, -1.8009e-02,  1.0838e-01, -4.2605e-01,\n",
              "                                    -1.9100e-02, -9.0088e-02, -6.3385e-01, -5.0508e-01,\n",
              "                                    -3.8478e-01, -4.6147e-01, -2.3786e-01,  1.9255e-01,\n",
              "                                     2.5568e-01,  6.3795e-02, -2.9233e-01, -8.0453e-02,\n",
              "                                     6.2393e-02,  1.8895e-01, -3.9125e-01,  6.6113e-01,\n",
              "                                    -4.6924e-01,  1.9762e-01,  1.4042e-01,  8.0787e-03,\n",
              "                                    -2.2911e-02, -8.4471e-02,  6.4622e-02,  1.8152e-01,\n",
              "                                    -1.6679e-02, -3.6163e-01,  5.5295e-01, -6.9597e-02,\n",
              "                                     7.1903e-02, -1.9047e-01, -1.0088e-01, -1.5217e-01,\n",
              "                                    -2.3002e-01, -5.8238e-02, -6.9158e-01, -5.2200e-01,\n",
              "                                    -9.5089e-02,  1.6545e-01, -6.1407e-01, -6.6783e-02,\n",
              "                                     1.2500e-01, -2.7144e-01, -3.7376e-01,  5.2356e-01,\n",
              "                                    -2.0464e-01,  3.2491e-01, -1.8114e-01,  3.3705e-01,\n",
              "                                    -2.3839e-01, -9.6500e-02, -1.9755e-02, -2.4393e-01,\n",
              "                                    -8.0262e-01, -4.2234e-01,  2.1921e-01,  5.0806e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn3.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([1.0455, 0.5890, 0.4185, 0.1766, 0.2950, 0.3742, 0.3032,\n",
              "                                    0.2253, 0.1926, 0.5441, 0.3473, 0.3513, 0.1586, 0.3246,\n",
              "                                    0.1234, 0.6994, 0.3231, 0.4272, 0.2747, 0.1613, 0.2900,\n",
              "                                    0.1941, 0.1974, 0.2055, 0.4583, 0.1496, 0.2404, 0.7650,\n",
              "                                    0.2110, 0.2557, 0.3280, 0.2503, 0.5357, 0.2642, 0.3933,\n",
              "                                    1.3335, 0.2746, 0.2392, 0.3206, 0.2383, 0.4188, 0.5368,\n",
              "                                    0.2424, 0.3372, 0.8087, 0.3106, 0.2689, 0.3600, 0.6649,\n",
              "                                    0.5307, 0.4561, 0.1683, 0.5224, 0.3085, 0.3445, 0.2452,\n",
              "                                    0.2938, 0.2640, 0.4916, 0.3608, 0.2336, 0.2187, 0.1846,\n",
              "                                    0.4311, 0.2159, 0.3607, 0.3772, 0.3653, 1.1824, 0.3701,\n",
              "                                    0.3129, 0.2037, 0.5246, 0.3327, 0.3755, 0.1823, 0.2136,\n",
              "                                    0.3524, 0.3245, 0.4616, 0.5141, 0.3719, 0.1471, 0.2627,\n",
              "                                    0.5697, 0.2467, 0.6714, 0.1746, 0.6117, 0.3139, 0.5245,\n",
              "                                    0.2210, 0.4692, 0.1482, 0.1953, 0.4856, 0.2570, 0.6055,\n",
              "                                    0.4112, 0.1993, 0.4963, 0.3088, 0.2166, 0.6265, 0.7588,\n",
              "                                    0.2747, 0.4233, 0.3845, 0.6338, 0.1417, 0.3497, 0.5911,\n",
              "                                    0.1292, 0.2250, 0.2999, 0.2166, 0.1910, 0.1859, 0.4089,\n",
              "                                    0.8639, 0.3121, 0.2700, 0.4006, 0.2267, 0.2587, 0.1573,\n",
              "                                    0.6242, 0.3291, 0.2968, 0.5258, 0.3208, 0.5186, 0.2850,\n",
              "                                    0.4629, 0.3013, 0.1784, 0.3654, 0.7442, 0.4557, 0.6820,\n",
              "                                    0.1350, 0.2577, 0.3828, 0.3399, 0.4137, 0.2112, 0.1583,\n",
              "                                    0.5388, 0.3869, 0.1119, 0.2659, 0.4973, 0.2977, 0.6678,\n",
              "                                    0.3009, 0.6983, 0.1161, 0.2055, 0.2959, 0.6216, 0.2235,\n",
              "                                    0.1993, 0.4873, 0.4159, 0.3838, 0.3888, 0.1875, 0.2723,\n",
              "                                    0.3632, 0.4047, 0.2736, 0.1810, 0.3109, 0.3713, 0.2863,\n",
              "                                    0.3963, 0.3473, 0.5297, 0.1681, 0.2548, 0.1751, 0.1946,\n",
              "                                    0.2417, 0.2547, 0.3158, 0.3149, 0.4163, 0.3675, 0.2254,\n",
              "                                    0.4382, 0.1450, 0.4254, 0.4856, 0.3187, 0.2638, 0.2984,\n",
              "                                    0.5064, 0.4752, 0.2761, 0.2670, 0.7337, 0.2354, 0.5102,\n",
              "                                    0.2847, 0.3033, 0.4161, 0.2806, 0.4765, 0.1193, 0.3240,\n",
              "                                    0.5589, 0.2752, 0.2704, 0.1993, 0.2748, 0.3182, 0.4203,\n",
              "                                    0.2340, 0.6274, 0.5086, 0.5353, 0.8241, 0.5338, 0.4850,\n",
              "                                    0.1791, 0.3946, 0.2289, 0.5222, 0.4515, 0.9194, 0.5546,\n",
              "                                    0.6346, 0.2601, 0.1155, 0.3693, 0.4622, 0.3051, 0.1479,\n",
              "                                    0.1984, 0.4833, 0.1725, 0.4021, 0.2062, 0.7624, 0.5651,\n",
              "                                    0.1975, 0.1967, 0.3845, 0.2097, 0.4187, 0.2219, 0.5857,\n",
              "                                    0.3563, 0.2053, 0.3249, 0.2013, 0.2173, 0.2451, 0.8101,\n",
              "                                    0.2539, 0.2090, 0.2633, 0.1974, 0.7605, 1.1578, 0.2251,\n",
              "                                    0.6063, 0.2406, 0.4131, 0.1618, 0.5146, 0.2668, 0.1504,\n",
              "                                    0.3616, 0.3565, 0.2538, 0.3419, 0.5717, 0.4829, 0.1851,\n",
              "                                    0.1433, 0.7039, 0.2219, 0.3271, 0.2350, 0.3217, 0.2875,\n",
              "                                    0.3121, 0.2841, 0.3887, 0.2839, 0.2519, 0.2522, 0.2415,\n",
              "                                    0.3022, 0.2473, 0.2285, 0.4226, 0.4617, 0.2773, 0.6756,\n",
              "                                    0.3420, 0.3765, 0.5509, 0.3183, 0.2075, 0.4119, 0.4234,\n",
              "                                    0.5139, 0.4242, 0.2719, 0.3918, 0.3197, 0.4842, 0.5965,\n",
              "                                    0.4010, 0.3154, 0.2064, 0.1830, 0.4129, 0.3892, 0.4423,\n",
              "                                    0.5958, 0.3655, 0.2820, 0.9643, 0.6004, 0.3092, 0.2636,\n",
              "                                    0.6296, 0.3445, 0.4683, 0.7562, 0.3622, 0.2142, 0.2288,\n",
              "                                    0.3041, 0.2101, 0.3807, 0.2245, 0.2783, 0.7891, 0.2630,\n",
              "                                    0.3364, 0.6115, 0.2978, 0.3498, 0.3403, 0.2457, 0.5226,\n",
              "                                    0.5952, 0.3603, 0.3378, 0.4087, 0.3178, 0.6947, 0.2033,\n",
              "                                    0.5101, 0.3311, 0.7750, 0.7261, 0.4365, 0.1712, 0.4043,\n",
              "                                    0.2870, 0.3153, 0.2354, 0.3799, 0.2477, 0.4120, 0.3439,\n",
              "                                    0.2576, 0.9960, 0.3464, 0.2001, 0.3063, 0.5086, 0.2295,\n",
              "                                    0.2330, 0.3539, 0.3345, 0.5176, 0.3848, 0.4098, 0.3402,\n",
              "                                    0.2505, 0.4491, 0.3541, 0.3783, 0.2458, 0.3454, 0.3318,\n",
              "                                    0.5128, 0.2022, 0.1665, 0.7319, 0.7045, 0.3731, 0.4086,\n",
              "                                    0.2317, 0.1787, 0.4561, 0.3218, 0.8906, 0.1585, 0.1272,\n",
              "                                    0.8327, 0.2141, 0.3387, 0.1479, 0.5094, 0.3187, 0.3518,\n",
              "                                    0.2595, 0.2392, 0.4924, 0.3752, 0.3913, 0.3925, 0.2747,\n",
              "                                    0.4291, 0.1831, 0.3671, 0.3561, 0.3201, 0.2305, 0.6529,\n",
              "                                    0.5752, 0.1426, 0.8962, 0.4777, 0.1870, 0.4170, 0.3561,\n",
              "                                    0.7691, 0.4268, 0.2161, 0.4339, 0.5050, 0.4288, 0.9543,\n",
              "                                    0.2722, 1.0880, 0.8826, 0.2680, 0.2201, 0.1693, 0.2693,\n",
              "                                    0.2501, 0.6007, 0.2853, 0.2731, 0.5419, 0.4517, 0.4085,\n",
              "                                    0.1798, 0.3111, 0.1910, 0.7024, 0.3060, 0.3180, 0.3724,\n",
              "                                    0.1699, 0.2831, 0.1466, 0.1908, 0.2277, 0.3899, 0.3147,\n",
              "                                    0.3284, 0.6183, 0.2769, 0.6565, 0.6756, 0.7157, 0.1925,\n",
              "                                    0.2588, 0.1951, 0.3057, 0.4124, 0.1423, 0.2100, 0.1763,\n",
              "                                    0.3664, 0.1380, 0.2613, 0.2747, 0.2547, 0.3050, 0.2329,\n",
              "                                    0.7705, 0.4215, 0.9551, 0.3556, 0.3262, 0.3767, 0.2452,\n",
              "                                    0.1963, 0.2860, 0.9211, 0.4545, 0.5899, 0.4247, 0.6013,\n",
              "                                    0.3713, 0.2086, 0.0887, 0.6560, 1.1611, 0.2760, 0.2628,\n",
              "                                    0.2299]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer2.3.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.conv1.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   1,   2,  ..., 509, 510, 511],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0],\n",
              "                                     [  0,   0,   0,  ...,   0,   0,   0]]),\n",
              "                     values=tensor([-0.0738,  0.0325, -0.1080,  ...,  0.0361,  0.0531,\n",
              "                                     0.1586]),\n",
              "                     size=(256, 512, 1, 1), nnz=131072, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([1.0003, 0.9905, 0.9878, 1.0173, 1.0101, 1.0135, 0.9822,\n",
              "                                    1.0163, 0.9895, 1.0073, 0.9807, 1.0039, 0.9647, 0.9969,\n",
              "                                    1.0159, 0.9962, 1.0123, 0.9942, 0.9490, 0.9867, 1.0030,\n",
              "                                    0.9958, 1.0117, 1.0146, 0.9818, 0.9958, 0.9914, 0.9928,\n",
              "                                    0.9911, 1.0144, 0.9774, 1.0082, 1.0007, 1.0204, 0.9967,\n",
              "                                    0.9873, 0.9903, 1.0152, 1.0047, 1.0212, 0.9861, 0.9990,\n",
              "                                    0.9838, 0.9878, 0.9880, 0.9940, 0.9728, 1.0101, 0.9842,\n",
              "                                    1.0271, 0.9850, 0.9829, 0.9841, 1.0007, 0.9839, 0.9933,\n",
              "                                    1.0094, 0.9929, 0.9986, 1.0132, 1.0107, 1.0142, 0.9811,\n",
              "                                    1.0023, 1.0067, 1.0018, 0.9744, 0.9855, 1.0037, 0.9885,\n",
              "                                    0.9847, 0.9964, 0.9814, 1.0011, 0.9877, 0.9918, 1.0043,\n",
              "                                    0.9605, 0.9752, 1.0087, 1.0100, 0.9660, 0.9814, 0.9904,\n",
              "                                    0.9881, 0.9926, 0.9985, 1.0178, 0.9840, 0.9946, 1.0212,\n",
              "                                    0.9845, 1.0160, 0.9971, 0.9980, 1.0060, 0.9926, 1.0377,\n",
              "                                    1.0030, 0.9859, 1.0257, 1.0151, 1.0099, 1.0074, 1.0210,\n",
              "                                    1.0261, 0.9997, 0.9923, 0.9866, 1.0155, 1.0262, 0.9962,\n",
              "                                    1.0027, 1.0142, 0.9760, 1.0093, 1.0114, 0.9985, 0.9990,\n",
              "                                    1.0116, 1.0058, 0.9920, 0.9902, 0.9947, 1.0254, 0.9820,\n",
              "                                    0.9996, 1.0286, 1.0275, 0.9967, 1.0351, 1.0026, 1.0403,\n",
              "                                    1.0225, 0.9812, 0.9818, 0.9908, 1.0240, 0.9786, 0.9799,\n",
              "                                    0.9945, 0.9881, 0.9811, 0.9736, 0.9950, 1.0045, 1.0052,\n",
              "                                    1.0002, 1.0143, 0.9914, 0.9952, 0.9974, 1.0115, 1.0077,\n",
              "                                    0.9885, 1.0132, 0.9901, 0.9965, 1.0094, 1.0037, 0.9991,\n",
              "                                    1.0259, 1.0087, 1.0032, 0.9647, 1.0008, 0.9929, 0.9775,\n",
              "                                    1.0059, 0.9941, 0.9949, 0.9985, 0.9915, 0.9901, 1.0008,\n",
              "                                    1.0298, 0.9905, 0.9926, 0.9964, 0.9878, 0.9884, 0.9948,\n",
              "                                    0.9976, 0.9979, 1.0067, 0.9972, 1.0114, 0.9946, 0.9928,\n",
              "                                    1.0127, 0.9991, 0.9708, 1.0014, 1.0114, 1.0018, 0.9859,\n",
              "                                    1.0219, 0.9854, 0.9979, 0.9623, 0.9944, 1.0018, 0.9962,\n",
              "                                    1.0096, 0.9879, 0.9942, 0.9972, 1.0031, 1.0087, 0.9778,\n",
              "                                    1.0428, 0.9890, 1.0204, 0.9862, 1.0179, 0.9981, 0.9602,\n",
              "                                    1.0024, 0.9901, 0.9809, 1.0341, 1.0212, 0.9915, 0.9894,\n",
              "                                    1.0093, 1.0305, 0.9991, 1.0067, 1.0006, 1.0093, 1.0302,\n",
              "                                    1.0034, 1.0184, 0.9877, 1.0171, 1.0066, 1.0003, 1.0209,\n",
              "                                    1.0093, 1.0550, 0.9779, 0.9739, 1.0053, 0.9934, 1.0094,\n",
              "                                    0.9911, 0.9878, 1.0117, 1.0110, 1.0171, 1.0046, 1.0078,\n",
              "                                    0.9945, 1.0212, 1.0139, 1.0328]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 1.2842e-02,  3.0048e-03, -1.1643e-02,  4.4806e-02,\n",
              "                                     1.0780e-02, -9.2765e-04, -7.9205e-03,  1.1552e-03,\n",
              "                                     1.8988e-02,  1.6305e-04, -8.3618e-03,  1.9601e-02,\n",
              "                                    -1.8334e-02,  1.3175e-02, -1.9739e-03,  5.9450e-03,\n",
              "                                    -3.3434e-03,  5.2952e-03, -1.0115e-02, -1.3866e-03,\n",
              "                                    -1.0030e-02, -1.5207e-04, -5.3788e-03,  1.7699e-03,\n",
              "                                    -1.3222e-02,  3.4592e-02, -1.4074e-02,  1.9837e-02,\n",
              "                                     1.3425e-03, -6.1519e-03,  1.4050e-02,  1.4933e-02,\n",
              "                                     3.5828e-02, -2.0584e-02,  1.5202e-03,  2.3737e-02,\n",
              "                                     6.4576e-03,  1.7924e-02,  9.7424e-03,  4.3216e-02,\n",
              "                                    -1.4236e-02, -2.0564e-02,  2.8975e-03,  3.5192e-03,\n",
              "                                     1.4994e-02, -1.0431e-02, -3.2644e-03, -2.6230e-02,\n",
              "                                     8.2931e-03,  2.5915e-02, -1.2724e-02, -6.4677e-03,\n",
              "                                    -2.3910e-02, -2.6636e-04,  4.7666e-03,  2.1632e-02,\n",
              "                                    -2.2075e-02,  1.0450e-02,  1.4079e-02,  2.4094e-02,\n",
              "                                     1.6322e-02,  3.6305e-02, -7.8033e-03,  1.5460e-02,\n",
              "                                     1.2172e-02, -3.1271e-03,  6.0623e-03, -1.8351e-02,\n",
              "                                     2.4126e-02, -1.9850e-02, -3.7951e-02,  4.2556e-04,\n",
              "                                    -1.2563e-02,  3.9238e-02, -1.2540e-02, -6.9037e-03,\n",
              "                                    -3.7018e-03, -4.8763e-03, -1.7846e-02,  2.1819e-02,\n",
              "                                    -2.1048e-02, -8.7347e-04, -2.7760e-02,  3.9902e-02,\n",
              "                                    -8.7286e-03, -1.9148e-02,  2.1248e-02, -2.0681e-02,\n",
              "                                    -9.9818e-03,  6.5800e-03, -1.7432e-04, -4.7637e-02,\n",
              "                                     1.7896e-02,  3.4245e-04,  1.6774e-02,  8.5763e-03,\n",
              "                                    -1.1177e-02,  4.9902e-02,  5.6826e-04, -2.5500e-02,\n",
              "                                    -5.5990e-03,  1.1000e-02,  1.1617e-02,  1.2798e-02,\n",
              "                                    -1.2878e-02, -9.0480e-03,  2.9013e-02, -1.2356e-02,\n",
              "                                    -1.0774e-02,  1.7415e-04,  2.4102e-02, -8.6141e-03,\n",
              "                                     1.8880e-02,  4.5394e-02, -1.3892e-02,  1.0625e-02,\n",
              "                                     1.3750e-02, -6.8390e-03, -1.4352e-02,  2.8715e-02,\n",
              "                                     1.8509e-02,  6.6214e-03,  2.6991e-02,  1.9355e-02,\n",
              "                                     3.0397e-02, -2.6457e-02, -1.6817e-02,  3.2369e-02,\n",
              "                                     5.5235e-02, -2.1525e-03,  2.7333e-02,  2.1356e-02,\n",
              "                                     3.3539e-03,  1.6088e-02,  9.0648e-04, -2.4237e-03,\n",
              "                                    -1.1190e-02,  3.7956e-03, -9.9443e-03, -1.5192e-03,\n",
              "                                    -4.9281e-03, -1.3785e-02, -1.5787e-02,  5.1573e-03,\n",
              "                                    -1.8031e-02,  2.0650e-02, -7.0339e-03,  1.3345e-02,\n",
              "                                    -4.0728e-03,  2.9502e-02, -1.3520e-02,  2.0070e-02,\n",
              "                                     5.5424e-03,  2.7882e-03,  8.6072e-03,  1.9871e-02,\n",
              "                                    -6.6862e-03, -1.5470e-02, -1.3448e-02,  1.8490e-02,\n",
              "                                     1.1353e-02, -8.1658e-03,  2.8910e-02, -4.0253e-04,\n",
              "                                     3.3949e-03,  2.2313e-02,  2.4156e-02,  1.6412e-02,\n",
              "                                     1.8574e-02, -1.4761e-03, -1.0447e-02,  1.3218e-02,\n",
              "                                    -9.7590e-03,  1.7934e-02, -1.3582e-02,  5.0689e-03,\n",
              "                                    -2.6369e-03, -7.7218e-04,  3.8727e-05,  1.2115e-02,\n",
              "                                     1.6310e-02,  1.1248e-02, -2.2115e-03,  1.2152e-02,\n",
              "                                     2.6284e-02,  2.1951e-02,  5.7528e-02,  4.1468e-04,\n",
              "                                     9.3149e-04,  1.6841e-02,  6.8228e-03,  1.0962e-02,\n",
              "                                    -1.7995e-03,  1.4981e-03, -1.1779e-03,  1.2089e-02,\n",
              "                                     1.8003e-02,  1.0695e-02,  2.0592e-02, -1.0914e-02,\n",
              "                                     1.0919e-02,  3.0050e-02,  1.2086e-02,  2.9248e-02,\n",
              "                                     4.9616e-03,  1.4311e-02,  6.3537e-04,  7.9791e-03,\n",
              "                                     2.3772e-02, -2.4998e-02, -7.7036e-03,  8.2093e-04,\n",
              "                                     7.7775e-03, -3.3715e-03, -8.8991e-04, -2.2764e-02,\n",
              "                                    -3.8758e-02, -3.3249e-03, -1.0444e-02, -8.9259e-03,\n",
              "                                    -5.7984e-03,  3.7751e-02, -5.8546e-04,  2.0685e-02,\n",
              "                                    -1.5423e-02,  2.3358e-02, -5.8155e-03,  1.7579e-02,\n",
              "                                     1.3591e-02,  7.1501e-03,  4.2937e-02,  2.2490e-02,\n",
              "                                     1.0695e-02,  1.5055e-02, -1.2481e-02, -6.3583e-03,\n",
              "                                     1.2265e-02,  3.5623e-02, -3.5379e-03,  4.1579e-02,\n",
              "                                    -4.8261e-02, -1.5114e-03,  1.8582e-02, -2.0828e-04,\n",
              "                                    -4.8498e-03, -1.6064e-02, -3.0739e-02,  5.7985e-03,\n",
              "                                     2.7785e-02, -1.5287e-03,  1.0929e-02, -2.1940e-03,\n",
              "                                     1.1930e-02,  1.4138e-02,  7.2841e-03,  1.9421e-03]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 2.6356e+00, -4.5772e+00,  2.9190e+00,  1.4420e+00,\n",
              "                                    -4.6680e+00,  9.8842e-01, -4.7861e-01,  2.4939e+00,\n",
              "                                    -3.2128e+00,  1.4479e+00, -1.6613e+00, -1.5557e+00,\n",
              "                                     3.0992e+00, -5.0500e-01,  4.7352e+00, -1.6045e+00,\n",
              "                                     1.2771e-01,  3.7136e+00,  3.8842e+00,  4.3134e+00,\n",
              "                                    -1.3204e-01, -3.8619e+00,  4.3193e+00,  2.9141e-01,\n",
              "                                    -1.4926e+00,  6.1413e+00, -3.8154e+00,  4.7016e+00,\n",
              "                                     2.1799e+00,  1.9156e+00,  4.6285e+00, -5.5230e+00,\n",
              "                                    -3.7777e+00, -4.7618e-01,  2.4558e-01, -2.0750e+00,\n",
              "                                    -1.6746e+00, -6.5733e-01, -7.2078e-01, -3.8188e+00,\n",
              "                                    -4.7537e-01,  2.3175e+00,  1.2494e+00,  1.6253e+00,\n",
              "                                     3.7009e+00, -5.8916e-01,  1.3793e+00,  9.2219e-01,\n",
              "                                     6.3647e-01, -4.8320e+00, -6.5961e+00,  7.5858e-01,\n",
              "                                    -5.2504e-01,  2.5927e+00,  2.7638e+00, -4.6921e+00,\n",
              "                                     6.4768e-01,  1.1427e+00,  2.0290e+00, -5.6324e+00,\n",
              "                                     4.5241e+00, -4.9011e+00, -1.2043e+00, -5.5942e+00,\n",
              "                                     2.0079e+00, -3.4359e+00,  2.6221e+00, -3.0537e+00,\n",
              "                                    -5.1260e+00, -3.6991e+00,  4.4639e-01, -2.0331e-01,\n",
              "                                    -1.5451e+00,  1.2435e+00, -2.3413e+00, -4.3868e+00,\n",
              "                                     2.9214e+00,  2.2498e+00,  4.9722e+00, -8.7943e-01,\n",
              "                                     6.6328e-01,  3.1583e+00,  1.6386e+00,  4.4902e+00,\n",
              "                                     2.8991e+00,  3.0154e+00,  1.4297e+00,  3.3083e+00,\n",
              "                                     1.0012e+00, -1.1417e+00,  2.1598e+00,  6.2207e-01,\n",
              "                                     2.3243e+00, -9.4568e-01,  4.9023e+00, -1.6581e-01,\n",
              "                                     2.1430e+00,  1.6427e-03,  1.8685e+00, -8.3726e-01,\n",
              "                                     9.3918e-01,  1.5080e+00, -3.8022e-01,  5.4984e+00,\n",
              "                                    -3.1024e-01,  3.5626e+00,  1.0109e+00, -5.5174e+00,\n",
              "                                    -2.2390e+00,  3.2951e+00, -1.7286e+00,  1.3108e+00,\n",
              "                                    -5.5271e+00, -5.3505e+00,  8.4541e-01,  1.3503e+00,\n",
              "                                     1.7124e+00, -1.7298e+00, -4.3387e+00,  2.8635e+00,\n",
              "                                    -1.0301e-01, -4.9411e-01,  4.3490e+00,  1.0191e+00,\n",
              "                                    -2.0967e-01,  1.4257e+00,  4.2655e-01,  2.7218e+00,\n",
              "                                     3.0797e+00, -2.5179e+00, -4.3896e+00, -1.6670e+00,\n",
              "                                     7.7901e-01,  1.5674e+00,  3.5115e+00,  3.4831e+00,\n",
              "                                    -1.7303e-01,  2.5401e+00, -3.0513e+00, -1.1987e+00,\n",
              "                                     4.3200e+00, -2.0278e+00,  1.7621e+00, -1.0937e+00,\n",
              "                                    -4.7270e+00,  7.9362e-01, -6.5242e-01, -3.2137e+00,\n",
              "                                     7.2727e-02,  4.1934e+00,  2.4928e-02,  6.4625e-01,\n",
              "                                    -7.7944e+00,  3.8050e+00, -2.1888e+00,  2.4981e+00,\n",
              "                                    -2.8545e+00,  3.5355e+00,  2.2859e+00,  2.7953e+00,\n",
              "                                    -2.5949e+00,  1.0862e+00,  2.2803e+00, -9.0206e-01,\n",
              "                                    -8.1724e-01,  2.8335e+00,  2.6775e+00,  3.9462e+00,\n",
              "                                     1.0986e+00, -1.1677e+00, -2.4631e+00, -9.4022e-01,\n",
              "                                    -4.1747e+00, -2.3608e-01, -4.8444e+00, -1.8199e+00,\n",
              "                                     2.0106e+00, -4.6677e+00,  2.2832e+00, -1.3268e+00,\n",
              "                                     3.2286e+00,  5.2635e+00,  8.0375e-01, -2.4346e+00,\n",
              "                                    -4.7137e+00,  3.8844e-01,  3.7873e+00, -2.0134e+00,\n",
              "                                    -2.2981e+00, -9.8840e-01, -1.1995e+00,  4.2380e+00,\n",
              "                                     3.5249e+00, -1.9901e+00,  4.1489e+00,  3.3653e+00,\n",
              "                                     3.3161e+00,  2.4199e+00,  1.8691e+00, -2.0478e+00,\n",
              "                                    -3.8019e+00, -5.4616e+00,  5.7814e-01,  3.6059e+00,\n",
              "                                    -2.9997e-01, -7.1451e-01,  3.1542e-02,  5.1751e-02,\n",
              "                                    -3.0385e+00,  1.0048e+00,  3.4356e+00, -3.4136e+00,\n",
              "                                    -3.3873e+00, -8.9772e-01,  4.7117e+00, -4.7761e-01,\n",
              "                                    -1.8327e+00, -1.9321e+00, -5.5248e+00,  1.4026e+00,\n",
              "                                     6.0357e-01,  1.0410e+00, -1.9637e+00,  3.4420e+00,\n",
              "                                     2.2154e+00, -3.4119e+00,  3.1199e+00,  6.2028e+00,\n",
              "                                     8.6313e-01, -5.1505e+00, -1.9322e+00,  1.6864e+00,\n",
              "                                    -2.9757e+00, -7.1414e+00,  1.4950e+00,  2.1767e+00,\n",
              "                                     3.4481e+00, -4.0346e+00, -1.6882e+00, -6.4006e+00,\n",
              "                                     2.5581e+00,  3.9441e+00,  1.5284e+00, -2.5682e+00,\n",
              "                                     5.5574e-01, -5.6459e+00,  2.0884e+00, -3.5604e+00,\n",
              "                                     4.8354e+00,  2.2263e+00,  2.3649e+00,  1.5336e+00,\n",
              "                                     1.1697e+00, -1.9922e+00,  2.8434e+00,  3.8708e-01]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([32.2015, 14.7999, 34.1272, 39.3749, 58.4220, 25.5712,\n",
              "                                    25.0577, 60.5954, 40.8683, 32.1972, 20.6535, 40.7504,\n",
              "                                    39.9554, 14.8898, 25.3447, 26.0593, 24.7236, 22.2469,\n",
              "                                    34.4088, 38.1605, 18.3660, 21.5678, 31.4633, 22.6190,\n",
              "                                    11.9784, 65.8854, 29.9835, 79.4169, 20.1628, 36.1320,\n",
              "                                    43.7500, 70.2878, 41.3507, 22.0148, 29.7109, 30.6252,\n",
              "                                    37.2262, 29.3556, 25.7483, 33.0414, 23.0822, 22.4174,\n",
              "                                    41.7829, 51.8033, 58.7238, 21.6319, 25.3980, 20.7417,\n",
              "                                    20.4919, 20.5477, 54.6135, 35.7192, 33.7408, 19.7427,\n",
              "                                    16.7833, 51.8538, 25.7174, 26.4458, 35.1562, 60.3617,\n",
              "                                    36.5407, 35.3829, 16.0533, 43.9086, 34.2759, 38.7951,\n",
              "                                    37.2903, 19.9505, 51.6392, 18.9794, 26.0923, 15.1717,\n",
              "                                    14.4690, 26.6099, 26.8772, 24.9211, 20.2523, 41.4637,\n",
              "                                    32.9344, 32.3036, 30.5275, 33.7379, 30.8828, 44.5953,\n",
              "                                    28.7417, 22.0479, 37.3803, 22.8129, 23.3805, 26.2442,\n",
              "                                    25.0597, 28.1274, 23.5925, 26.6382, 49.6063, 18.4757,\n",
              "                                    39.3626, 27.7744, 26.2998, 23.8064, 31.0542, 42.2298,\n",
              "                                    22.5228, 37.3154, 14.6331, 29.8125, 23.6641, 24.7955,\n",
              "                                    20.8503, 30.4865, 33.1076, 14.8708, 47.2737, 53.3471,\n",
              "                                    11.9743, 17.8001, 24.3980, 26.3806, 30.0677, 60.7003,\n",
              "                                    25.3010, 13.4357, 61.4148, 17.7665, 36.0514, 33.6168,\n",
              "                                    16.6355, 58.1401, 57.4670, 43.8527, 20.3947, 40.5517,\n",
              "                                    33.6690, 51.3414, 31.7280, 19.4466,  8.8222, 27.1264,\n",
              "                                    21.5517, 19.9997, 17.2218, 15.7786, 20.6025, 17.4651,\n",
              "                                    27.3743, 29.1959, 16.1041, 30.0499, 21.3302, 56.3204,\n",
              "                                    15.3874, 31.5453, 37.6576, 20.8520, 48.6430, 29.9071,\n",
              "                                    22.7253, 31.1804, 24.9583, 47.2894, 19.6269, 29.5123,\n",
              "                                    32.5143, 14.7004, 29.1447, 57.0145, 45.4667, 57.5183,\n",
              "                                    46.8805, 16.2125, 37.3210, 18.2795, 20.1999, 18.5936,\n",
              "                                    48.6275, 36.1082, 16.6997, 41.1185, 19.0124, 18.0729,\n",
              "                                    43.4998, 52.3279, 37.3079, 27.6420, 39.3050, 14.0566,\n",
              "                                    60.2492, 26.8386, 25.5438, 20.0975, 31.3564, 37.2676,\n",
              "                                    27.4356, 30.4541, 38.0851, 32.7399, 24.1001, 38.7202,\n",
              "                                    33.8789, 22.8748, 35.0921, 84.8090, 42.4769, 64.0262,\n",
              "                                    25.9571, 40.5901, 28.1554, 23.2270, 39.7343, 28.4629,\n",
              "                                    36.6130, 38.6900, 36.4820, 25.0401, 45.1948, 33.7174,\n",
              "                                    25.3217, 16.0999, 31.9331, 28.7402, 24.7965, 27.1424,\n",
              "                                    19.3609, 36.4089, 23.9683, 40.9691, 29.3754, 51.8858,\n",
              "                                    37.0854, 71.2346, 30.0481, 22.1228, 32.5497, 53.8989,\n",
              "                                    13.4053, 28.8325, 24.2309, 52.3490, 25.0263, 54.0022,\n",
              "                                    16.8974, 35.4822, 32.0692, 27.6121, 18.9084, 45.5467,\n",
              "                                    20.1346, 21.2113, 83.6971, 20.6931, 19.0911, 35.8753,\n",
              "                                    29.3038, 16.7259, 35.4845, 51.6053]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0209,  0.0440, -0.0223,  ...,  0.0346,  0.0050,\n",
              "                                     0.0171]),\n",
              "                     size=(256, 256, 3, 3), nnz=589824, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([1.0160, 0.9973, 1.0139, 1.0009, 0.9897, 0.9935, 0.9976,\n",
              "                                    1.0135, 0.9878, 0.9575, 0.9985, 0.9998, 1.0024, 0.9785,\n",
              "                                    1.0070, 0.9936, 0.9812, 0.9928, 0.9738, 1.0042, 1.0031,\n",
              "                                    0.9875, 1.0091, 0.9960, 1.0084, 0.9688, 1.0286, 1.0185,\n",
              "                                    1.0293, 1.0024, 0.9817, 1.0059, 1.0092, 0.9951, 1.0287,\n",
              "                                    1.0076, 1.0153, 0.9687, 1.0047, 0.9890, 1.0111, 0.9936,\n",
              "                                    1.0532, 0.9818, 1.0138, 0.9943, 0.9994, 0.9931, 0.9708,\n",
              "                                    1.0328, 0.9957, 1.0059, 1.0004, 0.9977, 0.9906, 0.9858,\n",
              "                                    0.9983, 0.9955, 1.0115, 1.0133, 1.0012, 1.0027, 0.9934,\n",
              "                                    1.0011, 1.0176, 0.9821, 1.0306, 0.9970, 0.9913, 1.0360,\n",
              "                                    1.0063, 1.0026, 1.0242, 1.0310, 1.0037, 0.9795, 0.9946,\n",
              "                                    1.0512, 1.0016, 0.9724, 0.9886, 1.0059, 0.9766, 1.0152,\n",
              "                                    0.9874, 1.0042, 0.9943, 0.9931, 1.0068, 1.0137, 0.9867,\n",
              "                                    1.0157, 1.0097, 1.0034, 1.0219, 0.9987, 0.9997, 1.0202,\n",
              "                                    0.9939, 0.9952, 0.9696, 0.9868, 0.9905, 1.0179, 0.9876,\n",
              "                                    0.9742, 0.9921, 0.9973, 1.0072, 0.9724, 0.9974, 0.9836,\n",
              "                                    1.0141, 1.0088, 0.9982, 1.0168, 1.0082, 1.0012, 0.9886,\n",
              "                                    0.9831, 1.0033, 0.9902, 1.0142, 1.0105, 1.0152, 0.9974,\n",
              "                                    1.0094, 1.0293, 1.0108, 0.9901, 0.9835, 0.9921, 1.0167,\n",
              "                                    1.0016, 0.9970, 1.0158, 1.0044, 0.9916, 0.9936, 0.9972,\n",
              "                                    0.9938, 0.9991, 1.0259, 0.9938, 0.9919, 1.0130, 0.9910,\n",
              "                                    0.9932, 1.0075, 0.9989, 0.9764, 1.0168, 1.0043, 0.9919,\n",
              "                                    1.0030, 0.9898, 0.9957, 1.0178, 0.9852, 0.9975, 0.9881,\n",
              "                                    0.9710, 0.9851, 0.9983, 1.0225, 0.9965, 1.0089, 0.9851,\n",
              "                                    1.0487, 0.9900, 1.0135, 1.0104, 1.0201, 1.0066, 1.0012,\n",
              "                                    1.0149, 1.0019, 1.0047, 0.9956, 1.0149, 1.0292, 0.9656,\n",
              "                                    0.9989, 1.0048, 0.9891, 0.9950, 0.9889, 0.9984, 0.9821,\n",
              "                                    1.0146, 1.0125, 1.0364, 1.0144, 0.9975, 1.0227, 1.0075,\n",
              "                                    1.0020, 0.9779, 1.0081, 1.0409, 0.9861, 0.9896, 1.0211,\n",
              "                                    1.0021, 0.9631, 1.0030, 0.9621, 0.9782, 0.9934, 1.0144,\n",
              "                                    1.0015, 1.0142, 1.0061, 0.9962, 1.0034, 1.0092, 0.9688,\n",
              "                                    1.0085, 0.9862, 0.9799, 0.9681, 0.9667, 1.0211, 1.0005,\n",
              "                                    0.9714, 0.9940, 1.0019, 1.0243, 0.9783, 0.9978, 1.0000,\n",
              "                                    1.0127, 0.9940, 0.9974, 1.0064, 1.0038, 1.0284, 1.0004,\n",
              "                                    1.0312, 1.0252, 0.9833, 0.9880, 0.9943, 1.0210, 0.9882,\n",
              "                                    0.9951, 1.0059, 0.9846, 1.0052, 1.0002, 0.9902, 0.9851,\n",
              "                                    0.9932, 1.0259, 0.9997, 0.9912]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 3.8066e-02, -2.6546e-02,  1.5823e-02, -2.8331e-02,\n",
              "                                    -3.0144e-02,  1.9398e-02,  2.1312e-02,  5.0906e-04,\n",
              "                                    -1.0476e-03, -4.3655e-02,  5.2360e-03,  3.3734e-03,\n",
              "                                    -1.4171e-02, -1.9928e-03,  2.5268e-02,  6.6964e-03,\n",
              "                                    -1.6324e-02, -8.9282e-03, -1.4935e-02,  7.9167e-03,\n",
              "                                     2.7883e-03, -1.4941e-02,  2.8168e-02,  1.0949e-02,\n",
              "                                     1.3331e-02, -1.8554e-02, -3.9882e-03,  4.4831e-02,\n",
              "                                     1.5224e-02,  1.7216e-02, -1.5011e-02,  1.5178e-02,\n",
              "                                     1.3915e-02, -3.0081e-02,  3.3460e-02,  1.4490e-02,\n",
              "                                     2.1021e-02, -4.8529e-03,  6.9765e-03, -6.4432e-03,\n",
              "                                     5.6558e-02, -1.6444e-03,  2.4655e-02,  1.6760e-02,\n",
              "                                    -3.3420e-02,  1.3459e-02, -8.6005e-03, -2.4324e-02,\n",
              "                                     1.0527e-02,  3.4329e-02, -3.8971e-03,  5.9415e-03,\n",
              "                                     1.6021e-02,  1.8403e-02,  2.5399e-02, -2.7990e-03,\n",
              "                                     5.8959e-03,  3.9433e-02,  1.4931e-02,  3.1341e-02,\n",
              "                                     2.3252e-03, -2.9833e-04, -4.4158e-04,  2.6312e-03,\n",
              "                                     2.6606e-02, -4.0600e-03, -1.6893e-02,  3.9800e-03,\n",
              "                                    -2.5465e-02,  4.9854e-03,  4.7285e-03,  1.1059e-02,\n",
              "                                     3.5016e-02, -9.1709e-03,  9.5266e-03, -6.1486e-03,\n",
              "                                    -9.1446e-03,  4.3760e-02,  3.7165e-03,  7.9071e-03,\n",
              "                                    -2.9256e-02,  1.1763e-02,  2.3672e-03,  1.5569e-02,\n",
              "                                    -1.7661e-02,  1.2603e-02,  9.1555e-03, -1.2493e-02,\n",
              "                                    -3.5236e-03,  4.4897e-02,  2.0814e-03,  2.0791e-02,\n",
              "                                    -8.6934e-03,  3.7121e-02,  9.6823e-03,  2.7034e-02,\n",
              "                                     4.4240e-03, -2.8406e-03,  1.0474e-02, -1.2817e-03,\n",
              "                                     9.6700e-03,  2.5790e-03, -9.4847e-03,  1.0992e-02,\n",
              "                                     1.4170e-02, -1.0751e-02,  6.7258e-03,  1.1464e-02,\n",
              "                                     2.1882e-02,  1.7486e-02,  2.3256e-02,  2.5551e-02,\n",
              "                                     8.6875e-03, -1.0721e-04, -4.5275e-02, -8.4734e-03,\n",
              "                                     1.2480e-02,  3.0169e-02, -5.3500e-04, -1.0486e-03,\n",
              "                                     4.6266e-03, -4.4788e-03,  1.9483e-02,  4.3329e-02,\n",
              "                                     1.6734e-02,  2.8628e-03, -3.0399e-04,  7.1797e-03,\n",
              "                                     2.1608e-02,  2.7520e-03,  3.4613e-02, -1.1136e-02,\n",
              "                                     1.0553e-02,  4.2251e-02,  1.4319e-03,  2.5366e-02,\n",
              "                                    -1.4390e-02, -1.1782e-02,  1.8918e-02,  1.8469e-02,\n",
              "                                     1.9163e-02, -1.3251e-02, -8.2250e-03, -1.7114e-02,\n",
              "                                     4.3713e-03, -6.9525e-05, -1.0711e-02,  2.1988e-02,\n",
              "                                     1.7802e-02,  1.3137e-02,  8.4048e-03,  5.5520e-02,\n",
              "                                     5.7136e-03,  1.9101e-02,  1.3518e-02, -1.7030e-03,\n",
              "                                    -1.1439e-02,  2.7987e-02, -4.0681e-03,  1.3394e-02,\n",
              "                                     6.1769e-03,  2.6455e-03, -2.1884e-02, -4.3771e-03,\n",
              "                                     3.6458e-02,  1.4181e-02,  3.4076e-02,  5.0578e-03,\n",
              "                                     1.0619e-02,  2.3190e-02,  1.4304e-02, -2.2667e-02,\n",
              "                                     4.0404e-02,  3.6287e-02, -1.1683e-02,  1.7318e-02,\n",
              "                                    -1.5490e-02,  4.3163e-03, -5.0805e-03,  6.1997e-04,\n",
              "                                     1.5277e-02, -1.5303e-02,  1.2246e-02,  2.4740e-02,\n",
              "                                    -2.9981e-03, -1.4383e-02,  2.0200e-02,  1.5824e-02,\n",
              "                                     1.0766e-02,  6.8654e-03,  1.7405e-02,  1.8183e-02,\n",
              "                                     9.5498e-03,  1.3139e-02,  2.0950e-02,  3.7660e-02,\n",
              "                                    -8.8741e-03, -4.2861e-03, -3.2081e-03,  2.1795e-02,\n",
              "                                     5.8482e-04, -1.8428e-02,  2.8511e-02,  6.2603e-03,\n",
              "                                    -2.2557e-02,  1.2433e-02, -8.9256e-03, -6.1250e-03,\n",
              "                                     3.0807e-03,  9.7640e-03, -3.7850e-03,  2.5061e-02,\n",
              "                                     1.2628e-02,  8.3855e-03, -2.5027e-03, -1.0180e-02,\n",
              "                                    -9.2591e-03,  1.5976e-02, -1.9427e-04,  6.0174e-03,\n",
              "                                    -2.5239e-02,  6.3479e-03, -1.3363e-02, -3.4362e-02,\n",
              "                                    -1.0919e-02,  2.9413e-02,  1.2877e-02,  4.6966e-02,\n",
              "                                     3.2639e-02,  3.7447e-02,  4.5210e-02,  1.7979e-02,\n",
              "                                     1.4442e-02, -3.5815e-03, -5.3943e-03,  3.8204e-02,\n",
              "                                     3.9223e-02,  2.1889e-02,  4.5804e-02,  1.4093e-02,\n",
              "                                     3.1739e-03, -4.9270e-03,  1.9862e-03, -4.9775e-03,\n",
              "                                    -1.6173e-02,  1.4191e-02, -4.6552e-03,  6.7001e-03,\n",
              "                                     1.0554e-02, -7.3365e-03, -5.0663e-03, -1.2585e-02,\n",
              "                                    -1.2668e-02,  2.8671e-02,  4.0246e-03, -1.5539e-03]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-5.4547e-01,  1.6963e+00, -2.3018e+00,  1.5432e+00,\n",
              "                                    -8.7833e-01,  1.2581e+00,  1.0365e+00, -9.8832e-01,\n",
              "                                     7.3971e-01,  1.2291e+00, -1.9950e+00, -2.7237e+00,\n",
              "                                    -2.1387e+00, -2.5799e-01, -3.8560e+00,  1.8132e+00,\n",
              "                                     2.3359e+00,  1.2307e+00,  4.7453e-02, -1.6554e+00,\n",
              "                                    -2.3154e+00,  2.1150e+00, -1.3174e+00, -2.1256e+00,\n",
              "                                    -9.2225e-01,  1.1029e+00,  6.2875e-01, -4.2686e+00,\n",
              "                                     1.1116e+00, -1.1667e+00,  7.5334e-01, -7.9347e-01,\n",
              "                                    -1.5325e+00, -1.4684e+00, -1.0383e+00,  2.0667e+00,\n",
              "                                     2.4980e-01,  8.0088e-02,  6.4677e-01, -2.0409e+00,\n",
              "                                    -1.8838e+00, -5.4745e-02, -6.6565e-01,  7.9391e-01,\n",
              "                                     1.9748e+00, -1.0397e+00,  1.4951e-01, -1.7292e+00,\n",
              "                                     1.4161e-01, -3.8868e-01,  9.2906e-01,  4.8874e-01,\n",
              "                                     1.0484e+00,  8.9780e-01,  8.2368e-01,  1.8443e+00,\n",
              "                                    -1.2905e+00, -1.7755e+00, -1.3826e-01, -2.8914e+00,\n",
              "                                    -3.9274e-01, -1.8599e+00, -2.5842e+00,  9.8700e-01,\n",
              "                                    -7.6767e-01, -2.0141e+00,  7.0665e-01, -2.1357e+00,\n",
              "                                    -5.6861e-01,  1.0877e-01,  1.3414e+00, -6.7349e-01,\n",
              "                                    -7.2839e-01, -5.0957e-01, -1.9912e+00,  7.1377e-01,\n",
              "                                     5.3630e-01,  2.6358e-01,  7.4775e-01, -4.6816e-01,\n",
              "                                     2.1984e+00,  1.8798e+00,  9.6271e-01,  7.4818e-01,\n",
              "                                    -1.2614e+00, -1.4918e+00,  1.6644e+00,  1.3975e+00,\n",
              "                                     1.5068e+00, -2.7449e+00, -7.3400e-02, -1.2317e+00,\n",
              "                                    -4.2249e-01, -1.8388e+00, -3.2814e+00, -1.8234e+00,\n",
              "                                    -2.7856e+00, -9.0962e-01, -9.8644e-01,  9.9558e-01,\n",
              "                                     2.7771e-01, -1.3166e+00,  2.2797e+00,  7.0420e-01,\n",
              "                                    -3.4286e+00,  1.7139e+00, -1.6146e+00, -2.1493e+00,\n",
              "                                    -2.8235e+00, -8.8249e-01, -1.4120e+00, -8.8147e-01,\n",
              "                                    -2.3959e+00,  3.8612e-01, -9.0455e-01,  1.2031e+00,\n",
              "                                     3.4045e-01,  9.7619e-01, -2.5565e+00, -1.3586e+00,\n",
              "                                    -4.3419e-01, -1.5458e+00, -2.6977e+00, -1.6408e+00,\n",
              "                                    -1.8078e+00,  8.5040e-01, -2.8564e-01,  2.7211e-01,\n",
              "                                    -3.2057e+00, -1.7186e+00,  2.2334e+00, -1.0598e+00,\n",
              "                                    -3.9988e+00, -1.0300e+00, -1.2040e+00,  6.5974e-01,\n",
              "                                    -4.1521e-01, -1.7120e+00, -3.6267e+00, -4.3875e-01,\n",
              "                                    -2.5237e-01,  9.9858e-01, -4.3395e-02, -1.4594e+00,\n",
              "                                    -1.8950e+00,  4.4987e-01,  8.2008e-01, -7.7919e-02,\n",
              "                                    -1.8040e+00, -1.8922e+00, -4.9959e-01, -3.0817e+00,\n",
              "                                     1.1426e+00,  9.3947e-01,  5.4445e-01, -3.7333e+00,\n",
              "                                     1.5721e+00,  1.0812e+00,  1.9746e+00,  1.5616e+00,\n",
              "                                    -4.2320e-01,  3.6291e-01,  3.5605e-01, -4.0223e-01,\n",
              "                                    -3.1933e-01,  1.0813e+00, -3.8393e+00, -8.7837e-01,\n",
              "                                     3.5460e-01, -4.2549e-02, -3.8043e+00,  1.3505e+00,\n",
              "                                    -2.6652e+00, -1.1717e-01,  1.9502e+00, -2.3277e+00,\n",
              "                                    -1.1024e+00, -3.2206e-01, -2.2780e+00, -1.2678e+00,\n",
              "                                     8.1354e-01,  1.4538e+00,  2.3380e+00, -2.4413e+00,\n",
              "                                     6.1495e-01,  2.2138e+00, -2.7858e+00, -3.5735e+00,\n",
              "                                    -4.4423e-01,  1.1875e+00, -1.3683e+00, -2.5138e+00,\n",
              "                                     1.5445e+00, -1.8299e+00, -2.6021e+00, -3.4859e+00,\n",
              "                                    -1.1039e+00,  1.0140e+00, -2.4685e+00,  1.9646e+00,\n",
              "                                     1.5017e+00,  2.8805e-01,  3.5933e-01, -7.5089e-01,\n",
              "                                     8.8536e-02, -1.8203e+00,  4.3527e-01, -1.8969e-01,\n",
              "                                    -3.1727e+00, -2.1777e+00,  5.6325e-01, -1.5584e+00,\n",
              "                                     7.8755e-01,  4.1942e-01, -9.7622e-01, -8.8069e-03,\n",
              "                                     1.1653e+00,  5.2443e-01,  9.5229e-01, -3.5834e-01,\n",
              "                                     4.3778e-01,  1.2111e-03,  1.2202e+00,  1.7377e+00,\n",
              "                                     2.2312e+00,  2.6590e-01, -5.2692e-01,  1.4763e+00,\n",
              "                                     1.1023e+00, -2.8374e+00,  7.3399e-01,  2.9287e-01,\n",
              "                                     6.2591e-01,  1.9576e+00,  7.1963e-01, -1.1864e+00,\n",
              "                                    -2.9898e+00,  6.2118e-01, -1.6489e+00, -1.7106e-01,\n",
              "                                    -1.1867e+00,  7.9627e-01, -7.4573e-01,  5.8530e-01,\n",
              "                                    -6.4088e-01, -2.9071e+00, -1.3710e+00, -7.7971e-01,\n",
              "                                    -1.4257e+00,  1.6841e-01, -2.0506e+00, -2.0151e+00,\n",
              "                                    -8.7413e-01, -8.1395e-01, -2.1107e+00, -2.4488e+00]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([12.0908, 12.4109, 13.6163, 16.6838,  7.5471, 16.3467,\n",
              "                                    21.4426, 18.5237, 24.9393, 15.0215, 11.1934, 30.1570,\n",
              "                                     8.0497, 11.8727, 21.8812, 30.0736, 22.1129, 14.7640,\n",
              "                                    14.5849, 10.1582,  3.9997, 15.6222, 15.3709,  7.4690,\n",
              "                                    12.4665,  6.7535, 11.1534, 32.9974, 13.4669,  5.9722,\n",
              "                                    10.9099,  6.4731, 15.9819,  7.1879, 18.0116, 50.8774,\n",
              "                                    10.5724, 12.0119, 13.2542, 13.4555, 24.5613, 13.1420,\n",
              "                                     9.3604, 13.5418, 12.2583, 25.5904, 10.2513,  6.8886,\n",
              "                                    13.0711, 14.2159, 11.2693, 12.3670, 20.6675, 24.1075,\n",
              "                                     9.7702, 16.1203, 13.8445, 11.9489, 10.4071, 12.9444,\n",
              "                                     9.0621, 12.3290, 13.6511, 27.8278, 10.3272, 12.2979,\n",
              "                                    12.3103, 13.0191,  5.3100,  8.4100,  8.4441,  6.7578,\n",
              "                                    21.4561,  8.9598, 12.7376, 10.8369, 19.7504, 10.5256,\n",
              "                                    12.3150, 14.7349,  6.9895, 15.0076, 23.5948, 21.0840,\n",
              "                                    13.0956, 11.8599, 17.7962, 13.2883, 22.6053, 21.5712,\n",
              "                                     6.0671, 17.4892, 13.7252, 20.6233, 16.3434, 11.1750,\n",
              "                                    11.4444, 10.5536,  8.0930, 13.7909, 14.6059, 17.7235,\n",
              "                                    13.0731, 12.9596, 23.0062, 32.9491,  6.4137, 22.2636,\n",
              "                                    43.5550, 11.5542, 12.5860, 11.1036, 15.4558, 10.8362,\n",
              "                                     4.9884, 16.2554, 15.8503, 20.1531, 11.5665, 16.0396,\n",
              "                                    10.1856,  5.6889, 19.4591, 18.4850, 14.9183, 20.9388,\n",
              "                                    10.7240, 16.5341, 10.1144, 11.4034, 34.2104,  7.3590,\n",
              "                                    34.6366, 14.6290,  4.3363, 18.7354, 16.7244,  9.6447,\n",
              "                                    33.0229, 15.6290, 18.3019, 15.5635, 11.7073,  5.6927,\n",
              "                                    12.5685, 15.2414, 17.2538, 20.1895, 10.2438, 12.7555,\n",
              "                                     7.8756, 18.2936, 13.9741, 18.8216, 12.9469, 35.6731,\n",
              "                                    23.2493, 17.8448, 20.2513, 22.7222,  9.6358, 22.7323,\n",
              "                                     8.8490,  8.3982, 17.5138, 25.1418, 20.9593,  7.4462,\n",
              "                                     9.4836, 23.6469, 13.3701, 15.4973, 19.9328, 20.3199,\n",
              "                                    13.9642, 32.3465,  8.5571, 11.2897, 27.0423,  7.8615,\n",
              "                                    13.3956, 15.4345, 24.7960, 34.2245, 16.1881, 25.3477,\n",
              "                                    14.0245, 31.3576, 14.4618,  8.1765, 16.8169, 34.1231,\n",
              "                                    21.3611, 19.8708, 51.0311, 31.8326, 16.9502, 16.5951,\n",
              "                                    18.2927, 15.7032, 26.4375,  8.0387,  8.6550,  7.8476,\n",
              "                                     9.1063, 22.4100, 14.0168,  6.9212, 16.8926, 16.2253,\n",
              "                                     7.6347,  9.9320, 19.3956, 19.0525, 10.7647, 12.0229,\n",
              "                                    14.3531, 18.1120, 23.3903, 12.6154, 13.5525,  9.7681,\n",
              "                                    10.1576,  8.7293, 31.6982, 10.9784, 11.8102, 10.4383,\n",
              "                                    10.5628, 31.6462, 40.8415, 10.2483,  6.0556, 31.1139,\n",
              "                                    16.1953,  7.0331, 39.5496, 13.9623,  7.9689, 12.5773,\n",
              "                                    15.7447,  9.7021, 10.6455, 10.6376, 11.2083, 21.5172,\n",
              "                                     8.4610, 14.6928, 14.1829,  6.8550, 21.6359, 10.4659,\n",
              "                                     9.0808, 23.2288, 14.2907, 13.6629]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  253,  254,  255],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0253, -0.0502, -0.0336,  ..., -0.0259,  0.0073,\n",
              "                                    -0.0224]),\n",
              "                     size=(1024, 256, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([1.0368, 1.0015, 1.0302,  ..., 0.9848, 0.9751, 1.0040]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([ 0.0046,  0.0246,  0.0540,  ..., -0.0119, -0.0127,\n",
              "                                    -0.0020]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([ 0.1620, -0.3372, -0.8952,  ..., -0.3154,  0.0266,\n",
              "                                     0.2537]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.6493, 1.2225, 2.0709,  ..., 0.5508, 0.3664, 0.6069]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.downsample.0.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  509,  510,  511],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0214,  0.0797,  0.0685,  ...,  0.0700,  0.0676,\n",
              "                                    -0.0106]),\n",
              "                     size=(1024, 512, 1, 1), nnz=524288, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.downsample.1.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([1.0167, 1.0078, 1.0515,  ..., 0.9619, 1.0011, 0.9837]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.downsample.1.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([ 0.0046,  0.0246,  0.0540,  ..., -0.0119, -0.0127,\n",
              "                                    -0.0020]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.downsample.1.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([ 1.8336,  2.9512, -0.8168,  ...,  3.4851, -0.2202,\n",
              "                                     0.0424]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.downsample.1.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([14.6452, 25.0921, 23.9312,  ..., 24.4241, 13.6053,\n",
              "                                     5.0178]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.0.downsample.1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  255,  255,  255],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0282, -0.1449,  0.0177,  ...,  0.1201,  0.0448,\n",
              "                                     0.0473]),\n",
              "                     size=(256, 1024, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([1.0111, 0.9923, 1.0228, 1.0212, 0.9781, 1.0326, 0.9903,\n",
              "                                    0.9783, 0.9938, 1.0272, 0.9848, 1.0257, 0.9987, 0.9753,\n",
              "                                    1.0002, 0.9686, 0.9871, 0.9869, 1.0044, 1.0063, 0.9909,\n",
              "                                    0.9956, 0.9950, 0.9971, 1.0355, 0.9941, 0.9982, 1.0262,\n",
              "                                    1.0194, 0.9735, 0.9657, 0.9856, 1.0383, 1.0278, 0.9708,\n",
              "                                    0.9918, 0.9936, 1.0027, 1.0394, 1.0097, 0.9752, 0.9761,\n",
              "                                    0.9825, 1.0496, 1.0198, 0.9930, 0.9803, 1.0034, 0.9896,\n",
              "                                    0.9796, 0.9752, 1.0138, 1.0105, 1.0095, 0.9915, 0.9634,\n",
              "                                    1.0443, 0.9989, 0.9845, 1.0161, 0.9815, 0.9405, 0.9725,\n",
              "                                    0.9906, 1.0091, 0.9916, 0.9871, 0.9964, 0.9814, 0.9863,\n",
              "                                    0.9988, 1.0125, 0.9861, 1.0339, 0.9695, 1.0165, 1.0171,\n",
              "                                    0.9646, 0.9759, 0.9741, 0.9865, 1.0457, 1.0007, 1.0201,\n",
              "                                    1.0061, 1.0038, 1.0515, 1.0246, 0.9603, 0.9755, 0.9974,\n",
              "                                    0.9851, 0.9718, 0.9659, 1.0256, 1.0342, 0.9900, 0.9834,\n",
              "                                    0.9802, 0.9823, 1.0158, 0.9834, 0.9785, 1.0014, 1.0017,\n",
              "                                    1.0021, 0.9913, 0.9971, 1.0461, 0.9948, 0.9749, 1.0336,\n",
              "                                    1.0046, 0.9902, 1.0127, 0.9813, 0.9816, 0.9954, 1.0032,\n",
              "                                    1.0251, 0.9749, 1.0054, 0.9851, 0.9779, 1.0050, 0.9847,\n",
              "                                    1.0113, 0.9987, 0.9832, 0.9919, 0.9638, 0.9887, 0.9918,\n",
              "                                    1.0330, 1.0069, 0.9818, 0.9876, 1.0684, 0.9796, 1.0100,\n",
              "                                    1.0174, 1.0062, 0.9745, 1.0121, 0.9946, 0.9587, 0.9931,\n",
              "                                    1.0063, 0.9852, 0.9663, 1.0314, 0.9818, 0.9683, 0.9767,\n",
              "                                    0.9795, 0.9905, 0.9728, 0.9903, 1.0052, 1.0869, 1.0078,\n",
              "                                    1.0020, 1.0272, 0.9611, 0.9769, 0.9909, 0.9745, 0.9801,\n",
              "                                    1.0012, 1.0011, 0.9796, 1.0449, 0.9686, 0.9816, 1.0154,\n",
              "                                    1.0121, 1.0054, 0.9865, 0.9710, 1.0053, 0.9764, 0.9966,\n",
              "                                    1.0194, 0.9801, 1.0175, 0.9845, 1.0054, 1.0192, 0.9922,\n",
              "                                    0.9995, 0.9949, 1.0694, 0.9900, 1.0008, 1.0466, 0.9531,\n",
              "                                    1.0100, 0.9821, 1.0676, 1.0037, 0.9842, 0.9486, 0.9739,\n",
              "                                    1.0137, 1.0021, 0.9654, 0.9769, 0.9960, 1.0028, 0.9897,\n",
              "                                    1.0227, 0.9646, 1.0290, 0.9655, 0.9759, 0.9921, 0.9968,\n",
              "                                    0.9722, 0.9720, 1.0148, 1.0021, 0.9787, 0.9672, 1.0174,\n",
              "                                    1.0186, 1.0098, 0.9907, 1.0085, 1.0070, 0.9939, 1.0639,\n",
              "                                    0.9997, 0.9799, 0.9767, 1.0082, 0.9774, 0.9941, 1.0316,\n",
              "                                    1.0043, 0.9795, 0.9779, 1.0020, 0.9777, 0.9536, 0.9611,\n",
              "                                    1.0091, 1.0290, 1.0457, 0.9884, 0.9819, 0.9525, 1.0208,\n",
              "                                    1.0436, 0.9927, 0.9743, 1.0478]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 0.0088,  0.0120,  0.0326,  0.0344, -0.0175,  0.0087,\n",
              "                                     0.0423,  0.0027, -0.0079,  0.0004, -0.0005,  0.0225,\n",
              "                                    -0.0025, -0.0226,  0.0315,  0.0395, -0.0017,  0.0140,\n",
              "                                     0.0128,  0.0175, -0.0335, -0.0146, -0.0248, -0.0035,\n",
              "                                     0.0318, -0.0352,  0.0401,  0.0541,  0.0046, -0.0203,\n",
              "                                    -0.0349,  0.0005, -0.0041,  0.0348,  0.0240,  0.0121,\n",
              "                                     0.0033,  0.0098,  0.0052,  0.0109, -0.0100, -0.0035,\n",
              "                                    -0.0222,  0.0362,  0.0372,  0.0118,  0.0160,  0.0291,\n",
              "                                    -0.0068,  0.0182, -0.0120,  0.0188,  0.0489, -0.0149,\n",
              "                                    -0.0058, -0.0221,  0.0398,  0.0409, -0.0207, -0.0097,\n",
              "                                    -0.0113, -0.0084,  0.0003,  0.0039,  0.0068, -0.0113,\n",
              "                                    -0.0187, -0.0007, -0.0101, -0.0207,  0.0068,  0.0100,\n",
              "                                     0.0009,  0.0062,  0.0193,  0.0354, -0.0114,  0.0042,\n",
              "                                     0.0088, -0.0175, -0.0097,  0.0332, -0.0462,  0.0354,\n",
              "                                     0.0283,  0.0290, -0.0021,  0.0333,  0.0037, -0.0046,\n",
              "                                     0.0063,  0.0141, -0.0257, -0.0011,  0.0221,  0.0550,\n",
              "                                    -0.0270, -0.0141, -0.0079, -0.0132,  0.0433, -0.0118,\n",
              "                                    -0.0102,  0.0350,  0.0007,  0.0560, -0.0138,  0.0578,\n",
              "                                     0.0721, -0.0113,  0.0149,  0.0572,  0.0004,  0.0157,\n",
              "                                    -0.0061,  0.0047, -0.0106,  0.0256,  0.0079,  0.0417,\n",
              "                                    -0.0072,  0.0252,  0.0036, -0.0110,  0.0147, -0.0274,\n",
              "                                     0.0100,  0.0069, -0.0226, -0.0093, -0.0182, -0.0153,\n",
              "                                     0.0565,  0.0288,  0.0498, -0.0028, -0.0121,  0.0529,\n",
              "                                    -0.0123,  0.0098,  0.0270,  0.0090, -0.0178,  0.0298,\n",
              "                                     0.0141, -0.0161,  0.0016,  0.0348, -0.0247,  0.0133,\n",
              "                                     0.0282,  0.0030, -0.0189,  0.0133, -0.0178,  0.0084,\n",
              "                                    -0.0117, -0.0051,  0.0231,  0.0300,  0.0270, -0.0160,\n",
              "                                    -0.0176,  0.0107, -0.0385,  0.0034,  0.0025, -0.0199,\n",
              "                                    -0.0364, -0.0027, -0.0301,  0.0291,  0.0055, -0.0008,\n",
              "                                     0.0044,  0.0231, -0.0121,  0.0213, -0.0210,  0.0257,\n",
              "                                     0.0148, -0.0151,  0.0246,  0.0065,  0.0232,  0.0019,\n",
              "                                    -0.0002,  0.0199, -0.0196,  0.0141,  0.0221,  0.0629,\n",
              "                                    -0.0087,  0.0125, -0.0088, -0.0101,  0.0675, -0.0125,\n",
              "                                     0.0509,  0.0074,  0.0209,  0.0012, -0.0154,  0.0062,\n",
              "                                     0.0128, -0.0028, -0.0250,  0.0055,  0.0062, -0.0182,\n",
              "                                    -0.0139, -0.0032,  0.0564, -0.0257, -0.0016,  0.0016,\n",
              "                                    -0.0026, -0.0154, -0.0037, -0.0166,  0.0122,  0.0081,\n",
              "                                    -0.0366,  0.0215,  0.0290,  0.0183, -0.0020,  0.0283,\n",
              "                                     0.0149, -0.0300,  0.0659,  0.0343, -0.0106,  0.0018,\n",
              "                                    -0.0150, -0.0131,  0.0027,  0.0651, -0.0103,  0.0218,\n",
              "                                    -0.0248,  0.0047,  0.0156, -0.0068, -0.0582,  0.0004,\n",
              "                                     0.0138,  0.0487,  0.0126, -0.0017, -0.0680,  0.0358,\n",
              "                                     0.0632,  0.0078, -0.0237,  0.0454]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-3.7445e+00, -1.9612e+00, -3.1251e+00, -1.6236e+00,\n",
              "                                    -6.9205e-01, -1.0037e+00,  6.4830e-01,  9.8879e-02,\n",
              "                                    -3.1668e+00, -6.3350e-01, -2.3704e+00,  2.0869e+00,\n",
              "                                    -2.3154e+00, -1.8240e+00, -4.5832e+00,  6.1093e-04,\n",
              "                                    -3.2362e+00, -1.0522e+00, -1.7117e+00, -2.3528e+00,\n",
              "                                     5.5877e-01, -8.0234e-01, -2.4493e-01, -1.7064e-01,\n",
              "                                    -3.4881e+00,  2.0071e+00, -3.7313e-01, -1.7646e+00,\n",
              "                                    -2.0517e+00,  1.3503e+00, -1.7272e+00, -3.6750e+00,\n",
              "                                    -9.8849e-01, -2.9785e+00, -6.8915e-01, -1.4262e+00,\n",
              "                                    -2.8828e+00, -2.2638e+00,  7.9585e-01, -2.0246e+00,\n",
              "                                    -3.2005e+00, -7.2162e-02, -2.2532e+00,  4.1091e-01,\n",
              "                                    -4.2513e+00, -5.4904e-01, -7.6781e-01, -3.9604e+00,\n",
              "                                    -3.7049e+00,  3.5121e+00, -4.7344e-01, -1.5740e+00,\n",
              "                                    -3.0367e+00, -5.2533e+00, -4.0168e+00, -2.3457e+00,\n",
              "                                    -3.1116e+00, -2.0263e+00, -1.5967e+00, -1.3014e+00,\n",
              "                                     7.6840e-01,  9.0268e-01, -8.4031e-01, -5.4134e-01,\n",
              "                                    -1.4896e+00, -2.9356e+00, -1.6974e+00, -2.8311e+00,\n",
              "                                    -3.2843e+00, -8.5396e-01, -4.7605e+00, -5.8187e+00,\n",
              "                                     3.1753e-01, -1.7272e+00, -1.3511e+00, -3.0886e+00,\n",
              "                                     3.8718e+00, -1.3558e+00, -1.0843e+00, -1.6940e+00,\n",
              "                                    -1.1017e+00, -3.7695e+00,  3.9411e+00, -2.1670e+00,\n",
              "                                    -5.6231e-01,  1.5099e+00, -1.2984e+00, -3.4303e+00,\n",
              "                                    -2.3385e+00, -4.6316e+00, -1.1429e+00,  2.5358e+00,\n",
              "                                    -4.1101e+00, -1.8421e+00,  7.6527e-01, -1.1821e+00,\n",
              "                                    -1.5045e+00, -1.3563e+00, -1.8266e+00,  7.0776e-01,\n",
              "                                     5.0089e-02, -9.3055e-02, -2.2152e-01, -3.1154e+00,\n",
              "                                     7.1767e-02, -4.5161e+00, -2.5600e+00, -1.9172e+00,\n",
              "                                     6.5220e-02, -3.7790e+00, -2.4797e-01, -1.2908e+00,\n",
              "                                    -3.2421e+00, -1.5312e+00,  6.5050e-01, -5.8371e-01,\n",
              "                                    -1.1982e+00, -3.1771e+00,  2.8045e+00, -1.5218e+00,\n",
              "                                    -2.5998e+00, -4.1615e+00, -2.8715e+00, -3.6287e+00,\n",
              "                                    -6.0612e+00, -1.1905e+00, -1.0183e+00, -3.7116e+00,\n",
              "                                    -2.1003e+00, -3.1689e+00,  2.8190e-01,  1.3403e+00,\n",
              "                                     5.8200e-01, -2.4985e+00, -4.6080e-01, -3.7841e+00,\n",
              "                                    -1.9186e+00, -6.7843e-01, -1.2077e+00, -4.9900e+00,\n",
              "                                    -1.9476e+00, -1.6400e-01, -7.7234e-01, -3.7667e+00,\n",
              "                                    -2.7818e+00, -3.1556e-01, -2.2312e+00, -2.2523e+00,\n",
              "                                    -2.0662e+00,  2.3822e+00,  5.6643e-01, -2.4419e+00,\n",
              "                                     5.8915e-01, -8.6117e-01, -2.0721e+00, -2.7772e+00,\n",
              "                                    -3.2804e+00, -2.6710e+00,  6.7064e-01, -3.2633e-01,\n",
              "                                    -4.4160e+00, -3.3218e+00, -4.9556e-01, -1.4083e+00,\n",
              "                                    -5.4700e-01, -2.5225e+00,  1.1617e+00, -1.2656e+00,\n",
              "                                    -1.1346e+00, -5.6631e+00, -3.9946e+00,  2.1729e+00,\n",
              "                                    -2.1657e-01, -3.3416e+00,  1.5547e+00, -3.5834e+00,\n",
              "                                     7.3972e-01, -2.4440e+00, -2.7875e+00,  1.8346e-01,\n",
              "                                     1.7218e+00,  1.6979e+00, -4.8358e+00,  2.7337e+00,\n",
              "                                    -1.2254e+00, -4.6865e-01,  2.0233e+00, -2.7372e+00,\n",
              "                                     3.0372e-01, -1.9587e+00, -2.2328e+00, -1.0195e+00,\n",
              "                                    -5.0256e+00, -1.7144e+00,  1.8031e+00,  1.9914e+00,\n",
              "                                     3.4967e+00, -4.5711e+00, -2.8281e+00,  6.1094e-01,\n",
              "                                    -1.1930e+00,  3.1546e+00, -7.1724e-01, -3.0318e+00,\n",
              "                                    -5.8013e+00,  1.7260e-01, -9.2651e-01, -5.2670e-02,\n",
              "                                     4.3274e-01,  1.9462e+00,  1.2892e+00,  1.2823e+00,\n",
              "                                    -1.6491e+00, -4.9245e+00, -1.6971e-01, -2.7114e+00,\n",
              "                                     3.2123e-01, -2.2817e+00, -1.4858e+00, -2.9393e+00,\n",
              "                                    -2.1479e+00, -3.6319e-01, -2.7788e+00, -1.9321e+00,\n",
              "                                    -1.8332e+00,  2.5796e-01, -2.4347e+00, -6.1397e-02,\n",
              "                                    -6.4282e+00, -1.8613e+00, -1.6321e+00, -1.7501e+00,\n",
              "                                    -7.7851e-01,  2.4286e+00, -3.9983e-01,  1.6703e-01,\n",
              "                                    -3.1694e+00, -5.8665e-01, -1.9338e+00, -2.0042e+00,\n",
              "                                    -1.2092e+00, -4.8539e+00,  1.0512e+00,  1.2614e+00,\n",
              "                                    -2.7320e-01, -4.7137e+00, -8.5128e-01, -5.8944e+00,\n",
              "                                     3.8700e+00, -1.5739e+00, -2.9533e-01, -1.4888e+00,\n",
              "                                    -1.7343e+00,  6.3903e-01, -1.6637e+00, -2.4352e+00]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 42.7274,  38.9724,  55.9379,  50.4953,  22.3766,\n",
              "                                     32.5097,  84.4870,  51.7442,  39.7182,  45.5979,\n",
              "                                     89.5824,  33.7670,  77.1952,  28.1047,  68.0323,\n",
              "                                     85.8915,  41.7025,  22.4590,  46.8285,  38.6425,\n",
              "                                     33.2503,  32.2464,  46.3262,  35.5753,  33.7991,\n",
              "                                     38.9605,  36.8604,  39.9970,  29.5486,  53.7349,\n",
              "                                     30.6338,  79.9057,  26.4048,  28.1846,  67.5808,\n",
              "                                     36.4518,  29.1114,  36.8649,  47.2248,  87.0959,\n",
              "                                     46.7137,  52.1546,  44.9649,  64.7176,  48.9855,\n",
              "                                     46.2855,  41.0884,  72.5508,  44.9683, 104.8675,\n",
              "                                     36.5701,  39.2533,  56.8870,  28.0867,  96.4756,\n",
              "                                     27.4742,  36.5711,  94.9517,  39.5351,  21.8714,\n",
              "                                     39.3128,  41.6371,  34.0917,  42.4451,  33.7414,\n",
              "                                     96.9108,  33.6076,  44.8837,  44.8940,  50.3187,\n",
              "                                     29.6761,  77.2057,  57.9673,  66.5630,  60.6347,\n",
              "                                     34.3521,  77.8378,  58.3712,  45.7050,  35.3192,\n",
              "                                     43.0957,  48.3294,  50.9292,  56.6041,  69.1028,\n",
              "                                     75.0252,  82.6256,  51.1901,  23.0834,  53.2588,\n",
              "                                     86.1875,  56.2804,  35.0315,  25.6969,  64.7712,\n",
              "                                     45.2502,  40.2734,  31.2215,  24.8872,  39.2306,\n",
              "                                     58.7677,  29.0074,  38.5221,  51.4671,  36.8379,\n",
              "                                     66.6877,  49.8090,  61.4635,  59.4027,  92.6052,\n",
              "                                     30.1468,  43.8111,  40.6945,  52.3610,  33.6238,\n",
              "                                     42.4154,  24.3592,  50.6836,  92.1534,  53.7147,\n",
              "                                     21.6313,  49.7919,  25.2968,  93.6630,  95.9491,\n",
              "                                     32.4293,  43.4678,  67.6945,  24.8905,  90.3630,\n",
              "                                     68.0486,  35.1590,  78.4196,  55.3829,  82.4425,\n",
              "                                     58.3208,  65.9718,  43.1281,  40.3402,  53.7280,\n",
              "                                     43.9056,  56.0926,  34.3160, 119.6641,  30.7585,\n",
              "                                     58.5877,  56.0020,  30.2943,  33.2817, 102.7072,\n",
              "                                     68.2721,  47.3002,  43.9244,  30.5412,  86.3331,\n",
              "                                     42.6411,  81.3133,  41.4876,  63.8524,  51.6298,\n",
              "                                     71.0514,  47.3523,  39.7008,  50.8697,  48.1434,\n",
              "                                     98.3191,  73.6756,  36.0711,  33.8393,  81.7662,\n",
              "                                     43.5683,  77.4879,  40.0698, 100.8406,  18.2595,\n",
              "                                     34.7868,  49.8855,  46.2160,  31.1641,  73.7132,\n",
              "                                    105.3616,  35.3786,  97.1236,  79.3585,  46.0233,\n",
              "                                     42.5957,  21.5158,  44.8821,  41.2442,  28.9074,\n",
              "                                     51.8199,  78.4275,  61.6759,  49.1869,  66.1054,\n",
              "                                     89.2008,  81.9544,  73.6510,  78.7193,  59.6413,\n",
              "                                     73.6469,  86.3863,  28.9202,  37.7410,  93.0362,\n",
              "                                     53.1713,  23.0225,  52.0226,  52.0003,  35.2573,\n",
              "                                     53.6796,  57.7120,  42.9267,  60.2953,  74.4691,\n",
              "                                     63.5639,  46.4985,  36.0237,  37.2328,  15.5106,\n",
              "                                     25.8960,  40.6402,  38.5434,  49.3220,  72.2806,\n",
              "                                     40.0189,  67.6824,  71.1084,  35.6721,  26.7289,\n",
              "                                     30.9097,  66.2163,  36.2955,  68.7820,  44.2360,\n",
              "                                     19.3390,  34.9292,  51.8253,  30.7823,  50.8709,\n",
              "                                     13.6348,  87.4258, 111.3471,  53.4567,  26.8210,\n",
              "                                     23.8252,  52.6738,  77.7085,  73.5458,  44.1707,\n",
              "                                     31.9821,  67.6219,  42.9485,  45.7871,  59.4588,\n",
              "                                     47.4754]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0037,  0.0092,  0.0251,  ...,  0.0122,  0.0250,\n",
              "                                    -0.0505]),\n",
              "                     size=(256, 256, 3, 3), nnz=589824, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9682, 1.0275, 1.0008, 0.9612, 0.9995, 0.9815, 0.9963,\n",
              "                                    0.9624, 0.9595, 1.0014, 1.0140, 1.0323, 1.0041, 1.0463,\n",
              "                                    1.0054, 1.0096, 0.9787, 0.9757, 1.0212, 0.9911, 1.0121,\n",
              "                                    1.0375, 1.0204, 0.9890, 0.9609, 0.9669, 1.0089, 1.0047,\n",
              "                                    1.0644, 1.0545, 0.9845, 0.9973, 1.0193, 0.9771, 1.0164,\n",
              "                                    0.9618, 1.0064, 0.9864, 0.9846, 1.0149, 1.0076, 0.9873,\n",
              "                                    1.0358, 1.0324, 1.0154, 0.9833, 0.9384, 0.9605, 0.9808,\n",
              "                                    0.9616, 1.0502, 1.0244, 1.0154, 0.9644, 1.0149, 0.9998,\n",
              "                                    0.9813, 1.0236, 1.0003, 0.9710, 0.9846, 0.9973, 1.0320,\n",
              "                                    1.0235, 0.9745, 1.0404, 0.9688, 0.9831, 0.9483, 1.0174,\n",
              "                                    0.9720, 1.0010, 0.9956, 1.0507, 1.0026, 1.0287, 1.0166,\n",
              "                                    1.0288, 1.0116, 1.0064, 1.0305, 0.9983, 1.0294, 1.0297,\n",
              "                                    0.9749, 0.9774, 0.9908, 1.0384, 1.0196, 0.9865, 1.0003,\n",
              "                                    0.9823, 1.0183, 1.0224, 0.9642, 0.9877, 1.0038, 0.9644,\n",
              "                                    1.0303, 1.0171, 0.9957, 1.0026, 0.9812, 0.9776, 0.9817,\n",
              "                                    1.0013, 1.0248, 0.9868, 0.9911, 1.0294, 1.0001, 0.9586,\n",
              "                                    0.9952, 0.9859, 0.9884, 1.0285, 0.9532, 1.0115, 1.0040,\n",
              "                                    0.9583, 0.9919, 1.0170, 0.9947, 1.0045, 0.9828, 1.0133,\n",
              "                                    1.0302, 0.9941, 0.9738, 1.0044, 0.9824, 1.0112, 1.0149,\n",
              "                                    0.9677, 0.9979, 0.9809, 1.0102, 0.9983, 0.9986, 0.9763,\n",
              "                                    1.0069, 1.0007, 0.9942, 0.9611, 0.9946, 0.9988, 0.9722,\n",
              "                                    1.0066, 1.0138, 1.0035, 0.9782, 1.0141, 0.9920, 1.0229,\n",
              "                                    1.0099, 0.9736, 0.9765, 1.0219, 1.0270, 1.0181, 0.9712,\n",
              "                                    1.0203, 1.0401, 0.9895, 0.9749, 1.0024, 1.0224, 0.9939,\n",
              "                                    1.0514, 0.9920, 1.0156, 1.0231, 0.9912, 0.9707, 0.9979,\n",
              "                                    0.9834, 1.0282, 1.0284, 0.9630, 1.0221, 0.9850, 1.0108,\n",
              "                                    0.9844, 1.0185, 1.0009, 0.9693, 0.9962, 1.0310, 0.9605,\n",
              "                                    0.9569, 0.9890, 1.0283, 1.0174, 0.9964, 0.9975, 1.0076,\n",
              "                                    1.0131, 0.9939, 0.9816, 0.9838, 1.0019, 0.9946, 0.9766,\n",
              "                                    0.9733, 1.0038, 1.0025, 0.9653, 0.9892, 1.0010, 0.9780,\n",
              "                                    0.9890, 1.0060, 1.0436, 1.0041, 1.0101, 0.9734, 1.0042,\n",
              "                                    0.9850, 1.0016, 0.9891, 0.9906, 0.9824, 0.9435, 1.0135,\n",
              "                                    1.0505, 1.0387, 0.9922, 0.9622, 0.9741, 1.0114, 1.0386,\n",
              "                                    1.0121, 0.9526, 1.0035, 0.9980, 0.9878, 1.0151, 0.9772,\n",
              "                                    1.0555, 0.9992, 0.9987, 1.0009, 0.9871, 1.0024, 0.9616,\n",
              "                                    0.9836, 1.0233, 1.0077, 1.0360, 0.9966, 0.9776, 1.0009,\n",
              "                                    1.0100, 1.0131, 1.0119, 1.0165]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-2.4868e-02,  3.0583e-02,  2.7163e-02, -1.9242e-02,\n",
              "                                    -4.2194e-03, -7.9919e-03, -1.6766e-02, -3.9648e-02,\n",
              "                                    -1.6986e-02,  1.5036e-02,  7.4192e-02,  6.4267e-03,\n",
              "                                    -9.1625e-03,  1.8655e-03, -2.2619e-02, -5.0356e-03,\n",
              "                                     7.4676e-03, -4.0173e-02,  5.4905e-03, -4.2370e-02,\n",
              "                                    -4.2634e-02,  2.4971e-02, -5.1360e-03,  1.2325e-02,\n",
              "                                    -2.3038e-02, -4.0520e-02, -2.7180e-02,  2.4249e-02,\n",
              "                                    -1.5181e-03, -6.4682e-04, -4.4079e-03, -2.4282e-02,\n",
              "                                     7.3442e-03, -2.4211e-02, -2.6677e-02, -1.7411e-02,\n",
              "                                    -5.3078e-02, -2.9829e-02, -2.5261e-02,  2.4231e-02,\n",
              "                                     1.8804e-02, -3.7351e-02, -8.0109e-03,  1.8155e-02,\n",
              "                                    -3.1641e-02, -1.2731e-02, -4.8281e-02, -2.0297e-02,\n",
              "                                     2.4942e-02, -3.9571e-02,  7.0555e-03,  1.2474e-02,\n",
              "                                     2.5665e-02, -8.0193e-03,  1.7934e-02,  2.6582e-02,\n",
              "                                    -3.7717e-02, -5.2570e-03,  4.2460e-04, -1.6373e-02,\n",
              "                                    -9.7664e-03, -1.3866e-02,  1.5390e-02,  2.9350e-02,\n",
              "                                    -3.2822e-02,  1.9321e-02, -5.6688e-02,  4.6129e-03,\n",
              "                                    -5.0645e-02,  4.5444e-02, -3.0465e-02,  7.0456e-03,\n",
              "                                     4.4845e-03, -3.3847e-02, -2.4120e-03, -3.1978e-02,\n",
              "                                     6.3112e-03, -1.9874e-02,  7.8345e-03, -3.5837e-02,\n",
              "                                    -2.2720e-02,  2.9122e-03,  1.8442e-02,  5.1409e-03,\n",
              "                                     5.3517e-03, -5.5952e-02, -4.0189e-03,  3.9418e-02,\n",
              "                                    -2.0334e-02, -2.6942e-02,  2.4688e-02, -2.1307e-02,\n",
              "                                    -3.6835e-02,  1.5125e-02, -1.8264e-02, -6.1935e-03,\n",
              "                                     3.0190e-02, -2.5761e-03,  2.8964e-02, -2.2495e-02,\n",
              "                                    -3.9739e-02, -3.7004e-02, -2.3789e-02, -2.5835e-02,\n",
              "                                    -6.2074e-02, -1.3106e-03, -2.4080e-02, -1.6988e-02,\n",
              "                                    -1.8466e-02, -1.2915e-02, -3.9177e-02, -5.3359e-02,\n",
              "                                    -9.4902e-03, -3.2899e-02, -3.9564e-02, -3.4077e-02,\n",
              "                                    -4.0309e-02, -2.6090e-02,  2.4743e-03, -4.7227e-02,\n",
              "                                     3.4901e-03, -1.3273e-02, -1.1291e-02,  7.2062e-04,\n",
              "                                    -4.2194e-02, -5.4825e-02, -1.9042e-02, -4.2469e-02,\n",
              "                                    -5.7023e-02, -6.5447e-03, -1.1398e-02,  1.3850e-02,\n",
              "                                     1.3970e-02, -2.8401e-02, -2.0946e-02, -4.6702e-02,\n",
              "                                    -2.5431e-03, -1.7830e-02,  1.0570e-02, -4.7001e-03,\n",
              "                                    -8.1358e-02, -8.5473e-03, -3.1160e-02, -5.2001e-02,\n",
              "                                    -2.3487e-02, -2.1534e-02, -3.2226e-02, -1.9782e-02,\n",
              "                                    -5.6042e-02, -2.4848e-03, -6.5058e-02, -3.0797e-02,\n",
              "                                    -4.1345e-02, -3.2365e-02,  3.5973e-03, -3.7534e-02,\n",
              "                                     1.8640e-02,  2.8296e-03,  1.6077e-02,  1.4324e-02,\n",
              "                                    -3.7866e-02, -2.4920e-02, -2.2623e-02, -7.8722e-03,\n",
              "                                    -2.4379e-02, -1.2539e-02,  1.9146e-02, -4.6367e-02,\n",
              "                                    -9.8984e-03, -1.4794e-02, -1.4391e-02, -1.2414e-02,\n",
              "                                     2.1096e-04, -2.0545e-02, -4.8329e-03, -5.9611e-02,\n",
              "                                     2.4297e-03, -4.0839e-03, -3.4632e-02,  2.2333e-02,\n",
              "                                    -3.4782e-02,  2.2639e-02, -4.6407e-02,  3.6720e-03,\n",
              "                                    -4.9662e-02, -5.5942e-03, -4.8768e-02, -7.2244e-03,\n",
              "                                    -5.1171e-02, -1.9164e-02, -1.1182e-03,  1.7366e-03,\n",
              "                                     9.3636e-03, -1.4234e-03, -1.0261e-02, -5.4904e-03,\n",
              "                                    -6.2062e-02, -6.9300e-03,  1.6888e-03, -2.7457e-02,\n",
              "                                    -4.5546e-03, -5.4886e-02, -9.7486e-03, -3.7742e-02,\n",
              "                                     1.6709e-02, -3.0414e-02, -2.9742e-02, -1.4224e-02,\n",
              "                                    -4.1067e-02, -1.4949e-02, -5.0786e-03, -5.0443e-02,\n",
              "                                     3.2101e-02, -2.2209e-02,  2.3193e-02, -1.3967e-02,\n",
              "                                    -5.6557e-03, -3.1106e-02,  1.9795e-02, -2.1499e-02,\n",
              "                                    -3.7457e-02, -5.4102e-02, -5.4036e-02,  3.1776e-03,\n",
              "                                     6.3560e-03, -6.2079e-03, -1.1392e-02, -7.4635e-02,\n",
              "                                    -3.5926e-02, -2.8072e-02,  1.8687e-02,  1.6118e-05,\n",
              "                                    -7.6827e-03, -4.3550e-02, -1.2861e-02, -1.7920e-02,\n",
              "                                     3.8725e-02,  9.0978e-03,  3.4207e-02, -7.2216e-03,\n",
              "                                    -3.0527e-03,  1.4478e-02, -4.6160e-03, -4.0964e-03,\n",
              "                                    -2.5864e-02, -1.7243e-02, -2.8151e-02, -7.3104e-03,\n",
              "                                    -2.4171e-03, -1.2072e-02, -5.0184e-02, -2.4267e-02,\n",
              "                                    -1.8780e-02,  1.7592e-02, -3.1642e-02, -7.6976e-03]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-3.3785, -1.4726, -0.7678,  1.1180,  0.9056, -1.0349,\n",
              "                                    -2.9227, -0.5438,  0.8838, -0.3835, -2.2167,  0.3257,\n",
              "                                     0.3125,  0.8186, -0.6935, -2.9522, -0.9410,  2.2365,\n",
              "                                    -1.6711,  0.1251, -0.1666, -3.0536,  1.0879, -2.4827,\n",
              "                                    -3.9449, -0.4626, -2.8538,  1.2011,  0.5836, -0.6244,\n",
              "                                     2.1765,  0.0287, -2.0756,  0.4495, -2.3128,  1.8255,\n",
              "                                    -0.7921,  0.2328, -1.1013, -1.9578, -1.6529, -1.6529,\n",
              "                                    -0.9145, -0.3162, -0.7277, -2.4260,  1.3377,  1.8552,\n",
              "                                     0.5485, -2.8662, -1.5869, -1.3668, -1.2249,  0.8544,\n",
              "                                    -0.6939, -1.5167, -3.9548,  0.7708, -0.5986,  0.8017,\n",
              "                                    -4.9892, -1.1303, -2.9618, -0.3171,  1.1939, -0.0810,\n",
              "                                     2.2796, -3.2998,  2.3430,  0.7886, -0.2351, -1.2698,\n",
              "                                     0.1790,  0.4155, -2.6150, -0.0546, -2.0474, -1.9072,\n",
              "                                    -3.0138, -1.4679,  2.0687, -1.5534,  0.6777, -0.9543,\n",
              "                                    -0.9976,  1.6984, -2.6304,  0.1384,  0.4732, -1.9738,\n",
              "                                    -1.6633, -1.2939,  0.7263, -2.9704,  1.1112, -3.7632,\n",
              "                                    -0.7000, -2.5236,  0.4257,  2.5038, -3.9424,  0.3723,\n",
              "                                     1.5297, -3.5294,  1.8725, -1.2520,  1.1237, -2.7386,\n",
              "                                    -1.6274, -0.1156, -1.9667,  1.2147, -0.1752,  0.6887,\n",
              "                                    -1.1371, -2.0929,  0.9905, -1.5212, -2.2921,  2.3102,\n",
              "                                    -1.2809, -1.3946, -2.9209, -2.7243,  1.3227, -1.2081,\n",
              "                                    -1.7063, -0.8112,  0.9977, -3.2537, -2.6512, -2.3565,\n",
              "                                     1.4686,  1.5779,  2.0931,  1.6099, -2.5014, -3.2496,\n",
              "                                    -1.5444,  0.2699,  2.0566, -0.4120, -2.1099,  1.8391,\n",
              "                                    -3.0870, -1.0695,  2.6548, -2.5615, -0.6235, -1.6059,\n",
              "                                     3.2128,  1.3542, -1.1224,  0.2979, -1.4042, -2.6435,\n",
              "                                    -3.5343, -0.1483, -3.1175, -3.8732, -2.0583, -1.4102,\n",
              "                                    -0.3152,  0.1008,  0.2785, -1.3871, -1.4577,  0.1862,\n",
              "                                    -2.5077, -0.9123, -1.3403,  1.0598, -3.2040, -1.4486,\n",
              "                                    -0.2084,  0.7538,  0.0654,  1.0977,  1.2649, -2.8140,\n",
              "                                    -0.0561, -0.9051,  0.7477, -3.5981,  1.4304, -2.9526,\n",
              "                                    -1.3620, -2.3986,  0.5747,  0.1528, -0.9028, -0.1845,\n",
              "                                    -0.8154, -2.3374,  1.1537, -1.3600,  2.9192,  0.4339,\n",
              "                                    -0.7384, -1.5849,  0.3222,  1.9552,  2.6667,  0.8831,\n",
              "                                    -1.8231, -1.7935,  0.2373, -0.4790, -1.8134, -0.3660,\n",
              "                                    -1.8885, -0.2985,  0.1524,  0.8355, -1.2935, -1.1678,\n",
              "                                    -0.2564,  0.4691, -0.0421,  0.1709,  2.8151,  0.1239,\n",
              "                                     1.8290, -2.6536, -1.0126, -0.7032,  1.2992,  0.1865,\n",
              "                                    -4.0313,  0.5206,  0.6381, -0.6142,  0.2376,  1.4271,\n",
              "                                    -2.7310,  1.5740, -1.8234, -3.5009, -2.9590, -1.6738,\n",
              "                                    -1.2206, -4.2954, -0.7392, -2.9812,  2.6038, -1.1299,\n",
              "                                     0.2810, -2.7387, -0.4501,  0.8229, -0.9692, -1.3536,\n",
              "                                    -0.0467,  0.4994, -2.6714,  0.3426]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([20.8581, 25.5476, 15.2905, 13.1119, 17.6425,  8.1807,\n",
              "                                    13.6776, 11.3411, 13.4345, 16.5849, 14.0401, 19.1484,\n",
              "                                    17.7746, 13.5048, 16.3931, 27.6308, 17.6320, 21.7677,\n",
              "                                    15.7148,  8.7404, 12.6144, 15.9349, 10.6458, 11.0869,\n",
              "                                    13.9698, 11.8035, 21.8749,  6.8545, 18.4238, 23.1204,\n",
              "                                    25.9839, 15.4012, 17.5343, 15.5632, 24.7829, 22.6657,\n",
              "                                    10.7515, 22.6961, 10.0439, 16.0852, 19.1694, 19.8062,\n",
              "                                    13.6388, 18.9156, 12.9901,  8.4294, 10.0921, 13.7395,\n",
              "                                    16.2502, 16.2035,  9.3952, 14.0716,  9.8342, 12.5386,\n",
              "                                    19.7747, 23.6849, 24.1796, 16.4441, 14.5147, 13.9921,\n",
              "                                    21.4331, 10.6696, 35.3310, 15.2836, 19.6661, 23.8282,\n",
              "                                    12.6617, 17.4857, 20.5450, 20.7632, 13.8085, 24.3783,\n",
              "                                    14.8493, 14.5619, 13.3318,  9.8927, 31.2212, 10.6686,\n",
              "                                    18.6842, 10.2006, 18.7950, 12.5079, 13.7480, 28.8560,\n",
              "                                    15.1764, 12.8213, 17.9167,  9.1098, 11.0870, 22.9911,\n",
              "                                    22.7109, 13.4388, 10.3532, 35.7077, 10.0668, 20.5742,\n",
              "                                     9.5508, 11.4302, 22.4039, 17.3393, 17.6254, 10.6011,\n",
              "                                    16.5085, 19.5784, 15.5858, 22.4386,  7.9985,  8.8631,\n",
              "                                    18.2093, 14.6432, 21.0994, 13.2145,  8.8256, 16.2349,\n",
              "                                    10.1460, 20.5164, 15.1819, 10.6907, 16.4260, 22.2077,\n",
              "                                    23.4082,  8.8495, 12.3091, 11.1351, 11.0562, 11.5639,\n",
              "                                    18.2127, 20.5797, 14.9135, 12.0375, 13.2316, 23.0586,\n",
              "                                    13.3441, 14.9755, 12.5555, 13.8179, 21.0425, 12.9259,\n",
              "                                     8.6526,  9.3282, 12.9738, 18.1943, 13.6858, 24.0486,\n",
              "                                    15.4835, 15.6342, 16.1099, 15.5578,  8.2756, 14.3770,\n",
              "                                    15.5238,  7.9971, 11.7718, 12.0409, 14.4416, 16.1508,\n",
              "                                    17.1762, 10.9336, 26.4370, 32.3994,  7.9550, 24.3672,\n",
              "                                    11.5941, 13.5744,  7.2715, 13.1465, 18.9379, 15.7889,\n",
              "                                    16.2252, 13.2177,  8.2029, 13.7722, 11.8588, 12.5853,\n",
              "                                    18.6088, 12.0765, 14.2194,  6.6579, 17.8200, 19.2935,\n",
              "                                     9.2705, 10.3503, 17.0973, 31.1583, 13.3990, 27.4157,\n",
              "                                     8.4258, 25.4909, 16.9443, 16.5862, 12.5806, 10.8205,\n",
              "                                    25.9141, 15.8761, 11.7890,  8.9966, 16.6809, 14.3390,\n",
              "                                    10.0410, 12.6639,  7.3940, 15.1670, 28.1166, 14.2524,\n",
              "                                    11.3814, 13.4520, 14.8051,  9.3868, 13.2833, 10.1714,\n",
              "                                    15.8618, 10.7684, 24.0690, 20.0319, 10.1567, 11.1498,\n",
              "                                    11.7906, 14.8551, 23.5006,  8.1508, 28.6319, 11.9540,\n",
              "                                    23.2037, 12.0882, 19.2338, 23.6710, 12.3850, 12.5924,\n",
              "                                    17.0117,  9.6920, 27.7505,  9.7434, 11.0235, 16.8842,\n",
              "                                    35.0885, 15.3146, 13.8956, 11.6820, 25.1994, 13.4300,\n",
              "                                    10.7216, 15.2473, 12.4673, 20.8484, 19.4579,  9.9810,\n",
              "                                    11.8763, 21.8750, 10.7846, 16.5948,  8.5812,  9.5467,\n",
              "                                     8.2895, 13.5260, 11.4041, 13.1409]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  253,  254,  255],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0466,  0.0041, -0.0231,  ..., -0.0559,  0.0204,\n",
              "                                    -0.0837]),\n",
              "                     size=(1024, 256, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([1.0179, 0.9889, 0.9719,  ..., 1.0203, 1.0139, 1.0275]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.0037,  0.0033,  0.0209,  ..., -0.0018, -0.0233,\n",
              "                                    -0.0040]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.3730,  0.0076, -0.8174,  ..., -0.2588, -0.4558,\n",
              "                                    -0.2154]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.4111, 0.4014, 0.7315,  ..., 0.4853, 0.5419, 0.2644]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.1.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  255,  255,  255],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0238,  0.0261, -0.0332,  ...,  0.0633, -0.1981,\n",
              "                                     0.0262]),\n",
              "                     size=(256, 1024, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9814, 0.9827, 0.9864, 1.0501, 1.0029, 1.0246, 0.9636,\n",
              "                                    0.9768, 1.0319, 0.9668, 0.9810, 0.9943, 0.9829, 1.0444,\n",
              "                                    1.0390, 0.9761, 0.9823, 0.9976, 1.0168, 1.0109, 0.9668,\n",
              "                                    0.9822, 1.0375, 1.0168, 0.9829, 0.9677, 1.0367, 0.9995,\n",
              "                                    0.9836, 1.0073, 0.9759, 1.0197, 0.9989, 0.9951, 1.0046,\n",
              "                                    1.0203, 1.0312, 0.9912, 0.9856, 1.0277, 0.9713, 1.0184,\n",
              "                                    0.9631, 0.9864, 0.9847, 0.9951, 1.0201, 0.9553, 1.0221,\n",
              "                                    1.0485, 1.0241, 1.0046, 1.0073, 0.9792, 1.0038, 0.9765,\n",
              "                                    1.0391, 1.0405, 1.0468, 0.9815, 0.9958, 0.9446, 0.9698,\n",
              "                                    0.9768, 0.9725, 0.9967, 0.9808, 0.9830, 0.9615, 1.0060,\n",
              "                                    0.9962, 1.0114, 0.9152, 0.9788, 0.9448, 1.0201, 1.0169,\n",
              "                                    0.9931, 0.9757, 1.0204, 0.9909, 0.9926, 0.9862, 1.0101,\n",
              "                                    1.0077, 1.0181, 1.0228, 1.0810, 1.0024, 0.9856, 0.9970,\n",
              "                                    1.0265, 0.9826, 0.9910, 1.0028, 1.0045, 0.9994, 0.9955,\n",
              "                                    0.9606, 1.0262, 0.9832, 0.9994, 0.9852, 0.9834, 0.9955,\n",
              "                                    0.9614, 1.0282, 1.0418, 1.0360, 1.0007, 1.0174, 1.0207,\n",
              "                                    1.0178, 1.0072, 1.0480, 1.0085, 0.9225, 0.9750, 0.9844,\n",
              "                                    1.0094, 1.0141, 0.9713, 0.9802, 1.0400, 0.9993, 1.0301,\n",
              "                                    0.9510, 0.9753, 0.9978, 1.0089, 1.0147, 1.0063, 0.9940,\n",
              "                                    1.0141, 0.9694, 1.0092, 0.9629, 1.0247, 0.9672, 0.9548,\n",
              "                                    1.0100, 1.0147, 0.9823, 0.9976, 1.0036, 0.9846, 0.9946,\n",
              "                                    1.0063, 0.9637, 0.9638, 1.0032, 0.9742, 0.9861, 1.0110,\n",
              "                                    0.9742, 1.0016, 0.9723, 0.9797, 0.9687, 1.0223, 0.9991,\n",
              "                                    1.0093, 0.9789, 1.0090, 0.9716, 0.9856, 1.0084, 1.0272,\n",
              "                                    0.9809, 0.9997, 0.9408, 0.9944, 1.0113, 1.0013, 0.9969,\n",
              "                                    0.9501, 0.9899, 1.0147, 1.0191, 1.0598, 0.9979, 0.9969,\n",
              "                                    1.0389, 1.0095, 0.9725, 0.9525, 0.9729, 0.9539, 0.9804,\n",
              "                                    0.9719, 1.0196, 1.0114, 1.0456, 0.9599, 1.0050, 0.9770,\n",
              "                                    0.9770, 1.0063, 1.0814, 0.9951, 1.0261, 0.9962, 1.0298,\n",
              "                                    0.9611, 0.9880, 0.9701, 0.9961, 1.0139, 1.0001, 0.9848,\n",
              "                                    1.0208, 1.0101, 0.9915, 1.0237, 1.0270, 0.9894, 1.0015,\n",
              "                                    1.0110, 0.9730, 0.9983, 1.0213, 1.0671, 1.0048, 0.9748,\n",
              "                                    0.9940, 0.9831, 0.9770, 0.9896, 1.0189, 1.0090, 1.0204,\n",
              "                                    0.9913, 0.9596, 0.9836, 1.0153, 1.0375, 0.9535, 1.0216,\n",
              "                                    0.9973, 1.0184, 1.0266, 0.9662, 0.9953, 1.0086, 0.9889,\n",
              "                                    1.0001, 1.0511, 1.0012, 0.9825, 1.0185, 1.0453, 0.9873,\n",
              "                                    0.9407, 0.9653, 1.0090, 0.9881]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 2.8841e-02,  1.4879e-02, -2.7707e-02,  2.6371e-02,\n",
              "                                     4.2352e-02,  1.8478e-02, -5.5789e-02, -1.2321e-02,\n",
              "                                     3.4724e-02, -1.2145e-02, -5.7458e-02, -2.6860e-02,\n",
              "                                    -3.2862e-02,  4.4717e-02, -7.6024e-03,  3.5518e-02,\n",
              "                                    -3.3923e-03, -5.2943e-03,  1.2452e-02,  4.9324e-02,\n",
              "                                     1.9049e-03, -2.2915e-02,  2.3923e-02,  4.9230e-02,\n",
              "                                     2.1430e-02, -3.5379e-02,  4.0021e-02,  3.9447e-03,\n",
              "                                     8.2461e-03,  4.5841e-02, -1.5968e-02,  4.0266e-02,\n",
              "                                    -2.1290e-02, -7.7522e-03,  1.8006e-02,  6.7703e-05,\n",
              "                                     1.3724e-02, -4.0100e-02,  3.8896e-02,  2.7291e-02,\n",
              "                                    -1.6591e-02,  1.8928e-02, -4.8419e-02, -3.5277e-02,\n",
              "                                     5.5587e-03, -2.9484e-03,  1.4258e-02, -8.4029e-03,\n",
              "                                    -1.3183e-02, -2.4193e-02,  2.0875e-02,  5.9198e-03,\n",
              "                                    -4.7226e-03, -1.1857e-02, -7.5140e-03, -1.7557e-02,\n",
              "                                     8.2813e-03,  4.3972e-02, -1.4274e-02, -1.7982e-02,\n",
              "                                    -3.9470e-02, -5.7153e-03, -1.9151e-02, -1.3020e-02,\n",
              "                                    -5.4614e-03,  1.3023e-02,  2.6689e-02, -6.0694e-03,\n",
              "                                    -4.6222e-03, -3.5896e-02, -2.6338e-02,  8.9087e-03,\n",
              "                                    -2.8632e-02,  2.6745e-02, -3.9645e-02,  1.3792e-02,\n",
              "                                    -2.3499e-02,  4.0845e-02, -1.4170e-02, -1.0586e-02,\n",
              "                                    -7.7207e-03, -7.3056e-03, -2.3619e-02,  2.0805e-02,\n",
              "                                     1.7349e-02,  4.6971e-02,  1.4585e-02,  2.1252e-02,\n",
              "                                     3.4411e-03,  1.1323e-02, -8.8524e-03,  4.3781e-02,\n",
              "                                    -1.2988e-02, -2.4939e-02,  4.7346e-03, -9.2239e-03,\n",
              "                                    -3.4535e-03, -1.2713e-02, -2.7769e-02, -4.9907e-02,\n",
              "                                    -7.9641e-03, -1.1154e-02,  6.0538e-04, -1.0798e-02,\n",
              "                                    -3.5913e-02, -3.6216e-02,  1.6536e-02,  1.2282e-02,\n",
              "                                     1.3301e-02,  3.0987e-02,  8.2447e-02,  5.4227e-03,\n",
              "                                     2.8746e-02,  3.5953e-02,  3.7665e-03, -2.9624e-02,\n",
              "                                    -5.0683e-02,  2.6728e-03, -1.7931e-02,  2.7912e-02,\n",
              "                                     4.0513e-02, -5.3735e-03, -3.0151e-03,  1.1476e-02,\n",
              "                                     9.5603e-04,  4.7555e-03, -2.2377e-02, -1.6047e-02,\n",
              "                                    -4.7832e-03, -3.5249e-02, -2.4850e-03,  4.7886e-03,\n",
              "                                    -1.4025e-03, -1.4692e-02, -5.8832e-03, -2.1977e-03,\n",
              "                                    -3.1001e-02, -1.1715e-02, -3.8403e-02,  1.7837e-02,\n",
              "                                    -2.4923e-02,  4.3731e-02,  1.1395e-02,  1.6270e-02,\n",
              "                                     9.3521e-04, -1.9835e-03, -1.7707e-02, -6.8032e-03,\n",
              "                                    -6.2568e-03, -2.8708e-02,  4.0463e-03, -3.8410e-03,\n",
              "                                    -2.1318e-02,  3.5068e-02, -1.8506e-02, -1.7550e-02,\n",
              "                                     2.7473e-03, -4.8020e-02, -3.8810e-02, -9.8859e-03,\n",
              "                                     2.0988e-02,  3.2207e-02, -3.4310e-03,  4.6830e-03,\n",
              "                                    -3.1332e-02,  1.7429e-02,  2.8020e-02,  2.0437e-02,\n",
              "                                     9.5522e-03,  7.7390e-03, -1.8372e-02, -1.4599e-02,\n",
              "                                     5.5812e-02, -1.1766e-02,  2.4963e-03, -5.2639e-02,\n",
              "                                     1.0363e-02, -3.0084e-02,  8.7630e-03,  1.0688e-02,\n",
              "                                    -1.4805e-02, -4.2153e-03,  7.0554e-02, -7.3116e-02,\n",
              "                                    -3.3365e-02, -2.1688e-02, -8.5677e-03, -3.7244e-02,\n",
              "                                    -4.6323e-02, -1.7330e-02,  5.2366e-02, -9.7647e-03,\n",
              "                                    -5.2190e-03, -2.6597e-02,  9.1965e-03, -1.0997e-02,\n",
              "                                    -2.0192e-02, -9.8997e-03,  4.5550e-03, -1.7725e-02,\n",
              "                                     5.3686e-03,  2.4044e-03,  4.3245e-02, -3.1360e-02,\n",
              "                                     1.4458e-02, -9.7507e-03,  1.6230e-02,  1.6499e-02,\n",
              "                                     6.7606e-03, -1.7339e-02, -3.2959e-03, -3.6398e-03,\n",
              "                                     7.5480e-03,  2.8449e-02,  1.3338e-02,  3.5528e-03,\n",
              "                                    -4.2476e-02,  6.6793e-02, -3.6009e-02,  4.0097e-03,\n",
              "                                     2.8503e-02,  5.7316e-02,  1.4412e-02, -2.1143e-02,\n",
              "                                     2.4581e-02, -1.7456e-02, -1.4719e-02, -2.0596e-02,\n",
              "                                    -6.3310e-03, -1.1670e-03,  4.9508e-02, -1.6440e-02,\n",
              "                                    -1.0946e-02, -2.9068e-02, -3.3868e-03,  4.0150e-03,\n",
              "                                    -3.4453e-02,  7.2908e-03,  2.2342e-02,  2.1420e-02,\n",
              "                                    -1.2328e-02, -3.5176e-02,  1.4363e-02,  2.4864e-04,\n",
              "                                     1.1790e-02,  1.5170e-02, -1.9726e-02, -1.8702e-03,\n",
              "                                    -2.0668e-02,  4.4270e-02,  4.1714e-02, -1.6933e-02,\n",
              "                                    -5.9979e-02, -3.8861e-02, -2.1994e-02, -2.0078e-02]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-5.4695e+00,  1.0748e+00, -1.3262e+00, -6.8188e+00,\n",
              "                                    -8.2169e+00, -8.4848e+00,  2.1551e+00, -5.7412e+00,\n",
              "                                    -1.0626e+01, -1.9393e+00,  1.0816e-01, -4.8555e+00,\n",
              "                                    -6.6244e-01, -7.9371e+00,  1.1714e+00,  3.5001e+00,\n",
              "                                    -3.3002e+00, -5.2966e+00,  3.1775e-01, -1.1692e+00,\n",
              "                                    -6.5863e+00, -2.2920e+00, -2.0599e+00, -1.1557e+00,\n",
              "                                    -1.3293e+00, -4.8966e+00, -4.8391e+00, -5.0465e+00,\n",
              "                                    -5.6500e-01, -1.0512e+01, -1.1294e-01, -2.7849e+00,\n",
              "                                    -4.6878e+00, -9.1512e-01,  1.5123e+00,  3.3057e+00,\n",
              "                                    -1.7847e+00, -4.1146e+00, -2.3634e-01, -4.2979e+00,\n",
              "                                    -1.7298e+00, -6.1798e+00, -3.1344e+00,  5.1279e+00,\n",
              "                                    -8.1517e+00, -2.2241e+00,  6.4118e-01,  4.9105e+00,\n",
              "                                     9.4105e-01,  4.2256e+00, -4.0650e+00, -5.3243e+00,\n",
              "                                     1.6743e-02,  4.8688e+00, -5.8083e+00,  1.9904e-01,\n",
              "                                     1.7473e+00, -7.8721e-01,  1.6760e+00, -1.1422e+00,\n",
              "                                     1.3003e+00, -6.5523e-02,  1.0925e+00, -6.6692e+00,\n",
              "                                    -1.5717e-01, -3.1180e+00,  4.3902e+00,  2.9526e-02,\n",
              "                                    -3.9965e+00, -2.4975e+00, -3.4340e+00,  1.3844e+00,\n",
              "                                     2.7115e+00, -1.4420e-01,  4.8260e+00, -7.9987e-01,\n",
              "                                     3.5074e+00, -6.7565e-01, -4.8715e+00, -2.5549e+00,\n",
              "                                    -5.8275e+00, -6.0370e+00, -2.7625e+00, -2.3444e+00,\n",
              "                                    -2.9312e+00, -5.8102e+00, -6.7602e+00, -9.8505e-01,\n",
              "                                    -7.7440e+00, -3.4416e+00, -7.3934e-01, -7.1961e+00,\n",
              "                                    -7.3801e-01, -4.7670e-03, -2.7935e+00,  1.9463e+00,\n",
              "                                    -2.6065e-01, -2.2021e+00, -2.1073e+00, -1.5735e+00,\n",
              "                                     2.3421e-01, -6.3051e-01, -1.8015e+00, -7.5202e+00,\n",
              "                                    -3.4781e+00,  1.8150e-02, -5.7998e+00, -2.9963e-02,\n",
              "                                    -2.7494e+00, -4.0249e+00, -3.3348e+00,  1.0061e+00,\n",
              "                                    -6.5475e+00, -4.6407e+00,  2.5107e+00,  1.7294e+00,\n",
              "                                     1.9258e+00,  1.3626e+00, -7.6190e+00, -8.5110e+00,\n",
              "                                    -9.4214e-02, -6.0578e+00, -1.4966e+00, -3.2805e-01,\n",
              "                                    -7.6259e+00, -4.1524e+00, -2.4820e+00, -3.0186e+00,\n",
              "                                    -4.6278e+00, -3.5354e+00, -3.5249e-03, -5.2022e-02,\n",
              "                                    -1.6727e+00,  4.7766e-01,  2.9767e+00, -2.0377e+00,\n",
              "                                     2.4486e+00,  5.3189e+00, -2.7500e+00,  1.0928e+00,\n",
              "                                     3.3295e+00, -4.5765e+00, -4.8080e-01, -3.3267e+00,\n",
              "                                     1.2084e+00, -3.7204e+00, -1.5733e+00, -2.5502e-01,\n",
              "                                     2.4693e+00, -2.4143e+00, -7.4520e-01, -2.4189e+00,\n",
              "                                     6.3163e-01, -1.1368e+01, -6.6270e+00,  8.8525e-01,\n",
              "                                     9.4868e-02, -4.3059e+00,  4.5987e+00,  6.8188e-01,\n",
              "                                    -6.2822e+00,  3.2067e+00, -7.5923e-01, -5.4036e+00,\n",
              "                                    -5.9267e+00,  1.5049e+00, -1.9303e+00,  1.0642e+00,\n",
              "                                    -4.7482e+00, -6.3430e+00,  4.8838e+00,  3.8313e+00,\n",
              "                                    -1.1322e+01,  2.5871e+00, -4.9049e+00,  1.2371e+00,\n",
              "                                     2.7215e+00,  1.4329e+00,  2.4494e+00, -1.2388e+00,\n",
              "                                    -3.0842e+00, -3.3471e+00,  6.0974e+00,  2.2971e+00,\n",
              "                                     3.0375e+00, -1.2372e+00,  2.3982e+00, -4.6415e-01,\n",
              "                                    -2.2813e+00, -2.7144e-01, -7.6453e+00, -3.7223e+00,\n",
              "                                     3.1860e+00, -3.0406e+00, -5.6482e+00, -5.6790e+00,\n",
              "                                     5.8449e+00,  1.6014e+00, -1.7968e-01, -6.3814e+00,\n",
              "                                    -2.3411e+00,  2.7618e+00, -7.6405e-01, -5.5713e+00,\n",
              "                                     3.3407e+00, -6.2527e-01, -4.3806e+00, -1.7467e+00,\n",
              "                                     2.7305e+00, -5.7978e+00, -3.5440e-02, -2.6326e+00,\n",
              "                                    -2.8598e+00, -5.7772e+00, -1.6988e+00, -6.5441e+00,\n",
              "                                    -3.3618e-01, -3.4829e+00, -2.6115e+00,  2.8560e-01,\n",
              "                                    -8.7648e-01, -5.8740e+00, -2.6725e+00, -4.0963e+00,\n",
              "                                    -3.4284e-01,  3.7438e-01, -3.5185e+00,  1.9832e+00,\n",
              "                                     4.8258e+00, -3.5013e+00,  2.6957e-01, -5.9531e+00,\n",
              "                                    -9.5303e-01,  5.1551e+00, -7.6417e+00, -2.7889e+00,\n",
              "                                     4.4267e+00, -1.7758e+00,  2.0240e-02, -3.5752e+00,\n",
              "                                    -4.2105e-01,  2.5313e+00, -4.4619e-01,  1.6954e+00,\n",
              "                                    -2.1079e+00, -9.1411e+00,  2.6237e+00, -3.2435e+00,\n",
              "                                    -1.0685e+00, -6.8723e+00, -8.1459e-01, -6.0208e+00,\n",
              "                                     3.8921e+00,  1.6311e+00, -1.7375e+00,  1.7357e+00]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 52.7711,  31.9120, 101.4180,  89.6171,  88.8287,\n",
              "                                    106.9511,  76.3395, 112.4379, 194.8675,  38.5764,\n",
              "                                     59.6918,  43.6342,  46.5818, 105.6168,  92.3397,\n",
              "                                    100.7366,  68.4833,  63.3024,  45.7403,  79.3853,\n",
              "                                     47.8121,  57.1117,  67.6613,  82.3863,  87.9336,\n",
              "                                     60.5722, 106.5963, 135.6042,  63.9078, 148.4609,\n",
              "                                     42.9604,  63.6116,  95.2538,  70.5405,  70.2713,\n",
              "                                    115.2829,  76.1083,  40.9837, 105.5408,  53.1352,\n",
              "                                     50.7292,  90.6607,  55.7467,  66.7488, 134.0471,\n",
              "                                     71.0016,  79.7478, 149.4153,  49.7440, 102.0527,\n",
              "                                     57.9232,  88.3766,  64.0589,  48.8989, 128.8621,\n",
              "                                     34.2840,  71.3690,  48.9263, 110.7857,  31.3590,\n",
              "                                     54.9652,  41.4775,  53.0470, 127.3500,  50.8858,\n",
              "                                     61.7681, 120.8751,  44.1155,  58.1514,  78.4889,\n",
              "                                     79.5899,  73.7700,  59.6109,  62.9483,  75.1491,\n",
              "                                     41.2671, 103.9579,  63.4878,  75.3120,  47.9826,\n",
              "                                    113.1628,  92.0719,  55.6400,  70.2526,  48.8622,\n",
              "                                     49.0259,  81.7419,  59.5277, 121.7769,  67.9011,\n",
              "                                     71.1662, 132.7132,  41.2230,  51.0089,  57.3171,\n",
              "                                     39.2958,  30.5035,  46.2235,  69.0278,  56.6719,\n",
              "                                    102.4822,  68.2530,  37.8317,  84.8620,  56.4184,\n",
              "                                     66.1353,  42.7500,  50.1521,  38.1242,  68.6395,\n",
              "                                    127.7947,  81.1285, 103.9217,  50.8757,  92.3579,\n",
              "                                     76.3055,  61.8350, 132.0472, 111.3983, 110.4242,\n",
              "                                     44.6099,  93.6027,  56.1399,  91.4433,  55.4192,\n",
              "                                     50.4674,  78.5967,  70.7240,  49.9473,  44.9499,\n",
              "                                     67.8360,  89.1856,  30.6422,  57.5844,  59.9786,\n",
              "                                     50.9021,  31.0137, 107.6019,  45.9501, 120.0729,\n",
              "                                     99.7026, 104.2317,  49.5851,  46.8122,  94.3013,\n",
              "                                     68.6981,  70.2697,  52.1450, 111.6457,  51.0645,\n",
              "                                     72.4909,  51.3941,  64.3627, 131.4943,  44.4739,\n",
              "                                     62.3090,  86.0769,  70.7356,  56.2081,  81.0542,\n",
              "                                     92.0036, 125.0023,  52.4347, 115.3148,  96.9072,\n",
              "                                     42.2840,  53.3708,  42.9174,  95.1488, 140.2487,\n",
              "                                    161.7428,  66.4361, 133.9105,  89.6167,  60.3876,\n",
              "                                     40.0612,  36.6058,  50.1587,  63.8460,  79.7708,\n",
              "                                     74.4078,  36.5983, 132.1078,  42.5074,  55.8392,\n",
              "                                     29.5648,  65.7617,  73.5807,  67.5126,  66.9748,\n",
              "                                    117.7035,  58.4359, 119.9297,  44.9350,  77.0351,\n",
              "                                     92.3033,  74.3979,  55.4564,  79.6671,  89.0642,\n",
              "                                    101.9093,  51.8545,  72.2610,  67.5219,  77.9472,\n",
              "                                     49.1631,  92.4632,  63.1945,  67.2675,  82.3664,\n",
              "                                     72.4239,  75.1694,  75.8031, 115.4528,  96.5473,\n",
              "                                     91.6615,  52.9209, 101.2801, 107.2282,  55.9025,\n",
              "                                     65.9957,  95.8155,  58.3027,  97.3950,  66.2218,\n",
              "                                     71.1515,  80.8162,  64.7803,  93.4913,  79.6466,\n",
              "                                     76.9841,  65.9780,  34.1235,  65.5079,  79.0073,\n",
              "                                     60.6369, 107.7720,  65.1077, 102.1950,  96.6933,\n",
              "                                     48.6121,  87.3899,  59.6666,  86.6218,  64.1026,\n",
              "                                     65.2969,  81.4759,  51.2249,  46.4559,  70.3697,\n",
              "                                     86.6818, 125.1944,  77.1999,  43.9427,  43.1248,\n",
              "                                     56.8269]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([-0.0208, -0.0140,  0.0104,  ..., -0.0233,  0.0139,\n",
              "                                    -0.0238]),\n",
              "                     size=(256, 256, 3, 3), nnz=589824, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9838, 0.9226, 0.9759, 1.0098, 1.0115, 0.9870, 1.0055,\n",
              "                                    0.9866, 1.0362, 0.9983, 0.9825, 0.9990, 0.9749, 1.0391,\n",
              "                                    0.9548, 0.9873, 0.9734, 0.9955, 1.0100, 1.0101, 0.9631,\n",
              "                                    0.9936, 1.0004, 1.0268, 1.0238, 0.9955, 0.9949, 0.9807,\n",
              "                                    1.0343, 0.9923, 0.9685, 0.9443, 0.9775, 0.9908, 0.9874,\n",
              "                                    1.0139, 0.9566, 1.0099, 0.9579, 0.9791, 1.0134, 1.0230,\n",
              "                                    0.9878, 1.0404, 0.9833, 0.9898, 0.9650, 1.0206, 1.0273,\n",
              "                                    0.9840, 0.9746, 0.9737, 0.9959, 1.0152, 1.0270, 0.9925,\n",
              "                                    1.0192, 0.9862, 1.0095, 1.0157, 0.9836, 0.9664, 0.9685,\n",
              "                                    1.0202, 1.0063, 0.9796, 1.0024, 0.9840, 1.0154, 0.9768,\n",
              "                                    0.9980, 1.0034, 0.9862, 1.0184, 1.0329, 0.9961, 0.9964,\n",
              "                                    0.9561, 0.9723, 1.0263, 1.0226, 1.0391, 1.0475, 1.0469,\n",
              "                                    1.0785, 0.9839, 1.0151, 0.9961, 0.9913, 1.0105, 0.9787,\n",
              "                                    0.9969, 0.9838, 0.9560, 0.9984, 0.9990, 1.0214, 0.9632,\n",
              "                                    0.9952, 0.9987, 1.0016, 0.9572, 0.9771, 0.9684, 1.0028,\n",
              "                                    0.9993, 0.9853, 1.0079, 1.0436, 0.9982, 1.0007, 0.9895,\n",
              "                                    0.9963, 1.0079, 0.9987, 1.0166, 0.9894, 0.9981, 0.9978,\n",
              "                                    0.9369, 1.0077, 1.0533, 1.0012, 0.9791, 0.9976, 1.0519,\n",
              "                                    0.9734, 0.9982, 1.0174, 1.0080, 0.9807, 1.0038, 1.0441,\n",
              "                                    0.9901, 1.0211, 1.0083, 0.9840, 0.9813, 1.0243, 1.0123,\n",
              "                                    0.9913, 0.9823, 0.9877, 1.0117, 0.9863, 0.9821, 0.9686,\n",
              "                                    0.9946, 0.9421, 0.9815, 1.0317, 0.9849, 1.0033, 0.9815,\n",
              "                                    0.9812, 0.9867, 1.0173, 0.9705, 1.0044, 1.0260, 0.9443,\n",
              "                                    0.9447, 0.9833, 0.9725, 0.9585, 1.0265, 1.0429, 1.0120,\n",
              "                                    0.9867, 0.9976, 1.0271, 0.9970, 0.9923, 0.9955, 0.9933,\n",
              "                                    0.9981, 1.0349, 0.9446, 0.9684, 0.9918, 0.9625, 1.0483,\n",
              "                                    0.9814, 0.9994, 1.0171, 1.0304, 1.0077, 0.9884, 1.0314,\n",
              "                                    0.9834, 1.0104, 0.9853, 1.0093, 0.9907, 1.0145, 0.9648,\n",
              "                                    0.9975, 0.9765, 1.0008, 1.0303, 1.0010, 0.9556, 0.9796,\n",
              "                                    1.0058, 0.9933, 1.0188, 0.9888, 0.9838, 1.0728, 0.9516,\n",
              "                                    0.9675, 1.0204, 0.9968, 1.0710, 0.9967, 0.9935, 1.0161,\n",
              "                                    1.0235, 1.0046, 1.0091, 0.9794, 1.0168, 0.9904, 0.9894,\n",
              "                                    0.9846, 0.9999, 1.0093, 1.0257, 1.0381, 1.0228, 1.0198,\n",
              "                                    0.9894, 1.0043, 0.9854, 1.0049, 1.0244, 1.0255, 0.9984,\n",
              "                                    0.9809, 0.9987, 0.9997, 1.0174, 0.9805, 0.9867, 0.9982,\n",
              "                                    0.9868, 1.0348, 1.0357, 0.9936, 1.0000, 0.9905, 0.9934,\n",
              "                                    0.9964, 1.0398, 1.0134, 1.0079]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-0.0357, -0.0227, -0.0191, -0.0145, -0.0036, -0.0197,\n",
              "                                    -0.0151, -0.0192, -0.0306, -0.0192, -0.0284,  0.0232,\n",
              "                                    -0.0091,  0.0211, -0.0373,  0.0058, -0.0205, -0.0047,\n",
              "                                    -0.0219, -0.0399, -0.0553, -0.0204, -0.0050, -0.0012,\n",
              "                                     0.0043,  0.0252, -0.0563, -0.0361, -0.0218,  0.0047,\n",
              "                                    -0.0467, -0.0014, -0.0243, -0.0342,  0.0015,  0.0183,\n",
              "                                    -0.0468, -0.0066, -0.0421, -0.0449,  0.0325, -0.0186,\n",
              "                                    -0.0285, -0.0320, -0.0472, -0.0405, -0.0382,  0.0003,\n",
              "                                    -0.0107, -0.0238, -0.0267, -0.0108, -0.0313, -0.0460,\n",
              "                                     0.0106, -0.0093, -0.0236, -0.0451,  0.0106, -0.0343,\n",
              "                                    -0.0065, -0.0449, -0.0441,  0.0348, -0.0175, -0.0233,\n",
              "                                     0.0027,  0.0064,  0.0016, -0.0283, -0.0481,  0.0074,\n",
              "                                     0.0214, -0.0054, -0.0524, -0.0023, -0.0124, -0.0448,\n",
              "                                    -0.0191, -0.0609, -0.0131, -0.0114, -0.0259,  0.0306,\n",
              "                                    -0.0006, -0.0248,  0.0116, -0.0227,  0.0122, -0.0207,\n",
              "                                    -0.0053, -0.0034, -0.0394, -0.0259,  0.0202,  0.0231,\n",
              "                                     0.0238, -0.0314, -0.0263,  0.0010, -0.0020, -0.0829,\n",
              "                                    -0.0213, -0.0172, -0.0240,  0.0098,  0.0132, -0.0238,\n",
              "                                     0.0238, -0.0178, -0.0257,  0.0034, -0.0130,  0.0004,\n",
              "                                    -0.0019, -0.0005,  0.0093, -0.0375, -0.0099, -0.0471,\n",
              "                                    -0.0259,  0.0198,  0.0062, -0.0260, -0.0449,  0.0038,\n",
              "                                    -0.0245,  0.0079, -0.0386, -0.0235, -0.0482, -0.0586,\n",
              "                                     0.0169, -0.0331,  0.0030, -0.0220, -0.0143, -0.0188,\n",
              "                                     0.0157, -0.0184,  0.0173, -0.0270, -0.0127, -0.0041,\n",
              "                                     0.0010, -0.0457, -0.0218, -0.0234, -0.0423, -0.0291,\n",
              "                                    -0.0268, -0.0420, -0.0626, -0.0308, -0.0174, -0.0004,\n",
              "                                    -0.0434, -0.0177, -0.0235,  0.0248, -0.0260, -0.0032,\n",
              "                                    -0.0042, -0.0727, -0.0130, -0.0547,  0.0105, -0.0180,\n",
              "                                    -0.0111, -0.0090, -0.0056, -0.0124, -0.0136, -0.0214,\n",
              "                                    -0.0220,  0.0106, -0.0135, -0.0660, -0.0385, -0.0140,\n",
              "                                    -0.0670,  0.0248, -0.0293,  0.0104, -0.0211, -0.0020,\n",
              "                                    -0.0571, -0.0090,  0.0350, -0.0612,  0.0113, -0.0041,\n",
              "                                     0.0025, -0.0130, -0.0171,  0.0051, -0.0631, -0.0329,\n",
              "                                     0.0158, -0.0124, -0.0071, -0.0457, -0.0362, -0.0431,\n",
              "                                    -0.0378, -0.0187, -0.0624, -0.0286, -0.0022, -0.0281,\n",
              "                                    -0.0133, -0.0240, -0.0152, -0.0656, -0.0684, -0.0350,\n",
              "                                    -0.0488, -0.0430,  0.0016, -0.0064, -0.0161,  0.0013,\n",
              "                                    -0.0138, -0.0055, -0.0183, -0.0162, -0.0023,  0.0194,\n",
              "                                    -0.0357,  0.0070, -0.0304, -0.0218, -0.0042, -0.0411,\n",
              "                                    -0.0070, -0.0207,  0.0083, -0.0128, -0.0194, -0.0109,\n",
              "                                    -0.0246, -0.0312, -0.0278, -0.0246,  0.0037, -0.0151,\n",
              "                                     0.0235,  0.0172,  0.0033, -0.0312, -0.0164, -0.0233,\n",
              "                                    -0.0078, -0.0257, -0.0276, -0.0295]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-0.2060,  1.1304, -1.4024,  0.3088,  0.1685, -0.1852,\n",
              "                                     1.8145,  2.0353, -0.9590,  1.6257, -0.9917, -1.3479,\n",
              "                                     0.2992, -2.2009, -0.4037, -2.8416,  0.7329, -0.0331,\n",
              "                                     0.5396,  0.4891,  2.3972, -0.6313, -2.6106, -0.3483,\n",
              "                                    -0.2781, -0.8906,  0.5625, -0.8201, -0.3052, -1.0944,\n",
              "                                    -2.5140,  0.2758, -0.2980,  0.3535, -2.7979,  0.1785,\n",
              "                                     1.2434, -2.3378,  1.5408,  0.9633, -1.8794, -0.7650,\n",
              "                                     0.5186,  0.1600,  0.0934, -1.2091, -0.8001, -1.3015,\n",
              "                                    -0.6435, -1.3019,  1.7408, -2.6931, -0.3572, -0.3893,\n",
              "                                    -0.8847, -3.1097, -1.1510, -2.7449, -3.9100, -1.3149,\n",
              "                                    -1.8687,  1.5617, -0.0346, -4.2673, -1.0237,  0.7215,\n",
              "                                    -3.5055, -1.6723, -0.9780,  0.7143,  0.9574, -2.1335,\n",
              "                                    -2.8109,  0.2156,  0.5174, -0.2135,  1.6957,  2.0782,\n",
              "                                    -2.0789, -1.1692,  1.2264,  0.7056, -0.3715, -2.1150,\n",
              "                                     1.0718, -2.4190,  2.0612, -1.5797, -2.7762, -0.2824,\n",
              "                                    -2.0134, -0.3107, -1.8146,  0.2314, -0.2953, -2.1813,\n",
              "                                    -0.6069, -2.3987, -0.9039, -0.9642,  0.3540, -2.0632,\n",
              "                                     1.9589,  0.0722,  0.3442, -1.1711, -1.2119, -2.7455,\n",
              "                                     0.9454, -0.9345, -0.0930, -2.2803, -0.5912,  0.5943,\n",
              "                                    -1.3406, -1.6131, -3.2657,  0.9720,  0.9008,  0.7950,\n",
              "                                    -0.7238,  1.4277, -0.6439, -2.1051, -1.1090,  1.1365,\n",
              "                                    -1.3803, -1.0140, -1.3131, -2.8804, -1.4562, -1.9775,\n",
              "                                    -0.5589, -4.7642, -3.3981,  0.3403,  1.5887,  0.6687,\n",
              "                                    -1.2310,  1.3042,  1.7343, -1.4321, -2.1551, -0.7365,\n",
              "                                     0.4837,  1.1926, -1.9459, -1.6853, -3.2460,  1.0805,\n",
              "                                     0.2064,  0.7890, -0.8628,  2.2031,  0.6498,  0.1931,\n",
              "                                     0.5017, -3.3656,  0.1128,  2.0123,  1.4122,  0.6091,\n",
              "                                    -0.7532, -0.1236, -1.2404,  0.2927, -0.8788, -0.1370,\n",
              "                                    -3.3035, -1.2123, -0.4337, -0.1754, -0.1430, -0.6597,\n",
              "                                     0.9783, -0.9430, -0.4332,  0.6083, -2.5790, -0.9832,\n",
              "                                     0.3753,  0.0152, -0.7723, -0.7751,  1.8642, -0.4727,\n",
              "                                    -0.0564, -2.3054,  1.3918, -0.1617, -1.4180,  1.6417,\n",
              "                                     0.3788, -2.1223, -0.8654, -2.8329, -1.3434,  2.6203,\n",
              "                                    -0.8183, -1.1747,  3.5370,  2.2716,  0.1728,  0.7699,\n",
              "                                    -0.8488, -2.7913, -0.1170,  1.6102,  0.2453,  0.9463,\n",
              "                                     1.5115, -0.1501, -4.0886, -0.6719,  0.9795, -1.1778,\n",
              "                                     0.2557,  1.2008, -1.3271, -0.8672, -0.2149, -0.0349,\n",
              "                                    -2.2100,  1.4509, -1.1910, -2.3240, -3.2287, -3.6951,\n",
              "                                     1.5570, -1.8853,  0.3198, -2.3484,  0.9160,  0.0214,\n",
              "                                    -0.5581,  0.5383, -3.3782, -0.9266,  1.2638, -0.2296,\n",
              "                                    -1.3833,  0.1726, -2.1759, -1.8910,  0.7697, -0.9090,\n",
              "                                    -5.2083,  0.0808,  1.0841,  0.5548,  0.6345, -3.7286,\n",
              "                                    -0.7484, -0.3943,  3.3399,  0.3018]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([11.6861, 13.7267, 12.4009, 13.5379, 15.8635, 12.6623,\n",
              "                                    20.9375, 18.2011, 13.0675, 12.4863, 10.4965,  7.9019,\n",
              "                                    11.9765, 18.9346,  7.0853, 18.9587, 15.7847,  8.9504,\n",
              "                                    11.7111, 16.0002, 17.3194, 10.5969, 13.5350, 12.7299,\n",
              "                                    15.8308, 16.5848, 17.2082, 10.9927, 11.1749, 12.0939,\n",
              "                                    12.6262, 13.4958,  9.5678, 11.6947, 18.0295, 19.7424,\n",
              "                                    17.5627, 15.9189, 22.7387, 12.4024, 12.7610,  9.6519,\n",
              "                                    11.3855, 21.2160, 11.4188,  7.0386,  9.7661, 11.4368,\n",
              "                                    13.8559, 14.5135, 30.3482, 14.0082, 11.6638, 15.8329,\n",
              "                                    18.2879, 18.0746, 21.7385,  9.0991, 11.7985,  7.4710,\n",
              "                                     8.0991, 13.2967, 10.1503, 22.2402,  7.9672,  8.8656,\n",
              "                                    17.1649, 14.4838, 11.4509, 10.4729, 15.9474, 15.4416,\n",
              "                                    21.5036,  9.7812, 20.0930, 10.9634, 22.7105, 24.8868,\n",
              "                                     7.0981, 10.0404, 16.1408, 13.7865, 12.1297, 12.9529,\n",
              "                                    11.6537, 27.0616, 16.9469, 12.1589,  6.5529, 11.8681,\n",
              "                                    19.7726, 15.2179, 12.3870, 18.6865, 10.9596, 23.0189,\n",
              "                                    16.7791,  7.9649, 10.9391, 10.2843, 12.2791, 22.3429,\n",
              "                                    21.7375, 18.0078,  6.7458, 10.2901, 12.6183, 10.1430,\n",
              "                                    20.7138, 19.6531,  6.9067, 10.7858, 10.9728, 12.2087,\n",
              "                                    12.2874, 14.2555, 19.9534, 11.6990, 11.3843, 20.0775,\n",
              "                                    28.4129, 18.4887, 20.0151, 14.3032,  9.5811, 19.7691,\n",
              "                                    13.1308, 12.8202, 13.8826, 21.7416, 12.9187, 12.1658,\n",
              "                                    12.9123, 21.8346, 29.3650, 14.7629, 11.0727, 14.6797,\n",
              "                                    16.4437, 10.9198, 15.9267, 13.9844, 24.5113, 14.2306,\n",
              "                                    14.5441, 10.9672, 16.4576, 11.0475, 17.6589, 24.1814,\n",
              "                                    11.1867, 10.8216, 11.0387, 13.3511, 16.7779,  8.2794,\n",
              "                                    17.6543, 13.7127, 10.6708, 12.1198,  9.7288, 16.8652,\n",
              "                                     9.8916, 12.5651, 11.3012,  8.9306, 18.3890, 10.4151,\n",
              "                                    16.8704,  8.3807, 16.0565,  6.5462, 14.1768,  7.2443,\n",
              "                                    15.3763, 14.2712, 15.9140, 14.3836, 16.9525,  9.8313,\n",
              "                                    11.2768, 21.9533, 12.6935,  7.6061,  8.0256, 18.1593,\n",
              "                                    11.2555,  7.3967, 15.3704,  7.1366, 12.5435, 13.7047,\n",
              "                                    11.9912,  9.6002, 11.3865, 15.3594,  8.5217, 15.0072,\n",
              "                                    15.8322, 15.0436, 19.5005, 18.7852, 14.8113, 12.1049,\n",
              "                                    10.8863, 30.9124, 10.3861, 15.5432, 11.9636, 17.3644,\n",
              "                                    19.2607, 14.8827, 23.8291, 17.0411, 11.8657, 12.2009,\n",
              "                                     9.7190, 14.8501, 10.8891, 13.5639, 14.6582, 11.2618,\n",
              "                                    20.6347, 25.1629, 14.9410, 10.4303,  9.6152, 22.1485,\n",
              "                                    13.2864, 17.3735, 16.3266,  9.1277, 11.9509, 10.2832,\n",
              "                                     9.1478, 19.2139, 26.5849, 22.3476, 13.3907, 14.1884,\n",
              "                                    12.0853, 15.0537, 11.8229, 16.3382, 18.9573,  9.0534,\n",
              "                                    45.0404, 18.6432, 23.9537, 11.2213,  8.7740, 17.1114,\n",
              "                                    21.6895, 14.3861,  9.6426,  8.0129]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  253,  254,  255],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0305,  0.0100, -0.0006,  ..., -0.0135, -0.0066,\n",
              "                                     0.0487]),\n",
              "                     size=(1024, 256, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.9905, 0.9862, 0.9954,  ..., 1.0234, 1.0129, 1.0044]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.0099, -0.0026,  0.0102,  ..., -0.0216, -0.0368,\n",
              "                                    -0.0164]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.5018, -0.3344, -0.4320,  ..., -0.5658, -0.5204,\n",
              "                                    -0.3346]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.7640, 0.3603, 0.6448,  ..., 0.5294, 0.7707, 0.5782]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.2.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  255,  255,  255],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0533,  0.1285,  0.1412,  ..., -0.0874,  0.0704,\n",
              "                                    -0.1197]),\n",
              "                     size=(256, 1024, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9732, 0.9996, 0.9963, 0.9792, 0.9883, 1.0310, 1.0341,\n",
              "                                    1.0404, 0.9973, 0.9643, 1.0255, 0.9891, 1.0079, 0.9974,\n",
              "                                    1.0144, 1.0215, 0.9645, 1.0625, 1.0077, 1.0265, 0.9856,\n",
              "                                    0.9781, 0.9764, 1.0045, 1.0307, 0.9919, 0.9871, 1.0308,\n",
              "                                    0.9734, 0.9887, 1.0363, 1.0272, 0.9678, 1.0255, 0.9660,\n",
              "                                    0.9858, 1.0695, 1.0278, 0.9882, 0.9912, 1.0125, 0.9754,\n",
              "                                    1.0248, 0.9775, 0.9896, 1.0183, 1.0115, 1.0197, 0.9694,\n",
              "                                    1.0053, 0.9980, 0.9697, 1.0202, 0.9900, 0.9814, 1.0069,\n",
              "                                    1.0069, 1.0040, 1.0024, 0.9816, 0.9667, 1.0020, 1.0035,\n",
              "                                    0.9635, 0.9697, 0.9694, 0.9801, 1.0117, 1.0445, 0.9945,\n",
              "                                    0.9783, 1.0014, 0.9954, 0.9862, 1.0382, 1.0061, 1.0423,\n",
              "                                    0.9677, 0.9805, 1.0203, 1.0052, 1.0370, 1.0462, 0.9940,\n",
              "                                    0.9762, 0.9850, 0.9681, 1.0553, 1.0366, 0.9986, 1.0410,\n",
              "                                    1.0356, 0.9877, 1.0070, 1.0136, 0.9796, 0.9866, 1.0193,\n",
              "                                    0.9920, 1.0073, 0.9970, 1.0020, 1.0208, 0.9998, 0.9779,\n",
              "                                    0.9988, 0.9981, 0.9925, 1.0014, 0.9768, 0.9559, 1.0714,\n",
              "                                    0.9886, 0.9979, 0.9916, 0.9939, 0.9988, 1.0040, 0.9913,\n",
              "                                    0.9366, 0.9773, 1.0059, 1.0119, 1.0259, 0.9747, 0.9849,\n",
              "                                    0.9853, 1.0229, 0.9710, 1.0254, 0.9948, 1.0167, 0.9615,\n",
              "                                    0.9860, 1.0246, 1.0228, 0.9734, 0.9740, 1.0119, 0.9892,\n",
              "                                    1.0018, 0.9603, 0.9737, 0.9967, 1.0010, 0.9837, 1.0006,\n",
              "                                    1.0748, 0.9865, 0.9726, 0.9762, 0.9698, 0.9770, 0.9640,\n",
              "                                    0.9940, 0.9724, 0.9967, 0.9895, 0.9915, 0.9800, 1.0125,\n",
              "                                    1.0535, 0.9844, 0.9574, 1.0366, 0.9938, 1.0051, 1.0222,\n",
              "                                    0.9753, 1.0247, 0.9905, 0.9638, 1.0369, 1.0031, 0.9343,\n",
              "                                    1.0027, 0.9893, 0.9709, 1.0012, 0.9597, 0.9685, 1.0109,\n",
              "                                    0.9869, 0.9926, 1.0006, 0.9978, 0.9672, 0.9806, 0.9697,\n",
              "                                    0.9996, 0.9699, 0.9725, 0.9917, 0.9812, 0.9662, 0.9958,\n",
              "                                    1.0530, 1.0239, 0.9791, 1.0604, 1.0595, 0.9970, 0.9912,\n",
              "                                    0.9970, 0.9634, 1.0019, 1.0097, 1.0190, 1.0124, 1.0257,\n",
              "                                    1.0014, 1.0174, 0.9802, 1.0388, 0.9954, 1.0004, 0.9986,\n",
              "                                    0.9779, 0.9851, 1.0086, 0.9835, 0.9817, 1.0126, 0.9828,\n",
              "                                    1.0065, 0.9821, 0.9690, 0.9676, 0.9967, 1.0071, 0.9542,\n",
              "                                    0.9749, 0.9903, 0.9661, 0.9975, 0.9916, 0.9737, 1.0163,\n",
              "                                    0.9925, 1.0130, 0.9450, 0.9748, 0.9849, 0.9879, 1.0151,\n",
              "                                    1.0101, 1.0439, 0.9863, 1.0104, 1.0129, 0.9984, 0.9817,\n",
              "                                    1.0520, 0.9884, 1.0060, 1.0552]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-7.5366e-03,  3.5022e-02,  1.9124e-05,  3.7815e-02,\n",
              "                                    -2.0885e-02,  1.9743e-02, -2.6807e-02,  5.4697e-03,\n",
              "                                     1.9077e-02, -4.0613e-02, -1.9696e-02, -2.3366e-02,\n",
              "                                    -3.8679e-02,  2.2636e-02, -2.2753e-02,  3.7037e-02,\n",
              "                                    -5.7949e-02,  3.9900e-02, -1.5820e-02,  3.1399e-03,\n",
              "                                    -9.8643e-03, -4.9692e-02, -9.2499e-03, -2.3802e-02,\n",
              "                                    -1.7216e-02,  7.1049e-04,  9.5533e-03,  4.6655e-02,\n",
              "                                     6.1945e-03, -2.2496e-02,  6.5451e-03,  2.1846e-02,\n",
              "                                    -1.8160e-02,  3.5471e-02, -2.8973e-03, -2.4995e-04,\n",
              "                                     1.7122e-02,  4.6413e-02,  2.1092e-03,  1.0201e-02,\n",
              "                                     2.9490e-02,  5.3165e-03,  3.1103e-02, -2.2306e-02,\n",
              "                                    -1.0400e-02, -2.5750e-03, -1.7128e-02, -2.9319e-02,\n",
              "                                    -3.2955e-02,  2.4121e-02,  3.1415e-02, -3.1762e-02,\n",
              "                                    -1.5569e-02,  9.4274e-03, -1.7928e-03, -3.4931e-04,\n",
              "                                     6.0012e-03,  1.2612e-02, -3.1480e-02, -9.7098e-03,\n",
              "                                    -9.3934e-03,  2.6630e-04,  1.3679e-02, -1.6840e-02,\n",
              "                                    -2.1360e-03, -4.1092e-02, -1.9457e-02, -1.0188e-02,\n",
              "                                     1.2365e-02, -2.9854e-04,  1.8612e-02, -1.3522e-03,\n",
              "                                    -2.4335e-02, -2.5303e-02, -1.8658e-02, -1.9649e-02,\n",
              "                                     1.3084e-02, -5.6224e-03,  1.0881e-02,  2.5877e-02,\n",
              "                                    -9.2641e-03,  7.1168e-02,  4.0051e-02,  1.3768e-03,\n",
              "                                    -3.4243e-03, -2.1897e-02,  2.3845e-02,  1.8829e-02,\n",
              "                                    -7.3017e-03, -1.8567e-02,  1.8902e-02,  2.3148e-02,\n",
              "                                     9.2538e-03,  5.8260e-03,  4.1174e-02, -2.3845e-02,\n",
              "                                     9.3024e-03,  4.4499e-02,  7.7421e-03,  2.6073e-02,\n",
              "                                    -4.1499e-03,  1.5721e-02, -1.8939e-02,  3.4158e-02,\n",
              "                                    -1.3109e-03, -7.9902e-04,  2.2430e-02, -4.6865e-02,\n",
              "                                     8.7092e-04,  3.6701e-02, -1.1228e-02,  5.8049e-02,\n",
              "                                     1.5129e-02,  9.0873e-03, -2.5123e-02,  1.4117e-02,\n",
              "                                     1.8800e-02,  1.9953e-03, -3.4784e-02, -5.9640e-02,\n",
              "                                     1.6345e-03,  4.6117e-03,  3.2857e-02,  2.5256e-03,\n",
              "                                    -2.2563e-03,  2.5762e-02, -2.7002e-02,  3.9649e-02,\n",
              "                                    -4.4033e-02,  9.6984e-03,  1.9972e-02, -2.7051e-02,\n",
              "                                    -2.1654e-02,  4.9974e-03,  3.0398e-02,  7.5760e-03,\n",
              "                                    -1.2374e-02, -3.3156e-02,  7.8570e-04,  7.2144e-03,\n",
              "                                    -7.1013e-04, -6.8444e-03, -9.4306e-03, -2.6132e-02,\n",
              "                                    -3.0730e-02,  8.3003e-03,  8.8999e-03,  1.8128e-02,\n",
              "                                    -1.7472e-02, -2.6116e-02, -1.0860e-02, -9.3776e-03,\n",
              "                                    -2.0670e-02, -3.5577e-02,  2.6481e-02,  2.4898e-03,\n",
              "                                    -3.6757e-02, -2.0050e-02, -2.9033e-02,  8.4607e-03,\n",
              "                                     5.4921e-02,  3.5221e-02, -4.5127e-02, -2.5989e-02,\n",
              "                                     3.4271e-03,  1.4482e-02,  6.2263e-02,  1.0119e-02,\n",
              "                                     1.2872e-02, -7.4557e-02, -2.8115e-02, -1.8729e-02,\n",
              "                                     5.0271e-02, -1.3425e-03, -2.2101e-02,  7.4351e-03,\n",
              "                                    -1.7841e-04, -1.8144e-02,  2.0111e-03, -9.1990e-03,\n",
              "                                    -3.6414e-02,  3.8519e-02,  7.1445e-04,  6.7647e-03,\n",
              "                                     2.6311e-02, -2.6171e-02, -5.7654e-02, -1.0590e-02,\n",
              "                                    -1.3990e-02,  2.0872e-02, -1.5210e-02, -2.4962e-02,\n",
              "                                    -3.8277e-02, -5.2980e-02, -6.9334e-02, -3.4727e-03,\n",
              "                                    -1.4474e-03, -2.2142e-03,  3.8865e-03,  2.1186e-02,\n",
              "                                     1.9613e-02, -1.1337e-02, -3.1656e-02, -2.9659e-02,\n",
              "                                    -7.0748e-03,  9.3609e-03,  3.9527e-03,  1.5296e-02,\n",
              "                                     1.4397e-02,  9.3247e-03,  1.2274e-02, -1.7489e-02,\n",
              "                                    -1.5873e-02, -8.9966e-04, -1.5378e-02, -1.7330e-02,\n",
              "                                     2.8365e-02, -2.6895e-02, -3.6922e-02,  6.5857e-03,\n",
              "                                    -1.2643e-02,  1.4576e-02,  2.3427e-02, -3.8617e-02,\n",
              "                                    -3.2762e-02,  7.8670e-04, -2.0947e-02, -3.5288e-02,\n",
              "                                     7.5984e-03, -1.6723e-02, -3.3241e-02,  1.5016e-02,\n",
              "                                     1.4793e-02, -1.2381e-02,  2.5521e-03, -3.4306e-03,\n",
              "                                    -1.9970e-02,  3.8432e-03, -1.5800e-02,  2.1805e-03,\n",
              "                                    -5.9687e-02, -6.5233e-02,  1.1725e-03,  2.9954e-02,\n",
              "                                     6.2271e-02, -2.5259e-02,  1.2338e-02, -2.3562e-02,\n",
              "                                     2.1198e-02, -2.2489e-03,  1.0688e-02,  2.6664e-02,\n",
              "                                     8.0065e-02, -9.0877e-03, -3.6148e-02,  2.5050e-02]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ -4.6308,   6.3495,  -2.2232,   2.7559,   3.6633,\n",
              "                                      3.0516,   0.6125,  -2.2463,   3.6005,   0.9713,\n",
              "                                      1.5853,  -9.9065,  -3.4366,  -8.4644,   3.4326,\n",
              "                                     -0.0273,  -1.0656,   0.9400,  -0.3411,  -1.4936,\n",
              "                                     -1.4019,   1.8860,   8.0585,  -0.7386,  -4.3238,\n",
              "                                    -11.1503,   4.5872,   1.1600,  -3.2113,   0.5868,\n",
              "                                      0.4698,   3.3747,   2.1497, -12.9257,   7.0876,\n",
              "                                    -15.2011,  -4.1146,   5.3023, -10.4436,  -2.6662,\n",
              "                                      0.2893,   4.4590,  -4.0073,   5.2109,   2.4811,\n",
              "                                    -13.5171,  -4.9117,   5.8151,  -3.4705,  -2.6578,\n",
              "                                     -7.2595,  -7.8867,   3.6364,  -3.3141,   5.2340,\n",
              "                                     -7.5055,  -2.7188,  -0.9247,   3.9675,  -7.0540,\n",
              "                                     -0.2369,   0.0359,  -5.1249,  -6.4035,  -3.1674,\n",
              "                                     -1.9236,  -6.9282,  -1.2424,   2.3810,   3.8285,\n",
              "                                      6.8351,   2.0410,  -0.4438,   4.0744,  -1.8405,\n",
              "                                     -1.4823,   2.0812,  -8.3077,  -2.8605,  -7.4007,\n",
              "                                     -6.7641,  -5.3046,  -9.2549,  -4.6021,   1.4185,\n",
              "                                    -15.6269,   1.2770,   1.1191,  -2.6771,  -5.9681,\n",
              "                                      1.2569,   0.8068,  -2.1802, -10.2596,   1.5711,\n",
              "                                     -0.1248,   0.4621,  -5.4311,  -6.9685,   4.3015,\n",
              "                                      3.6488,  -8.0800,   4.4494,  -2.9737,  -2.7181,\n",
              "                                     -0.7856,  -7.3283,   1.9496, -12.2438,  -0.2006,\n",
              "                                      9.5708, -10.8527,  -5.0873,  -6.8625,  -6.3823,\n",
              "                                     10.7291,   2.3451,  -8.5039,  -5.4545,   0.1084,\n",
              "                                    -10.9385,  -1.6024,  -8.1519,  -3.0481,   4.4408,\n",
              "                                     -3.8989,  -2.6067,   4.2029,  -2.8828,  -0.7322,\n",
              "                                    -11.2058,   4.4813,  -8.6369,   4.9600,   4.0486,\n",
              "                                     -7.4604,  -9.2510,  -1.6506,  -9.9049,   3.4421,\n",
              "                                     -3.0446,  -0.8848,   6.8040,   1.1681,   0.5362,\n",
              "                                      5.4118, -15.1391,   2.2573,  -1.4964,  -2.5460,\n",
              "                                     -4.9802,  -9.1905,   3.5882,   4.3447,   7.6423,\n",
              "                                      1.8643,  -0.7384,  -0.4892,   1.8913,  -6.2257,\n",
              "                                      2.3385,  -1.6465,   0.8499, -11.6583,   3.5839,\n",
              "                                      6.8592,   7.7945,  -7.0196,  -4.8378,   5.5362,\n",
              "                                      6.0872,  -4.7958,  -9.0165,  -1.7099,   4.0039,\n",
              "                                     -1.5551,  -6.7054,   8.9185,   4.7561,  -6.0016,\n",
              "                                     14.6596,   0.9826,  -2.7617,  -3.8554,  -6.6206,\n",
              "                                     -2.9814,  -1.9220,  -8.0303,  -0.9506,  -5.8765,\n",
              "                                     -1.7527,  -8.7434,  -8.4800,  -4.4816,   0.1659,\n",
              "                                    -11.2791,  -3.6963,   5.1206,   6.1710,  -0.5280,\n",
              "                                     -0.8289,   2.7593,  -4.1145,   7.4435,   1.9027,\n",
              "                                     -4.2260,  -0.5619,   3.9042,  -1.5437,  -1.6716,\n",
              "                                      0.9110,   2.1711,  -1.6807,   0.7485,  -2.3537,\n",
              "                                      7.8167,  -6.0131,  -4.1832,   7.4952,  -0.6420,\n",
              "                                     -3.2676,   1.7427,  -7.0812,   2.1189,  -1.0925,\n",
              "                                     -5.1746, -11.1598,   5.3849,   2.0702,   2.4328,\n",
              "                                      1.9593,   9.1572,   6.7048,   7.1536,  -7.5661,\n",
              "                                      2.8924,  -7.2190,  -0.8236,  -1.1571,  -9.7471,\n",
              "                                     -2.9668,  -5.1019,  -7.3694,   6.8059,  -2.5487,\n",
              "                                     -3.8517,  -0.0487,  -6.2805,  -0.9873,   1.4206,\n",
              "                                      0.5038,  -6.0795, -11.3189,   1.7951,  -1.6200,\n",
              "                                     -3.4885]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 92.2707, 116.1204,  63.6959, 150.4612, 141.1215,\n",
              "                                    146.3937,  67.5882,  98.6137, 212.2660,  79.2664,\n",
              "                                    138.5015, 163.7219,  76.8462, 101.2729,  69.9037,\n",
              "                                    102.4449, 148.8813,  88.6721,  90.7939, 107.7122,\n",
              "                                     58.7463, 100.8930, 176.4003, 126.5783,  58.5414,\n",
              "                                    161.5874, 108.5938,  97.8021,  65.3577, 144.2181,\n",
              "                                     74.9013, 146.3295,  73.1918, 163.6651, 111.9314,\n",
              "                                    287.3650,  83.5157, 144.0250,  95.3380,  58.1889,\n",
              "                                    116.4339, 139.2748,  55.7389, 115.7973,  98.0838,\n",
              "                                    196.7059,  97.0199, 124.5896,  76.5374,  98.8861,\n",
              "                                    119.0961,  73.3443,  76.9431, 122.4509, 145.7075,\n",
              "                                     90.6879,  93.4017,  86.7431, 103.7330, 116.3948,\n",
              "                                     91.7674,  74.9583,  99.3148, 165.1490, 133.7629,\n",
              "                                     88.4776,  90.3260,  82.5043, 113.0105, 112.5181,\n",
              "                                    207.9012, 145.7243,  74.8423,  73.3036,  60.9966,\n",
              "                                     69.9415,  72.1027,  80.6509,  61.9466, 122.8817,\n",
              "                                     87.2412,  70.9977,  61.3515,  65.0210, 103.9489,\n",
              "                                    206.5656,  84.3545, 108.5210, 109.4707, 135.7316,\n",
              "                                     93.1041, 103.4382,  49.1447, 203.2241,  75.7907,\n",
              "                                     50.6507,  58.3053,  64.0500,  82.8698, 152.0440,\n",
              "                                    124.4058,  88.8405, 137.4361,  80.3192,  95.9284,\n",
              "                                     66.1863, 119.5831, 102.2502, 133.3625,  57.9326,\n",
              "                                    149.2739, 141.5701, 203.8952, 153.9238,  69.0323,\n",
              "                                    263.3043,  87.8738, 113.5821,  91.5377, 108.6306,\n",
              "                                     95.4411,  87.8240, 102.0300,  70.8367, 183.5678,\n",
              "                                     65.3231,  81.0330,  81.0936,  82.7407,  99.8760,\n",
              "                                    150.3120,  87.9942,  68.7665, 110.4073, 201.8515,\n",
              "                                    124.6095, 137.5749,  59.9519, 140.7802,  57.7558,\n",
              "                                     88.7781,  93.5048, 110.4202, 124.9804,  66.4881,\n",
              "                                    141.5604, 181.9200,  99.3687,  97.4462,  84.7260,\n",
              "                                     67.3884,  81.9150,  77.6152, 116.5364, 177.1969,\n",
              "                                     52.9900,  68.9049, 133.9204,  71.7303,  74.6915,\n",
              "                                     89.1391, 115.9911,  63.2698, 139.8023, 118.5029,\n",
              "                                    143.1001, 184.4951,  70.7168,  58.9133,  93.5706,\n",
              "                                    135.6830,  76.1026, 146.4304,  96.3597, 100.8144,\n",
              "                                     72.9746,  95.4103, 228.0211, 182.6722, 118.4150,\n",
              "                                    231.7050, 108.0308,  70.7197,  65.0219, 118.3250,\n",
              "                                     76.8618,  52.1124, 164.8306,  81.8669,  67.7673,\n",
              "                                    108.2895, 123.8841,  90.9916,  75.6897,  60.6880,\n",
              "                                    124.1050, 100.7824,  59.1992, 145.0986,  70.0079,\n",
              "                                     94.9035, 142.0035,  85.4812, 109.0913, 127.3938,\n",
              "                                     99.9079,  78.0946, 153.2323,  73.0464,  73.3060,\n",
              "                                    127.2590, 132.1732,  74.8070, 115.5400,  80.5928,\n",
              "                                    150.2048,  63.7260,  57.8558, 130.8439,  73.3949,\n",
              "                                     55.6339,  94.0314, 116.6641,  58.8345,  67.6473,\n",
              "                                     52.3988, 173.3847, 212.3812,  73.2112, 147.7700,\n",
              "                                     79.9172, 251.4562,  99.8041, 175.7921, 102.2330,\n",
              "                                    120.0626,  87.5267,  66.2488,  85.3361, 108.0578,\n",
              "                                    134.4062,  35.9120, 140.9406, 170.5646, 109.7769,\n",
              "                                     60.9079, 111.3190,  68.4122,  97.5391,  81.6954,\n",
              "                                    111.9362,  80.5433, 261.0767,  79.8350,  88.0741,\n",
              "                                    117.8514]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0025, -0.0353,  0.0282,  ...,  0.0657, -0.0982,\n",
              "                                    -0.0418]),\n",
              "                     size=(256, 256, 3, 3), nnz=589824, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9993, 1.0435, 1.0019, 0.9881, 1.0033, 0.9837, 1.0125,\n",
              "                                    1.0160, 0.9892, 0.9938, 0.9686, 1.0345, 0.9716, 0.9809,\n",
              "                                    0.9762, 1.0270, 0.9812, 0.9872, 1.0191, 1.0005, 0.9889,\n",
              "                                    1.0386, 1.0284, 1.0059, 1.0315, 0.9832, 1.0108, 1.0191,\n",
              "                                    1.0093, 1.0094, 0.9803, 0.9667, 1.0019, 1.0116, 0.9714,\n",
              "                                    0.9719, 1.0071, 0.9877, 0.9819, 0.9795, 0.9525, 1.0039,\n",
              "                                    0.9669, 0.9981, 1.0020, 0.9948, 0.9631, 0.9793, 1.0106,\n",
              "                                    0.9906, 0.9935, 0.9888, 0.9880, 0.9736, 1.0125, 0.9964,\n",
              "                                    1.0067, 0.9896, 1.0148, 1.0249, 0.9641, 0.9857, 0.9816,\n",
              "                                    1.0016, 0.9799, 0.9805, 1.0121, 1.0138, 0.9683, 0.9885,\n",
              "                                    0.9832, 1.0088, 1.0331, 1.0656, 1.0069, 0.9716, 1.0294,\n",
              "                                    0.9597, 0.9674, 0.9942, 1.0398, 1.0204, 0.9705, 1.0204,\n",
              "                                    0.9851, 0.9568, 1.0189, 0.9693, 1.0270, 0.9665, 1.0273,\n",
              "                                    1.0183, 0.9783, 0.9882, 0.9888, 0.9570, 1.0143, 0.9780,\n",
              "                                    1.0311, 1.0106, 1.0235, 0.9800, 0.9925, 0.9758, 1.0348,\n",
              "                                    0.9745, 1.0212, 1.0222, 1.0000, 1.0465, 1.0264, 0.9425,\n",
              "                                    0.9535, 0.9895, 1.0624, 1.0404, 0.9465, 0.9692, 0.9880,\n",
              "                                    0.9809, 1.0330, 1.0216, 1.0546, 0.9757, 0.9663, 0.9933,\n",
              "                                    0.9768, 1.0039, 0.9861, 1.0273, 0.9989, 0.9660, 1.0522,\n",
              "                                    1.0023, 0.9957, 0.9950, 0.9525, 0.9947, 1.0252, 0.9706,\n",
              "                                    1.0069, 1.0255, 1.0024, 1.0179, 0.9846, 0.9509, 1.0065,\n",
              "                                    0.9824, 0.9994, 0.9799, 1.0129, 1.0141, 0.9740, 1.0108,\n",
              "                                    0.9927, 0.9778, 1.0107, 1.0092, 0.9738, 0.9634, 1.0187,\n",
              "                                    0.9916, 1.0043, 0.9854, 0.9579, 1.0054, 1.0035, 1.0222,\n",
              "                                    1.0016, 0.9864, 1.0220, 0.9656, 1.0343, 0.9920, 0.9733,\n",
              "                                    0.9735, 0.9540, 0.9964, 1.0207, 0.9540, 0.9858, 1.0246,\n",
              "                                    1.0004, 1.0047, 1.0105, 0.9903, 0.9984, 1.0234, 0.9877,\n",
              "                                    1.0153, 0.9691, 0.9878, 1.0299, 0.9625, 1.0035, 0.9961,\n",
              "                                    0.9818, 1.0046, 1.0224, 0.9762, 0.9943, 0.9934, 0.9917,\n",
              "                                    1.0410, 0.9608, 0.9576, 1.0137, 0.9991, 1.0030, 1.0276,\n",
              "                                    0.9736, 1.0175, 1.0435, 0.9973, 0.9996, 1.0536, 1.0173,\n",
              "                                    0.9850, 1.0326, 0.9866, 1.0600, 1.0192, 0.9996, 0.9716,\n",
              "                                    1.0029, 1.0130, 0.9919, 0.9739, 1.0001, 1.0136, 0.9821,\n",
              "                                    1.0127, 0.9679, 0.9859, 0.9886, 0.9782, 1.0114, 0.9880,\n",
              "                                    1.0133, 0.9768, 1.0136, 0.9658, 0.9833, 0.9914, 0.9915,\n",
              "                                    0.9864, 0.9892, 0.9669, 0.9873, 0.9763, 0.9903, 1.0370,\n",
              "                                    0.9914, 0.9935, 1.0452, 1.0573]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-0.0087,  0.0501, -0.0241, -0.0391,  0.0001, -0.0423,\n",
              "                                    -0.0446,  0.0138, -0.0687, -0.0132, -0.0267,  0.0200,\n",
              "                                    -0.0102, -0.0271, -0.0184,  0.0013, -0.0347, -0.0178,\n",
              "                                     0.0020, -0.0227, -0.0215,  0.0114, -0.0166, -0.0237,\n",
              "                                    -0.0123, -0.0093, -0.0162, -0.0580, -0.0160, -0.0239,\n",
              "                                    -0.0426, -0.0420, -0.0337, -0.0218,  0.0036, -0.0097,\n",
              "                                    -0.0329, -0.0486, -0.0326, -0.0003, -0.0313, -0.0413,\n",
              "                                    -0.0210,  0.0013, -0.0520, -0.0174, -0.0096, -0.0219,\n",
              "                                    -0.0410, -0.0288, -0.0209, -0.0123, -0.0388,  0.0225,\n",
              "                                    -0.0203, -0.0192,  0.0234, -0.0133, -0.0268, -0.0445,\n",
              "                                    -0.0297, -0.0195, -0.0091, -0.0094, -0.0166, -0.0209,\n",
              "                                     0.0214, -0.0111, -0.0173, -0.0020, -0.0599, -0.0031,\n",
              "                                    -0.0249, -0.0047, -0.0308, -0.0155, -0.0253, -0.0706,\n",
              "                                    -0.0251, -0.0237, -0.0144, -0.0344, -0.0638,  0.0489,\n",
              "                                    -0.0437, -0.0414,  0.0266, -0.0247, -0.0052, -0.0291,\n",
              "                                    -0.0268, -0.0203, -0.0480, -0.0174, -0.0161, -0.0570,\n",
              "                                    -0.0001, -0.0153, -0.0201, -0.0275, -0.0151,  0.0026,\n",
              "                                    -0.0109, -0.0269, -0.0414, -0.0265, -0.0103,  0.0062,\n",
              "                                    -0.0579, -0.0370, -0.0454, -0.0488, -0.0449,  0.0044,\n",
              "                                    -0.0059, -0.0313, -0.0713, -0.0352, -0.0077, -0.0154,\n",
              "                                    -0.0227, -0.0139,  0.0023, -0.0108,  0.0084, -0.0355,\n",
              "                                    -0.0180, -0.0005,  0.0191,  0.0062, -0.0174, -0.0259,\n",
              "                                    -0.0360, -0.0214, -0.0018,  0.0155, -0.0354, -0.0337,\n",
              "                                    -0.0333, -0.0599, -0.0321,  0.0404, -0.0073, -0.0397,\n",
              "                                    -0.0731, -0.0331, -0.0417, -0.0446, -0.0192, -0.0222,\n",
              "                                    -0.0520, -0.0485, -0.0253, -0.0122, -0.0282, -0.0034,\n",
              "                                    -0.0491, -0.0296, -0.0417, -0.0216,  0.0037, -0.0454,\n",
              "                                    -0.0519,  0.0037, -0.0323, -0.0305, -0.0362, -0.0382,\n",
              "                                    -0.0428, -0.0065, -0.0229, -0.0337, -0.0329, -0.0173,\n",
              "                                    -0.0260, -0.0414, -0.0050,  0.0044, -0.0039, -0.0599,\n",
              "                                    -0.0451, -0.0004, -0.0431, -0.0269,  0.0163, -0.0021,\n",
              "                                    -0.0491, -0.0198, -0.0219, -0.0054, -0.0701, -0.0317,\n",
              "                                    -0.0047, -0.0418, -0.0330, -0.0432, -0.0153, -0.0365,\n",
              "                                    -0.0092, -0.0224, -0.0074, -0.0523, -0.0191,  0.0273,\n",
              "                                    -0.0242, -0.0541,  0.0066, -0.0136, -0.0666, -0.0431,\n",
              "                                    -0.0015, -0.0164, -0.0302,  0.0121, -0.0551, -0.0160,\n",
              "                                     0.0061,  0.0070, -0.0323, -0.0647, -0.0008, -0.0146,\n",
              "                                    -0.0070, -0.0284, -0.0308, -0.0611, -0.0280, -0.0084,\n",
              "                                     0.0264, -0.0088, -0.0649, -0.0098, -0.0592, -0.0362,\n",
              "                                     0.0034, -0.0277, -0.0103, -0.0102, -0.0302, -0.0387,\n",
              "                                    -0.0135, -0.0087, -0.0078, -0.0045, -0.0436, -0.0346,\n",
              "                                    -0.0061, -0.0692, -0.0136, -0.0263, -0.0366,  0.0050,\n",
              "                                    -0.0176,  0.0121,  0.0084,  0.0089]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 7.5519e-02,  1.5047e-01,  3.5683e+00,  7.1318e-01,\n",
              "                                     7.5660e-01, -1.8218e+00, -5.4956e-01,  1.4405e-01,\n",
              "                                     6.5353e-01, -2.0528e+00, -2.7607e+00, -1.2911e+00,\n",
              "                                    -2.9887e+00, -6.4172e-01,  2.2667e+00, -3.8102e+00,\n",
              "                                     2.2294e-01,  1.9095e-01, -5.2556e-01, -7.1577e-01,\n",
              "                                     2.6592e+00, -2.2252e+00,  5.0381e-01, -1.0138e+00,\n",
              "                                     1.4527e+00, -2.4041e+00, -3.7761e+00,  1.4188e+00,\n",
              "                                     2.7616e+00, -2.4640e+00, -1.5504e+00, -2.4545e+00,\n",
              "                                    -8.9797e-01,  2.4716e+00,  1.3520e+00, -2.8904e+00,\n",
              "                                    -1.3974e+00,  3.2701e-01,  5.6918e-01, -2.6810e+00,\n",
              "                                    -2.6459e+00, -5.6610e-01,  7.7009e-01, -3.2954e+00,\n",
              "                                     6.3421e-01, -2.1408e+00, -1.4162e+00,  3.0492e-01,\n",
              "                                     8.9919e-01, -2.3280e+00,  1.5610e+00, -1.0332e-01,\n",
              "                                     2.8345e+00, -3.8494e+00,  1.6999e+00, -9.1438e-01,\n",
              "                                    -8.6533e-01,  1.1964e+00, -7.3816e-01, -2.1933e+00,\n",
              "                                    -2.9543e+00,  1.3531e+00,  2.6665e+00,  1.1617e+00,\n",
              "                                    -3.4828e+00,  4.1071e-01,  1.3238e+00,  7.5741e-01,\n",
              "                                     2.3680e+00,  1.0857e+00,  6.8127e-01, -1.8811e-01,\n",
              "                                    -6.3902e-01,  4.5612e-01, -3.6068e+00, -2.7093e+00,\n",
              "                                     4.9775e-01, -3.8995e+00, -2.9047e-01,  4.7295e-02,\n",
              "                                    -1.2397e+00, -3.5984e+00,  2.7135e+00, -2.4629e+00,\n",
              "                                    -1.6535e+00, -2.8111e+00,  2.9082e+00, -3.4241e+00,\n",
              "                                     3.8440e-01, -3.3521e+00,  1.1747e+00, -1.1616e+00,\n",
              "                                     2.5415e+00, -3.1741e+00, -2.9530e+00,  6.8335e-03,\n",
              "                                    -5.8382e-01, -9.7076e-01,  1.0992e+00, -1.3946e+00,\n",
              "                                    -7.6041e-01, -2.2628e+00, -2.7641e+00, -2.7238e+00,\n",
              "                                    -3.2300e+00, -2.0307e+00, -8.7003e-01, -7.7657e-02,\n",
              "                                     2.4711e+00, -5.9833e-01, -3.7531e-01, -2.8443e+00,\n",
              "                                    -2.0531e+00, -3.8952e+00, -7.4163e-01,  6.1234e-01,\n",
              "                                    -2.1963e+00,  2.5961e+00,  1.6800e+00,  1.3370e-01,\n",
              "                                     1.7230e-01, -3.3048e-01, -4.9836e-03, -2.4960e+00,\n",
              "                                     6.4796e-01, -2.9043e+00, -2.2289e+00,  4.2464e-01,\n",
              "                                    -9.9410e-01, -9.7171e-02,  5.0224e-01,  2.4530e+00,\n",
              "                                     8.3345e-01,  1.1524e+00, -7.5695e-01,  1.6437e+00,\n",
              "                                    -4.8182e+00, -1.4417e+00, -4.0882e-01, -4.9565e+00,\n",
              "                                    -1.8891e-01, -4.9834e+00, -2.7313e+00, -4.4871e-01,\n",
              "                                     2.7810e+00,  1.9222e-01,  4.3682e-02, -3.4835e-01,\n",
              "                                    -3.1371e+00, -8.8033e-01, -2.1344e+00, -1.6955e-01,\n",
              "                                    -3.4563e+00,  4.5582e-01, -1.9270e-01, -3.7755e+00,\n",
              "                                    -5.4366e-01, -2.3956e+00, -2.0350e+00, -1.3552e+00,\n",
              "                                     4.4644e-01,  1.9935e+00,  1.0115e-01, -1.5690e+00,\n",
              "                                    -6.2887e-02,  1.4106e+00,  6.1579e-01,  2.2787e+00,\n",
              "                                    -2.2295e-01, -2.6012e+00,  7.0957e-01, -2.4381e+00,\n",
              "                                     2.9425e-01, -1.3025e-01, -2.3912e+00, -1.2430e+00,\n",
              "                                     2.0492e+00, -7.5263e-01, -4.9610e-03, -4.1664e+00,\n",
              "                                     2.0231e-01,  1.4756e+00,  4.2779e-01,  1.0661e+00,\n",
              "                                    -1.0613e+00, -2.0860e+00,  1.1200e+00, -1.2053e+00,\n",
              "                                     1.1667e+00, -1.4822e+00, -2.0853e+00,  1.4320e+00,\n",
              "                                    -1.0319e+00,  2.7810e+00,  2.0847e+00,  2.1596e+00,\n",
              "                                    -3.7505e-01,  3.5113e+00, -2.2170e-01,  2.5609e+00,\n",
              "                                    -1.2983e+00, -3.7547e+00,  4.0148e-01, -1.9933e+00,\n",
              "                                    -1.1774e+00,  8.6336e-01,  3.9530e+00, -2.5545e-01,\n",
              "                                    -7.8964e-01, -6.1212e-01, -1.2759e+00,  2.9688e-01,\n",
              "                                     8.1328e-01,  6.4065e-01, -5.1210e-01,  1.0400e+00,\n",
              "                                    -1.7765e+00,  2.0525e+00,  6.2808e-01, -2.4318e+00,\n",
              "                                    -9.0145e-02, -3.5924e-01, -1.5849e+00,  1.4790e+00,\n",
              "                                    -4.0847e+00, -5.5662e-01, -1.1230e+00, -3.4528e+00,\n",
              "                                     9.7015e-01,  1.1094e+00,  7.0687e-01, -5.1390e-01,\n",
              "                                    -3.6579e+00, -3.1287e-01,  2.6997e-01, -3.6621e+00,\n",
              "                                     1.4164e+00, -1.5072e+00,  3.8832e-01,  2.0897e+00,\n",
              "                                    -3.9220e-01, -4.7462e+00, -2.7873e-02, -1.4579e+00,\n",
              "                                    -1.8659e+00, -1.7910e+00, -5.3070e-01,  3.7687e+00,\n",
              "                                    -3.8020e+00,  9.4369e-01,  2.2470e+00, -2.3850e+00,\n",
              "                                     3.1893e+00, -5.6643e-01,  1.6043e+00, -6.9457e-01]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([15.7021, 16.8111, 29.7818, 15.2586, 13.8179, 17.5110,\n",
              "                                    15.3996,  9.1467, 13.6759,  9.1570, 17.2208, 21.4315,\n",
              "                                    18.0113, 15.6896, 20.3733, 21.8935, 13.3407,  9.1913,\n",
              "                                    14.5652, 14.6593, 11.7930, 28.9876,  9.6398, 18.8400,\n",
              "                                    15.1911, 27.8461, 15.3674,  7.6852, 30.6058, 25.0192,\n",
              "                                     8.3486, 28.2592,  9.5212, 18.0711, 19.2726, 22.0868,\n",
              "                                    16.9423,  7.6472, 16.9835, 14.2624, 16.0219, 11.0895,\n",
              "                                     8.5618, 16.0630, 14.3590,  9.8361, 13.3524, 13.4680,\n",
              "                                    13.4282, 15.3674, 10.8089, 13.2146, 21.5128, 30.4216,\n",
              "                                    23.7877,  9.9556,  8.9836, 21.2548, 17.0303, 13.3231,\n",
              "                                    20.7867, 24.0831, 20.8373, 11.8936, 22.3420, 27.0520,\n",
              "                                     8.1754, 12.2872, 20.3661, 14.0716, 10.1360, 13.6456,\n",
              "                                    20.1611, 23.6346, 22.6010, 10.1088, 12.4993, 21.0455,\n",
              "                                     7.0423, 13.0027, 21.3998, 17.4931, 21.3255, 12.3259,\n",
              "                                    10.3923, 10.3299, 17.8138, 25.6122,  9.8869, 13.0773,\n",
              "                                    12.7521, 13.4527, 25.7666, 21.9124,  8.6993,  9.6906,\n",
              "                                    12.7870,  7.7890, 16.9194, 15.0332, 14.9789, 11.4019,\n",
              "                                    18.2402, 13.3520, 22.0115, 15.8390, 13.1955, 14.5595,\n",
              "                                    15.6844,  9.8359,  9.0473, 13.4524, 11.2166, 10.1740,\n",
              "                                    13.9596, 15.7773, 10.3293, 20.0331, 15.5396, 12.0954,\n",
              "                                     8.5256, 10.6649, 15.6587, 12.6082,  8.6560, 18.2878,\n",
              "                                    21.2534, 16.5391,  8.9373, 12.9092,  7.5543, 31.0749,\n",
              "                                    20.0208, 10.6736,  7.9594, 13.6726, 36.5162, 17.3436,\n",
              "                                    19.2491, 22.0741, 13.4692, 26.1064, 14.9187, 13.5646,\n",
              "                                    16.6311, 15.1217, 11.1176, 13.0874, 26.1586, 10.0581,\n",
              "                                     8.5615, 13.2302, 16.5592,  9.6715, 10.5128, 25.7656,\n",
              "                                    11.0644, 22.9114, 20.0319, 10.0681, 14.2541, 10.3556,\n",
              "                                     9.7583, 16.4814, 11.8131, 15.4014,  8.8361, 13.0571,\n",
              "                                    17.8270, 12.2197, 14.8009, 15.9299, 17.4893, 10.8478,\n",
              "                                    14.6643, 13.3759, 18.7125, 14.5660, 12.5049, 22.7503,\n",
              "                                     9.2118, 19.5648,  8.0496,  7.8086, 10.8082,  8.9491,\n",
              "                                    14.5086, 19.9403, 12.6827, 17.7766, 12.0571, 18.8689,\n",
              "                                    18.1496, 18.1917, 17.0218, 15.9225, 10.3168, 17.7000,\n",
              "                                    12.3717, 11.7171, 16.3860, 22.7561, 10.2622, 25.1086,\n",
              "                                    12.8507, 11.7890, 25.9995, 15.8887, 10.4444, 13.3187,\n",
              "                                    12.1594, 15.4772, 14.2631, 13.2763, 11.1885, 17.0104,\n",
              "                                    16.4182, 17.2193, 11.0823, 12.1906, 22.8605, 10.8297,\n",
              "                                     9.5596, 15.3595, 13.6640, 12.3196, 24.0992, 18.6779,\n",
              "                                    12.1291, 14.9708, 16.9504, 19.2915, 26.7757, 15.4914,\n",
              "                                    11.9900, 12.7438, 13.6926, 10.6240, 14.5693, 17.7953,\n",
              "                                    13.5638, 27.0043, 10.9180, 13.6740, 13.3408,  9.3652,\n",
              "                                    11.2284, 26.2723, 22.1321, 11.1848, 18.2223, 11.7951,\n",
              "                                    19.1574, 13.4010, 15.2064, 16.4577]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  253,  254,  255],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0643, -0.0595, -0.0584,  ...,  0.0952, -0.0858,\n",
              "                                     0.0572]),\n",
              "                     size=(1024, 256, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([1.0169, 0.9975, 0.9957,  ..., 1.0322, 0.9934, 0.9765]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.0114, -0.0103, -0.0106,  ..., -0.0039, -0.0211,\n",
              "                                    -0.0444]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.5132,  0.0802, -0.5612,  ...,  0.5919, -0.4195,\n",
              "                                     0.1632]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.6256, 0.7742, 0.8258,  ..., 0.6009, 0.5897, 0.7714]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.3.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  255,  255,  255],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0429, -0.0895,  0.0608,  ...,  0.0838,  0.0566,\n",
              "                                     0.1048]),\n",
              "                     size=(256, 1024, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9732, 1.0199, 1.0130, 0.9954, 1.0411, 1.0247, 0.9866,\n",
              "                                    1.0165, 0.9909, 1.0084, 1.0143, 1.0018, 0.9841, 1.0144,\n",
              "                                    0.9798, 0.9907, 1.0026, 0.9948, 0.9997, 1.0207, 1.0259,\n",
              "                                    1.0345, 1.0375, 1.0241, 1.0083, 0.9895, 1.0246, 0.9934,\n",
              "                                    0.9740, 1.0007, 1.0547, 0.9889, 0.9798, 1.0051, 1.0038,\n",
              "                                    0.9943, 0.9691, 0.9665, 0.9929, 0.9902, 1.0436, 0.9980,\n",
              "                                    0.9719, 0.9727, 1.0304, 0.9836, 1.0271, 1.0071, 0.9838,\n",
              "                                    1.0248, 1.0015, 1.0123, 1.0432, 1.0020, 1.0268, 0.9950,\n",
              "                                    1.0359, 0.9899, 1.0026, 1.0223, 0.9571, 0.9456, 0.9778,\n",
              "                                    0.9890, 1.0269, 0.9960, 1.0024, 0.9841, 0.9933, 1.0456,\n",
              "                                    0.9578, 1.0143, 0.9961, 0.9519, 1.0790, 0.9386, 0.9532,\n",
              "                                    0.9852, 1.0195, 0.9567, 1.0062, 1.0292, 0.9959, 0.9715,\n",
              "                                    1.0105, 0.9966, 1.0274, 0.9757, 1.0130, 1.0113, 1.0062,\n",
              "                                    1.0232, 1.0114, 1.0052, 0.9955, 1.0366, 1.0000, 1.0271,\n",
              "                                    1.0011, 1.0555, 0.9818, 1.0068, 1.0148, 1.0352, 1.0080,\n",
              "                                    0.9762, 0.9868, 0.9417, 1.0038, 1.0314, 1.0013, 1.0108,\n",
              "                                    0.9886, 1.0111, 1.0060, 1.0257, 0.9739, 0.9905, 1.0204,\n",
              "                                    0.9649, 0.9703, 0.9507, 0.9828, 0.9858, 0.9551, 1.0332,\n",
              "                                    1.0020, 0.9561, 0.9818, 0.9908, 0.9849, 1.0103, 0.9916,\n",
              "                                    1.0448, 0.9963, 0.9940, 0.9720, 0.9726, 1.0051, 0.9644,\n",
              "                                    0.9797, 0.9793, 1.0340, 0.9582, 1.0170, 1.0186, 1.0227,\n",
              "                                    1.0407, 0.9673, 0.9666, 1.0233, 0.9756, 1.0357, 0.9603,\n",
              "                                    0.9986, 1.0003, 1.0398, 0.9919, 0.9949, 0.9724, 1.0240,\n",
              "                                    1.0072, 0.9757, 0.9848, 1.0197, 1.0229, 0.9944, 0.9567,\n",
              "                                    0.9913, 1.0392, 0.9870, 0.9620, 0.9849, 0.9678, 1.0287,\n",
              "                                    0.9634, 0.9465, 0.9852, 0.9871, 0.9999, 0.9896, 0.9812,\n",
              "                                    0.9576, 1.0113, 0.9843, 0.9902, 0.9934, 0.9869, 0.9819,\n",
              "                                    0.9873, 0.9551, 0.9669, 1.0066, 1.0211, 1.0071, 1.0174,\n",
              "                                    1.0174, 0.9937, 1.0263, 1.0453, 0.9705, 1.0106, 1.0770,\n",
              "                                    1.0009, 0.9640, 0.9741, 1.0154, 0.9913, 1.0032, 0.9655,\n",
              "                                    0.9758, 0.9769, 0.9943, 0.9715, 1.0232, 0.9687, 0.9893,\n",
              "                                    1.0079, 0.9814, 0.9603, 1.0396, 0.9950, 0.9824, 0.9607,\n",
              "                                    0.9978, 0.9882, 1.0012, 0.9739, 1.0100, 1.0093, 1.0311,\n",
              "                                    0.9933, 0.9729, 0.9833, 0.9717, 0.9842, 0.9543, 0.9784,\n",
              "                                    1.0254, 1.0042, 1.0697, 0.9638, 1.0125, 0.9767, 1.0136,\n",
              "                                    1.0076, 0.9977, 1.0527, 0.9698, 1.0143, 0.9689, 1.0018,\n",
              "                                    0.9451, 0.9781, 1.0139, 0.9509]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-5.3552e-03,  1.5120e-02, -3.3742e-02, -3.0909e-02,\n",
              "                                     4.4994e-02, -1.4535e-02, -1.4882e-02, -1.4555e-02,\n",
              "                                    -1.6102e-02, -1.0349e-02, -3.2388e-02, -1.9585e-02,\n",
              "                                    -2.0685e-02, -2.1118e-02,  1.4318e-03,  4.9398e-03,\n",
              "                                     4.7793e-02, -5.4162e-02, -8.6514e-03,  6.7345e-03,\n",
              "                                     2.6230e-02,  2.3833e-02, -4.9064e-03,  5.7672e-02,\n",
              "                                    -1.0209e-02, -2.0067e-02,  2.0518e-02, -2.8355e-02,\n",
              "                                    -2.9383e-02, -6.1232e-03, -8.6170e-03,  1.5503e-02,\n",
              "                                    -4.5956e-02,  2.2722e-02,  1.1852e-03, -1.8591e-02,\n",
              "                                    -1.3740e-02, -3.6337e-02,  4.2036e-03, -8.7782e-03,\n",
              "                                     3.5506e-02,  5.5872e-03, -4.1682e-02, -3.3857e-02,\n",
              "                                    -2.6346e-02, -4.7340e-02, -1.7021e-02, -8.5982e-04,\n",
              "                                    -3.3509e-02,  2.4493e-02,  7.5115e-03, -1.0974e-02,\n",
              "                                     6.5844e-02,  4.5114e-03,  1.9736e-03,  2.0619e-02,\n",
              "                                     2.9136e-02, -7.5828e-03,  4.0277e-02, -9.9026e-03,\n",
              "                                    -2.4350e-02, -3.3063e-02, -1.0597e-02,  3.6175e-03,\n",
              "                                    -2.1609e-02, -2.8082e-02, -1.5086e-02, -5.1175e-03,\n",
              "                                     4.0524e-03, -5.1619e-03, -4.1220e-02, -2.6928e-03,\n",
              "                                    -2.5751e-02, -3.6078e-02,  2.0252e-02, -1.6436e-02,\n",
              "                                    -1.3829e-02,  9.5464e-03,  1.4175e-02, -3.8911e-03,\n",
              "                                    -5.1699e-03,  3.3368e-03, -3.8777e-02, -4.9373e-02,\n",
              "                                     2.4800e-02, -9.1853e-03, -4.0485e-02, -2.0683e-02,\n",
              "                                    -3.8172e-02,  6.5629e-02,  2.3652e-02,  3.0118e-02,\n",
              "                                    -1.0730e-02,  5.2104e-03,  2.1286e-02,  2.5221e-02,\n",
              "                                     1.8333e-03, -2.2394e-02,  3.0408e-02, -2.4642e-02,\n",
              "                                    -7.8550e-02,  1.7687e-02, -2.2496e-02,  2.3443e-02,\n",
              "                                     6.0494e-03, -5.6760e-02, -1.9419e-03, -3.6987e-02,\n",
              "                                     3.1265e-02, -1.0400e-02,  3.1302e-02,  4.1454e-02,\n",
              "                                     2.2566e-02,  2.6802e-02, -6.6695e-03,  9.5447e-03,\n",
              "                                    -3.0438e-02, -6.0601e-02,  2.3151e-02, -1.3666e-02,\n",
              "                                    -1.5867e-02, -2.4744e-02,  8.3216e-03, -1.8734e-02,\n",
              "                                    -4.8481e-02, -6.2063e-03, -3.5948e-02, -5.9744e-02,\n",
              "                                     3.2511e-02, -8.3813e-03, -2.0062e-02,  9.8579e-03,\n",
              "                                    -9.4825e-04, -2.9368e-02, -4.2234e-03,  2.7070e-02,\n",
              "                                    -2.6892e-02, -4.5036e-02,  3.2512e-02, -3.0915e-02,\n",
              "                                     2.3954e-03,  1.6727e-02,  3.3025e-02, -5.7790e-02,\n",
              "                                     1.9293e-02, -3.9524e-03,  1.7653e-02,  3.3538e-02,\n",
              "                                    -3.2246e-02, -9.2407e-04, -1.9177e-02, -2.5028e-02,\n",
              "                                     6.0892e-02, -3.5263e-02, -2.3065e-02, -4.6997e-03,\n",
              "                                    -1.4593e-02,  1.4203e-02, -1.2413e-02, -3.3656e-02,\n",
              "                                     5.1665e-03,  3.7346e-02, -9.9638e-03, -3.7120e-03,\n",
              "                                    -1.7846e-02,  1.8588e-02,  5.4128e-03, -4.6074e-02,\n",
              "                                    -1.1521e-02,  2.4771e-02, -4.9086e-02, -3.8035e-02,\n",
              "                                    -1.7297e-02, -7.4704e-02,  2.2718e-02, -3.7198e-02,\n",
              "                                    -3.9132e-03, -1.4290e-02, -1.8181e-02, -2.9264e-05,\n",
              "                                    -1.7677e-02, -3.6624e-02,  1.9478e-02,  4.5020e-03,\n",
              "                                    -6.2993e-03,  1.7183e-02, -1.3402e-02, -8.9967e-03,\n",
              "                                    -3.3419e-02, -1.1013e-02, -5.2752e-02, -4.1246e-02,\n",
              "                                    -6.5741e-03, -3.1005e-02,  3.7039e-03,  4.8427e-03,\n",
              "                                     2.0748e-02, -5.3600e-03,  7.2674e-03,  6.4402e-02,\n",
              "                                    -2.8481e-02, -3.1514e-02,  7.4029e-02,  1.6701e-03,\n",
              "                                    -2.9460e-02, -2.3611e-02, -1.8989e-02,  6.2033e-03,\n",
              "                                     3.9538e-02, -1.1677e-03, -1.7884e-03, -1.0697e-02,\n",
              "                                    -2.0775e-02, -1.3424e-03, -9.1332e-03, -2.3035e-02,\n",
              "                                     2.3960e-03, -1.2763e-02, -1.7108e-02, -2.3583e-02,\n",
              "                                     2.7198e-02,  1.3879e-02, -5.1026e-03, -1.2795e-02,\n",
              "                                     2.5736e-03, -2.9072e-02, -1.2395e-02, -2.0904e-02,\n",
              "                                    -2.9648e-02, -2.2569e-02, -5.9297e-03, -2.7728e-02,\n",
              "                                    -1.9438e-02, -1.7813e-02, -1.9083e-02, -5.3919e-03,\n",
              "                                    -3.1285e-03, -2.4768e-02, -3.0645e-02,  1.7333e-02,\n",
              "                                     4.7643e-02, -2.1484e-02, -1.2319e-02, -2.9166e-02,\n",
              "                                    -3.4415e-02, -8.6982e-03, -2.9020e-02,  4.3013e-02,\n",
              "                                    -2.1468e-02,  3.6564e-02, -1.4922e-02,  1.4646e-02,\n",
              "                                    -4.5252e-02, -4.8654e-02,  1.1136e-02, -4.5273e-02]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 11.5280,   1.6702, -15.4148,   4.0517,  -7.8278,\n",
              "                                     -4.3767,  -7.1833,  -1.3436,  -3.5680,  -9.1173,\n",
              "                                      6.4820,   0.2664,  -6.8328,  -5.1577,  -7.0852,\n",
              "                                    -16.5070,  -0.9489,  12.6248,  -6.0294,   3.4040,\n",
              "                                     -3.1768,  -1.9656,  -3.3778,  -0.0892,  -1.2909,\n",
              "                                      2.6735,   3.6183,  -3.5378,  -2.0482,  -3.1464,\n",
              "                                     -1.5076,  -7.9719,  -0.6063, -14.1489, -16.0201,\n",
              "                                     -2.8758, -12.1325,  -6.5948, -15.9367,  -7.3671,\n",
              "                                     -2.1974,  -2.9526,  -6.4069,  -3.0652,  -0.8957,\n",
              "                                      1.5137,  -0.2471,  -0.5360,  -5.9047,  -0.6027,\n",
              "                                     -2.9970,  -0.1851,  -4.2077, -10.2203,  -8.7653,\n",
              "                                    -16.8908,  -5.9406,  -6.6332,  -5.8032,   4.2008,\n",
              "                                     -2.4413,  -1.1247,  -8.6241,  -3.9404,  -0.2407,\n",
              "                                     -3.7892,   2.3454,   1.9521,   4.2548,   0.8698,\n",
              "                                    -11.6189,  -0.3015,   5.3696,  -7.2599,  -1.0164,\n",
              "                                      7.2245,  -1.6664,  -7.4743,   2.1109,   1.8523,\n",
              "                                     -7.7047,  -2.7886,  -2.1344,  -5.1003,   4.8384,\n",
              "                                    -10.2720,   6.3088,   3.1498,  -3.9704,   3.1416,\n",
              "                                      4.7429,   4.2400,  -2.6428,  -8.0957,  -0.2544,\n",
              "                                      4.7051,  -3.4608,  -4.5926,  -6.9233,   1.5723,\n",
              "                                      0.0955, -11.3087,  -1.8099,  -4.0700,   8.5486,\n",
              "                                      3.0741,   2.6354,  -8.5471,  -0.4200,  -0.5375,\n",
              "                                    -14.4688,   3.9815,  -2.5205,   5.5181,   3.5462,\n",
              "                                     -4.6880,  -7.3887,   3.1190,  -4.1286,  -8.7493,\n",
              "                                      0.3766, -12.5245,  -5.3536,  -3.1200, -10.1272,\n",
              "                                      0.0629,  -0.8772,   6.8191, -11.8484, -16.1910,\n",
              "                                      9.9682, -19.7856,  -6.1835,  -0.6526,  -4.4341,\n",
              "                                      0.1928,  -2.0928,   0.4708,  -9.3472,   1.7240,\n",
              "                                     -3.4966,  -3.6612,  -5.3006,  -0.0337,  -9.1897,\n",
              "                                      6.4736,  -0.2928,   1.6107,   9.9051,  -2.8548,\n",
              "                                      3.9930,  -8.7111,  -0.5624,   1.0884,  -4.9434,\n",
              "                                      3.5422,   1.6483,  -1.1542,   0.8984, -17.1680,\n",
              "                                     -3.6441,  -1.9239,  -0.2337,  -3.2933,  -0.6352,\n",
              "                                     -8.4410,  -9.5639,  -5.6512, -16.4443,   0.6118,\n",
              "                                     -2.8582,  -1.6926, -12.6140,  -1.8040, -11.5639,\n",
              "                                     -3.9432,   8.8634, -11.3593,   7.8499,   9.6090,\n",
              "                                     -8.9810,  -4.7770,  -1.5687,  -1.1407,   4.3174,\n",
              "                                     -2.8975,  -9.6301,  -4.1546, -13.2029,  -6.4649,\n",
              "                                     -7.4013,   1.0718,   1.8223,  -5.8769,  -3.8669,\n",
              "                                      5.1733,   4.1266,  -1.2829,  -3.4330,  -7.3393,\n",
              "                                     -6.5609,   5.8886, -13.3938,   2.7536,  -8.0852,\n",
              "                                    -10.1426,   2.8419, -12.4861,  -3.1672, -14.3584,\n",
              "                                      5.8974, -13.6437,  -6.2526, -14.2480,  -1.9444,\n",
              "                                    -12.6098,  -4.1818,   1.6548,  -3.3937, -10.6308,\n",
              "                                      1.4842,  -0.9189,  -5.2393,  -4.2003,   0.9692,\n",
              "                                     -5.4731,   2.0734, -10.6470,  -1.3239,  -6.5032,\n",
              "                                    -16.0824,  -0.2176,  -5.9023, -11.7376,   5.8636,\n",
              "                                      0.3174,  -5.8142,  -6.4063,  -1.3588,  -6.0438,\n",
              "                                     -1.9310,  -5.3757,   0.0292,   9.8804,  -5.2179,\n",
              "                                    -10.9533,  11.8189,   3.8309,  -2.9856,  -2.5056,\n",
              "                                    -13.8363,  -5.2453,  -4.7650,  -7.0184,  -4.0523,\n",
              "                                      8.9836]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([231.5245, 139.4950, 388.1655, 161.6511, 110.8346,\n",
              "                                    151.9817,  67.9057, 120.4454,  88.8648, 201.3387,\n",
              "                                    112.6916, 140.7602,  60.7558, 104.3909,  77.5007,\n",
              "                                    323.5068,  89.8755, 167.2444,  78.9078, 155.6528,\n",
              "                                    126.8331, 102.2714, 172.7140, 122.9131, 113.2474,\n",
              "                                     76.1775, 129.6738, 142.8461, 108.2843, 113.6910,\n",
              "                                    142.8358,  78.4674,  81.6655, 185.8218, 178.4706,\n",
              "                                    108.5980, 160.5852, 110.2272, 263.0237,  99.4642,\n",
              "                                    142.8877, 114.5872, 132.6825, 131.1635, 103.3263,\n",
              "                                    119.1471,  93.5350, 109.7078,  71.6921,  82.0708,\n",
              "                                    129.0536, 130.5264, 124.0469, 165.8511, 113.8720,\n",
              "                                    217.5708, 107.2286, 112.7578,  79.1185, 119.4184,\n",
              "                                     60.9162, 109.9872, 163.3816,  67.1175, 126.2450,\n",
              "                                    106.1527, 156.2005, 142.3890, 136.4257, 133.9041,\n",
              "                                    114.6951, 160.5173,  96.8519,  76.4741, 123.6886,\n",
              "                                     93.5899, 117.3548, 113.4735, 119.7575,  89.0006,\n",
              "                                    168.7930, 116.6574, 120.0261, 103.8113, 152.1665,\n",
              "                                    102.7604, 121.4701, 164.9741, 150.8061, 126.5415,\n",
              "                                    151.4403, 144.8479, 168.8159, 170.0126, 102.5158,\n",
              "                                    118.6054,  81.8718,  74.5441,  71.0972, 109.6463,\n",
              "                                    111.6980, 206.8024,  91.2195, 109.7414, 175.7185,\n",
              "                                    102.3292, 137.6599, 131.1360, 133.4441,  92.9232,\n",
              "                                    204.9181, 195.3374,  91.2108, 141.5000, 142.0525,\n",
              "                                    121.4054, 126.4071, 107.6353, 132.3507, 154.7403,\n",
              "                                    112.4669, 273.1030,  82.6259, 197.0380, 250.4964,\n",
              "                                     70.0421,  71.0657, 198.0583, 164.0402, 230.1915,\n",
              "                                    185.4043, 312.5282,  87.1564,  94.2528, 164.2263,\n",
              "                                     82.7434,  81.3486, 159.2906, 202.1400,  73.9075,\n",
              "                                    124.7775,  91.6693, 111.7451, 100.7158, 119.2857,\n",
              "                                    143.6640, 138.8164, 145.9217,  84.2374,  80.7059,\n",
              "                                    136.5329, 167.2505, 115.9098,  93.3933, 156.3278,\n",
              "                                    126.6779, 114.6557, 200.0776, 119.4957, 237.2138,\n",
              "                                    165.9431, 161.6973,  65.4168, 142.0994,  96.3448,\n",
              "                                    129.6732, 193.1762, 105.2973, 279.5916, 132.7721,\n",
              "                                    107.0504,  68.8662, 166.3138,  49.5616, 241.2893,\n",
              "                                    137.6223, 252.2546, 208.6034, 143.6996, 158.9139,\n",
              "                                     97.1294, 128.4925,  92.6884, 142.0054, 188.6742,\n",
              "                                    138.6519, 188.2947, 131.9280, 366.1579, 143.2290,\n",
              "                                    112.5945,  95.5573, 117.7539, 200.4211, 109.1385,\n",
              "                                    151.4617, 110.3827,  84.1790, 145.9549,  74.9205,\n",
              "                                    159.3249, 206.3124, 127.8464, 124.9450, 188.3647,\n",
              "                                    158.1766,  55.4796, 168.2341, 103.7837, 215.9222,\n",
              "                                    194.3882, 166.5570, 101.3719, 297.8492, 156.4751,\n",
              "                                    265.7436, 139.7682,  64.9738, 118.3967, 196.0715,\n",
              "                                    110.2544, 133.3446, 174.4098, 134.6557,  80.7394,\n",
              "                                     84.9071, 122.1279, 218.9618, 131.0869, 113.4558,\n",
              "                                    207.0331, 112.2914, 116.2392, 199.1886, 155.5709,\n",
              "                                     87.5211,  92.0560, 155.7827,  98.9419, 123.0764,\n",
              "                                    113.3144,  65.9426, 128.9409, 217.7087,  90.2240,\n",
              "                                    156.5247, 166.2816, 131.3896, 137.2338, 120.9807,\n",
              "                                    118.2788, 160.2204,  90.2821,  67.6182,  77.2109,\n",
              "                                    246.3391]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([ 0.0797, -0.0300, -0.0150,  ...,  0.0073, -0.0014,\n",
              "                                     0.0045]),\n",
              "                     size=(256, 256, 3, 3), nnz=589824, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9960, 1.0037, 0.9793, 0.9756, 1.0234, 1.0014, 0.9681,\n",
              "                                    0.9896, 0.9870, 1.0033, 0.9475, 0.9988, 0.9935, 1.0122,\n",
              "                                    0.9710, 1.0130, 0.9650, 0.9842, 0.9905, 0.9513, 1.0247,\n",
              "                                    0.9570, 1.0175, 0.9599, 1.0296, 1.0097, 0.9737, 1.0014,\n",
              "                                    1.0166, 0.9872, 1.0099, 1.0325, 0.9961, 1.0108, 0.9923,\n",
              "                                    1.0051, 0.9721, 0.9754, 0.9735, 0.9593, 0.9868, 0.9842,\n",
              "                                    0.9551, 0.9900, 1.0076, 0.9834, 1.0323, 1.0072, 1.0020,\n",
              "                                    0.9642, 0.9932, 1.0330, 0.9625, 1.0071, 1.0260, 0.9793,\n",
              "                                    1.0052, 0.9507, 0.9882, 1.0016, 0.9909, 0.9859, 0.9902,\n",
              "                                    1.0180, 1.0178, 0.9931, 1.0234, 0.9978, 1.0102, 0.9999,\n",
              "                                    0.9418, 0.9916, 1.0067, 0.9976, 0.9738, 1.0112, 1.0035,\n",
              "                                    1.0110, 0.9958, 1.0085, 0.9974, 0.9914, 0.9785, 0.9702,\n",
              "                                    1.0397, 1.0124, 1.0009, 0.9871, 1.0132, 1.0125, 1.0015,\n",
              "                                    1.0271, 0.9763, 1.0144, 1.0003, 0.9755, 0.9604, 0.9574,\n",
              "                                    0.9539, 1.0010, 0.9819, 1.0103, 1.0089, 0.9917, 0.9667,\n",
              "                                    1.0132, 0.9773, 1.0147, 0.9715, 0.9970, 1.0085, 1.0071,\n",
              "                                    1.0259, 1.0228, 0.9954, 1.0098, 0.9980, 1.0057, 0.9935,\n",
              "                                    1.0280, 0.9441, 1.0023, 1.0140, 0.9905, 1.0555, 1.0186,\n",
              "                                    0.9869, 1.0117, 0.9797, 1.0026, 0.9796, 1.0306, 0.9850,\n",
              "                                    0.9847, 0.9632, 0.9989, 1.0232, 1.0032, 0.9741, 0.9830,\n",
              "                                    0.9656, 1.0441, 1.0209, 1.0222, 1.0214, 0.9635, 0.9965,\n",
              "                                    1.0069, 1.0217, 1.0203, 1.0049, 0.9617, 1.0263, 0.9693,\n",
              "                                    0.9722, 1.0200, 0.9709, 1.0089, 0.9862, 1.0167, 0.9537,\n",
              "                                    1.0365, 0.9714, 0.9517, 1.0204, 0.9865, 1.0075, 0.9977,\n",
              "                                    1.0132, 1.0376, 0.9995, 0.9833, 0.9798, 1.0016, 1.0154,\n",
              "                                    1.0075, 1.0041, 1.0213, 0.9916, 0.9747, 0.9874, 0.9891,\n",
              "                                    0.9844, 1.0034, 1.0016, 1.0117, 1.0029, 1.0100, 0.9792,\n",
              "                                    0.9640, 1.0048, 1.0222, 0.9976, 1.0201, 0.9699, 0.9910,\n",
              "                                    1.0012, 1.0011, 0.9904, 0.9726, 0.9855, 0.9987, 0.9368,\n",
              "                                    1.0418, 1.0038, 0.9824, 1.0373, 1.0207, 1.0070, 0.9991,\n",
              "                                    0.9888, 0.9827, 0.9808, 1.0121, 1.0076, 1.0148, 0.9937,\n",
              "                                    0.9692, 0.9586, 0.9804, 1.0079, 1.0599, 0.9812, 0.9749,\n",
              "                                    1.0170, 1.0112, 0.9904, 0.9848, 1.0207, 0.9863, 0.9757,\n",
              "                                    0.9939, 0.9745, 1.0052, 0.9695, 1.0092, 0.9601, 1.0160,\n",
              "                                    1.0089, 0.9557, 1.0067, 0.9948, 0.9853, 1.0040, 1.0094,\n",
              "                                    1.0214, 1.0070, 1.0299, 0.9705, 0.9988, 0.9935, 1.0151,\n",
              "                                    0.9913, 1.0456, 0.9949, 1.0230]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-1.8646e-02, -4.6714e-02, -2.1010e-02, -2.9596e-02,\n",
              "                                    -1.9255e-03, -1.0601e-02, -2.6712e-02,  5.1613e-03,\n",
              "                                    -1.5041e-02,  1.6218e-02, -2.3860e-03,  2.8564e-03,\n",
              "                                    -3.3157e-02, -9.3034e-03, -2.6781e-02, -6.9180e-03,\n",
              "                                    -4.5545e-02, -2.1667e-02,  3.0846e-03, -4.2766e-02,\n",
              "                                    -3.3783e-03, -6.8534e-03, -1.9463e-02, -3.1486e-02,\n",
              "                                     2.1730e-02,  1.7972e-02,  1.0837e-02, -5.3310e-02,\n",
              "                                     2.2831e-03, -1.8702e-02, -2.4997e-02, -6.1054e-02,\n",
              "                                    -2.9057e-02, -2.8561e-02, -6.5900e-02, -3.0776e-02,\n",
              "                                    -2.6405e-02, -6.5696e-03, -5.3338e-02, -2.4249e-02,\n",
              "                                    -1.9623e-02, -1.3127e-02, -5.0792e-02, -1.7116e-02,\n",
              "                                     8.9440e-03, -5.3836e-02, -6.3372e-02, -5.8405e-03,\n",
              "                                    -6.2606e-02, -3.0329e-02, -8.8166e-03, -4.4375e-02,\n",
              "                                     8.7401e-03, -4.1333e-02,  2.4180e-03, -3.7339e-02,\n",
              "                                    -6.9172e-02, -2.6891e-02, -2.3323e-02,  5.0825e-05,\n",
              "                                     2.2538e-03, -5.7217e-02, -4.3767e-02, -4.4486e-02,\n",
              "                                    -1.1689e-02, -4.7261e-02, -5.2794e-02, -3.5910e-02,\n",
              "                                    -2.2857e-02, -1.8025e-02, -7.5881e-02, -2.2896e-02,\n",
              "                                    -3.1561e-02, -3.3773e-02, -3.8510e-02, -1.0355e-02,\n",
              "                                    -3.1476e-02,  6.4454e-04, -6.0794e-03, -1.1284e-02,\n",
              "                                    -6.4811e-03, -4.5350e-03, -2.6278e-02,  8.3586e-04,\n",
              "                                    -1.2459e-03, -2.1048e-02, -3.7055e-02, -2.1220e-02,\n",
              "                                     7.7550e-03, -4.5293e-02, -2.8502e-02, -4.0858e-02,\n",
              "                                    -9.5700e-03, -5.3165e-02, -4.8040e-02, -4.4770e-02,\n",
              "                                    -5.5986e-02, -5.1746e-02, -2.2422e-02, -1.1817e-02,\n",
              "                                    -1.8522e-02, -3.0282e-02, -8.0135e-03, -5.8490e-02,\n",
              "                                    -3.8802e-02, -3.0601e-02, -3.5335e-02, -5.6081e-02,\n",
              "                                    -1.6081e-02, -3.2293e-02, -1.2883e-02, -5.5044e-02,\n",
              "                                    -5.8862e-03, -6.0427e-02, -2.8910e-02, -3.6466e-02,\n",
              "                                    -3.4400e-02, -2.0953e-02, -2.7043e-02,  1.1563e-02,\n",
              "                                    -6.3268e-02, -8.3233e-02, -5.9032e-02, -3.4568e-02,\n",
              "                                    -9.2736e-03, -6.7720e-02, -2.5172e-02, -1.4801e-02,\n",
              "                                    -6.3550e-02, -5.4177e-02, -3.1171e-02, -3.1959e-02,\n",
              "                                    -2.4998e-02, -1.5138e-02,  7.1793e-03, -2.8191e-03,\n",
              "                                     1.2839e-02,  4.2432e-03, -7.0462e-03, -3.7678e-02,\n",
              "                                     1.0218e-02, -4.0597e-02,  1.9921e-03, -2.9114e-02,\n",
              "                                    -2.4835e-02, -2.8336e-02, -7.7596e-03, -1.2701e-02,\n",
              "                                     3.6146e-02, -3.8722e-02, -5.7432e-02,  4.7386e-03,\n",
              "                                    -4.2936e-03, -3.5469e-03, -3.4984e-02, -3.3002e-02,\n",
              "                                    -2.0489e-02,  9.5990e-03, -3.8821e-02, -3.2027e-02,\n",
              "                                    -5.7659e-02,  2.6769e-02, -3.1363e-02, -1.6912e-02,\n",
              "                                    -1.0691e-01, -1.8467e-02, -3.7262e-02, -1.6712e-02,\n",
              "                                    -3.8072e-02, -6.3592e-02,  3.2179e-03,  4.4188e-03,\n",
              "                                    -2.8496e-02, -7.6754e-04, -3.3520e-02, -2.1438e-02,\n",
              "                                     4.7404e-03, -4.7908e-02, -3.3716e-02, -1.8166e-02,\n",
              "                                    -2.8121e-02, -3.5148e-02, -3.2906e-02, -2.0015e-02,\n",
              "                                    -3.8599e-02, -2.2153e-02,  1.6182e-02,  7.6502e-03,\n",
              "                                    -6.0349e-03, -6.2174e-02, -3.7160e-02, -3.5791e-02,\n",
              "                                    -4.1963e-02, -7.1542e-02, -4.9551e-02, -2.1859e-02,\n",
              "                                    -1.1077e-02, -1.2195e-02, -5.9880e-02, -2.3834e-02,\n",
              "                                    -1.6995e-02, -7.7900e-02, -4.8851e-02,  4.5411e-03,\n",
              "                                    -2.8523e-02, -1.2590e-02, -7.3639e-02, -1.8086e-03,\n",
              "                                    -1.3060e-02, -4.3316e-02,  6.9504e-03, -2.2318e-02,\n",
              "                                    -1.8297e-02, -5.0422e-02, -6.3796e-02, -1.7961e-02,\n",
              "                                    -1.1440e-02, -6.6898e-02, -5.3690e-02, -3.0222e-02,\n",
              "                                    -2.7508e-02, -7.0043e-03, -2.3042e-02, -1.2668e-02,\n",
              "                                    -1.7245e-02, -3.0087e-02, -3.3778e-02, -1.9964e-02,\n",
              "                                    -3.7469e-02, -4.4967e-02, -5.0829e-04, -1.0556e-02,\n",
              "                                    -3.5745e-02, -4.1510e-02, -1.0129e-02, -1.9264e-02,\n",
              "                                    -2.8073e-02,  1.0006e-02, -1.8737e-02, -1.8030e-02,\n",
              "                                     7.2854e-03,  3.4205e-02, -3.6920e-02, -1.3983e-02,\n",
              "                                    -2.8210e-02, -6.6247e-02, -3.4995e-02,  3.3438e-03,\n",
              "                                    -7.1633e-03, -4.5944e-02, -4.2660e-02, -4.5863e-02,\n",
              "                                     1.8787e-02, -4.3661e-03, -3.2985e-02, -4.7978e-03]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-1.7977e-01, -1.1327e+00,  2.1456e+00, -1.8097e+00,\n",
              "                                     1.1480e+00, -4.4229e-01, -1.2389e-02,  2.1911e+00,\n",
              "                                    -4.1351e+00,  1.6498e+00, -2.3581e+00, -1.4712e+00,\n",
              "                                     1.2794e+00, -3.1408e-01, -9.3277e-01,  1.3118e-01,\n",
              "                                    -1.7316e+00, -3.0425e+00, -4.7656e+00, -2.0623e+00,\n",
              "                                    -1.4721e+00,  2.2555e+00,  9.7897e-01, -2.4026e+00,\n",
              "                                    -2.1712e+00, -1.3770e-01, -2.4835e+00, -4.9987e-01,\n",
              "                                    -8.1735e-01,  1.3597e-02,  6.1063e-01, -1.3851e+00,\n",
              "                                    -6.9558e-01, -4.9413e-01,  1.6105e+00,  5.2189e-02,\n",
              "                                    -5.1176e-01, -8.5874e-01, -8.2887e-02, -7.8159e-01,\n",
              "                                    -1.6894e+00,  2.1971e-01, -1.8193e+00,  4.4763e-01,\n",
              "                                     6.8691e-01, -2.8863e+00,  1.9770e+00,  4.9509e-01,\n",
              "                                    -1.7607e+00, -1.0385e-01, -1.4925e+00,  9.5837e-02,\n",
              "                                    -2.2326e+00,  7.8830e-01,  3.0850e-01, -3.1768e-01,\n",
              "                                    -1.4564e+00, -1.7545e+00, -1.4780e+00, -4.4456e+00,\n",
              "                                     2.6594e+00, -2.2562e-01,  6.8932e-01,  1.0013e+00,\n",
              "                                    -8.3521e-01, -9.8374e-01,  4.2738e-01,  4.4869e-01,\n",
              "                                     3.7838e-01, -6.7197e-01,  2.7284e+00,  2.4362e+00,\n",
              "                                     1.2303e+00,  1.4964e+00,  3.0601e+00,  8.3684e-01,\n",
              "                                    -2.7530e+00, -1.4831e+00,  1.9330e-01,  2.4440e+00,\n",
              "                                     5.0344e-01, -2.6917e+00, -1.2285e+00,  4.2198e-01,\n",
              "                                    -1.9862e+00, -3.4912e-02, -2.9178e+00,  1.2709e-01,\n",
              "                                     3.3388e+00,  5.8041e-01,  1.9135e+00, -3.3802e-01,\n",
              "                                    -4.2881e+00,  3.6756e-01,  1.5379e+00, -4.8536e-01,\n",
              "                                     2.0582e+00, -1.3067e+00, -3.0675e+00,  3.7472e-01,\n",
              "                                    -1.1450e+00, -2.2023e+00, -1.9755e+00,  1.4417e+00,\n",
              "                                    -9.6325e-01,  1.2442e-01, -2.7459e+00, -7.3268e-01,\n",
              "                                    -3.9999e+00,  2.3467e+00, -1.0085e+00, -3.9293e-03,\n",
              "                                     5.2378e-01, -6.5320e-01, -1.1566e+00,  2.9873e+00,\n",
              "                                     2.3703e-02, -5.0497e-01, -1.6557e+00, -4.5971e-01,\n",
              "                                    -1.4929e+00,  7.6091e-02,  9.4496e-01, -1.0492e+00,\n",
              "                                    -1.7512e-01,  1.8729e+00, -3.2700e+00,  1.0956e+00,\n",
              "                                    -4.1409e-01,  8.1324e-01,  6.2333e-01,  2.1024e-01,\n",
              "                                    -4.8097e-01,  1.1636e+00, -2.8297e+00, -1.0546e+00,\n",
              "                                    -8.5343e-01,  3.0897e+00, -2.7894e+00, -1.3846e+00,\n",
              "                                    -1.0545e+00,  7.0562e-01, -3.7097e+00,  7.8135e-01,\n",
              "                                    -4.3746e-02, -1.2276e+00, -1.4102e+00, -8.0055e-01,\n",
              "                                    -2.5255e+00, -1.0368e+00, -3.1764e+00, -1.8472e+00,\n",
              "                                    -7.6298e-02, -2.8073e+00,  1.6741e+00,  1.0466e+00,\n",
              "                                     2.4948e+00, -1.9458e-03, -3.7200e+00,  1.1281e+00,\n",
              "                                    -1.3702e+00, -1.9174e+00, -3.7900e+00,  1.9207e+00,\n",
              "                                     1.4498e+00,  2.1271e+00, -8.1119e-02,  1.6404e+00,\n",
              "                                     1.8653e+00,  1.3211e+00,  3.8616e-01, -2.1613e+00,\n",
              "                                    -1.7471e+00,  6.4329e-01,  7.3867e-01,  2.1483e+00,\n",
              "                                    -6.7223e-02,  1.3317e+00,  5.5246e-01,  1.0816e+00,\n",
              "                                    -3.9249e-01, -3.4493e+00,  3.0009e+00, -2.9199e+00,\n",
              "                                    -1.3508e+00, -2.2993e+00, -3.3932e+00, -1.1485e+00,\n",
              "                                    -1.7615e+00, -1.7060e-01,  2.6023e+00, -2.9995e+00,\n",
              "                                    -1.2006e+00,  7.5824e-01, -2.0810e+00, -1.2867e+00,\n",
              "                                    -3.1796e+00,  1.2907e+00,  1.9101e+00,  2.2390e-01,\n",
              "                                    -3.0607e+00,  2.5201e+00, -4.4433e+00,  1.3934e+00,\n",
              "                                    -1.5031e+00,  8.4102e-02,  4.2488e-01, -1.6068e+00,\n",
              "                                    -5.5237e-01,  1.6549e-01, -2.0362e+00,  3.0344e+00,\n",
              "                                    -1.1958e+00, -5.5543e-01, -1.5255e+00,  1.4124e-01,\n",
              "                                    -1.9881e+00, -4.3892e+00, -2.2495e+00, -7.9214e-01,\n",
              "                                    -3.5791e-01,  7.5910e-02,  2.6102e+00,  1.9596e-01,\n",
              "                                    -1.7822e+00, -2.0183e+00, -2.1740e+00,  1.4784e+00,\n",
              "                                     3.6196e-02, -3.0270e-01, -1.8838e+00, -1.2420e+00,\n",
              "                                    -3.4624e+00, -2.9494e+00, -2.3450e+00,  1.6664e+00,\n",
              "                                    -2.1142e+00, -2.1986e+00,  9.5530e-01, -2.8883e+00,\n",
              "                                     3.6672e+00, -2.6080e+00,  1.6569e+00, -1.8807e+00,\n",
              "                                    -5.7225e+00,  1.3545e+00,  1.8770e+00, -1.2206e+00,\n",
              "                                    -2.0129e+00,  2.1253e+00, -7.3010e-01,  1.3473e+00,\n",
              "                                    -1.5286e+00, -2.1937e-01,  6.2877e-01,  2.6483e-01]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([ 9.4373,  8.7464, 15.4820, 11.9832, 15.0761, 10.8506,\n",
              "                                    10.4391, 14.4226, 28.2590, 23.3619, 21.2676,  8.0725,\n",
              "                                     9.4583, 12.6071, 13.6684, 16.5793,  8.4652, 11.2706,\n",
              "                                     6.7232, 14.8852,  9.4992,  8.4544, 21.4354, 13.7080,\n",
              "                                    29.4925, 17.3327, 14.4002,  7.8188, 10.5647, 11.5530,\n",
              "                                    11.7961, 16.9017,  8.5738, 15.7896, 14.4018, 11.4264,\n",
              "                                    14.4355, 10.3435,  7.4968,  9.2946, 11.8920, 10.3611,\n",
              "                                     7.6242, 16.9088, 14.4441, 15.1565, 16.2683, 12.3045,\n",
              "                                    15.6306,  9.3166, 18.5560,  8.9280, 16.6669, 12.8844,\n",
              "                                    16.6036,  8.0735, 20.1767,  9.4347, 18.4328,  9.5738,\n",
              "                                     9.2377, 12.2270, 10.6938, 10.2119,  6.7932, 13.6641,\n",
              "                                    16.4092, 10.9941,  9.4147,  7.9840, 10.3057, 27.6629,\n",
              "                                    11.2885, 13.5844, 32.6095, 17.8522, 11.2763, 12.3026,\n",
              "                                    15.2586, 15.2067, 15.6934, 16.7851, 14.3629, 12.5252,\n",
              "                                    14.6602, 13.3139,  8.7281,  7.7657, 13.7894, 10.8693,\n",
              "                                    25.6909, 14.6534, 14.5788, 10.0016, 13.9811, 15.1686,\n",
              "                                    17.9391, 18.1645, 20.5833, 16.5069, 10.2087, 12.2183,\n",
              "                                     7.9200, 11.1871, 18.2133, 11.7830, 20.1590,  8.4484,\n",
              "                                    11.6205, 16.3513, 12.8419, 15.4724, 12.8322, 13.6022,\n",
              "                                    14.9017, 13.3787, 17.4426, 14.1985, 20.3379,  8.8253,\n",
              "                                     9.2409, 12.8546,  9.7229, 12.1815, 22.3829, 14.8955,\n",
              "                                    18.2287, 13.0527,  8.6876, 12.5504, 10.0738, 11.2719,\n",
              "                                    13.6399, 10.6408, 19.4908, 13.2241, 18.0754, 20.1886,\n",
              "                                    19.7372, 12.5756, 11.9592, 15.1623,  9.0599, 14.4350,\n",
              "                                    12.9488,  8.3235,  8.3169, 12.7639, 20.7120,  8.2216,\n",
              "                                    18.3676, 11.0214, 11.3627, 24.5946, 21.6240, 11.3755,\n",
              "                                    18.2570, 12.2668, 14.4128, 10.8144,  8.0174, 12.4780,\n",
              "                                    21.3712, 16.6417,  9.5450, 23.5911, 15.3275, 24.6135,\n",
              "                                    10.8029, 10.6876,  8.0912, 11.8162, 12.4124, 12.6129,\n",
              "                                    10.4335, 14.0844, 10.7562, 12.8293,  7.1225,  7.4680,\n",
              "                                    18.9979, 11.1762, 20.6356, 16.0755, 10.5712, 12.4540,\n",
              "                                    13.7409, 10.6627,  6.3109,  8.5920, 13.9081, 14.7076,\n",
              "                                    14.0152, 10.5522, 11.2350, 16.2460, 15.0165, 11.0124,\n",
              "                                    12.8184, 16.6934, 10.3969, 15.1897, 13.4562, 21.4040,\n",
              "                                    13.6225,  5.5606, 10.6298, 11.9542, 17.6465, 14.0795,\n",
              "                                    12.6419, 22.7278,  6.4241, 16.2185, 12.0000, 15.3973,\n",
              "                                    12.4959, 12.3642, 13.1412, 10.2123, 11.2925, 17.5616,\n",
              "                                    12.7812,  5.0298, 16.4232, 10.9534, 16.9739,  5.9249,\n",
              "                                    11.3494, 15.6785, 26.8398,  7.0594, 18.0645, 11.7011,\n",
              "                                    12.9971, 11.3492,  6.5747,  9.5378, 16.3999,  9.0699,\n",
              "                                    24.3082, 17.2882, 20.5987, 17.7781, 17.4559, 16.7195,\n",
              "                                    13.4630, 10.1589, 25.7327, 12.6649, 11.9479, 10.0983,\n",
              "                                    10.9715, 15.9800, 12.6300, 12.1412]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  253,  254,  255],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0658,  0.1158,  0.0006,  ...,  0.0093,  0.0703,\n",
              "                                    -0.0179]),\n",
              "                     size=(1024, 256, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.9746, 0.9975, 0.9860,  ..., 1.0074, 1.0084, 0.9849]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.0151, -0.0154, -0.0321,  ..., -0.0579, -0.0169,\n",
              "                                    -0.0629]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([ 0.4954, -0.6777,  0.1362,  ...,  0.2535, -0.4899,\n",
              "                                     0.0087]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.9191, 0.5727, 1.0152,  ..., 0.5061, 0.8150, 0.5582]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.4.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  255,  255,  255],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.2042, -0.0868, -0.0948,  ...,  0.2268,  0.0371,\n",
              "                                    -0.0457]),\n",
              "                     size=(256, 1024, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9890, 0.9758, 0.9830, 0.9893, 0.9629, 1.0067, 1.0438,\n",
              "                                    0.9785, 1.0239, 1.0294, 1.0066, 0.9994, 1.0508, 1.0142,\n",
              "                                    1.0020, 1.0298, 0.9846, 0.9986, 0.9983, 0.9974, 0.9656,\n",
              "                                    1.0303, 1.0413, 1.0208, 0.9923, 0.9873, 0.9850, 1.0067,\n",
              "                                    1.0118, 0.9465, 1.0275, 1.0665, 1.0537, 1.0110, 0.9933,\n",
              "                                    1.0412, 1.0867, 1.0226, 1.0247, 0.9264, 1.0055, 1.0128,\n",
              "                                    1.0207, 1.0053, 0.9895, 0.9783, 0.9691, 1.0333, 0.9540,\n",
              "                                    0.9495, 0.9737, 0.9569, 1.0001, 1.0148, 0.9852, 1.0602,\n",
              "                                    1.0117, 0.9592, 0.9981, 0.9837, 0.9754, 0.9883, 1.0052,\n",
              "                                    0.9858, 0.9717, 0.9802, 1.0001, 0.9991, 0.9655, 1.0115,\n",
              "                                    1.0046, 0.9533, 1.0228, 0.9618, 1.0111, 1.0607, 0.9802,\n",
              "                                    0.9884, 0.9593, 1.0379, 1.0230, 0.9821, 1.0146, 0.9958,\n",
              "                                    0.9834, 1.0434, 1.0289, 1.0107, 0.9682, 1.0406, 1.0480,\n",
              "                                    1.0020, 1.0550, 1.0044, 0.9734, 1.0083, 0.9871, 1.0413,\n",
              "                                    0.9540, 0.9622, 1.0145, 0.9993, 0.9696, 1.0180, 0.9978,\n",
              "                                    0.9786, 1.0334, 0.9862, 0.9939, 0.9739, 0.9712, 1.0056,\n",
              "                                    0.9806, 1.0383, 0.9951, 1.0301, 0.9872, 0.9895, 0.9981,\n",
              "                                    1.0063, 0.9357, 1.0257, 0.9796, 1.0047, 0.9840, 0.9698,\n",
              "                                    0.9869, 1.0106, 0.9573, 1.0117, 0.9984, 0.9592, 1.0410,\n",
              "                                    1.0012, 0.9971, 0.9412, 0.9691, 0.9851, 0.9810, 0.9767,\n",
              "                                    0.9605, 0.9732, 0.9597, 1.0440, 0.9821, 1.0134, 0.9849,\n",
              "                                    0.9906, 1.0041, 1.0031, 0.9965, 1.0076, 1.0087, 0.9684,\n",
              "                                    1.0230, 1.0273, 1.0188, 0.9823, 1.0074, 1.0435, 0.9839,\n",
              "                                    1.0198, 1.0022, 1.0061, 0.9842, 0.9884, 1.0175, 0.9801,\n",
              "                                    0.9903, 1.0166, 1.0553, 1.0069, 1.0420, 0.9667, 0.9988,\n",
              "                                    1.0022, 0.9835, 1.0003, 0.9783, 0.9994, 0.9903, 0.9834,\n",
              "                                    0.9926, 0.9781, 0.9899, 1.0250, 1.0263, 0.9717, 0.9889,\n",
              "                                    0.9919, 0.9568, 0.9949, 0.9668, 1.0003, 0.9936, 0.9883,\n",
              "                                    1.0026, 0.9854, 1.0136, 1.0014, 1.0127, 0.9882, 0.9959,\n",
              "                                    1.0132, 1.0097, 0.9887, 1.0062, 0.9812, 0.9995, 0.9687,\n",
              "                                    1.0401, 0.9720, 1.0058, 1.0321, 0.9911, 0.9524, 0.9659,\n",
              "                                    0.9852, 0.9819, 0.9489, 1.0518, 0.9686, 1.0038, 1.0247,\n",
              "                                    0.9950, 1.0206, 0.9840, 1.0280, 1.0153, 0.9817, 0.9605,\n",
              "                                    0.9996, 0.9682, 0.9851, 0.9863, 0.9569, 0.9654, 1.0575,\n",
              "                                    1.0281, 1.0324, 0.9649, 0.9672, 0.9452, 0.9121, 1.0053,\n",
              "                                    1.0151, 0.9719, 0.9917, 0.9840, 1.0219, 1.0205, 1.0259,\n",
              "                                    1.0155, 1.0242, 0.9782, 1.0202]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-0.0059,  0.0175, -0.0592, -0.0044, -0.0147, -0.0060,\n",
              "                                    -0.0074, -0.0121, -0.0568,  0.0488, -0.0064, -0.0076,\n",
              "                                    -0.0375, -0.0063,  0.0006, -0.0023, -0.0374, -0.0543,\n",
              "                                    -0.0534, -0.0057, -0.0750, -0.0182,  0.0312, -0.0179,\n",
              "                                     0.0006, -0.0059, -0.0059, -0.0138, -0.0253, -0.0556,\n",
              "                                    -0.0591,  0.0448,  0.0526, -0.0074,  0.0056, -0.0610,\n",
              "                                     0.0137, -0.0127,  0.0351, -0.0260,  0.0034,  0.0033,\n",
              "                                    -0.0124,  0.0276, -0.0060, -0.0149, -0.0044, -0.0002,\n",
              "                                    -0.0671, -0.0392, -0.0004,  0.0027, -0.0148, -0.0355,\n",
              "                                    -0.0402, -0.0552, -0.0148, -0.0503, -0.0322, -0.0103,\n",
              "                                    -0.0154, -0.0321,  0.0007, -0.0330,  0.0157, -0.0184,\n",
              "                                    -0.0010,  0.0123,  0.0126, -0.0015,  0.0233, -0.0600,\n",
              "                                     0.0186, -0.0375, -0.0065, -0.0342, -0.0440, -0.0058,\n",
              "                                    -0.0355,  0.0059,  0.0205, -0.0193,  0.0234, -0.0047,\n",
              "                                    -0.0264,  0.0667, -0.0032,  0.0047, -0.0509, -0.0083,\n",
              "                                     0.0148, -0.0232, -0.0298, -0.0390, -0.0137, -0.0125,\n",
              "                                    -0.0163, -0.0141, -0.0429, -0.0773, -0.0162, -0.0392,\n",
              "                                    -0.0524,  0.0301,  0.0016, -0.0204, -0.0034,  0.0015,\n",
              "                                    -0.0185, -0.0271, -0.0565, -0.0285, -0.0708,  0.0008,\n",
              "                                    -0.0207,  0.0042, -0.0194, -0.0248, -0.0018, -0.0102,\n",
              "                                    -0.0359,  0.0180, -0.0300,  0.0003,  0.0175, -0.0233,\n",
              "                                    -0.0192,  0.0071, -0.0497, -0.0037,  0.0091, -0.0691,\n",
              "                                     0.0270,  0.0153, -0.0318, -0.0428, -0.0551, -0.0486,\n",
              "                                    -0.0079, -0.0141, -0.0428,  0.0011, -0.0465, -0.0169,\n",
              "                                    -0.0142,  0.0148, -0.0004, -0.0598, -0.0007,  0.0199,\n",
              "                                    -0.0118, -0.0126,  0.0334, -0.0227, -0.0224,  0.0020,\n",
              "                                    -0.0033, -0.0465, -0.0301,  0.0525, -0.0099, -0.0322,\n",
              "                                    -0.0352, -0.0238, -0.0339, -0.0445, -0.0228, -0.0154,\n",
              "                                    -0.0198, -0.0365,  0.0286, -0.0539,  0.0518, -0.0710,\n",
              "                                    -0.0008,  0.0196, -0.0186,  0.0030,  0.0016,  0.0019,\n",
              "                                    -0.0246, -0.0374, -0.0053, -0.0224, -0.0129, -0.0024,\n",
              "                                    -0.0208, -0.0104, -0.0016,  0.0290, -0.0242, -0.0197,\n",
              "                                    -0.0198, -0.0424, -0.0116,  0.0269, -0.0092, -0.0488,\n",
              "                                     0.0377, -0.0031,  0.0217, -0.0458,  0.0227, -0.0312,\n",
              "                                    -0.0069, -0.0283, -0.0192,  0.0114, -0.0535, -0.0289,\n",
              "                                     0.0026, -0.0488, -0.0087, -0.0130, -0.0141, -0.0597,\n",
              "                                    -0.0696,  0.0060, -0.0211, -0.0179, -0.0523, -0.0135,\n",
              "                                     0.0325,  0.0123, -0.0113,  0.0220, -0.0258, -0.0495,\n",
              "                                     0.0088, -0.0299, -0.0282, -0.0325, -0.0244,  0.0052,\n",
              "                                    -0.0236, -0.0327, -0.0218,  0.0191, -0.0066, -0.0458,\n",
              "                                    -0.0178, -0.0235, -0.0369, -0.0467, -0.0193, -0.0246,\n",
              "                                    -0.0301, -0.0350, -0.0093,  0.0006, -0.0284, -0.0589,\n",
              "                                     0.0235, -0.0001,  0.0129,  0.0091]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([  3.8514,   1.9198,  -3.3954,  -7.4599, -18.1029,\n",
              "                                    -11.6385,   3.1312,  -7.6903,  -1.6754, -14.1347,\n",
              "                                      5.6424,  -0.0572,  -4.2182,  -2.1879,   4.8663,\n",
              "                                      1.4098, -10.7098,   8.3190,   4.1702,  -5.2288,\n",
              "                                      1.5646,   1.1952,  11.1618,  -0.7153,  -2.4314,\n",
              "                                     -2.5034,  -7.4770,  -9.2334,   2.6765, -16.9776,\n",
              "                                      5.2805,   2.2629, -12.2327,  -7.1366,   0.3538,\n",
              "                                      1.3025,  -0.7145,  -0.5195,   7.8085,  -6.3923,\n",
              "                                     -1.4574,  -0.2247,  -3.4790, -15.6027,   3.0628,\n",
              "                                     -9.0937,  -2.6710,  -0.2791,   4.6079,  -5.2291,\n",
              "                                     -2.1992,  -3.5156,   2.5577,   1.2449,  -6.1010,\n",
              "                                      1.7682,  -1.2578,  -6.8485,  -6.9199, -10.6657,\n",
              "                                    -17.5531,  -9.9902,  -7.3916,  -3.5217,   3.4377,\n",
              "                                      6.5720,  -2.1316, -10.2200,   1.3559,   2.1263,\n",
              "                                     13.7453,  -7.7194,  -2.9974,  -1.8467,  -8.2522,\n",
              "                                      1.2381,  -1.7453,  -6.1420, -11.4281,   6.6278,\n",
              "                                     -5.8804, -19.2053,   6.3862,   0.8660,  -1.7897,\n",
              "                                     -3.8539, -10.1752,  -4.1435, -13.2791,   4.8265,\n",
              "                                      1.4491,   0.3952,   2.9862,  -6.3718,  12.8650,\n",
              "                                      1.9517,   5.5253,   0.9074,  -7.5561,  -1.8814,\n",
              "                                      0.0581,  -5.7146,   0.7761,  -7.5218, -13.9114,\n",
              "                                     -9.4326,  -2.6232, -11.0313, -14.5097,  11.5546,\n",
              "                                     13.8589,   3.7530,   0.3464,  -3.9702,   0.7546,\n",
              "                                     10.2061,  -2.3885, -15.0899,  -3.1044,   1.7797,\n",
              "                                      7.5307,  -4.7032,   0.9020, -14.5859,  -2.5286,\n",
              "                                    -16.5455,  -8.5251,  -0.6053,   0.5913,   1.7203,\n",
              "                                    -13.9757,   1.9367,  -0.3133, -10.3792,  -3.4112,\n",
              "                                     11.8281,  -7.7265, -13.3734,   3.6236,  -1.1715,\n",
              "                                      8.2520,  -6.5425,   9.3261,  -2.1627,  -7.3053,\n",
              "                                     -3.6396,  -9.2037,  -4.7343,   5.2365, -11.4667,\n",
              "                                     -9.9807, -11.6745,  -6.9618,  -0.3564,  -6.5651,\n",
              "                                     -4.9490, -11.2610,   5.5853,  -0.6494, -16.1516,\n",
              "                                      1.0291,  -6.4565,  -4.5471,   2.2467,  -2.0630,\n",
              "                                     10.1516,  -3.8751,   9.0545,  -2.2204,   7.7511,\n",
              "                                    -11.9841,   1.5452,  -1.8551,   2.9538,  -3.7738,\n",
              "                                     -4.7779,  10.5672,   1.0449,  -8.6139,  -2.1394,\n",
              "                                     13.6334,  -4.6909,  -6.6072,  -6.7317,   1.0755,\n",
              "                                     -5.1978,   3.6248,  -1.7758,  -5.7638,  -2.4549,\n",
              "                                      4.6293,  -2.5974,  -0.1423,  -4.4345,   2.3807,\n",
              "                                     -4.4841,  -5.5769,  -8.0614,  -5.6611,   3.6568,\n",
              "                                     -5.6231,   3.6872, -12.9741,   0.6252,  -2.7184,\n",
              "                                      8.5975,  -4.7264, -10.5557,   3.3103, -10.3013,\n",
              "                                     -0.5127,  -8.6334,   5.7870,   3.4040,  -7.2083,\n",
              "                                      0.9059,   2.8307,  -2.6070, -13.0072,   8.8589,\n",
              "                                     -5.4943,   6.1432,  -8.9962,  -5.9706,  -5.4669,\n",
              "                                    -13.4842,   5.0871,   2.4115,  -2.0197,  -6.4340,\n",
              "                                     -3.8968,  -3.9701, -10.4962, -10.3547,  -7.8585,\n",
              "                                    -12.4338,   3.4233,  -1.1016, -17.0165,   1.6411,\n",
              "                                     -2.7144,   6.9636,   3.8013,  12.5168,   1.1348,\n",
              "                                      1.5270,  -5.8027,  -2.9413,   3.1655,  -1.6330,\n",
              "                                      4.6321,   0.2772,  -0.2443,   4.7579,   8.5477,\n",
              "                                      0.5760]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([220.6705, 158.9124, 130.7170,  90.0348, 179.8735,\n",
              "                                    225.5867, 143.8236, 193.1032, 124.8193, 200.0623,\n",
              "                                    156.6463, 127.3319, 161.9086, 162.7696, 127.1793,\n",
              "                                    228.4026, 302.9296, 139.9175, 179.0685, 145.1795,\n",
              "                                    173.0367, 207.8116, 324.2704, 127.4891, 127.2613,\n",
              "                                    165.2642, 144.9361, 115.3421, 244.9167, 193.3456,\n",
              "                                     99.6311, 145.6644, 250.1583, 126.9276, 132.3328,\n",
              "                                     80.4731, 138.6489, 120.7380, 176.6852, 151.1017,\n",
              "                                    143.6718, 153.6694, 132.4034, 159.8534,  89.2647,\n",
              "                                    294.8266, 136.0462, 131.2698,  99.2287, 159.5747,\n",
              "                                     82.2416, 103.3433, 139.8838, 228.8090,  98.0760,\n",
              "                                    191.3636, 162.3164, 112.5252, 145.4930, 203.4194,\n",
              "                                    239.0240, 185.3497,  71.4476, 164.8264, 139.6987,\n",
              "                                    132.5841, 107.9433, 188.4541, 214.3433, 155.2874,\n",
              "                                    181.5466, 196.3657, 106.9523, 117.2008, 151.9135,\n",
              "                                    126.3220, 173.5908, 186.2719, 213.6707, 144.8444,\n",
              "                                     87.7772, 205.1662, 225.4561,  86.3308, 178.0002,\n",
              "                                    187.9727, 186.4447, 167.1929, 267.1635, 293.9089,\n",
              "                                    140.6791,  72.5761, 195.2881,  99.1635, 160.2425,\n",
              "                                    214.1519, 239.5561, 169.4931, 188.2544, 144.6029,\n",
              "                                    160.9845, 128.9441, 128.4353,  94.9722, 181.9078,\n",
              "                                    189.9355, 206.7230, 190.4492, 355.1733, 397.6547,\n",
              "                                    147.9977, 160.1140,  93.6359,  55.1199, 114.1087,\n",
              "                                     96.0232,  99.4540, 205.9568,  86.5250, 122.4862,\n",
              "                                    142.1548, 130.5432, 106.5764, 278.1227, 111.0766,\n",
              "                                    148.2819, 170.8515, 192.3524, 133.0170, 121.1251,\n",
              "                                    184.5233,  77.6021, 158.7045, 223.3534, 112.9098,\n",
              "                                    212.1565, 108.5166, 265.2384, 149.6432, 165.0974,\n",
              "                                    165.8054, 174.0473, 165.8961, 128.9356, 145.9487,\n",
              "                                    120.1186, 153.4117, 140.5463, 328.1747, 175.5498,\n",
              "                                    133.6933, 193.2011, 177.4085, 115.6715, 128.8537,\n",
              "                                    165.9227, 142.8275, 157.4400, 175.8275, 155.8247,\n",
              "                                    217.8452, 124.4955, 127.1596, 111.7656,  96.0760,\n",
              "                                     70.6769, 159.3689, 153.0852, 165.5630, 155.4630,\n",
              "                                    158.8146, 173.9503, 165.6850, 112.0599, 125.7683,\n",
              "                                    131.2764, 176.7233, 103.3198, 160.1371, 124.9504,\n",
              "                                    131.0936, 103.4854, 115.0802, 126.9268, 175.7963,\n",
              "                                    185.2398, 259.7238, 206.5604, 113.8385, 113.3841,\n",
              "                                    224.6466, 122.1941, 116.2213, 115.7627, 165.7215,\n",
              "                                    121.3862, 143.5189, 270.8072, 169.5273, 210.4662,\n",
              "                                    115.3017, 135.1085, 177.1359, 120.2579, 158.4591,\n",
              "                                    208.2304, 151.0092, 237.3295, 109.9269, 188.4524,\n",
              "                                    195.4371, 133.9505, 142.0542, 160.4037, 120.4309,\n",
              "                                    114.4586, 107.2695,  70.6914, 210.8907, 196.0955,\n",
              "                                    110.5092, 134.5095, 156.7742, 252.2576,  83.6678,\n",
              "                                    194.7547, 212.6014, 100.5358, 187.0886, 138.7950,\n",
              "                                    145.8944, 172.1468, 188.4613, 236.0117, 121.3406,\n",
              "                                    212.6113, 203.3463, 180.7409, 173.6585, 185.3870,\n",
              "                                     55.7738, 166.8405, 152.8712, 332.3759, 174.7270,\n",
              "                                    150.3534, 180.1493, 156.1737, 187.2510, 124.8433,\n",
              "                                    157.7604, 140.5927, 123.5302, 163.4417, 194.5669,\n",
              "                                    119.8066]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ..., 255, 255, 255],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([-0.0742, -0.0574,  0.0395,  ...,  0.0076, -0.0435,\n",
              "                                     0.0153]),\n",
              "                     size=(256, 256, 3, 3), nnz=589824, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([0.9925, 0.9784, 0.9980, 1.0120, 0.9815, 0.9850, 0.9530,\n",
              "                                    0.9879, 1.0009, 1.0263, 0.9968, 0.9620, 0.9963, 0.9940,\n",
              "                                    1.0073, 0.9857, 1.0172, 0.9740, 0.9627, 1.0389, 0.9833,\n",
              "                                    1.0047, 1.0021, 0.9935, 1.0531, 1.0070, 0.9554, 1.0030,\n",
              "                                    0.9994, 1.0171, 0.9571, 0.9742, 0.9959, 1.0170, 1.0134,\n",
              "                                    0.9466, 0.9694, 0.9388, 0.9986, 1.0001, 0.9720, 1.0618,\n",
              "                                    1.0138, 1.0260, 0.9393, 0.9652, 0.9872, 1.0082, 1.0351,\n",
              "                                    1.0192, 0.9941, 0.9556, 0.9735, 0.9593, 0.9419, 0.9869,\n",
              "                                    0.9688, 0.9727, 1.0585, 1.0200, 1.0038, 0.9682, 0.9752,\n",
              "                                    1.0003, 1.0072, 1.0149, 0.9916, 1.0202, 0.9716, 1.0129,\n",
              "                                    1.0007, 0.9891, 0.9895, 0.9583, 0.9819, 1.0053, 0.9814,\n",
              "                                    1.0147, 0.9791, 1.0703, 0.9867, 1.0055, 1.0259, 1.0408,\n",
              "                                    0.9741, 0.9925, 1.0118, 1.0227, 1.0451, 0.9723, 1.0187,\n",
              "                                    0.9973, 1.0102, 1.0065, 0.9540, 1.0311, 1.0000, 0.9963,\n",
              "                                    1.0231, 1.0076, 0.9845, 0.9757, 1.0592, 1.0210, 0.9848,\n",
              "                                    0.9733, 0.9839, 0.9782, 1.0298, 0.9585, 1.0761, 1.0193,\n",
              "                                    0.9981, 0.9779, 0.9738, 1.0403, 1.0119, 1.0179, 1.0077,\n",
              "                                    1.0463, 1.0212, 0.9967, 1.0298, 0.9949, 1.0307, 0.9691,\n",
              "                                    1.0242, 0.9916, 0.9661, 0.9645, 0.9707, 0.9676, 0.9738,\n",
              "                                    0.9585, 0.9696, 1.0182, 1.0193, 0.9467, 0.9409, 1.0381,\n",
              "                                    0.9928, 0.9874, 0.9691, 0.9519, 0.9834, 0.9940, 0.9837,\n",
              "                                    0.9748, 0.9746, 1.0545, 0.9785, 0.9713, 1.0106, 1.0057,\n",
              "                                    0.9657, 0.9735, 0.9783, 1.0087, 1.0196, 0.9876, 0.9848,\n",
              "                                    1.0265, 0.9973, 0.9296, 0.9901, 0.9900, 0.9493, 0.9695,\n",
              "                                    0.9858, 0.9849, 0.9929, 1.0140, 1.0228, 1.0049, 0.9728,\n",
              "                                    1.0059, 0.9934, 1.0183, 0.9951, 0.9997, 0.9966, 0.9832,\n",
              "                                    0.9928, 1.0336, 0.9531, 0.9869, 0.9915, 0.9771, 0.9877,\n",
              "                                    0.9979, 0.9890, 1.0096, 0.9744, 1.0045, 0.9505, 0.9353,\n",
              "                                    0.9752, 0.9726, 0.9671, 0.9622, 1.0001, 1.0049, 0.9710,\n",
              "                                    0.9795, 1.0374, 1.0277, 0.9676, 0.9883, 1.0649, 0.9875,\n",
              "                                    1.0672, 0.9867, 1.0285, 1.0131, 0.9873, 0.9645, 0.9499,\n",
              "                                    1.0044, 0.9983, 1.0001, 0.9911, 1.0231, 1.0340, 0.9721,\n",
              "                                    0.9698, 1.0076, 0.9978, 1.0305, 0.9978, 1.0237, 0.9881,\n",
              "                                    1.0203, 0.9769, 0.9794, 1.0261, 0.9431, 1.0080, 0.9707,\n",
              "                                    0.9768, 1.0184, 1.0240, 0.9832, 1.0063, 1.0003, 0.9976,\n",
              "                                    0.9745, 1.0175, 1.0055, 0.9737, 0.9996, 0.9696, 1.0183,\n",
              "                                    0.9862, 0.9643, 0.9689, 1.0480]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-0.0445, -0.0213, -0.0081, -0.0477, -0.0871, -0.0340,\n",
              "                                    -0.0327, -0.0413, -0.0097, -0.0400, -0.0041, -0.0361,\n",
              "                                    -0.0299, -0.0348, -0.0179,  0.0016, -0.0704, -0.0205,\n",
              "                                    -0.0448, -0.0692, -0.0104, -0.0446, -0.0217, -0.0333,\n",
              "                                    -0.0491, -0.0025, -0.0751, -0.0411, -0.0047,  0.0212,\n",
              "                                    -0.0485, -0.0002, -0.0212, -0.0009, -0.0933, -0.0232,\n",
              "                                    -0.0613, -0.0573, -0.0587, -0.0337, -0.0066, -0.0576,\n",
              "                                    -0.0292, -0.0073, -0.0714, -0.0446, -0.0552, -0.0108,\n",
              "                                    -0.0022, -0.0072, -0.0188, -0.0404, -0.0496, -0.0728,\n",
              "                                    -0.0209, -0.0782, -0.0284, -0.0403, -0.0603, -0.0338,\n",
              "                                    -0.0327, -0.0094,  0.0013,  0.0344, -0.0094, -0.0447,\n",
              "                                    -0.0286, -0.0356, -0.0324, -0.0225, -0.0496, -0.0096,\n",
              "                                    -0.0199, -0.0071, -0.0195, -0.0426, -0.0098, -0.0304,\n",
              "                                    -0.0113, -0.0804, -0.0452, -0.0488, -0.0285, -0.0610,\n",
              "                                    -0.0029, -0.0571, -0.0284, -0.0207, -0.0533, -0.0304,\n",
              "                                    -0.0643,  0.0070, -0.0273, -0.0240, -0.0034,  0.0025,\n",
              "                                    -0.0165, -0.0252, -0.0366, -0.0812, -0.0624, -0.0536,\n",
              "                                    -0.0931, -0.0238, -0.0448, -0.0420, -0.0477, -0.0418,\n",
              "                                    -0.0624,  0.0072, -0.0609, -0.0166, -0.0163, -0.0438,\n",
              "                                    -0.0129,  0.0329, -0.0468, -0.0574, -0.0333, -0.0375,\n",
              "                                    -0.0301, -0.0108, -0.0382,  0.0227,  0.0127, -0.0224,\n",
              "                                     0.0006, -0.0484, -0.0116, -0.0595, -0.0519, -0.0333,\n",
              "                                    -0.0602,  0.0148, -0.0608,  0.0215, -0.0363, -0.0653,\n",
              "                                    -0.0831, -0.0132, -0.0334, -0.0025, -0.0595, -0.0129,\n",
              "                                    -0.0400, -0.0242, -0.0334, -0.0046, -0.0501, -0.0231,\n",
              "                                    -0.0192, -0.0402, -0.0356, -0.0746, -0.0651, -0.0143,\n",
              "                                    -0.0556, -0.0695,  0.0084, -0.0531, -0.0322, -0.0314,\n",
              "                                    -0.0295, -0.0875, -0.0041, -0.0194, -0.0166, -0.0478,\n",
              "                                    -0.0290, -0.0263,  0.0114, -0.0085,  0.0010, -0.0342,\n",
              "                                    -0.0290, -0.0137, -0.0245, -0.0355, -0.0152, -0.0420,\n",
              "                                    -0.0823, -0.0136, -0.0124, -0.0344, -0.0368, -0.0610,\n",
              "                                    -0.0197, -0.0312,  0.0023, -0.0064, -0.0327, -0.0390,\n",
              "                                    -0.0499, -0.0260, -0.0467, -0.0536, -0.0585, -0.0205,\n",
              "                                    -0.0107, -0.0300, -0.0209, -0.0107, -0.0158, -0.0285,\n",
              "                                    -0.0280, -0.0214, -0.0551, -0.0373,  0.0021, -0.0435,\n",
              "                                    -0.0708, -0.0265, -0.0285, -0.0374, -0.0445, -0.0373,\n",
              "                                    -0.0462, -0.0412, -0.0137, -0.0227, -0.0109, -0.0664,\n",
              "                                    -0.0405, -0.0291, -0.0257, -0.0506, -0.0379,  0.0185,\n",
              "                                    -0.0164, -0.0290, -0.0049, -0.0743, -0.0377, -0.0016,\n",
              "                                     0.0089, -0.0509, -0.0367, -0.0364,  0.0036, -0.0112,\n",
              "                                    -0.0462,  0.0112, -0.0422, -0.0435, -0.0502, -0.0185,\n",
              "                                    -0.0077, -0.0157, -0.0326, -0.0430, -0.0347, -0.0372,\n",
              "                                    -0.0336, -0.0152, -0.0204, -0.0416]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([-0.2089,  1.2100, -1.1537,  0.7755,  1.7594,  0.2168,\n",
              "                                    -3.1888, -3.0006,  1.3973, -1.5429, -0.9707,  0.8039,\n",
              "                                     2.0325,  1.7767, -2.3555, -3.3503,  1.2760, -1.4310,\n",
              "                                    -3.1768,  1.3500,  3.6730,  0.6418,  2.3298,  2.3616,\n",
              "                                    -1.2097, -3.4489,  1.4544,  1.6916, -0.2041, -2.8591,\n",
              "                                    -4.5978,  0.7566, -1.0143,  1.3670,  0.4351, -4.0571,\n",
              "                                    -2.0273, -3.3757,  1.5963,  1.2526, -3.3209,  0.3628,\n",
              "                                    -0.6076,  0.1194, -1.6413, -4.2222, -0.1073,  2.4908,\n",
              "                                     2.0251,  1.3533,  3.1317, -2.7917,  0.4576, -0.2761,\n",
              "                                    -2.4209,  0.5211, -3.2244, -1.6041,  0.8257,  2.4281,\n",
              "                                     1.7389, -3.5054, -0.8664,  0.6577, -0.0150,  0.1118,\n",
              "                                    -1.8499,  1.4460, -2.4925,  0.4891, -1.4455, -1.5507,\n",
              "                                     0.4210, -3.2951,  0.3167, -2.4672, -3.0922, -2.9283,\n",
              "                                    -0.1498,  1.1340,  2.5858, -0.8838,  0.5995,  1.9546,\n",
              "                                     2.0821,  2.3384, -2.1173, -2.0259,  1.3747, -2.9820,\n",
              "                                     1.4588,  2.5315, -0.5873,  0.2969, -0.2752,  0.6223,\n",
              "                                     2.1984, -3.7451,  0.3523,  1.1709, -2.7358,  1.4562,\n",
              "                                     0.6248, -0.8503, -1.5484,  2.5322,  0.7922, -1.6127,\n",
              "                                     0.7990,  1.5517,  1.8252,  0.7557, -0.2347,  2.4735,\n",
              "                                    -2.3379, -0.3775, -1.2258,  0.4955, -1.8426,  0.4956,\n",
              "                                     1.8264, -1.3470, -2.0752,  0.3977,  1.0019, -1.7491,\n",
              "                                    -0.1518, -2.1327,  1.2138, -0.7761, -2.2652, -4.1122,\n",
              "                                     3.8133,  1.4063,  0.2147, -1.7359,  1.8631, -3.2916,\n",
              "                                    -2.4581,  3.5962, -2.2099, -3.6567,  0.7663, -5.0878,\n",
              "                                    -1.6015,  2.1578, -4.7711, -4.0302,  0.0281,  0.2341,\n",
              "                                    -2.9434, -2.3858,  1.8778,  1.3971, -3.5586, -2.9666,\n",
              "                                     0.1187,  2.4536,  0.3108,  3.1373, -3.3967,  0.7669,\n",
              "                                    -1.6615, -1.0852, -2.1785,  2.4336, -0.9367,  0.6033,\n",
              "                                     0.0595, -1.5545, -0.2408,  0.8356,  0.2856, -0.5528,\n",
              "                                    -1.5146, -0.8424,  1.1770,  0.9513,  0.7037, -2.3787,\n",
              "                                     0.2239,  2.2029, -0.4179,  0.9055, -3.0918,  1.0755,\n",
              "                                    -0.0978,  1.9724, -5.6695, -1.0075,  1.8474, -3.6877,\n",
              "                                    -0.7106,  0.6740, -3.6522, -5.4967, -2.5187, -0.1879,\n",
              "                                    -2.2029, -3.5181,  0.8465,  1.0240, -1.8867,  0.9243,\n",
              "                                     0.7378, -0.7734, -2.6098, -0.2118, -0.7914, -0.7347,\n",
              "                                     0.4968, -3.5377,  2.5469, -0.6688,  2.3163,  0.1731,\n",
              "                                    -3.2821, -0.1333, -3.9297, -1.0892, -2.1004,  0.6618,\n",
              "                                    -1.5690,  1.5956, -0.7109, -0.2402, -0.0148,  0.6563,\n",
              "                                     2.3008,  2.0369,  2.3935,  1.1627, -3.5375, -2.5128,\n",
              "                                    -0.2552, -1.8986, -0.8565, -0.1112, -3.4112,  1.9179,\n",
              "                                     2.2537, -2.6830,  1.4153,  0.7050, -1.5206,  2.0142,\n",
              "                                    -0.5325, -1.1568, -2.8698, -0.0274, -2.8978, -1.4828,\n",
              "                                    -0.1155, -2.8174, -3.9717, -0.7296]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255]]),\n",
              "                     values=tensor([15.0949, 11.7859, 14.4759, 11.5363, 11.1830, 10.0769,\n",
              "                                    17.5671, 17.1748, 12.4856, 10.9751, 10.6921, 15.2276,\n",
              "                                     6.3669, 13.8052, 19.9428, 25.4651,  9.4113,  8.5753,\n",
              "                                     9.9002, 14.8650, 32.1357,  8.4532, 20.8848, 14.1784,\n",
              "                                    13.2040, 15.1608,  9.6328, 16.5770, 11.3171, 14.2183,\n",
              "                                    24.4970, 14.0997, 12.9729, 12.2331, 13.1821, 14.8945,\n",
              "                                    11.1029, 18.2393, 13.5517, 12.3716, 15.0936, 19.4017,\n",
              "                                    14.0992, 16.8087,  6.8583, 20.6092, 10.7570, 13.3978,\n",
              "                                    16.0102, 14.5122, 25.6178, 16.3289, 13.4671,  8.5295,\n",
              "                                    16.1627, 13.1567, 16.0989,  8.6901, 21.8001, 18.3933,\n",
              "                                    12.5300, 20.2668, 10.2048,  9.6196, 14.7964, 11.3139,\n",
              "                                     9.2227, 11.6385, 14.0106, 17.5617, 18.1059, 15.6325,\n",
              "                                    10.3962,  9.6272, 12.1311, 20.5442, 15.6237, 14.5837,\n",
              "                                    14.4487, 14.1464, 23.3940,  9.0055, 11.3797, 17.0133,\n",
              "                                    17.5123, 14.1798, 14.7210, 14.6012,  7.9782, 17.2980,\n",
              "                                    14.0447, 21.6905, 13.9546, 16.9519, 14.9052, 12.2596,\n",
              "                                    26.7830, 13.1336, 22.2523, 10.5600, 11.2508, 25.0308,\n",
              "                                    12.3803, 16.2334, 11.2036, 23.6162, 13.1220, 10.4803,\n",
              "                                    12.1493, 10.5725, 18.3096, 12.7935, 10.0182, 13.2853,\n",
              "                                    11.4546, 14.0394, 11.5710, 15.0726,  9.8207, 16.6592,\n",
              "                                    14.0064, 12.5611, 11.6122, 11.7552, 21.8267, 20.3190,\n",
              "                                    12.2832, 10.5582, 17.4268,  7.7245, 21.2023, 22.1537,\n",
              "                                    23.6852, 14.8891, 12.5778, 14.7905, 22.6629, 16.2954,\n",
              "                                     9.7326, 12.7290, 13.1239, 18.5168, 14.1474, 24.8170,\n",
              "                                     9.5876, 17.0686, 16.4449, 16.6292, 14.1888, 14.4255,\n",
              "                                    14.1956,  9.3627, 15.7315,  8.4186, 18.4199, 13.7356,\n",
              "                                    15.1218, 11.4625, 12.7588, 24.5635,  9.8464, 19.1504,\n",
              "                                     9.5679,  8.5180, 12.0434, 15.6703, 18.2673, 13.8120,\n",
              "                                    12.3321, 17.7497, 11.2168, 10.4678,  9.3677,  9.9574,\n",
              "                                    10.7797, 20.2066,  9.2415, 13.3788, 13.8092, 11.7805,\n",
              "                                    15.4714, 19.3728,  8.8367, 15.1640, 10.3539, 13.8202,\n",
              "                                    14.8011, 15.9972, 27.9585,  8.8619, 10.1258, 16.8165,\n",
              "                                    11.5387, 11.6008, 14.9130, 16.0941, 17.2841, 12.8560,\n",
              "                                    20.0168, 12.5279, 12.7949, 10.1077, 11.6459, 16.2112,\n",
              "                                    14.1430,  8.6337, 19.0675, 16.6443, 27.8414, 12.3266,\n",
              "                                    13.2158, 24.8487, 17.1313, 10.4245, 11.2644,  9.7152,\n",
              "                                    14.0958, 12.0639, 18.6209, 11.4909, 13.3006, 16.8131,\n",
              "                                    12.9057, 14.1972, 11.7772, 12.8465,  9.6659, 13.3342,\n",
              "                                    14.4127, 15.0642, 13.8864, 11.3647, 16.3105, 17.1306,\n",
              "                                    13.4835,  8.8122,  8.4098,  9.7075, 20.7019, 15.3481,\n",
              "                                    18.4412, 14.2016, 15.4124, 14.1488, 13.5757, 15.2201,\n",
              "                                    14.4673, 15.1671,  8.7973,  7.7579, 15.3539, 15.6370,\n",
              "                                    18.1108, 16.9848, 14.0917, 15.2799]),\n",
              "                     size=(256,), nnz=256, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 1023, 1023, 1023],\n",
              "                                     [   0,    1,    2,  ...,  253,  254,  255],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0139, -0.0395,  0.0924,  ..., -0.0387, -0.0057,\n",
              "                                     0.0455]),\n",
              "                     size=(1024, 256, 1, 1), nnz=262144, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([0.9981, 0.9934, 0.9920,  ..., 0.9910, 1.0029, 0.9548]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.0029,  0.0144,  0.0263,  ..., -0.0578, -0.0043,\n",
              "                                    -0.0383]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([-0.2864, -0.7673, -0.1641,  ..., -0.0658, -0.3273,\n",
              "                                    -0.1894]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]]),\n",
              "                     values=tensor([1.1529, 1.0584, 1.5868,  ..., 0.5545, 0.9517, 0.6701]),\n",
              "                     size=(1024,), nnz=1024, layout=torch.sparse_coo)),\n",
              "             ('layer3.5.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  511,  511,  511],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0840,  0.0381, -0.0124,  ..., -0.0137,  0.0609,\n",
              "                                    -0.0200]),\n",
              "                     size=(512, 1024, 1, 1), nnz=524288, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9384, 1.0153, 0.9732, 0.9978, 0.9889, 1.0387, 0.9970,\n",
              "                                    1.0138, 0.9698, 1.0333, 1.0613, 1.0001, 1.0132, 0.9641,\n",
              "                                    1.0295, 1.0031, 1.0104, 0.9772, 0.9848, 0.9894, 1.0112,\n",
              "                                    0.9964, 0.9712, 0.9829, 0.9657, 1.0041, 0.9756, 0.9957,\n",
              "                                    0.9781, 0.9766, 0.9659, 1.0510, 1.0250, 0.9976, 1.0201,\n",
              "                                    1.0279, 0.9807, 0.9969, 0.9976, 0.9890, 1.0314, 1.0463,\n",
              "                                    0.9806, 1.0313, 0.9986, 0.9685, 0.9924, 1.0106, 0.9828,\n",
              "                                    1.0003, 0.9523, 0.9755, 0.9973, 0.9893, 0.9765, 0.9655,\n",
              "                                    1.0226, 0.9895, 0.9912, 0.9575, 0.9633, 0.9929, 1.0009,\n",
              "                                    0.9754, 0.9981, 0.9706, 1.0208, 0.9678, 1.0035, 0.9902,\n",
              "                                    0.9833, 0.9871, 1.0218, 1.0047, 1.0367, 0.9951, 0.9967,\n",
              "                                    1.0039, 1.0229, 0.9977, 0.9793, 1.0264, 1.0212, 0.9949,\n",
              "                                    0.9874, 1.0025, 0.9888, 1.0135, 0.9589, 1.0248, 1.0041,\n",
              "                                    1.0409, 0.9661, 0.9809, 0.9781, 1.0111, 1.0118, 0.9752,\n",
              "                                    0.9969, 0.9920, 0.9779, 0.9767, 1.0171, 0.9928, 1.0252,\n",
              "                                    1.0223, 1.0012, 0.9901, 0.9610, 0.9727, 1.0556, 0.9561,\n",
              "                                    0.9709, 0.9684, 1.0132, 1.0437, 0.9700, 0.9807, 0.9874,\n",
              "                                    0.9773, 1.0003, 1.0554, 1.0183, 0.9685, 0.9685, 0.9739,\n",
              "                                    1.0243, 0.9366, 0.9853, 0.9712, 1.0325, 1.0440, 0.9875,\n",
              "                                    0.9883, 1.0063, 0.9933, 1.0206, 1.0160, 1.0148, 0.9552,\n",
              "                                    0.9859, 1.0124, 0.9801, 0.9809, 1.0124, 0.9958, 0.9730,\n",
              "                                    0.9731, 0.9713, 0.9998, 1.0386, 1.0167, 1.0349, 1.0106,\n",
              "                                    0.9790, 0.9824, 0.9881, 1.0082, 1.0242, 1.0050, 1.0349,\n",
              "                                    1.0048, 0.9897, 0.9816, 0.9653, 0.9811, 1.0185, 1.0058,\n",
              "                                    1.0147, 0.9998, 0.9990, 0.9751, 0.9824, 0.9944, 1.0457,\n",
              "                                    1.0300, 1.0049, 1.0220, 0.9693, 0.9587, 0.9888, 1.0411,\n",
              "                                    1.0156, 1.0153, 0.9820, 0.9762, 1.0299, 1.0035, 0.9575,\n",
              "                                    1.0200, 1.0192, 0.9843, 1.0124, 1.0195, 0.9778, 0.9795,\n",
              "                                    1.0138, 1.0088, 0.9698, 0.9763, 0.9933, 1.0077, 1.0305,\n",
              "                                    0.9788, 0.9953, 0.9954, 1.0545, 1.0018, 1.0208, 0.9541,\n",
              "                                    0.9728, 0.9557, 1.0403, 0.9839, 1.0026, 0.9753, 0.9558,\n",
              "                                    1.0326, 0.9935, 0.9779, 0.9991, 0.9967, 0.9831, 0.9108,\n",
              "                                    1.0162, 0.9310, 0.9871, 1.0375, 0.9943, 0.9913, 1.0026,\n",
              "                                    0.9935, 1.0277, 0.9639, 0.9716, 0.9873, 1.0260, 0.9309,\n",
              "                                    0.9563, 0.9802, 0.9673, 0.9808, 1.0184, 1.0220, 0.9561,\n",
              "                                    1.0236, 0.9729, 1.0209, 0.9862, 0.9889, 1.0031, 1.0131,\n",
              "                                    1.0160, 0.9778, 0.9587, 1.0080, 1.0256, 0.9928, 0.9920,\n",
              "                                    0.9893, 1.0175, 0.9310, 1.0494, 0.9681, 0.9936, 1.0423,\n",
              "                                    1.0252, 0.9892, 1.0055, 0.9863, 0.9764, 1.0021, 0.9540,\n",
              "                                    1.0481, 1.0504, 1.0039, 1.0274, 0.9990, 1.0066, 0.9886,\n",
              "                                    1.0042, 0.9795, 1.0012, 0.9959, 1.0010, 1.0624, 0.9557,\n",
              "                                    0.9874, 1.0224, 0.9595, 0.9903, 0.9991, 1.0283, 1.0007,\n",
              "                                    1.0382, 1.0188, 0.9590, 0.9962, 0.9788, 1.0424, 0.9904,\n",
              "                                    0.9944, 0.9809, 1.0478, 0.9601, 0.9798, 1.0261, 1.0211,\n",
              "                                    0.9851, 1.0231, 1.0041, 0.9652, 0.9878, 0.9638, 0.9783,\n",
              "                                    1.0083, 1.0024, 1.0132, 1.0093, 1.0125, 0.9581, 1.0416,\n",
              "                                    0.9792, 1.0325, 1.0145, 0.9673, 1.0197, 0.9422, 0.9793,\n",
              "                                    1.0378, 0.9824, 1.0048, 0.9918, 0.9933, 1.0250, 1.0385,\n",
              "                                    0.9547, 1.0021, 1.0081, 1.0263, 0.9834, 1.0173, 0.9853,\n",
              "                                    1.0018, 1.0004, 1.0080, 0.9865, 0.9912, 0.9895, 0.9942,\n",
              "                                    1.0108, 1.0388, 1.0077, 1.0000, 1.0303, 1.0006, 1.0145,\n",
              "                                    0.9834, 0.9518, 1.0130, 0.9870, 1.0079, 0.9724, 1.0319,\n",
              "                                    1.0478, 0.9423, 1.0413, 0.9995, 1.0128, 0.9877, 0.9953,\n",
              "                                    0.9636, 1.0173, 0.9668, 0.9826, 0.9955, 0.9011, 0.9651,\n",
              "                                    0.9894, 1.0185, 1.0431, 0.9698, 1.0233, 1.0117, 0.9873,\n",
              "                                    1.0032, 0.9584, 0.9924, 1.0158, 0.9870, 1.0153, 0.9919,\n",
              "                                    1.0094, 0.9760, 0.9760, 1.0290, 0.9925, 1.0162, 1.0230,\n",
              "                                    0.9553, 1.0020, 0.9682, 1.0245, 0.9923, 1.0282, 1.0375,\n",
              "                                    0.9824, 1.0654, 1.0467, 0.9597, 0.9849, 0.9698, 1.0012,\n",
              "                                    0.9299, 0.9714, 1.0003, 0.9652, 1.0183, 1.0133, 0.9576,\n",
              "                                    1.0015, 0.9818, 1.0531, 0.9718, 1.0122, 0.9957, 0.9695,\n",
              "                                    0.9895, 0.9664, 0.9853, 0.9919, 0.9756, 1.0064, 0.9833,\n",
              "                                    1.0676, 1.0085, 1.0369, 0.9599, 0.9875, 1.0197, 0.9698,\n",
              "                                    0.9643, 1.0088, 0.9973, 1.0138, 1.0212, 0.9519, 1.0219,\n",
              "                                    0.9624, 0.9819, 1.0134, 0.9760, 1.0014, 1.0010, 1.0301,\n",
              "                                    0.9986, 0.9951, 0.9995, 1.0743, 0.9901, 0.9990, 0.9565,\n",
              "                                    1.0244, 1.0320, 0.9943, 1.0043, 0.9894, 1.0132, 0.9698,\n",
              "                                    0.9900, 0.9959, 1.0190, 0.9894, 1.0225, 0.9998, 0.9836,\n",
              "                                    0.9959, 1.0108, 1.0215, 1.0150, 0.9633, 0.9965, 1.0108,\n",
              "                                    1.0097, 0.9860, 0.9801, 1.0049, 1.0177, 0.9554, 0.9839,\n",
              "                                    0.9927, 1.0047, 0.9602, 1.0501, 1.0367, 1.0081, 1.0013,\n",
              "                                    1.0415, 0.9966, 0.9546, 0.9748, 0.9671, 0.9915, 1.0263,\n",
              "                                    1.0268, 1.0023, 0.9958, 0.9829, 1.0209, 0.9805, 0.9736,\n",
              "                                    1.0078]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-7.3225e-02, -2.3435e-02, -4.3874e-02,  1.5306e-03,\n",
              "                                    -7.3913e-03,  2.6179e-02, -2.8454e-02, -1.0091e-02,\n",
              "                                    -5.3669e-02,  4.0666e-02, -9.3251e-02,  8.0985e-03,\n",
              "                                    -2.4339e-02, -3.8825e-02,  1.7779e-03, -2.4810e-02,\n",
              "                                    -4.7711e-02, -2.5362e-02, -1.3900e-02,  6.0071e-03,\n",
              "                                    -1.6585e-02, -1.5402e-02,  1.9542e-03,  3.2750e-02,\n",
              "                                    -2.1294e-02, -4.0332e-02, -1.9964e-02,  3.6872e-02,\n",
              "                                    -9.4024e-02, -2.9847e-02, -4.3436e-02, -1.0646e-02,\n",
              "                                     2.2531e-02, -2.1737e-02, -7.6386e-02, -9.4283e-02,\n",
              "                                    -3.5552e-02, -6.1124e-02,  1.2382e-02, -4.0329e-02,\n",
              "                                    -2.0903e-02,  8.2471e-04,  1.1138e-02, -3.9984e-02,\n",
              "                                    -5.1092e-02, -2.7525e-02, -5.4782e-03, -2.5007e-02,\n",
              "                                    -8.0093e-03, -1.5611e-02,  2.4492e-03, -3.7381e-03,\n",
              "                                     6.9882e-03, -5.8566e-03, -4.7300e-02, -1.0688e-02,\n",
              "                                     2.1681e-02, -2.5241e-02, -1.5647e-02, -4.3386e-02,\n",
              "                                    -1.8255e-02,  1.6040e-03, -1.0720e-04, -6.6599e-03,\n",
              "                                     6.6974e-03, -3.1498e-02,  9.6032e-03, -3.1725e-02,\n",
              "                                    -5.9809e-02, -1.7399e-02, -6.7726e-02, -2.9160e-02,\n",
              "                                    -4.8941e-02, -3.9137e-03, -1.4635e-02,  6.0671e-03,\n",
              "                                     8.7346e-03, -3.0439e-03, -3.2952e-02, -2.8707e-03,\n",
              "                                    -4.8094e-03, -1.1348e-02,  3.8170e-02, -1.5003e-02,\n",
              "                                    -3.9539e-03,  3.3842e-02,  9.3668e-03, -5.9726e-03,\n",
              "                                    -4.7804e-02, -3.8138e-03,  2.5590e-02, -7.0512e-02,\n",
              "                                    -2.7445e-03, -6.2147e-02, -1.9227e-02, -6.0210e-03,\n",
              "                                    -5.9993e-03,  1.4815e-02, -2.4027e-02, -1.9918e-02,\n",
              "                                    -5.8722e-02, -3.0153e-02, -6.6748e-03, -4.6585e-02,\n",
              "                                     2.7215e-02, -2.3387e-02, -4.5901e-02, -1.7827e-02,\n",
              "                                    -5.8243e-02, -4.8100e-02, -7.1806e-02, -2.5136e-02,\n",
              "                                    -3.5422e-02, -4.2965e-02, -6.4830e-02, -3.3502e-02,\n",
              "                                    -2.9492e-02, -3.2335e-02, -4.6453e-02, -2.8959e-02,\n",
              "                                     5.2660e-04, -8.4096e-02, -1.8996e-02, -1.3996e-02,\n",
              "                                    -3.3885e-02,  1.0920e-03,  2.5616e-02, -1.6800e-02,\n",
              "                                    -5.5883e-02,  1.2112e-02,  2.9258e-03, -1.2920e-02,\n",
              "                                    -5.6034e-02, -2.8226e-02, -3.9902e-02,  9.3341e-04,\n",
              "                                    -2.7689e-02,  1.4045e-02, -2.2973e-02, -2.2148e-02,\n",
              "                                     8.9599e-03, -1.2859e-02, -4.3580e-02, -3.5751e-02,\n",
              "                                    -1.1940e-02, -3.7302e-02, -3.1929e-03, -4.2339e-03,\n",
              "                                    -6.2806e-04,  6.3947e-03, -5.2034e-03, -8.6849e-03,\n",
              "                                    -1.6959e-02, -1.0214e-02, -2.8349e-02, -2.5022e-02,\n",
              "                                    -1.4925e-02, -4.6270e-02, -3.7782e-02,  1.6566e-02,\n",
              "                                     5.3901e-03,  1.8797e-02, -4.4637e-02,  2.8486e-02,\n",
              "                                    -2.0092e-02,  1.9852e-02, -2.0255e-02, -3.6372e-02,\n",
              "                                    -3.8552e-02,  5.6747e-03,  3.1224e-03, -9.2769e-03,\n",
              "                                    -4.0851e-02, -1.5468e-02,  2.2677e-02, -7.7082e-03,\n",
              "                                    -1.0083e-02, -5.4378e-02, -1.5611e-02, -4.5488e-02,\n",
              "                                    -1.3136e-02, -1.0889e-02,  6.0274e-05,  2.2045e-02,\n",
              "                                    -1.1735e-02, -1.8785e-02,  3.7282e-02, -8.8168e-04,\n",
              "                                    -2.2797e-02, -1.1341e-02,  8.2919e-03, -1.1913e-02,\n",
              "                                     3.4663e-02, -3.3798e-02,  1.0087e-02, -4.2851e-02,\n",
              "                                    -4.4301e-03, -5.1127e-03, -8.8281e-03,  1.4348e-02,\n",
              "                                    -1.1761e-02,  1.5681e-02, -8.8640e-03, -3.6480e-02,\n",
              "                                    -1.9980e-02, -3.3267e-02, -1.0985e-02, -3.5297e-02,\n",
              "                                    -5.2460e-02, -5.1954e-02, -2.5891e-04, -3.9483e-02,\n",
              "                                    -4.4500e-02, -1.8439e-03, -8.9565e-03,  6.6534e-03,\n",
              "                                    -2.7346e-02,  3.1401e-02,  2.1447e-02, -7.0379e-02,\n",
              "                                     9.0290e-04,  5.0547e-03, -2.7304e-02, -4.3161e-02,\n",
              "                                    -5.7625e-02, -4.6439e-02, -5.5141e-02, -8.3564e-03,\n",
              "                                    -2.3277e-03,  9.2159e-03, -1.1803e-02,  1.1974e-02,\n",
              "                                    -3.8156e-02, -4.3541e-03, -8.0051e-03, -1.7610e-02,\n",
              "                                    -5.5458e-02, -5.9756e-02, -3.1334e-02, -5.4308e-02,\n",
              "                                    -6.5057e-03, -3.2288e-02,  5.2899e-04,  2.0316e-02,\n",
              "                                     1.0515e-02, -3.0362e-02,  6.6394e-03, -1.2703e-03,\n",
              "                                    -1.9612e-02, -4.6379e-02, -6.7394e-03,  1.1369e-02,\n",
              "                                    -7.4831e-02, -5.9316e-02,  1.0809e-02, -3.0892e-02,\n",
              "                                    -2.3130e-02,  6.4996e-04,  1.8566e-02, -1.2681e-02,\n",
              "                                    -5.3888e-02, -2.6653e-02, -2.7637e-02, -3.6832e-02,\n",
              "                                    -1.8785e-02,  1.0756e-02, -2.6181e-02, -3.3438e-02,\n",
              "                                    -2.7053e-02, -2.0929e-02, -6.5365e-02, -4.9339e-03,\n",
              "                                    -4.3409e-02, -4.6587e-02, -2.3301e-02, -3.0529e-02,\n",
              "                                     1.9786e-02,  8.3694e-03,  3.0285e-02,  1.8015e-02,\n",
              "                                     7.4628e-03, -1.0046e-02, -1.3906e-02, -1.6834e-02,\n",
              "                                    -2.8961e-02, -3.6228e-02, -4.0969e-02,  6.1783e-03,\n",
              "                                     8.7631e-03, -2.7036e-02, -2.2064e-03, -2.4176e-02,\n",
              "                                    -2.9049e-02, -1.8569e-02, -1.8293e-02,  8.3841e-03,\n",
              "                                    -1.9383e-02, -5.2279e-02, -1.7998e-02, -4.1470e-02,\n",
              "                                     8.8819e-03, -2.9570e-02, -1.8459e-02, -5.9311e-02,\n",
              "                                    -1.3908e-02, -1.9382e-02, -2.4303e-02, -2.9148e-02,\n",
              "                                    -2.7719e-02, -1.4776e-02,  7.0872e-03,  2.8906e-02,\n",
              "                                    -1.8951e-02, -5.3722e-02,  1.5020e-02, -3.3883e-02,\n",
              "                                    -9.6515e-03,  6.3022e-03, -3.5369e-02,  1.2735e-03,\n",
              "                                    -6.4914e-02, -4.3944e-02, -4.8442e-02, -2.6417e-02,\n",
              "                                     5.5426e-03, -3.1030e-02, -6.8700e-02, -3.0224e-02,\n",
              "                                    -4.5935e-02, -1.7631e-02, -2.0469e-02, -3.0299e-02,\n",
              "                                    -2.5272e-02, -2.8099e-02, -1.0200e-02, -4.3568e-02,\n",
              "                                    -3.0143e-02, -3.6935e-02, -2.1462e-02,  2.9110e-03,\n",
              "                                    -1.8423e-02, -2.9878e-03, -1.0224e-02, -5.5899e-03,\n",
              "                                    -6.8204e-02, -3.5640e-02, -1.2779e-03, -5.3977e-02,\n",
              "                                     4.3309e-02, -1.8057e-02, -1.5877e-03, -1.1803e-02,\n",
              "                                    -2.2531e-02,  1.3569e-02, -8.7185e-03, -7.7595e-02,\n",
              "                                    -2.3555e-02, -6.0082e-02, -2.1444e-02, -2.7233e-02,\n",
              "                                    -4.0385e-02, -2.1760e-04, -1.6006e-02, -3.8626e-02,\n",
              "                                     6.2098e-03, -5.7299e-02, -9.8079e-03, -2.4331e-02,\n",
              "                                    -4.4314e-02,  7.6163e-03,  1.2891e-02, -7.2887e-03,\n",
              "                                    -2.8193e-02, -1.1389e-02, -3.2529e-02,  5.7880e-03,\n",
              "                                    -5.1087e-02,  1.3490e-03, -3.0208e-03, -3.3893e-02,\n",
              "                                    -1.5102e-02, -1.7386e-02, -1.9679e-02,  3.3748e-02,\n",
              "                                     9.8719e-03, -1.3739e-03, -2.4525e-02, -4.4551e-02,\n",
              "                                    -8.4987e-02,  8.9067e-03, -1.2230e-02, -1.5822e-02,\n",
              "                                    -6.1080e-02, -2.6214e-02, -2.2379e-02, -1.3111e-02,\n",
              "                                    -1.8937e-04, -2.5512e-02,  1.3945e-03, -1.4447e-02,\n",
              "                                     1.2262e-02, -7.2196e-02, -3.2661e-02, -3.2357e-03,\n",
              "                                     7.7838e-04, -7.6999e-02, -4.7700e-03, -8.6745e-02,\n",
              "                                    -4.3717e-02, -2.1363e-02, -6.3776e-03, -3.6858e-02,\n",
              "                                    -7.4713e-03, -4.3478e-02, -1.4086e-02, -2.4632e-02,\n",
              "                                    -1.8386e-02, -1.8576e-02,  3.1219e-03, -4.6002e-02,\n",
              "                                    -3.1716e-02,  1.6660e-02, -2.5484e-02, -3.3749e-02,\n",
              "                                     1.2177e-02, -4.5482e-02, -3.3356e-02, -1.6801e-02,\n",
              "                                    -4.8724e-02, -1.5899e-02, -9.6324e-03, -2.7858e-02,\n",
              "                                     2.2122e-02, -3.1471e-02, -3.1550e-02, -2.4486e-02,\n",
              "                                    -5.5326e-02, -5.8035e-03, -1.1170e-02,  1.4875e-02,\n",
              "                                    -2.5759e-02, -3.9369e-03, -3.6149e-02, -2.0059e-02,\n",
              "                                    -1.2397e-02, -7.9945e-03, -3.0270e-02,  2.9772e-02,\n",
              "                                    -7.3594e-02, -3.3364e-02, -1.3500e-02, -2.0731e-03,\n",
              "                                    -3.7741e-03,  8.1096e-03,  1.5809e-02,  1.7694e-02,\n",
              "                                    -7.8468e-02, -5.6529e-03, -5.0551e-02, -1.2958e-02,\n",
              "                                     1.5295e-02, -3.0916e-02, -4.3030e-02,  1.8600e-02,\n",
              "                                    -5.8362e-02, -3.4637e-02, -1.3279e-02, -7.4706e-03,\n",
              "                                    -4.7520e-02, -1.7549e-02, -1.9863e-02,  1.4597e-02,\n",
              "                                    -2.4239e-03, -2.0582e-02, -2.2984e-02,  4.0881e-03,\n",
              "                                    -3.1743e-02,  1.0341e-03,  6.5312e-03,  1.7322e-02,\n",
              "                                    -3.4332e-02,  1.3265e-02,  1.4991e-02, -4.4969e-02,\n",
              "                                     7.0984e-03,  7.0707e-03, -2.5312e-02,  6.1955e-03,\n",
              "                                    -2.4649e-02, -1.3619e-02,  1.5219e-02, -4.1996e-02,\n",
              "                                    -1.3510e-02, -3.1678e-02,  6.7880e-03,  1.0277e-02,\n",
              "                                     1.7063e-02, -1.2339e-02,  9.9794e-03,  2.6895e-02,\n",
              "                                    -2.7117e-02, -1.7954e-02, -3.2680e-03, -5.0809e-02,\n",
              "                                    -6.5933e-02, -2.6306e-03, -1.4256e-02, -1.6767e-02,\n",
              "                                    -1.1931e-02, -2.3439e-02, -2.9625e-02, -1.1552e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([  1.9637,  10.4236,  -6.4205,  -9.3983,  -0.9015,\n",
              "                                    -14.0770,  -6.1858,   5.1052,   1.9104,   1.4465,\n",
              "                                      4.4982,   8.1117,  -8.1667,  -0.1916,  -0.8659,\n",
              "                                      5.7435,   4.7996,  -5.0780,  -8.8498,   3.6537,\n",
              "                                    -14.8573, -12.3348,   6.6896, -11.4316,  -5.2762,\n",
              "                                     -3.9565,  -6.7101, -10.7052,   2.4255,   3.5471,\n",
              "                                    -15.0689,   1.5558,   7.3122,  -9.7093,   6.6028,\n",
              "                                     -3.6472,  -4.9267,  -3.2429,  -4.7151,  -4.7749,\n",
              "                                      0.2277,  -0.5588,   1.9878,  -3.8982,   0.8295,\n",
              "                                     -1.8176,   5.0269,  -7.1763,  -2.2403, -10.6434,\n",
              "                                      6.2116,   7.3488,  -9.5002,  -6.8703,   7.0765,\n",
              "                                     -2.6469,  -9.3650,  -1.2513,  -0.0346,  -1.1805,\n",
              "                                     -6.6150,  -7.9347,  -0.7073,  -4.3264, -14.2277,\n",
              "                                     -8.5834,  -1.8584, -20.2430,  -1.7565,  -0.2129,\n",
              "                                      2.6759,   1.1620,   5.5519, -10.6114,   4.6587,\n",
              "                                    -14.8967, -10.2700,  -4.5050,   4.8119,  -2.3190,\n",
              "                                    -10.1414,  -9.7891, -12.3841,  -2.4591,   7.2290,\n",
              "                                     -0.5331,   3.4922,  -7.0471,  -5.7544,  -0.4262,\n",
              "                                    -19.1619,  -1.6561,   3.4684,   5.5666,  10.4673,\n",
              "                                     -0.6442,   8.6036,  -4.6343, -14.6706, -10.6421,\n",
              "                                     -0.2338,   6.1042,  -9.0966,   5.8717,   3.4041,\n",
              "                                     -1.5605,  11.2838,  -2.2021,  -9.7444,  11.2688,\n",
              "                                      6.5400, -12.3819,   3.5947,  -6.0134,   7.1038,\n",
              "                                     -1.8667,  -7.0622,  -2.8262,  -1.4177, -12.0317,\n",
              "                                    -11.9379,   3.5909,  10.4234,  -1.0218,   1.4466,\n",
              "                                     -5.9399,  -7.1901,   5.9957,  -5.4734, -17.2984,\n",
              "                                    -14.9896,  -5.2272,  -5.2401,  -2.7170,   3.8608,\n",
              "                                      8.3030,  -3.6331,   8.3812,   7.9970,   0.4009,\n",
              "                                     -6.9229,  -1.6207,   9.9680,  -5.7533,  -7.8169,\n",
              "                                     -8.6787,   0.5596,  -2.9827,  -1.6182,   4.6080,\n",
              "                                      8.7466,   2.9500,   3.8258, -11.6335,   9.1472,\n",
              "                                      7.2613,   2.7552,   1.3354,  -2.1016, -17.3213,\n",
              "                                     -5.8492,  -9.5663,   2.3168, -17.9067,  -7.6523,\n",
              "                                     -0.7725,  -4.6869,   4.9473,  -2.3653,   2.0522,\n",
              "                                     -4.9836, -11.2997,  -7.7836,  -2.9698,  -1.8534,\n",
              "                                     -3.7631,  -3.1613,   2.4539,  -3.1610,   6.0268,\n",
              "                                     -7.5793,   5.5467, -10.7100, -16.3550, -12.0320,\n",
              "                                      7.4401,  -6.7772,  -6.9729,  -9.8846,   1.8968,\n",
              "                                    -11.1405,   2.0574,  -3.8446,   1.5842,  -6.6845,\n",
              "                                      0.3959,  -3.5618,  -5.4011,   9.8676, -16.3336,\n",
              "                                     -3.6644, -15.6439,  -1.6131,  -3.5397,  -8.5616,\n",
              "                                     -4.3726,  -8.4817,   5.6769,   2.1059,  -1.9624,\n",
              "                                    -13.7519, -12.8477,   0.8503, -13.4529,  -1.7085,\n",
              "                                    -10.3749,  -1.5800, -10.3864, -11.7431,   6.1708,\n",
              "                                     -3.1342,  -7.8727,  -5.0989,   6.7827,  -1.4592,\n",
              "                                      8.2291,   3.4620,  -2.0311, -10.0155,  13.3870,\n",
              "                                      3.2337,   4.7516,   0.4997,  -4.2161,  -3.1465,\n",
              "                                     -2.3660,  -4.7410,  -7.0907, -10.0506,  -5.5139,\n",
              "                                      2.8860, -10.0363,   4.7410,  -4.2709,   9.9364,\n",
              "                                      2.8690,  -7.2555,  -4.2417,   4.2261,   3.7427,\n",
              "                                     -5.4090,   6.4587,   3.7560,  -1.4606,   4.2832,\n",
              "                                      8.0016,   5.9591, -16.6702,  -9.4879,   3.9505,\n",
              "                                     -8.3976,  -7.9570,   3.4593,  -5.4095, -10.1109,\n",
              "                                     -2.7295,   4.2669,  -1.9786,  -1.2029, -11.9079,\n",
              "                                      6.4284,  -7.7106,  -9.6437,   2.4875,  -1.5365,\n",
              "                                      3.3359,   1.4265,  12.6044, -19.3972,  -0.6007,\n",
              "                                    -11.7703, -13.2831,  -4.6039,  -0.7433,   0.1643,\n",
              "                                      2.9819,  -2.2615,  -5.0407, -12.9260,   7.7593,\n",
              "                                     -6.9227,  -0.7498,  -2.1554,   1.6323,  -6.2458,\n",
              "                                     -6.2879,   2.7832,   7.2016,  -3.6299,   0.3192,\n",
              "                                    -13.0677,   8.0744, -16.5812,   5.1772, -10.8204,\n",
              "                                     -2.4921,   3.3393,   7.2459,  -9.3423,   2.0302,\n",
              "                                      8.2554,  -8.2717,   1.8683, -11.2147,  -9.1296,\n",
              "                                      3.4075,  -5.1140,  -2.4565,  -2.2110, -10.3129,\n",
              "                                     -4.6617,   4.6229,  -6.0503,   7.8199,  -9.8372,\n",
              "                                      3.6934,  -0.9130,  -4.4809,   8.3339,   2.2644,\n",
              "                                      7.2191,   1.1337, -10.7049,   1.0875,   1.8872,\n",
              "                                     -0.2928,  -3.2683,   2.0165,   5.7164,  -5.1768,\n",
              "                                    -10.0973,  -3.7554,  -1.4616,  -0.8771,   3.4994,\n",
              "                                    -16.2922,  -1.4514,   4.7407, -16.3313, -12.3750,\n",
              "                                      9.9847,   3.0028,   2.3415,  12.1149,  -3.8755,\n",
              "                                      4.4903,  -8.2043,  -4.4212,  -4.2375,   7.8704,\n",
              "                                      5.2562,   7.1092,   2.5226,   6.3948,   0.0623,\n",
              "                                     -5.4737,  -1.4282,   3.4445,   1.8380,   8.0006,\n",
              "                                     -6.7507,   4.0824,  -1.5168, -11.3766,  -3.5941,\n",
              "                                     -6.5509,   3.3285, -11.1135, -10.2743,   6.3862,\n",
              "                                     -2.8345,  -8.8434,   4.4943,   5.1215,  -7.2372,\n",
              "                                    -16.3403,   6.3380,  -2.3456,   7.6997,  -6.6038,\n",
              "                                      0.6206,  -8.3650,  -1.9544,   4.9800,  -2.9775,\n",
              "                                      0.4572,   3.6176,   8.7408,   3.7442,   2.3344,\n",
              "                                      6.6222,   4.5845,   5.2572,  -0.5734,  -5.5651,\n",
              "                                      0.8465,   4.9691,  -5.8872,  -0.8438,   4.4906,\n",
              "                                     -0.3970,  -7.8732,  -0.8869,  -6.8536,   7.5434,\n",
              "                                      3.5565,  -6.1310,  -4.8404,  -3.0937,  -2.8036,\n",
              "                                     -1.6129,  -5.7770, -10.2720, -10.7568,  -4.0351,\n",
              "                                     -5.6066, -12.2596,  -7.3747,  -3.3137, -12.8005,\n",
              "                                     -3.0626,  -6.4542, -12.5352,  -3.4159,   2.6347,\n",
              "                                      0.3684,   5.3121,   7.9122,  -0.4913,  -0.7968,\n",
              "                                     -5.8917,   3.1165,  -0.2123,  -8.1965, -14.8144,\n",
              "                                      3.4562,  -1.5775,   4.4153,   1.1425,   2.3841,\n",
              "                                      9.9190, -10.5286,   0.0463,  -7.6295, -12.1520,\n",
              "                                      4.3833,   3.6324,  -1.3241,   0.8167,   1.8269,\n",
              "                                    -14.7040,   0.0925,   2.3935,  -1.4379,   1.6761,\n",
              "                                      0.8852,   0.1021,   1.4204,   4.4363,  -7.8502,\n",
              "                                      4.4107,   3.3978, -18.2185,  11.3522,   3.3732,\n",
              "                                    -12.1983,   9.4031,  -2.7473, -10.7063,   3.3138,\n",
              "                                      8.1721,  -7.4797, -16.2195,   4.0178,   3.7145,\n",
              "                                     -1.0253,   0.6278,  -4.9909,   3.4224, -14.7669,\n",
              "                                     -5.7871,   2.8366,   2.0097,   0.2924,  -8.2278,\n",
              "                                      8.1213,  -5.8620,   1.5800,  -6.1860,  -3.4140,\n",
              "                                      2.4687,  -3.9888,  -9.6701,   2.1979,   2.4171,\n",
              "                                      0.7830,  -8.0248, -10.7322,   4.8802,   6.7999,\n",
              "                                      2.6508,  -4.2217]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([132.8288, 159.3587, 126.4362, 138.6024, 100.0893,\n",
              "                                    145.2417, 124.2694, 227.2651,  71.4053,  86.5887,\n",
              "                                    184.1998, 168.8915, 229.2677, 178.7837, 135.6689,\n",
              "                                    235.3258, 163.8224, 107.0004, 236.5118, 187.9136,\n",
              "                                    155.7981, 236.5762, 165.7367, 271.5811, 140.3604,\n",
              "                                    109.8804, 133.1866, 218.2950, 112.1139,  70.9624,\n",
              "                                    192.4264, 171.0550, 182.4066,  98.1555, 167.2065,\n",
              "                                    159.0144,  98.5855,  79.5590, 124.3104, 112.4943,\n",
              "                                    132.8262, 196.0109, 213.6715, 172.8895, 131.6236,\n",
              "                                    129.1918, 219.7419, 224.7578, 118.9898, 203.2723,\n",
              "                                    141.8283, 222.4209, 203.6801,  99.8812,  80.5811,\n",
              "                                    107.5337, 136.2790, 130.1185, 122.2058, 122.2403,\n",
              "                                    230.0788,  90.9822, 232.3831, 152.1629, 245.2040,\n",
              "                                    220.2155, 132.6422, 329.0625, 113.9580,  91.2334,\n",
              "                                    125.0271,  78.1484, 157.5806, 189.6749, 102.9574,\n",
              "                                    261.4496, 158.1697, 196.2535, 273.7576, 106.4645,\n",
              "                                    127.1429, 117.4237, 139.6529, 104.2657, 176.7943,\n",
              "                                    115.3968, 151.6995, 123.6088,  92.7343, 149.7251,\n",
              "                                    272.5414, 181.6182, 244.8905, 109.8163, 222.1167,\n",
              "                                    118.7032, 174.0285, 147.0849, 216.6430, 172.9316,\n",
              "                                    118.5492, 145.3004, 229.3618,  73.2670, 148.4355,\n",
              "                                    119.8536, 208.9683, 100.5877,  95.2640, 248.8967,\n",
              "                                    223.5043, 235.0154, 167.5537,  93.4390, 205.2684,\n",
              "                                    101.9707, 105.2656, 200.6046,  90.5819, 159.6575,\n",
              "                                    168.6589, 180.8219, 305.1396, 127.1805, 178.2750,\n",
              "                                    104.0905, 140.5053,  71.4363, 112.1713, 233.1205,\n",
              "                                    208.4524, 165.4964,  95.7970,  99.1484, 112.7440,\n",
              "                                    216.9461, 141.3347, 177.8211, 207.3065, 116.2910,\n",
              "                                    120.6009, 136.8522, 194.4218,  95.0064, 148.7482,\n",
              "                                    160.1130, 131.7078,  57.3231,  85.8768, 324.2155,\n",
              "                                    187.1417, 125.5292, 192.1394, 176.7681, 281.8960,\n",
              "                                    185.0004, 122.6160, 107.1856,  91.3612, 243.5946,\n",
              "                                    138.4580, 176.5800, 119.9779, 206.6285, 184.0075,\n",
              "                                     93.8171, 138.8422, 154.6035, 127.8210,  90.7391,\n",
              "                                    136.9768, 148.1096, 135.5643,  67.8215, 191.0101,\n",
              "                                    137.5177, 139.2336, 170.6054,  91.6790, 118.8983,\n",
              "                                    119.2111, 217.5316, 165.9574, 271.0360, 117.3878,\n",
              "                                    120.8186, 217.8377, 134.8674, 150.6389, 248.1423,\n",
              "                                    167.3450,  80.3934, 167.2284, 137.8482, 206.1067,\n",
              "                                     87.9393, 121.7267, 119.0627, 330.5526, 220.4389,\n",
              "                                    132.6706, 232.1804, 184.0594,  92.9823, 115.1794,\n",
              "                                    148.0133, 199.1207, 120.6599, 269.6236, 108.1190,\n",
              "                                    286.6424, 147.0682, 133.1971, 318.1042, 161.0081,\n",
              "                                    112.3680, 150.7204, 219.9709, 277.3192, 219.4096,\n",
              "                                    117.8236, 246.5102, 157.9456, 106.5234, 126.6208,\n",
              "                                    198.3703,  96.9648, 169.5515, 186.0293, 293.8568,\n",
              "                                    235.1131, 121.1093, 172.9636,  68.1922, 107.5898,\n",
              "                                    153.7209, 180.7159,  98.0168, 172.1456,  89.4725,\n",
              "                                    134.4340, 284.4744, 230.7737, 127.7429, 205.2739,\n",
              "                                    143.6426, 173.1342, 135.8342, 269.2764, 210.9021,\n",
              "                                    165.8967, 134.4300, 217.9918, 144.0844, 301.0627,\n",
              "                                    189.9991, 162.5588, 248.1964, 216.8462, 291.8797,\n",
              "                                    140.6171, 186.8200, 183.3315,  86.9342, 118.9883,\n",
              "                                    173.1043, 213.0685, 136.4247, 177.4665, 226.5265,\n",
              "                                    145.3734, 153.5265, 147.3320, 134.3295, 138.8621,\n",
              "                                    206.7681, 187.1532, 354.0323, 369.6664, 137.8357,\n",
              "                                    246.7169, 218.0427, 254.2034, 131.9344, 228.2464,\n",
              "                                    164.5830, 116.4718, 100.9912, 197.2309, 197.3988,\n",
              "                                    134.4440, 107.4287,  94.9029, 153.2319, 118.8837,\n",
              "                                    113.5876, 157.1873, 127.2185, 136.8770, 199.4568,\n",
              "                                    252.2607, 147.6970, 235.5501, 188.1606, 169.0200,\n",
              "                                    111.0387, 236.8371, 253.7609, 224.9796, 224.6006,\n",
              "                                    289.2414, 118.6121, 120.7409, 148.7690, 169.4107,\n",
              "                                    207.1326, 118.3481, 138.8935, 144.4710, 241.8040,\n",
              "                                     94.1366, 182.9938,  71.3106, 201.1991, 168.0533,\n",
              "                                    186.1848, 211.1673, 202.0450, 170.7160, 124.2239,\n",
              "                                    291.7687, 147.4706, 126.3689, 151.6314, 225.6566,\n",
              "                                    189.4518, 129.1814, 180.5971, 131.5039, 130.0267,\n",
              "                                    247.7649, 230.2343,  94.7709, 167.9694, 131.2502,\n",
              "                                    234.4202,  90.1630, 214.1567, 149.2326, 263.7298,\n",
              "                                    149.7876, 223.1140, 157.9633, 179.5373, 127.8801,\n",
              "                                    171.5262, 156.1506,  97.3518,  82.4770, 214.6043,\n",
              "                                     78.9831, 260.0154, 104.4493, 247.2404, 175.8826,\n",
              "                                    113.5724, 130.4032, 205.3515, 131.5115, 114.9886,\n",
              "                                    171.3898,  96.6412, 131.5992, 147.5266,  79.4797,\n",
              "                                     76.3980,  98.4968, 127.7989, 198.1024, 207.2522,\n",
              "                                    135.2046, 166.2963,  78.1206, 203.7947, 173.8591,\n",
              "                                    159.8028, 203.7057, 159.7023, 156.0912, 172.0780,\n",
              "                                    160.1245,  97.3685, 110.2783, 174.1999, 150.2300,\n",
              "                                     83.2587, 164.0960, 234.5176, 118.9383, 121.4201,\n",
              "                                    167.4826,  70.4320, 142.8578, 105.9606, 123.8429,\n",
              "                                    199.0387, 183.0339, 110.6153, 163.5723, 152.3055,\n",
              "                                     96.1395, 108.7186, 115.4062, 105.7601, 220.4196,\n",
              "                                    203.6714, 139.5296, 139.5220, 138.8179, 121.5407,\n",
              "                                    135.1343, 118.4023, 188.1365, 112.9608, 155.7043,\n",
              "                                    130.8345,  83.3698, 191.3714, 106.3123, 243.5692,\n",
              "                                    108.6827, 153.5355, 166.1981, 199.3275, 216.4258,\n",
              "                                    158.9485, 216.8201, 139.4249, 138.4057, 194.3179,\n",
              "                                    157.4678, 174.7420, 148.5972, 182.5525, 192.9728,\n",
              "                                     95.1670,  95.5167, 154.0229, 118.5692, 127.1851,\n",
              "                                    152.5231, 205.9654, 108.1406, 154.8015, 192.8125,\n",
              "                                     87.4590, 150.0954, 138.7088, 257.2167, 136.2889,\n",
              "                                    194.1729, 114.5454, 209.1670, 180.4661,  71.7893,\n",
              "                                    136.1001, 166.4051, 108.2146, 100.2209,  76.5716,\n",
              "                                    147.5937, 216.2371, 240.5542, 210.4295, 100.7904,\n",
              "                                    267.4660, 289.1041, 130.7156, 114.9540, 183.7110,\n",
              "                                    141.0163, 222.9664, 210.0115,  87.8194, 134.6974,\n",
              "                                     89.8175, 199.4989, 135.2971, 103.0053, 157.1986,\n",
              "                                    177.5897, 148.3378,  86.7565, 208.5400, 219.2359,\n",
              "                                     87.2664,  99.8330, 178.2340, 123.8097, 141.1682,\n",
              "                                    196.9359,  87.6145, 138.4810, 150.3047, 170.1066,\n",
              "                                    107.6558, 125.3324, 127.3010, 109.9658, 183.2833,\n",
              "                                    131.5343, 148.3836]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([-0.0044,  0.0284, -0.0067,  ..., -0.0057,  0.0014,\n",
              "                                     0.0160]),\n",
              "                     size=(512, 512, 3, 3), nnz=2359296, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([1.0129, 1.0153, 0.9569, 1.0051, 1.0038, 0.9821, 1.0080,\n",
              "                                    1.0396, 0.9985, 0.9750, 0.9882, 0.9939, 1.0121, 0.9993,\n",
              "                                    0.9987, 1.0239, 0.9301, 1.0016, 1.0367, 1.0029, 1.0345,\n",
              "                                    0.9580, 0.9860, 1.0176, 0.9586, 0.9755, 1.0242, 0.9948,\n",
              "                                    0.9776, 1.0063, 0.9722, 0.9693, 1.0027, 0.9443, 0.9540,\n",
              "                                    1.0060, 1.0329, 1.0599, 1.0666, 0.9911, 1.0232, 1.0227,\n",
              "                                    0.9683, 1.0337, 0.9430, 1.0082, 1.0012, 0.9878, 1.0419,\n",
              "                                    1.0563, 0.9509, 1.0045, 0.9487, 1.0031, 0.9667, 0.9863,\n",
              "                                    0.9910, 1.0145, 1.0084, 0.9818, 0.9878, 0.9868, 0.9873,\n",
              "                                    1.0325, 0.9950, 0.9758, 1.0116, 0.9672, 0.9760, 1.0274,\n",
              "                                    0.9626, 0.9798, 1.0322, 0.9711, 1.0379, 0.9235, 1.0208,\n",
              "                                    0.9361, 0.9689, 1.0070, 1.0227, 0.9895, 0.9579, 1.0314,\n",
              "                                    1.0538, 1.0039, 1.0539, 0.9837, 1.0129, 1.0298, 0.9985,\n",
              "                                    1.0426, 1.0108, 0.9920, 0.9991, 0.9716, 0.9936, 0.9623,\n",
              "                                    1.0353, 0.9549, 0.9919, 0.9629, 0.9797, 1.0655, 1.0520,\n",
              "                                    0.9664, 1.0293, 1.0068, 0.9779, 1.0051, 0.9624, 0.9370,\n",
              "                                    0.9701, 0.9963, 0.9899, 0.9672, 1.0002, 0.9765, 0.9810,\n",
              "                                    0.9870, 0.9831, 0.9738, 1.0251, 1.0084, 0.9902, 0.9688,\n",
              "                                    0.9909, 0.9515, 0.9715, 0.9457, 0.9749, 0.9990, 0.9643,\n",
              "                                    0.9832, 1.0224, 0.9693, 0.9961, 0.9629, 0.9882, 1.0076,\n",
              "                                    0.9692, 1.0066, 0.9619, 0.9458, 1.0042, 1.0147, 1.0228,\n",
              "                                    0.9844, 0.9586, 0.9899, 1.0090, 1.0017, 0.9633, 0.9913,\n",
              "                                    1.0362, 0.9804, 1.0212, 0.9678, 0.9738, 0.9759, 0.9864,\n",
              "                                    0.9673, 1.0113, 1.0241, 0.9721, 0.9709, 0.9652, 1.0337,\n",
              "                                    1.0072, 0.9971, 0.9856, 0.9558, 0.9932, 0.9761, 0.9656,\n",
              "                                    1.0051, 0.9729, 0.9974, 0.9709, 1.0270, 0.9983, 0.9536,\n",
              "                                    0.9632, 0.9206, 0.9497, 0.9665, 0.9826, 1.0210, 1.0185,\n",
              "                                    0.9890, 0.9803, 1.0414, 0.9907, 1.0301, 1.0099, 0.9946,\n",
              "                                    1.0655, 0.9900, 1.0313, 1.0097, 0.9906, 1.0029, 0.9707,\n",
              "                                    1.0064, 0.9675, 0.9595, 1.0149, 1.0266, 1.0361, 0.9799,\n",
              "                                    1.0323, 1.0257, 1.0149, 1.0051, 0.9642, 1.0093, 0.9983,\n",
              "                                    1.0241, 1.0263, 0.9596, 0.9911, 0.9666, 0.9958, 0.9588,\n",
              "                                    1.0481, 1.0115, 0.9954, 1.0125, 0.9682, 0.9527, 0.9581,\n",
              "                                    0.9860, 0.9817, 1.0108, 0.9903, 1.0065, 1.0225, 1.0393,\n",
              "                                    1.0000, 0.9624, 0.9455, 1.0073, 1.0521, 1.0420, 0.9820,\n",
              "                                    1.0057, 0.9922, 0.9804, 1.0040, 0.9559, 0.9623, 1.0127,\n",
              "                                    0.9796, 1.0222, 0.9661, 1.0097, 0.9810, 0.9660, 0.9723,\n",
              "                                    0.9613, 1.0348, 0.9642, 1.0019, 0.9699, 0.9786, 0.9421,\n",
              "                                    1.0092, 1.0428, 1.0156, 0.9971, 0.9758, 1.0097, 1.0104,\n",
              "                                    1.0257, 0.9641, 0.9668, 1.0343, 1.0208, 1.0192, 1.0094,\n",
              "                                    1.0903, 0.9891, 1.0009, 1.0000, 0.9882, 1.0325, 1.0204,\n",
              "                                    0.9621, 1.0047, 1.0127, 0.9619, 1.0412, 0.9770, 1.0175,\n",
              "                                    1.0151, 0.9611, 0.9816, 1.0150, 0.9651, 0.9382, 1.0755,\n",
              "                                    1.0032, 1.0158, 0.9898, 1.0382, 1.0359, 0.9726, 0.9914,\n",
              "                                    0.9884, 0.9886, 0.9610, 1.0339, 0.9622, 0.9963, 0.9758,\n",
              "                                    0.9422, 0.9747, 0.9842, 1.0108, 0.9639, 0.9822, 0.9627,\n",
              "                                    0.9816, 0.9727, 1.0042, 1.0234, 0.9836, 1.0056, 0.9845,\n",
              "                                    1.0281, 1.0399, 0.9684, 1.0176, 1.0208, 0.9891, 1.0070,\n",
              "                                    0.9975, 1.0080, 1.0271, 0.9790, 0.9629, 1.0291, 0.9494,\n",
              "                                    1.0023, 0.9959, 0.9749, 1.0306, 0.9770, 0.9706, 0.9855,\n",
              "                                    1.0170, 0.9811, 1.0267, 0.9675, 0.9887, 0.9783, 1.0034,\n",
              "                                    1.0103, 0.9760, 1.0349, 0.9651, 1.0137, 1.0398, 1.0030,\n",
              "                                    1.0056, 1.0196, 0.9681, 0.9862, 0.9733, 0.9581, 0.9404,\n",
              "                                    0.9884, 1.0216, 0.9791, 1.0190, 0.9581, 1.0253, 0.9640,\n",
              "                                    0.9644, 0.9734, 0.9914, 0.9908, 1.0424, 0.9727, 0.9159,\n",
              "                                    1.0087, 0.9920, 1.0505, 1.0168, 1.0001, 1.0349, 0.9504,\n",
              "                                    0.9955, 1.0175, 1.0079, 0.9466, 1.0119, 1.0400, 0.9684,\n",
              "                                    0.9746, 0.9849, 1.0015, 1.0245, 1.0083, 0.9766, 1.0028,\n",
              "                                    0.9944, 1.0436, 0.9945, 0.9652, 1.0401, 1.0070, 1.0052,\n",
              "                                    1.0095, 0.9942, 1.0021, 1.0380, 0.9694, 0.9871, 1.0101,\n",
              "                                    0.9622, 1.0147, 1.0118, 0.9515, 0.9953, 1.0104, 1.0419,\n",
              "                                    1.0081, 0.9829, 0.9806, 0.9467, 1.0027, 1.0208, 0.9814,\n",
              "                                    0.9950, 1.0017, 0.9986, 0.9914, 0.9406, 0.9985, 0.9363,\n",
              "                                    1.0089, 1.0622, 0.9564, 1.0754, 1.0110, 0.9586, 1.0548,\n",
              "                                    0.9951, 1.0063, 1.0215, 0.9822, 0.9603, 0.9811, 1.0142,\n",
              "                                    1.0335, 0.9848, 0.9790, 1.0556, 0.9783, 0.9987, 1.0277,\n",
              "                                    1.0140, 1.0231, 1.0640, 0.9660, 0.9515, 0.9799, 0.9869,\n",
              "                                    0.9844, 1.0546, 0.9902, 1.0333, 1.0369, 0.9756, 1.0099,\n",
              "                                    0.9754, 0.9695, 0.9723, 0.9617, 0.9812, 1.0216, 0.9551,\n",
              "                                    0.9668, 1.0283, 1.0784, 0.9777, 1.0233, 1.0155, 0.9522,\n",
              "                                    1.0096, 1.0085, 0.9987, 1.0081, 1.0512, 0.9915, 0.9930,\n",
              "                                    1.0402, 1.0253, 0.9977, 0.9991, 0.9985, 0.9974, 0.9594,\n",
              "                                    0.9897, 1.0325, 1.0114, 0.9555, 0.9652, 0.9926, 1.0092,\n",
              "                                    1.0044]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-4.2004e-02, -2.8130e-02, -5.0096e-02, -2.6308e-02,\n",
              "                                    -1.3307e-02, -2.2442e-03, -5.3689e-02,  1.3050e-02,\n",
              "                                    -2.3842e-02, -4.7389e-02, -6.9416e-02, -1.9253e-02,\n",
              "                                    -3.5580e-03, -6.3310e-02, -5.5801e-02,  1.7453e-02,\n",
              "                                    -3.4419e-02, -2.0619e-02,  1.1100e-02, -4.1777e-02,\n",
              "                                    -3.9348e-02, -5.3844e-02, -9.6834e-03, -5.0524e-02,\n",
              "                                    -6.6887e-03, -3.3468e-02, -3.5082e-02,  3.0754e-02,\n",
              "                                    -5.1878e-02, -2.2970e-02, -4.5923e-03, -2.1129e-02,\n",
              "                                    -6.9478e-03, -6.4210e-02, -1.2228e-02, -3.8294e-02,\n",
              "                                    -1.0731e-02,  1.9188e-02, -3.2960e-02, -7.9885e-03,\n",
              "                                     2.4576e-03, -1.8411e-02, -3.3383e-02, -5.3940e-02,\n",
              "                                    -3.0461e-02, -9.9752e-03, -6.4916e-03, -2.1090e-02,\n",
              "                                    -2.7473e-02, -1.0589e-02, -4.9370e-02, -9.3628e-03,\n",
              "                                    -8.2062e-02, -1.9673e-02, -4.1374e-02, -6.5777e-04,\n",
              "                                    -5.6784e-03, -1.0663e-02,  2.3737e-03, -1.6535e-02,\n",
              "                                    -2.3699e-02, -6.2875e-02, -9.5574e-03, -2.1743e-02,\n",
              "                                    -6.2849e-02, -3.6752e-02, -4.0024e-02, -2.6515e-02,\n",
              "                                    -1.8221e-02, -2.9556e-02, -4.7275e-02, -4.7511e-02,\n",
              "                                     1.6141e-03, -2.0435e-02, -5.8434e-02, -1.5008e-02,\n",
              "                                    -4.6517e-02, -2.3559e-02, -4.4813e-02, -5.8511e-04,\n",
              "                                    -1.6427e-02, -2.6068e-02, -4.2452e-02, -2.8118e-02,\n",
              "                                    -1.6404e-02, -2.5254e-02, -3.2619e-02, -2.1037e-02,\n",
              "                                    -1.9732e-04, -2.8974e-02, -4.5282e-02, -3.0582e-02,\n",
              "                                    -3.1332e-03, -4.4598e-02, -3.3159e-02, -4.9789e-02,\n",
              "                                     4.8242e-04, -6.2921e-02, -1.6271e-02, -1.5678e-03,\n",
              "                                    -2.9157e-02, -1.6642e-02, -3.5630e-03, -3.6760e-02,\n",
              "                                    -3.4577e-02, -6.3324e-02, -3.2023e-02, -5.9373e-02,\n",
              "                                    -2.8614e-02, -2.6391e-03, -4.6711e-02, -7.1779e-02,\n",
              "                                    -1.8617e-02, -7.6231e-02, -2.7249e-02, -4.2468e-02,\n",
              "                                    -4.3148e-02, -2.5124e-02, -2.2702e-02, -1.5316e-03,\n",
              "                                    -8.5010e-02, -1.4740e-02, -5.5029e-02, -2.4640e-02,\n",
              "                                    -1.5144e-02, -3.0009e-02, -3.5560e-02, -5.2829e-02,\n",
              "                                    -5.8731e-02, -4.2047e-02, -5.8092e-02, -4.6700e-02,\n",
              "                                    -2.3560e-02,  2.3917e-02, -2.6525e-02, -1.6958e-02,\n",
              "                                    -1.5159e-02,  8.9101e-04, -4.5562e-02, -4.8402e-02,\n",
              "                                     9.7224e-04, -5.4855e-02, -4.9722e-02, -2.5673e-02,\n",
              "                                    -2.5284e-02,  3.2364e-03, -7.2714e-02, -6.3840e-02,\n",
              "                                    -6.0030e-02, -7.2311e-02, -5.3804e-04, -1.4489e-02,\n",
              "                                    -3.6278e-02, -1.7573e-02, -1.3737e-02, -5.7157e-02,\n",
              "                                    -5.3884e-02, -3.7290e-02, -5.2941e-02, -6.4661e-02,\n",
              "                                     7.4210e-03, -5.8829e-02, -2.1270e-02, -3.4208e-02,\n",
              "                                    -1.6885e-02, -1.9368e-02, -3.9252e-02,  2.1136e-02,\n",
              "                                    -6.7163e-02, -5.9324e-02, -1.3300e-02, -3.8666e-02,\n",
              "                                    -5.3028e-02, -2.8871e-02, -4.0788e-03, -3.1892e-02,\n",
              "                                    -3.5477e-02, -2.6551e-02, -1.8044e-02, -4.3656e-02,\n",
              "                                    -1.5509e-02, -6.0553e-02, -4.7993e-02, -6.7797e-02,\n",
              "                                    -7.6173e-02, -2.4771e-02, -4.3663e-02,  4.3995e-02,\n",
              "                                    -2.8299e-02, -7.8366e-02, -3.7510e-04, -3.1400e-02,\n",
              "                                    -1.5275e-02, -3.9033e-02, -5.4800e-02, -5.7682e-02,\n",
              "                                    -7.1520e-03, -2.8473e-02, -3.4455e-03, -2.5148e-02,\n",
              "                                    -5.8982e-02, -5.0762e-02, -3.7229e-02, -1.9802e-02,\n",
              "                                    -5.4087e-02, -3.8195e-02, -1.1017e-02, -2.7721e-02,\n",
              "                                    -5.3803e-02, -2.8550e-02, -1.4895e-02, -9.9916e-03,\n",
              "                                    -6.0755e-02, -1.6565e-02, -4.1592e-02, -2.8739e-02,\n",
              "                                    -2.2947e-02, -5.7634e-02, -1.1123e-02, -2.5325e-02,\n",
              "                                     8.0513e-03, -2.6307e-02, -3.2760e-02, -6.3475e-02,\n",
              "                                    -2.8598e-03, -6.6137e-02, -2.4813e-02, -3.3373e-02,\n",
              "                                    -2.4354e-02, -4.5548e-02, -5.3517e-02, -3.9261e-02,\n",
              "                                    -1.9630e-02, -4.3629e-02,  2.3057e-02, -1.1201e-02,\n",
              "                                    -5.0254e-03,  1.0700e-02, -1.2689e-02, -1.2242e-02,\n",
              "                                    -1.1151e-01, -3.4518e-02, -4.3692e-03, -1.3024e-02,\n",
              "                                    -6.6600e-03, -1.3167e-03, -3.9391e-02, -3.3837e-02,\n",
              "                                    -3.8900e-03, -8.3776e-02, -2.3891e-02, -8.0818e-02,\n",
              "                                    -3.1424e-02, -4.4074e-02, -4.4316e-02, -4.5548e-02,\n",
              "                                    -1.2981e-02, -6.5361e-02, -6.6382e-02, -4.9598e-02,\n",
              "                                    -5.8375e-02, -2.1640e-02,  1.9021e-04, -3.1050e-02,\n",
              "                                    -2.6628e-02, -5.0381e-02, -1.8432e-03,  4.6084e-02,\n",
              "                                     4.2421e-03, -5.1770e-02, -1.6805e-02, -1.3818e-02,\n",
              "                                    -3.7288e-02, -1.5139e-02, -4.1529e-02, -4.6001e-02,\n",
              "                                     2.1381e-03,  7.8771e-03, -1.7138e-02, -7.7720e-03,\n",
              "                                    -3.0753e-02, -2.8675e-02, -8.1617e-03, -4.9718e-02,\n",
              "                                    -2.1633e-02, -4.1558e-02, -4.0469e-02, -5.0421e-02,\n",
              "                                    -1.6947e-02, -2.6256e-02, -1.4409e-03, -4.0005e-02,\n",
              "                                    -1.8292e-02, -1.5296e-02, -2.6985e-02, -3.1567e-02,\n",
              "                                     3.8652e-03, -2.4932e-02, -1.5147e-02, -4.2464e-02,\n",
              "                                    -2.3009e-02, -2.4839e-02, -4.3752e-02, -4.1104e-02,\n",
              "                                    -5.0921e-03, -4.3142e-02, -5.0328e-02, -4.1440e-02,\n",
              "                                    -3.1846e-02, -6.7284e-02, -7.8923e-02, -5.0912e-02,\n",
              "                                    -6.4583e-02,  7.5754e-03, -1.4234e-02, -6.3076e-02,\n",
              "                                    -1.4466e-02, -4.5055e-02, -8.5468e-03, -4.5832e-02,\n",
              "                                    -5.6506e-02, -1.8811e-02,  8.5962e-04, -4.5936e-02,\n",
              "                                     1.6667e-03, -4.9628e-02, -1.3847e-02, -5.2590e-02,\n",
              "                                    -1.3683e-02, -5.4979e-02, -1.6284e-02, -2.4622e-02,\n",
              "                                     2.4984e-02,  1.5161e-02,  6.3005e-03,  6.0544e-03,\n",
              "                                    -3.1791e-02,  1.0960e-02, -3.7396e-02,  1.1565e-03,\n",
              "                                    -3.8666e-02, -2.0756e-02, -4.2621e-02, -8.1420e-03,\n",
              "                                    -8.2989e-03, -2.5690e-02, -7.5419e-03, -4.2648e-02,\n",
              "                                    -2.0081e-02, -4.4048e-02, -4.1091e-02, -2.2284e-02,\n",
              "                                     6.1405e-03, -2.2719e-02, -3.2315e-02,  1.0385e-02,\n",
              "                                     2.3006e-02, -5.0560e-02, -2.1606e-02, -2.8624e-02,\n",
              "                                    -1.6026e-02, -3.5043e-02, -3.0725e-02,  1.3113e-02,\n",
              "                                     1.0200e-02,  9.4534e-03, -2.4130e-02, -5.3602e-02,\n",
              "                                    -2.6258e-02, -2.4957e-02, -4.8338e-02, -2.7881e-02,\n",
              "                                    -3.7191e-02, -3.9137e-02, -3.1523e-02, -1.9197e-02,\n",
              "                                    -4.8564e-02, -6.9982e-02, -3.7332e-02, -3.5440e-02,\n",
              "                                    -3.8944e-02, -7.4562e-02, -3.3382e-02, -3.4813e-02,\n",
              "                                    -2.2671e-02, -1.8654e-02, -3.0503e-02, -4.0653e-02,\n",
              "                                    -2.7312e-02, -5.9264e-03, -1.0917e-02, -1.7361e-02,\n",
              "                                    -4.8069e-02,  1.0797e-02, -1.8778e-02, -7.4670e-02,\n",
              "                                    -5.3537e-02, -3.4066e-02,  7.3930e-03, -3.7149e-02,\n",
              "                                    -5.0028e-02,  2.5632e-02,  5.1250e-02, -3.3767e-02,\n",
              "                                    -1.3964e-02, -2.3873e-02, -1.9649e-02, -4.7373e-02,\n",
              "                                    -5.2044e-02, -3.4740e-02, -1.7200e-02,  1.4388e-03,\n",
              "                                    -1.5387e-02, -2.8453e-02, -9.9633e-03, -4.2433e-02,\n",
              "                                    -2.8223e-02, -3.5677e-02, -1.8119e-02, -1.9023e-02,\n",
              "                                    -3.6324e-02, -1.9790e-02,  2.4422e-02, -3.9184e-02,\n",
              "                                    -2.9882e-02, -3.5639e-02, -1.3298e-02, -3.3670e-02,\n",
              "                                    -8.1222e-02, -1.9854e-02, -1.3847e-02, -1.2888e-02,\n",
              "                                    -3.5379e-02,  2.2529e-03, -9.5363e-03, -2.8646e-02,\n",
              "                                    -3.2410e-02, -3.1729e-02, -4.8751e-02,  1.5788e-02,\n",
              "                                    -8.1704e-02,  8.6712e-03, -3.5106e-02, -5.6305e-02,\n",
              "                                    -2.5754e-02,  2.8726e-02, -5.1271e-02, -5.0342e-02,\n",
              "                                    -1.5842e-02, -5.4580e-02, -3.3897e-02, -4.5570e-02,\n",
              "                                    -2.1231e-02, -2.1567e-02, -1.5656e-02, -7.1933e-03,\n",
              "                                    -3.6890e-02, -3.1950e-02, -2.3054e-02, -4.5367e-02,\n",
              "                                    -6.3489e-03, -1.6780e-02, -5.0739e-03, -8.6374e-02,\n",
              "                                     3.4639e-02, -3.5932e-02, -5.1146e-02, -5.4613e-02,\n",
              "                                    -1.5140e-02, -4.9032e-02, -1.2140e-03, -4.6430e-02,\n",
              "                                    -4.5049e-02, -1.0161e-02, -1.4894e-02, -3.7582e-02,\n",
              "                                    -7.1797e-02, -6.2346e-02, -2.0615e-02, -4.8100e-02,\n",
              "                                    -1.4285e-02, -4.0045e-03, -1.9788e-02, -5.0760e-03,\n",
              "                                    -1.9837e-02, -1.4170e-02, -4.0680e-02, -2.5292e-02,\n",
              "                                    -4.1461e-03, -5.9397e-02, -2.1744e-02, -2.3586e-02,\n",
              "                                    -4.6166e-03, -4.2926e-02, -4.8345e-02, -5.2926e-02,\n",
              "                                    -5.7426e-02, -3.7274e-02,  5.5084e-03, -4.3078e-02,\n",
              "                                    -2.6399e-02, -1.2173e-02, -2.2876e-02, -4.5651e-03,\n",
              "                                    -6.1694e-02, -2.7763e-02, -1.1291e-05, -4.9021e-02,\n",
              "                                    -1.3674e-02, -1.5362e-02,  1.3865e-02, -3.2672e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 1.9127, -3.9632, -7.1680,  3.1946,  1.4360, -6.9273,\n",
              "                                    -1.2140,  0.1256, -2.0811,  1.6499,  3.2786,  3.8295,\n",
              "                                     3.5366,  1.8883,  2.8123,  3.9825, -4.1602,  1.1098,\n",
              "                                     1.0880,  2.3912, -5.9562, -5.5240, -1.3818, -4.9511,\n",
              "                                    -5.3882,  2.9722,  1.2005, -1.0083, -6.2406,  1.9769,\n",
              "                                    -4.6927, -2.1798,  1.9042, -5.7105, -7.4594,  1.2905,\n",
              "                                    -5.8999,  1.9512, -1.8859, -2.7584, -1.2637,  2.7494,\n",
              "                                     1.2926,  0.7159, -3.0929, -1.8118,  4.8158,  2.8445,\n",
              "                                     2.1121,  2.2318, -7.9005, -3.7074,  0.0737, -0.9027,\n",
              "                                    -3.0422, -4.3304,  5.7484, -4.9785,  3.7536,  4.1355,\n",
              "                                    -3.5375,  5.0725,  0.3204,  3.3352,  2.6868, -7.6737,\n",
              "                                     2.3913, -4.7747, -5.7482,  5.6084, -0.8731,  0.2514,\n",
              "                                    -0.2057, -6.6834,  1.8278, -2.6482, -1.2976, -3.9712,\n",
              "                                    -5.0383, -0.1982, -1.7899, -0.1535, -2.0162,  3.4131,\n",
              "                                     2.2874,  3.0533,  0.3228, -6.9990,  1.7341,  1.8737,\n",
              "                                     0.3315,  3.9961, -3.7944,  6.2500, -3.7375, -3.3398,\n",
              "                                    -0.2540,  2.2136,  0.7503,  2.5733, -0.1432, -5.1303,\n",
              "                                    -4.6234,  2.0350,  3.0133, -3.8993,  2.7005,  3.3939,\n",
              "                                     0.1316,  3.2897,  4.5771, -6.4694,  3.2236, -2.0480,\n",
              "                                     4.8368, -4.1609, -2.0872, -3.0346, -1.9789, -2.2203,\n",
              "                                     0.5107,  2.9875,  2.7517, -4.2175, -6.1647,  1.3207,\n",
              "                                     2.0980, -8.1650, -3.4934, -1.4482, -4.6725, -4.8223,\n",
              "                                     1.0164,  0.3179,  2.1957, -6.2516, -5.2372, -6.6009,\n",
              "                                    -8.3449,  1.4716, -6.4982,  3.2488, -2.2320, -7.1531,\n",
              "                                     4.0369,  3.2335,  1.6874,  0.8289, -4.2568,  2.6074,\n",
              "                                    -2.9563,  1.3469,  0.7740, -2.9256,  2.2186, -5.1079,\n",
              "                                     2.2223, -4.2746,  1.1732, -2.4257, -2.1457, -9.8302,\n",
              "                                     0.3032,  0.3939, -5.7923, -2.9394,  4.0991, -1.7143,\n",
              "                                     2.6259,  0.9405,  4.3187, -3.0349, -0.2716,  3.8950,\n",
              "                                     3.9844, -7.6183, -3.8529,  3.2338, -6.1561,  1.3935,\n",
              "                                     4.3446, -2.6162, -3.0767, -6.9887,  0.6947, -3.4728,\n",
              "                                    -1.3663, -3.0449, -2.0191,  0.4642, -4.8026,  2.2708,\n",
              "                                    -2.4570,  2.8570,  0.2431, -1.6898,  0.2501,  0.8984,\n",
              "                                     2.8765,  1.7582,  0.0275,  1.4438, -2.7383, -1.7276,\n",
              "                                     7.3058, -1.5474, -0.4235,  1.7423,  0.0114, -2.2997,\n",
              "                                     0.1740,  3.9721,  0.6387,  1.5221, -4.2068,  3.6257,\n",
              "                                     2.8570, -0.0602,  0.5355, -1.8759, -3.8688, -7.7362,\n",
              "                                     4.4796, -5.7553,  2.5751, -2.5088,  1.7845, -6.3466,\n",
              "                                    -6.6920, -6.6500, -3.9876, -5.0409, -1.1712,  3.5089,\n",
              "                                    -1.2309,  3.5113,  3.2405,  1.9286,  0.1338, -7.2987,\n",
              "                                    -2.0359,  2.4874,  3.6418,  0.9738,  1.9683,  0.4565,\n",
              "                                    -2.1139, -1.3099,  2.8874, -2.6884, -5.4084,  0.5856,\n",
              "                                    -4.8801,  1.4755,  1.5911,  1.7563, -2.9931,  1.8377,\n",
              "                                    -2.6781, -2.0418,  2.8075, -4.7058, -0.6168, -4.7107,\n",
              "                                    -3.4999, -1.6323, -1.9387, -3.1179, -1.8630, -2.0177,\n",
              "                                     4.7988,  0.9689,  1.0482,  1.6876, -4.1395, -3.6191,\n",
              "                                     2.6142, -2.5816,  6.2652,  3.0592, -1.4398,  5.5712,\n",
              "                                    -1.4580,  0.8610, -5.6302, -0.5955, -5.6267, -5.6109,\n",
              "                                    -0.0292,  2.1181, -2.1532, -1.5058, -2.4387, -1.8535,\n",
              "                                     0.0943,  1.2480, -0.9377,  1.9148, -2.5896, -8.5074,\n",
              "                                     1.7860,  1.6499,  1.4685,  3.5011,  2.6527,  3.3543,\n",
              "                                     2.7666,  0.2972,  3.6263,  0.8375, -3.9917,  3.2437,\n",
              "                                    -6.6948, -0.8694, -4.1912, -2.2634, -1.2761,  2.1428,\n",
              "                                    -5.2894,  1.0744,  1.6414, -3.9212, -1.9358,  0.4822,\n",
              "                                    -3.0693,  1.6272, -3.0574,  0.8866,  2.8402,  4.0583,\n",
              "                                    -1.0460,  2.6022, -3.6867, -2.7339, -0.6972,  3.6277,\n",
              "                                     1.0247,  2.7902,  0.2425, -3.7786, -8.3395,  2.3934,\n",
              "                                    -7.6620, -3.8636,  4.7089, -0.5059,  2.7478,  0.5028,\n",
              "                                    -2.8001,  1.7622, -0.3234, -0.2508,  2.3799, -3.4902,\n",
              "                                    -3.3776, -4.0106, -3.3620,  1.0415, -3.8313, -5.1758,\n",
              "                                    -4.2385,  4.6187, -0.2989, -1.0306,  1.3844, -3.5175,\n",
              "                                    -5.8636, -0.7529, -5.7021, -4.1406, -6.8614, -2.7127,\n",
              "                                    -1.6798,  4.0306,  2.4562, -3.1755, -0.5176,  1.7988,\n",
              "                                    -5.5458, -2.6939, -6.4027, -4.7854,  2.3981, -4.0309,\n",
              "                                     5.3661,  3.3813,  4.3597,  1.6156,  1.1180, -2.5614,\n",
              "                                     3.6880, -3.9733,  1.8698,  3.1059,  3.2238, -3.3483,\n",
              "                                     0.8505, -1.6045,  1.1368, -8.9649,  4.5503, -6.3840,\n",
              "                                     2.4650,  2.8101, -4.0864,  1.5313,  0.5970,  0.2408,\n",
              "                                    -2.5285, -6.0708,  2.7090, -1.6208,  0.5537,  3.4357,\n",
              "                                     0.1930, -0.2764,  1.7717, -6.7513, -6.0741,  3.1014,\n",
              "                                    -3.0967,  1.6406,  0.8716, -6.6329, -4.5535,  0.7560,\n",
              "                                     2.8523,  1.4256, -0.3735, -5.2817, -1.7501,  2.2229,\n",
              "                                    -1.0176, -4.8612,  1.6895,  2.0078,  3.5413, -3.0963,\n",
              "                                    -4.1411,  2.2879,  1.7959, -1.6723, -1.1932, -5.6075,\n",
              "                                     1.9502, -2.4363, -0.1532,  0.3321, -3.6248,  3.3850,\n",
              "                                    -0.7563, -4.2113, -4.7696, -6.6120, -0.2542,  0.9648,\n",
              "                                    -8.7083, -9.9141,  1.0808,  0.3422,  1.2986, -1.3289,\n",
              "                                     0.6880,  2.6582,  0.5435, -5.9285, -4.6525, -5.2990,\n",
              "                                    -6.4218, -0.0690, -0.5864,  0.7998,  4.9702,  2.6404,\n",
              "                                    -2.5629,  0.0558, -5.7852,  2.8072, -0.1724, -0.6273,\n",
              "                                    -6.8141,  0.9349, -1.9341, -5.1770,  1.7720, -1.5071,\n",
              "                                    -3.3553, -0.8466,  1.2696, -0.1082,  2.1641,  1.4354,\n",
              "                                     2.3738,  3.0368, -1.1450, -0.6423, -0.5982,  1.1801,\n",
              "                                     1.9079,  3.9932, -0.2732, -1.8139,  1.6953, -2.7123,\n",
              "                                    -2.0969,  3.4068, -2.0568, -7.3598, -2.1363, -6.1590,\n",
              "                                     2.9912, -0.6111]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 57.8174, 108.7714, 142.3192,  64.4063,  39.5789,\n",
              "                                     66.2631,  59.3812,  58.7136,  77.4733,  86.9934,\n",
              "                                     59.3711, 127.0650,  84.7377,  63.6377,  70.1832,\n",
              "                                     94.2021,  63.0547,  37.3893,  64.8244,  49.6890,\n",
              "                                     42.5449,  89.9034,  55.4166,  45.4168,  80.2428,\n",
              "                                     38.5310,  98.1302,  61.7541, 129.0024,  67.3584,\n",
              "                                     52.0935,  68.2953,  64.3706,  64.2812, 101.2563,\n",
              "                                     45.5972,  50.0920,  54.0061,  83.1455,  46.2772,\n",
              "                                     83.2541,  69.7758,  49.5873,  59.9044,  37.0436,\n",
              "                                     56.5446,  47.9437,  40.7631,  50.2488,  47.5706,\n",
              "                                    104.0982,  61.6322,  51.6406,  48.5849,  59.0250,\n",
              "                                     83.2833,  56.5426,  62.2829, 133.5056,  53.4767,\n",
              "                                     64.1027,  76.6194,  57.4890,  47.3810,  63.9341,\n",
              "                                     92.7170,  49.6166,  72.6544,  80.8391,  98.8440,\n",
              "                                     55.8659,  64.6333,  47.6746, 106.1718,  89.2195,\n",
              "                                     46.7209,  42.0790,  57.2730,  63.0772,  33.4393,\n",
              "                                     58.5142,  75.3609,  43.5451, 101.4264, 124.7646,\n",
              "                                     54.2212,  53.9220, 107.7400,  85.5326, 118.0667,\n",
              "                                     37.9777,  87.5609,  57.8157,  60.5854,  54.8053,\n",
              "                                     73.5922,  61.3924,  61.7891,  39.6756,  36.3072,\n",
              "                                     25.2752, 112.6890,  69.6382,  35.5665,  67.4567,\n",
              "                                     29.0510,  78.3935,  81.7510,  68.8708, 101.6842,\n",
              "                                    103.8747,  97.4902,  61.0072,  36.0434,  84.4414,\n",
              "                                     97.2358,  47.5011,  58.0978,  67.5569,  70.1306,\n",
              "                                     60.3414,  54.6288,  65.3373,  60.3643,  86.0907,\n",
              "                                     51.5170,  77.7815, 140.9894,  39.6514,  83.9089,\n",
              "                                     29.2621,  83.5781,  68.6047,  68.6256,  82.3698,\n",
              "                                     79.9156,  48.6456, 115.9462,  68.9438,  55.7999,\n",
              "                                     57.5992,  66.8621,  61.9450, 118.0475,  66.4263,\n",
              "                                     73.3379,  63.7690,  43.3562,  52.7751,  48.7530,\n",
              "                                     51.9205,  72.0889,  52.8808,  64.9926, 105.1817,\n",
              "                                     66.0203,  70.3676,  75.8512,  41.2641,  61.5203,\n",
              "                                     54.4014, 142.3353,  38.4230,  43.9209,  90.0038,\n",
              "                                     49.1838, 118.1718,  82.9430,  54.3263,  65.6302,\n",
              "                                     54.8831,  88.5172,  28.5048,  44.7922,  77.3882,\n",
              "                                     88.7577,  50.5241, 105.8381,  65.5755,  55.0042,\n",
              "                                     81.9341,  35.4650,  56.1674,  85.1405,  49.1366,\n",
              "                                     82.8868,  45.2994, 121.2014,  32.3051,  63.2493,\n",
              "                                     48.1793,  70.8300,  45.5885,  64.3465,  65.4325,\n",
              "                                     52.1495,  82.1159,  49.9690,  54.0080,  31.4192,\n",
              "                                     52.3124,  64.9035,  38.8910,  71.5561,  96.6778,\n",
              "                                     66.8654,  62.4881,  58.3630,  36.0942,  94.9805,\n",
              "                                     47.9128,  76.2675,  30.7479,  59.2431,  58.4859,\n",
              "                                     83.5105, 100.3159,  52.3047,  68.5810,  54.2283,\n",
              "                                     46.9419, 166.6075,  70.1628,  73.9668,  81.5030,\n",
              "                                     50.8549,  57.0363,  45.7027,  86.8384,  81.7451,\n",
              "                                     39.4195,  67.0792,  43.7224,  64.2808,  73.6720,\n",
              "                                    144.5804,  62.4857,  68.3540,  40.2294,  65.9088,\n",
              "                                     45.3871,  61.4762,  88.3188,  52.9142,  48.1999,\n",
              "                                     64.1127,  28.0573,  61.5861,  60.4309,  52.2570,\n",
              "                                    103.0731,  67.6382,  93.5508,  53.9484,  81.8145,\n",
              "                                     50.3404,  85.5824,  28.8871,  44.4669,  38.0365,\n",
              "                                     44.8804,  86.3632,  40.8511,  73.1293,  44.7873,\n",
              "                                     47.1463,  46.5323,  64.4144,  66.6066,  51.7927,\n",
              "                                     60.5361,  38.8653,  52.9554,  64.5783, 112.8388,\n",
              "                                     52.5213,  46.4174,  51.3261,  57.3240,  78.2456,\n",
              "                                     46.5667,  99.1726,  47.4889,  34.1857,  65.8715,\n",
              "                                     78.7782,  74.0810,  52.7774,  41.8217,  81.5166,\n",
              "                                     69.6483,  47.4556,  45.8217,  33.7875,  34.3650,\n",
              "                                     58.0875,  55.2701,  92.7138,  54.5913, 129.2559,\n",
              "                                     71.1064,  91.9285,  55.8599,  47.9954,  71.7053,\n",
              "                                     35.8474,  59.7129,  56.4477,  84.3626,  68.2647,\n",
              "                                     52.7288,  90.9895, 108.0781,  70.6404,  44.9816,\n",
              "                                     38.3925,  50.2458,  44.1097,  54.0448,  74.4143,\n",
              "                                     49.8020,  62.2595,  47.2349,  49.8830,  63.0951,\n",
              "                                     53.2897,  85.6636,  44.3529,  43.8264,  57.4399,\n",
              "                                     47.5125,  61.2047,  65.1142,  48.2373,  54.0723,\n",
              "                                     68.6836,  68.4186,  81.3602,  83.3383,  42.9636,\n",
              "                                     98.9041,  55.6208,  76.7462,  73.1521,  52.0191,\n",
              "                                     37.9168,  42.2602,  38.1350,  69.8881,  37.8748,\n",
              "                                     74.5304,  58.7325,  64.1775,  62.5554,  96.7624,\n",
              "                                    104.5503,  69.0246,  50.7609,  52.0744,  44.5579,\n",
              "                                     49.0796,  95.2215,  65.4409,  60.1863,  89.4290,\n",
              "                                     82.0754,  60.9279,  53.0181,  59.8750,  75.7846,\n",
              "                                     80.7556,  68.5302,  81.6069, 114.8288,  80.1878,\n",
              "                                     59.7610,  47.1029,  40.3322,  75.2826,  74.0582,\n",
              "                                    105.8385,  68.1046,  61.2521,  64.5171,  75.5528,\n",
              "                                     71.2230,  59.1125,  55.9488, 123.5691,  62.5235,\n",
              "                                     82.4265,  48.2400,  78.7643,  57.5791,  68.7341,\n",
              "                                     50.4729,  93.5800,  59.6840,  64.3630,  98.9563,\n",
              "                                     60.8760,  85.1745,  75.9509,  87.8139,  88.5423,\n",
              "                                     33.8172,  84.9646,  55.8792,  58.8168,  69.0779,\n",
              "                                     92.1940,  43.8769,  30.4974,  81.3487,  61.8509,\n",
              "                                     56.5696,  59.0379,  53.6407, 118.9412,  83.0900,\n",
              "                                     47.1931,  66.9744,  49.8899,  89.8623,  55.3626,\n",
              "                                     64.5489, 111.7151,  36.4356,  27.2553,  49.9147,\n",
              "                                     54.4069,  44.1066,  52.0316,  77.5492,  30.2412,\n",
              "                                     74.0195,  55.4816,  53.7367,  57.8258,  80.9756,\n",
              "                                     21.7051,  63.9588,  75.6015,  60.9845, 110.6432,\n",
              "                                     47.6391,  38.5681,  72.5981,  60.8966,  47.0986,\n",
              "                                     62.8007,  57.6076,  34.6737,  66.2062,  68.4937,\n",
              "                                     52.2863, 156.8947,  95.0943,  57.6562,  84.3179,\n",
              "                                     92.2341,  34.9587, 103.0885,  66.0681,  61.3359,\n",
              "                                     82.7275,  57.9760,  85.0710, 147.1655,  65.1341,\n",
              "                                     79.7679,  80.5702,  72.6123,  74.2183,  33.5221,\n",
              "                                     38.1628,  70.1917,  56.5243,  43.9592,  57.0805,\n",
              "                                     76.4799,  80.2258,  60.2098,  65.7414,  78.2239,\n",
              "                                     80.6709,  48.0701,  48.8250,  51.1189,  59.5263,\n",
              "                                     40.9943,  77.7849,  60.4319,  72.8430,  38.4661,\n",
              "                                     57.9886,  54.1910,  61.7244,  97.2331,  44.9234,\n",
              "                                     58.4587,  77.5257,  58.8618,  81.9014,  52.5813,\n",
              "                                     96.2689,  60.1282,  72.2025,  38.0209,  81.4736,\n",
              "                                     35.8658,  28.4769]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 2047, 2047, 2047],\n",
              "                                     [   0,    1,    2,  ...,  509,  510,  511],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0089,  0.0225,  0.0550,  ...,  0.0563, -0.0241,\n",
              "                                     0.0327]),\n",
              "                     size=(2048, 512, 1, 1), nnz=1048576, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([0.9704, 1.0005, 0.9528,  ..., 0.9872, 0.9939, 0.9933]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([-0.0260, -0.0286, -0.0440,  ..., -0.0259, -0.0259,\n",
              "                                    -0.0409]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([-1.3165, -1.6579,  1.3029,  ..., -0.2100, -1.2371,\n",
              "                                    -1.3136]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([5.0109, 1.6261, 3.5168,  ..., 2.4250, 3.3635, 4.1512]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.downsample.0.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 2047, 2047, 2047],\n",
              "                                     [   0,    1,    2,  ..., 1021, 1022, 1023],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0836,  0.0661,  0.0014,  ...,  0.0040, -0.0016,\n",
              "                                     0.0292]),\n",
              "                     size=(2048, 1024, 1, 1), nnz=2097152, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.downsample.1.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([0.9887, 1.0027, 0.9816,  ..., 0.9799, 0.9924, 0.9464]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.downsample.1.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([-0.0260, -0.0286, -0.0440,  ..., -0.0259, -0.0259,\n",
              "                                    -0.0409]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.downsample.1.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([ 4.3820,  3.6026, -8.6605,  ...,  4.8077, -2.1588,\n",
              "                                    11.0260]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.downsample.1.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([142.1100,  69.2816, 158.8813,  ...,  74.6693,\n",
              "                                     83.9889, 191.7089]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.0.downsample.1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  511,  511,  511],\n",
              "                                     [   0,    1,    2,  ..., 2045, 2046, 2047],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0224, -0.0100,  0.0465,  ..., -0.0980, -0.0355,\n",
              "                                    -0.0447]),\n",
              "                     size=(512, 2048, 1, 1), nnz=1048576, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9847, 1.0200, 0.9765, 1.0386, 1.0289, 1.0554, 1.1345,\n",
              "                                    0.9884, 1.0385, 1.0112, 0.9835, 0.9415, 1.0390, 0.9629,\n",
              "                                    0.9329, 1.0082, 0.9790, 0.9904, 0.9305, 0.9458, 1.0196,\n",
              "                                    1.0729, 0.9450, 0.9535, 1.0160, 1.0044, 0.9885, 0.9643,\n",
              "                                    1.0030, 0.9685, 1.0088, 0.9637, 0.9722, 0.9907, 0.9874,\n",
              "                                    1.0102, 1.0030, 1.0302, 0.9991, 0.9949, 0.9823, 0.9996,\n",
              "                                    0.9775, 0.9803, 0.9907, 1.0110, 0.9600, 0.9730, 0.9865,\n",
              "                                    0.9957, 1.0366, 1.0002, 0.9985, 0.9832, 1.0053, 1.0737,\n",
              "                                    0.9789, 0.9687, 0.9262, 0.9487, 1.0332, 1.0275, 1.0375,\n",
              "                                    1.0324, 0.9935, 1.0021, 0.9119, 1.0306, 1.0310, 1.0113,\n",
              "                                    0.9172, 0.9589, 0.9913, 1.0008, 0.9870, 0.9815, 1.0237,\n",
              "                                    0.9547, 1.0094, 1.0065, 1.0266, 0.9928, 1.0041, 1.0258,\n",
              "                                    1.0289, 0.9555, 1.0307, 0.9947, 1.0071, 0.9583, 0.9788,\n",
              "                                    0.9575, 0.9837, 1.0211, 1.0278, 1.0169, 1.0297, 0.9584,\n",
              "                                    1.0151, 0.9534, 1.0010, 0.9888, 0.9861, 0.9680, 0.9314,\n",
              "                                    0.9584, 0.9994, 0.9769, 0.9470, 1.0153, 0.9969, 0.9861,\n",
              "                                    1.0537, 0.9840, 0.9715, 1.0300, 0.9793, 1.0001, 0.9895,\n",
              "                                    0.9734, 1.0352, 1.0519, 1.0528, 1.0004, 0.9736, 0.9980,\n",
              "                                    1.0386, 0.9719, 0.9965, 1.0462, 0.9544, 1.0531, 1.0313,\n",
              "                                    1.0097, 1.0082, 0.9667, 0.9530, 1.0072, 0.9665, 1.0560,\n",
              "                                    0.9141, 1.0522, 0.9545, 0.9865, 1.0094, 1.0054, 1.0195,\n",
              "                                    1.0061, 0.9966, 1.0083, 1.0534, 1.0231, 1.0157, 1.0459,\n",
              "                                    0.9953, 1.0112, 0.9872, 1.0092, 1.0291, 0.9974, 0.9835,\n",
              "                                    1.0082, 1.0485, 1.0265, 0.9834, 1.0057, 1.0169, 1.0328,\n",
              "                                    1.0051, 1.0534, 0.9636, 0.9816, 0.9684, 0.9310, 0.9616,\n",
              "                                    0.9732, 1.0099, 1.0047, 0.9826, 1.0491, 1.0280, 0.9874,\n",
              "                                    0.9879, 0.9415, 0.9606, 1.0189, 1.0173, 0.9732, 0.9340,\n",
              "                                    1.0246, 0.9843, 1.0274, 1.0200, 0.9697, 1.0387, 0.9758,\n",
              "                                    1.0021, 1.0188, 0.9947, 1.0093, 1.0018, 0.9908, 0.9651,\n",
              "                                    1.0507, 1.0043, 0.9510, 1.0643, 1.0494, 1.0105, 1.0067,\n",
              "                                    0.9914, 0.9363, 0.9740, 0.9740, 1.0203, 1.0306, 1.0012,\n",
              "                                    1.0482, 0.9384, 0.9846, 0.9675, 1.0430, 0.9673, 1.0151,\n",
              "                                    0.9962, 1.0093, 0.9946, 1.0202, 0.9942, 0.9601, 1.0061,\n",
              "                                    1.0425, 0.9980, 1.0996, 1.0254, 0.9647, 1.0349, 0.9913,\n",
              "                                    0.9756, 0.9987, 1.0161, 0.9753, 0.9624, 0.9875, 0.9782,\n",
              "                                    1.0022, 1.0284, 1.0116, 1.0391, 0.9699, 0.9878, 1.0191,\n",
              "                                    1.0098, 1.1095, 0.9787, 0.9980, 1.0416, 1.0670, 1.0398,\n",
              "                                    0.9899, 0.9655, 1.0713, 1.0145, 0.9556, 0.9495, 1.0056,\n",
              "                                    0.9797, 0.9882, 1.0409, 1.0370, 0.9478, 0.9929, 0.9876,\n",
              "                                    1.0140, 0.9809, 1.0236, 0.9868, 1.0371, 0.9791, 1.0706,\n",
              "                                    1.0382, 0.9827, 1.0239, 0.9881, 1.0663, 0.9930, 0.9672,\n",
              "                                    0.9786, 1.0152, 1.0353, 1.0219, 1.0388, 0.9902, 1.0148,\n",
              "                                    0.9523, 1.0474, 0.9546, 1.0214, 0.9678, 0.9545, 1.0068,\n",
              "                                    0.9749, 0.9913, 1.0391, 1.0598, 0.9632, 0.9585, 0.9824,\n",
              "                                    1.0486, 0.9881, 1.0074, 1.0464, 0.9978, 0.9856, 1.0019,\n",
              "                                    0.9971, 0.9923, 0.9721, 1.0418, 1.0849, 1.0037, 0.9656,\n",
              "                                    1.0085, 0.9872, 0.9962, 0.9976, 0.9654, 0.9745, 1.0512,\n",
              "                                    1.0080, 0.9894, 0.9651, 0.9824, 0.9875, 1.0345, 1.0543,\n",
              "                                    1.0591, 0.9664, 0.9712, 0.9956, 1.0076, 1.0463, 0.9616,\n",
              "                                    1.0860, 0.9702, 1.0220, 0.9954, 1.0615, 0.9347, 1.0350,\n",
              "                                    0.9840, 1.0437, 0.9732, 1.0564, 0.9734, 1.0464, 0.9841,\n",
              "                                    1.0533, 0.9874, 0.9202, 1.0151, 0.9451, 0.9854, 1.0539,\n",
              "                                    1.0110, 1.0027, 0.9551, 0.9917, 1.0556, 1.0063, 0.9491,\n",
              "                                    1.0281, 1.0068, 0.9947, 0.9128, 1.0042, 0.9844, 0.9231,\n",
              "                                    1.0113, 1.0037, 0.9897, 1.0311, 1.0490, 1.0137, 1.0199,\n",
              "                                    0.9908, 1.0239, 0.9989, 0.9963, 0.9829, 1.0935, 1.0051,\n",
              "                                    0.9128, 1.0151, 1.0456, 0.9969, 0.9929, 1.0276, 0.9846,\n",
              "                                    0.9527, 1.0041, 1.0391, 0.9525, 0.9675, 0.9603, 1.0541,\n",
              "                                    0.9950, 0.9894, 0.9951, 1.0392, 1.0482, 1.0007, 0.9425,\n",
              "                                    1.0232, 1.0152, 0.9839, 1.0386, 1.0133, 1.0158, 0.9382,\n",
              "                                    0.9701, 1.0017, 0.9882, 1.0437, 0.9698, 0.9903, 1.0636,\n",
              "                                    0.9806, 1.0378, 0.9709, 1.0167, 1.0403, 1.0415, 0.9434,\n",
              "                                    1.0290, 1.0166, 1.0095, 0.9662, 0.9884, 1.0373, 0.9745,\n",
              "                                    1.0542, 0.9704, 1.0276, 1.0161, 1.0136, 0.9661, 1.0124,\n",
              "                                    0.9883, 1.0020, 0.9939, 0.9931, 0.9972, 1.0014, 0.9816,\n",
              "                                    0.9557, 0.8895, 1.0038, 0.9133, 1.0069, 0.9882, 0.9669,\n",
              "                                    1.0154, 1.0111, 1.0033, 0.9677, 0.9601, 0.9836, 1.0319,\n",
              "                                    1.0017, 0.9217, 1.0095, 0.9138, 1.0116, 1.0203, 1.0152,\n",
              "                                    0.9982, 0.9772, 1.0177, 0.9719, 0.9534, 0.9507, 1.0071,\n",
              "                                    1.0005, 0.9862, 0.9889, 0.9432, 0.9916, 1.0068, 1.0141,\n",
              "                                    1.0667, 1.0395, 0.9516, 1.0106, 1.0264, 1.0303, 0.9445,\n",
              "                                    1.0305, 1.0090, 0.9818, 0.9595, 1.0024, 0.9399, 1.0304,\n",
              "                                    0.9581, 1.0209, 0.9901, 0.9968, 1.0044, 1.0532, 1.0048,\n",
              "                                    1.0055]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-0.0206,  0.0537, -0.0223, -0.0275,  0.0099,  0.0046,\n",
              "                                     0.0553, -0.0527,  0.0441, -0.0148, -0.0061, -0.0823,\n",
              "                                     0.0405,  0.0006, -0.0305, -0.0224,  0.0365,  0.0365,\n",
              "                                    -0.0318,  0.0242,  0.0183,  0.0447, -0.0480, -0.0167,\n",
              "                                     0.0127, -0.0198,  0.0258, -0.0048,  0.0162,  0.0084,\n",
              "                                     0.0345, -0.0129, -0.0019,  0.0139, -0.0060, -0.0215,\n",
              "                                     0.0262, -0.0003,  0.0295, -0.0123, -0.0285,  0.0169,\n",
              "                                    -0.0134,  0.0124, -0.0542,  0.0208, -0.0046,  0.0118,\n",
              "                                    -0.0085,  0.0079,  0.0167, -0.0140,  0.0128, -0.0323,\n",
              "                                     0.0369,  0.0150,  0.0414, -0.0325,  0.0257, -0.0302,\n",
              "                                     0.0309,  0.0133,  0.0205,  0.0272, -0.0107, -0.0190,\n",
              "                                    -0.0799, -0.0074,  0.0002,  0.0406, -0.0737, -0.0355,\n",
              "                                     0.0420,  0.0591,  0.0248, -0.0036,  0.0120, -0.0259,\n",
              "                                     0.0092,  0.0046, -0.0198,  0.0428,  0.0016, -0.0065,\n",
              "                                     0.0272,  0.0024, -0.0155,  0.0003,  0.0494, -0.0466,\n",
              "                                     0.0203, -0.0137, -0.0203,  0.0347,  0.0319,  0.0218,\n",
              "                                     0.0712, -0.0188,  0.0103, -0.0107, -0.0296,  0.0093,\n",
              "                                    -0.0079, -0.0268, -0.0661, -0.0636, -0.0618,  0.0193,\n",
              "                                    -0.0507,  0.0506, -0.0041,  0.0058,  0.0750, -0.0087,\n",
              "                                    -0.0184,  0.0159,  0.0147, -0.0113, -0.0105,  0.0024,\n",
              "                                     0.0594,  0.0703,  0.0001,  0.0130, -0.0024, -0.0231,\n",
              "                                     0.0432, -0.0219, -0.0184,  0.0058,  0.0247,  0.0234,\n",
              "                                     0.0312, -0.0294,  0.0591,  0.0124, -0.0266,  0.0468,\n",
              "                                    -0.0005,  0.0153, -0.0434,  0.0180, -0.0636, -0.0238,\n",
              "                                     0.0064,  0.0192, -0.0142,  0.0463, -0.0493, -0.0092,\n",
              "                                     0.0237,  0.0466, -0.0437,  0.0110,  0.0089,  0.0199,\n",
              "                                     0.0109,  0.0064,  0.0746,  0.0142, -0.0309, -0.0095,\n",
              "                                     0.0285, -0.0242,  0.0116, -0.0214,  0.0028,  0.0217,\n",
              "                                     0.0263, -0.0078, -0.0412, -0.0016,  0.0017, -0.0307,\n",
              "                                    -0.0599, -0.0210, -0.0008,  0.0154, -0.0104,  0.0234,\n",
              "                                     0.0239, -0.0715, -0.0495,  0.0154, -0.0270,  0.0232,\n",
              "                                    -0.0315, -0.0051,  0.0205,  0.0163, -0.0254,  0.0238,\n",
              "                                    -0.0398, -0.0343, -0.0104, -0.0567,  0.0449,  0.0899,\n",
              "                                     0.0432,  0.0029,  0.0352,  0.0097, -0.0164,  0.0543,\n",
              "                                    -0.0147, -0.0378,  0.0653,  0.0376, -0.0041, -0.0153,\n",
              "                                     0.0075, -0.0539, -0.0354,  0.0146,  0.0276,  0.0224,\n",
              "                                     0.0043, -0.0471,  0.0352,  0.0300, -0.0169, -0.0159,\n",
              "                                    -0.0710, -0.0075,  0.0108, -0.0275,  0.0353,  0.0130,\n",
              "                                    -0.0004, -0.0152,  0.0269,  0.0034,  0.0285,  0.0582,\n",
              "                                     0.0223,  0.0277,  0.0349, -0.0348,  0.0036,  0.0132,\n",
              "                                     0.0417, -0.0474, -0.0162,  0.0093, -0.0179, -0.0127,\n",
              "                                     0.0046,  0.0287,  0.0397,  0.0365, -0.0300, -0.0126,\n",
              "                                    -0.0186,  0.1038,  0.0448,  0.0043,  0.0429,  0.0393,\n",
              "                                     0.0636,  0.0399, -0.0430, -0.0188, -0.0039, -0.0225,\n",
              "                                    -0.0136,  0.0287,  0.0433, -0.0077,  0.0256,  0.0697,\n",
              "                                    -0.0119, -0.0097, -0.0068, -0.0305,  0.0093,  0.1051,\n",
              "                                     0.0585,  0.0671, -0.0243,  0.0648,  0.0155,  0.0198,\n",
              "                                     0.0548, -0.0007, -0.0028,  0.0549, -0.0379,  0.0307,\n",
              "                                     0.0129,  0.0244, -0.0139,  0.0264, -0.0443,  0.0400,\n",
              "                                    -0.0326,  0.0142, -0.0216,  0.0533, -0.0025, -0.0404,\n",
              "                                    -0.0457, -0.0338,  0.0404,  0.0342,  0.0620, -0.0038,\n",
              "                                    -0.0716, -0.0344,  0.0201, -0.0097,  0.0033,  0.0313,\n",
              "                                     0.0576,  0.0253,  0.0091,  0.0277, -0.0493, -0.0421,\n",
              "                                    -0.0090,  0.0428,  0.0713, -0.0390, -0.0179,  0.0086,\n",
              "                                     0.0186,  0.0062,  0.0125,  0.0163,  0.0794, -0.0005,\n",
              "                                    -0.0280, -0.0118, -0.0073, -0.0128, -0.0046,  0.0327,\n",
              "                                     0.0289, -0.0336, -0.0572,  0.0095,  0.0275,  0.0855,\n",
              "                                    -0.0142,  0.0239, -0.0301, -0.0288,  0.0189,  0.0138,\n",
              "                                    -0.0150,  0.0533, -0.0343, -0.0118,  0.0291,  0.0165,\n",
              "                                    -0.0113,  0.0272,  0.0005,  0.0101,  0.0139, -0.0229,\n",
              "                                     0.0211, -0.0423, -0.0202,  0.0069, -0.0062,  0.0396,\n",
              "                                    -0.0244,  0.0048,  0.0748,  0.0538,  0.0219,  0.0440,\n",
              "                                    -0.0109,  0.0109, -0.0571,  0.0036,  0.0404, -0.0036,\n",
              "                                     0.0127,  0.0622, -0.0014,  0.0186, -0.0004,  0.0421,\n",
              "                                    -0.0027, -0.0228,  0.0422, -0.0110, -0.0113,  0.0509,\n",
              "                                    -0.0449,  0.0019, -0.0530,  0.0027,  0.0305,  0.0667,\n",
              "                                     0.0306, -0.0187, -0.0401,  0.0288,  0.0277,  0.0430,\n",
              "                                    -0.0150, -0.0484,  0.0141,  0.0171,  0.0457,  0.0020,\n",
              "                                     0.0019,  0.0104, -0.0009,  0.0056, -0.0208,  0.0396,\n",
              "                                     0.0157,  0.0338,  0.0192,  0.0251, -0.0317, -0.0144,\n",
              "                                     0.0175,  0.0457, -0.0340, -0.0643, -0.0058, -0.0318,\n",
              "                                    -0.0093,  0.0034, -0.0267, -0.0019,  0.0772,  0.0018,\n",
              "                                     0.0458,  0.0249,  0.0585,  0.0142,  0.0558,  0.0007,\n",
              "                                     0.0103,  0.0411, -0.0305,  0.0520, -0.0751,  0.0323,\n",
              "                                     0.0318, -0.0047, -0.0021,  0.0219, -0.0111, -0.0025,\n",
              "                                    -0.0234,  0.0406, -0.0113,  0.0080, -0.0153, -0.0040,\n",
              "                                    -0.0475,  0.0435, -0.0159,  0.0084, -0.0005, -0.0102,\n",
              "                                     0.0075,  0.0234,  0.0374,  0.0693, -0.0417,  0.0133,\n",
              "                                     0.0611,  0.0078, -0.0392,  0.0629, -0.0583, -0.0070,\n",
              "                                     0.1123,  0.0460, -0.0003, -0.0183,  0.0029,  0.0060,\n",
              "                                    -0.0418, -0.0253,  0.0038, -0.0230,  0.0191,  0.0041,\n",
              "                                    -0.0023,  0.0091,  0.0011,  0.1018, -0.0074,  0.0219,\n",
              "                                    -0.0066,  0.0117,  0.0139,  0.0612, -0.0437,  0.0253,\n",
              "                                     0.0478, -0.0456, -0.0164, -0.0434,  0.0056,  0.0047,\n",
              "                                     0.0116, -0.0090, -0.0115,  0.0278,  0.0491,  0.0297,\n",
              "                                     0.0413, -0.0233]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-5.7555e+00, -2.9407e-01, -8.5602e+00, -3.5305e+00,\n",
              "                                     2.4046e-02, -2.9040e+00, -4.1404e+00, -7.6846e+00,\n",
              "                                    -3.7222e+00, -2.2473e+00, -1.3366e+00, -1.8095e+00,\n",
              "                                    -3.8357e+00,  1.7324e+00, -8.0927e-01, -1.5772e+00,\n",
              "                                    -4.5496e+00, -3.8608e+00, -2.3144e+00, -5.0263e+00,\n",
              "                                    -2.3249e+00, -6.8330e+00, -2.3476e+00, -6.6292e+00,\n",
              "                                    -4.2189e+00, -2.8842e-01, -5.6831e+00, -3.7633e+00,\n",
              "                                    -1.2789e+00, -6.2511e+00, -6.4891e+00, -4.7234e+00,\n",
              "                                    -3.0989e+00, -4.4122e+00, -4.0377e+00, -1.5048e+00,\n",
              "                                    -4.3197e+00, -1.5039e+00, -2.7344e+00, -6.1031e+00,\n",
              "                                    -2.6248e+00, -6.4302e+00, -3.7697e+00, -1.4282e+00,\n",
              "                                    -4.7454e+00,  1.1409e+00, -1.8184e+00, -7.0775e+00,\n",
              "                                    -2.1143e+00, -1.7169e+00, -4.9104e+00, -1.6712e+00,\n",
              "                                     5.5827e-01, -2.3974e+00, -7.5425e+00, -1.7249e+00,\n",
              "                                    -2.3862e+00, -3.3254e+00, -1.2602e+00, -2.5393e+00,\n",
              "                                    -2.1653e+00, -8.0694e-01, -1.8292e+00, -3.1451e+00,\n",
              "                                    -7.5504e+00, -5.9891e-01, -2.9615e-03, -3.7677e+00,\n",
              "                                    -3.8644e+00, -9.1116e+00, -2.4822e+00, -3.8815e+00,\n",
              "                                    -3.7679e+00, -3.4594e+00, -1.8414e+00, -1.6818e+00,\n",
              "                                    -6.9939e-01, -6.7773e+00, -1.0173e+00,  2.8042e-01,\n",
              "                                    -6.0795e+00, -3.2273e+00, -1.2324e+00, -3.5175e+00,\n",
              "                                    -1.7623e+00, -2.7433e+00,  1.5071e+00, -1.6574e+00,\n",
              "                                    -1.6256e+00, -5.0228e+00, -3.6383e+00, -3.9938e+00,\n",
              "                                    -9.3024e-01,  8.9452e-01, -5.6065e-02, -3.8708e+00,\n",
              "                                    -9.3357e+00, -6.0916e+00, -1.5175e+00, -2.1855e+00,\n",
              "                                    -2.3243e+00, -7.0906e+00, -2.5309e+00,  5.1282e-01,\n",
              "                                    -2.7236e+00,  1.0909e+00, -5.3126e+00, -6.6106e+00,\n",
              "                                    -2.5665e+00, -7.4822e+00,  1.1264e-01, -5.2367e+00,\n",
              "                                    -3.0363e+00, -2.8006e+00, -4.7304e+00, -9.6611e-01,\n",
              "                                    -5.5313e+00, -4.0596e+00, -5.1568e+00, -5.1714e+00,\n",
              "                                     1.0649e-01, -9.0808e+00, -2.7548e+00, -4.6226e+00,\n",
              "                                    -4.3791e+00, -7.1783e-01, -3.3191e+00, -7.5993e-01,\n",
              "                                    -4.5043e+00, -3.9858e+00, -6.2686e+00, -2.9757e+00,\n",
              "                                    -6.7124e+00, -4.9924e+00, -7.1073e+00, -3.4441e+00,\n",
              "                                    -4.6445e+00, -7.1497e+00, -5.8278e+00, -3.3497e+00,\n",
              "                                    -3.2782e+00, -1.3019e+00, -1.6002e+00, -6.0603e+00,\n",
              "                                    -1.2820e+00, -3.0250e+00, -1.7800e+00, -5.3108e+00,\n",
              "                                    -5.1881e+00, -1.8418e+00, -5.0851e+00, -4.9695e+00,\n",
              "                                    -2.4137e+00, -2.5486e+00,  2.3280e+00, -1.3880e+00,\n",
              "                                    -1.6779e+00, -3.1590e+00, -5.5491e-01,  5.3517e-01,\n",
              "                                    -1.2969e+00,  4.2132e-01, -9.8230e-01, -1.3241e+00,\n",
              "                                    -4.7651e+00, -5.4523e+00, -4.3637e-01,  1.0579e+00,\n",
              "                                    -4.9170e+00, -1.1731e-01, -3.2879e+00, -7.8742e+00,\n",
              "                                    -8.1867e-01, -1.7662e+00, -3.9381e+00, -2.0072e+00,\n",
              "                                    -5.2333e+00, -6.9034e+00, -2.5551e+00,  5.6680e-01,\n",
              "                                    -3.5098e+00, -2.5344e+00, -2.8412e+00, -3.4754e+00,\n",
              "                                    -6.0258e-01, -6.8841e+00,  1.7206e+00, -9.4000e-01,\n",
              "                                    -1.6945e+00, -2.7064e+00, -3.0926e+00, -2.4211e+00,\n",
              "                                    -3.2793e+00, -3.6458e+00, -4.5674e+00, -3.5266e+00,\n",
              "                                    -3.1524e+00, -2.9573e+00, -8.8610e+00, -1.3612e+00,\n",
              "                                    -1.8763e+00,  8.3473e-02, -4.4824e+00, -7.4702e+00,\n",
              "                                    -3.3561e+00, -6.1440e-01, -8.5029e+00, -4.4648e+00,\n",
              "                                    -4.5320e+00, -1.9310e+00, -7.9352e-01, -6.1726e-01,\n",
              "                                    -5.3122e+00,  6.1229e-01, -3.6033e+00, -2.7854e+00,\n",
              "                                    -8.0996e+00, -5.8028e+00, -4.2897e+00, -3.5260e+00,\n",
              "                                     1.3056e+00, -8.3575e-01, -1.7127e+00, -5.2131e+00,\n",
              "                                    -5.3497e+00, -2.5639e+00, -8.3125e+00, -1.5232e+00,\n",
              "                                    -4.6543e+00, -1.4754e+00, -5.2456e+00,  8.1143e-01,\n",
              "                                    -9.0844e+00, -4.0900e+00, -4.6111e+00, -9.5336e+00,\n",
              "                                    -1.8668e+00, -3.0208e+00, -5.1434e-01, -9.0856e+00,\n",
              "                                    -8.5673e+00, -3.8393e+00, -7.2349e-01, -1.2203e+00,\n",
              "                                    -6.0380e+00, -3.5354e+00,  1.4236e+00, -3.5150e+00,\n",
              "                                    -7.8085e+00, -4.1281e+00, -6.2543e-01, -4.2115e+00,\n",
              "                                    -4.6193e+00, -7.6445e+00, -3.1633e+00,  4.7124e-01,\n",
              "                                    -8.5644e+00, -2.3797e+00, -2.5493e+00, -3.0489e+00,\n",
              "                                    -3.3444e+00, -1.3858e-01, -2.8570e+00,  1.6600e-01,\n",
              "                                    -4.7274e+00, -8.0106e-01, -5.4625e+00, -3.8744e+00,\n",
              "                                    -5.6699e+00, -7.6734e+00, -1.4029e+00, -2.3720e+00,\n",
              "                                    -2.2917e+00, -1.3178e+00, -4.7949e+00, -7.9274e+00,\n",
              "                                    -2.6249e+00, -9.0003e+00, -4.1876e+00, -5.0684e+00,\n",
              "                                    -1.3755e+00, -2.0717e-01, -3.4920e+00, -3.3170e+00,\n",
              "                                    -5.9301e+00, -7.6056e+00, -1.6647e+00, -6.8405e+00,\n",
              "                                    -6.0905e+00, -5.1649e-01, -3.7928e+00, -2.8334e+00,\n",
              "                                     1.3552e+00, -2.8575e+00, -2.0571e+00, -2.2999e+00,\n",
              "                                    -2.9040e+00, -6.0888e+00, -2.2003e-01, -4.0634e+00,\n",
              "                                    -3.3096e+00, -2.8001e+00, -7.8389e+00, -4.7928e+00,\n",
              "                                    -4.6071e+00, -3.3089e+00, -3.9617e-01, -6.0859e+00,\n",
              "                                    -1.8725e+00,  1.2205e+00, -6.4000e+00, -5.2868e+00,\n",
              "                                    -4.1053e+00, -3.1458e+00, -4.8374e+00, -5.3628e+00,\n",
              "                                    -7.0084e-01,  8.4085e-01, -4.4156e+00, -7.6087e+00,\n",
              "                                    -8.1900e+00, -3.8511e+00,  3.9479e+00, -2.1176e+00,\n",
              "                                    -6.3462e+00, -2.0594e+00, -6.5818e+00, -5.5944e+00,\n",
              "                                    -3.5924e+00,  2.9273e-01, -3.3964e+00, -8.0534e+00,\n",
              "                                    -3.1034e+00, -4.9866e+00, -2.6815e+00, -1.6836e+00,\n",
              "                                    -6.0307e+00, -9.5796e-01, -3.5968e+00, -4.4863e+00,\n",
              "                                    -6.2174e+00, -3.9063e+00, -1.7576e+00, -3.5589e+00,\n",
              "                                    -1.1878e+00, -4.4099e+00, -5.8062e+00, -8.0543e+00,\n",
              "                                    -5.5905e+00, -4.2707e+00, -2.9787e+00, -3.3661e+00,\n",
              "                                    -4.4846e+00, -6.2954e-01, -1.4529e+00,  4.7515e-01,\n",
              "                                    -1.2203e+00, -9.2646e-02, -2.2381e+00, -6.2926e+00,\n",
              "                                    -1.6904e+00,  1.9503e-01, -6.8376e+00, -3.2654e+00,\n",
              "                                    -8.4342e-01, -2.6936e+00, -5.0309e+00, -1.2265e+00,\n",
              "                                    -6.2756e+00, -3.5154e+00, -4.5007e+00, -5.4014e+00,\n",
              "                                    -2.5635e-01, -2.7330e+00, -8.8636e-01, -3.8820e+00,\n",
              "                                    -9.9012e+00, -1.3430e+00, -8.8678e-01, -6.4685e+00,\n",
              "                                    -2.2287e+00, -7.4287e-02, -1.9338e+00, -6.0242e+00,\n",
              "                                    -3.4292e+00, -5.6718e+00, -5.1304e+00, -4.0110e+00,\n",
              "                                    -2.3119e-01, -3.6105e+00, -4.9148e+00,  8.1984e-01,\n",
              "                                    -2.7614e+00, -3.6487e+00,  3.3311e-01, -7.6983e+00,\n",
              "                                    -8.8775e+00, -5.4356e+00, -1.7691e+00, -2.1617e+00,\n",
              "                                    -8.0027e+00, -2.9013e+00, -1.6722e+00, -1.8889e+00,\n",
              "                                    -4.2859e+00, -6.9101e-01, -3.7768e+00, -3.8668e+00,\n",
              "                                    -6.0066e+00, -1.5946e+00, -1.9017e+00,  3.9186e-01,\n",
              "                                    -3.0223e+00, -4.5856e+00, -4.5556e+00, -4.3434e+00,\n",
              "                                    -4.6325e+00, -2.4482e+00, -1.2228e+00, -5.1943e+00,\n",
              "                                    -2.5564e+00, -1.3471e+00,  3.1889e-02,  6.9740e-01,\n",
              "                                    -8.4162e+00, -1.8076e+00, -3.2564e+00, -5.2983e+00,\n",
              "                                    -1.9161e+00, -2.0194e+00, -3.7050e+00, -2.4950e+00,\n",
              "                                    -5.3382e+00, -2.9711e+00, -5.5349e+00, -5.0499e+00,\n",
              "                                    -1.2048e+00, -2.5973e+00, -7.0032e+00, -6.8893e+00,\n",
              "                                    -6.1907e+00, -6.8270e+00, -4.9769e+00,  2.6936e-01,\n",
              "                                    -4.3517e+00, -2.0014e-01, -5.5401e+00,  2.5002e-01,\n",
              "                                    -2.2247e+00, -1.4883e+00, -1.6328e+00, -3.2347e+00,\n",
              "                                    -2.9687e+00, -3.8064e+00, -6.0824e+00, -5.8590e+00,\n",
              "                                    -9.8593e-01, -9.0108e+00,  6.0178e-01, -4.4854e+00,\n",
              "                                    -4.7613e+00, -7.4490e-01, -3.2083e+00, -6.5695e+00,\n",
              "                                    -3.6065e+00, -3.2679e+00,  3.2834e-01,  4.7035e-01,\n",
              "                                    -4.0788e+00, -8.2252e+00, -3.4291e+00, -2.4738e+00,\n",
              "                                     7.0808e-01, -1.2772e+00, -5.0194e+00, -3.7775e+00,\n",
              "                                    -5.3399e+00, -3.9243e-01, -3.6638e+00, -2.9379e+00,\n",
              "                                    -2.6538e+00, -3.5498e+00, -8.3443e-01, -6.0516e-01,\n",
              "                                    -5.4352e+00, -5.8364e+00, -3.9730e+00, -4.2142e+00,\n",
              "                                    -4.2778e-01, -7.5724e+00, -4.9067e-01, -3.8635e+00,\n",
              "                                    -3.2989e+00, -1.9150e+00, -5.8439e+00, -2.9522e+00,\n",
              "                                    -3.6235e+00, -4.8854e+00, -2.9730e+00, -6.3414e+00,\n",
              "                                    -1.8124e+00, -4.3946e+00, -4.4753e+00, -1.0578e-01,\n",
              "                                    -7.5643e+00, -5.9358e+00, -6.6121e-01, -3.1898e+00,\n",
              "                                    -3.0552e+00, -5.4740e+00, -6.1052e+00,  6.1577e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 49.8499,  95.6562,  98.1143,  59.7411,  55.7923,\n",
              "                                     59.9540,  70.0587,  57.6270,  72.3690,  90.7464,\n",
              "                                     53.1580,  86.9051,  88.9245, 196.4481,  50.3859,\n",
              "                                     69.9453, 105.2374,  89.4748, 194.0556,  76.7165,\n",
              "                                     92.1953,  75.9556,  70.3376,  73.5450,  86.5362,\n",
              "                                     97.4947,  65.6649,  72.9566,  95.5392, 144.3854,\n",
              "                                     72.0677,  40.8292,  68.8824,  85.4464, 110.3648,\n",
              "                                     76.7225,  80.4164,  43.2206,  37.2271,  63.8320,\n",
              "                                     95.3746,  66.6279,  74.5701, 108.8357,  50.2661,\n",
              "                                     55.8418, 119.8981,  76.1258, 109.6228,  95.9029,\n",
              "                                     79.9644, 104.0951,  32.6058, 159.6317, 141.3794,\n",
              "                                     92.6607,  78.7923,  48.1441,  90.9516,  64.6028,\n",
              "                                     92.2081,  88.9054,  80.4485, 111.3379,  66.0034,\n",
              "                                     44.2765,  67.0622,  65.8127, 118.2621, 206.4278,\n",
              "                                     64.7351, 117.5493,  65.7740, 127.7356, 105.9292,\n",
              "                                     86.7392,  76.5928, 158.3174,  54.2837,  92.3093,\n",
              "                                     53.5837,  78.2116,  52.1282,  49.5522, 117.7788,\n",
              "                                     73.6148,  72.7642,  71.1067,  60.0058,  52.8806,\n",
              "                                     76.1886,  50.6622,  69.7685,  85.1572,  69.5351,\n",
              "                                     59.3281,  95.6091,  93.2495,  91.0364,  56.2892,\n",
              "                                     57.4454,  99.3928,  87.4023, 183.3482,  71.9207,\n",
              "                                     89.1752,  59.0700,  74.1285,  51.7596,  85.6628,\n",
              "                                    104.7119,  67.8301,  86.9538,  76.0940,  74.8655,\n",
              "                                     81.3376, 108.0490,  58.2413,  61.4101,  62.6347,\n",
              "                                     94.4021,  84.7899,  75.1372,  78.9907,  66.7310,\n",
              "                                     61.1978, 117.6165, 180.9664,  73.8926,  64.6280,\n",
              "                                     72.8940,  92.7170,  91.3218,  55.6022,  66.5013,\n",
              "                                     64.5879,  98.9770, 149.8673, 102.8871,  45.5836,\n",
              "                                    125.9226,  88.2643,  55.4158,  50.6877,  59.6618,\n",
              "                                     58.6313,  56.8144,  81.6700,  37.0965,  54.1107,\n",
              "                                     55.7955,  98.3275,  39.6470,  99.3393,  73.9687,\n",
              "                                     69.6752,  77.4318,  53.6878,  90.9521, 108.3930,\n",
              "                                     67.0997,  72.3626,  64.4732, 104.3853,  70.7630,\n",
              "                                     52.9866,  83.4740, 115.7010,  81.9253, 125.6159,\n",
              "                                     81.4447, 127.2455, 137.0550, 109.4911,  83.9751,\n",
              "                                    117.0987,  64.7115,  89.7878,  71.4690,  97.6430,\n",
              "                                     78.8477,  59.5431,  56.6040,  63.6962,  58.3043,\n",
              "                                    112.9400,  51.1592,  50.1209,  77.6916, 109.7418,\n",
              "                                     64.0996,  63.9873,  62.7523,  52.9112,  86.9211,\n",
              "                                     84.3074,  53.4118,  84.8558, 151.6303,  77.8472,\n",
              "                                     94.7567,  84.3857,  51.1495,  85.2051,  61.7016,\n",
              "                                    108.1082,  75.4390,  63.5913,  70.2093,  78.9583,\n",
              "                                     77.5096, 127.4413,  66.9240,  71.0284,  72.4832,\n",
              "                                     61.3727,  88.1067,  70.6147,  66.8990, 143.5258,\n",
              "                                     68.2899,  82.7346,  69.7083,  40.3156,  64.1010,\n",
              "                                     63.8156,  73.4548,  71.8570,  51.3735, 157.2276,\n",
              "                                     96.0475,  67.8412, 102.8900,  97.6500,  65.5407,\n",
              "                                    140.3620,  58.8563,  98.1749,  63.4294, 142.6658,\n",
              "                                    155.0349,  73.9925,  74.6013, 104.2806,  53.8289,\n",
              "                                     70.5077,  95.1418,  74.3153,  84.5895,  64.0456,\n",
              "                                     96.7254,  52.7049,  30.2062,  89.1999, 119.3025,\n",
              "                                     58.1732,  72.2930, 105.4069,  63.0148, 112.3616,\n",
              "                                     66.1300,  97.8810,  80.7959, 158.4156,  56.8958,\n",
              "                                     75.3750, 149.4157,  74.8210,  97.1094, 134.7171,\n",
              "                                    176.6504,  79.1886,  62.9139,  78.3562,  77.4011,\n",
              "                                     84.7713,  84.2095, 147.6988,  54.1039, 107.0897,\n",
              "                                     79.6597,  69.4401,  87.7127,  67.1612,  65.2440,\n",
              "                                     75.6231,  96.5945, 124.3004,  73.4480,  56.2871,\n",
              "                                     71.7164,  65.6661,  66.3693,  98.5411,  70.9534,\n",
              "                                     67.5912,  84.3897,  46.5643, 101.2908,  79.6223,\n",
              "                                     69.4111,  58.4035,  85.7465,  82.0689,  81.5274,\n",
              "                                     81.0063,  91.6567,  71.0567,  87.9006,  73.4685,\n",
              "                                    104.0006,  59.2095,  75.5913,  83.3188,  85.9300,\n",
              "                                     51.2972,  76.5484, 108.7481,  80.9567,  60.1194,\n",
              "                                    139.3562,  87.9134,  68.5387, 110.9648, 109.4675,\n",
              "                                     58.5413,  71.4981,  49.8108, 134.6651,  81.0292,\n",
              "                                    203.2269, 126.4948, 126.6046,  91.2435,  78.7130,\n",
              "                                    105.3319,  69.8463,  92.2638,  66.1404,  58.0726,\n",
              "                                     98.9111,  53.3412, 124.8809,  56.2646, 122.9658,\n",
              "                                     82.0300, 121.4592,  78.7893,  66.8474,  96.5162,\n",
              "                                     70.1588,  62.9069, 122.1533,  72.9669,  69.4243,\n",
              "                                     76.0187,  88.3613, 101.1189,  68.4031,  60.9722,\n",
              "                                     97.2438, 143.9005,  83.5863,  79.6021,  71.6095,\n",
              "                                    104.9010,  70.3759,  46.2827,  67.5243,  58.2644,\n",
              "                                     74.6515,  69.0258,  92.0272,  63.3642,  99.7221,\n",
              "                                     54.8806, 133.6084, 128.3153,  75.3591,  95.0994,\n",
              "                                     49.1086,  80.0506,  72.0621, 124.9455,  55.4610,\n",
              "                                     51.8262,  73.2637,  83.4357,  89.2068,  91.7354,\n",
              "                                     64.5252, 118.9936,  62.7789,  65.1323,  68.9556,\n",
              "                                     87.3047, 143.6713,  60.3545,  71.2465,  49.8985,\n",
              "                                     57.8804,  96.4165,  69.1632,  58.6192,  83.3058,\n",
              "                                     80.9784,  99.3595,  56.5382,  54.5755,  52.6378,\n",
              "                                     61.5582,  94.1239,  59.9056,  48.8517,  64.0249,\n",
              "                                     66.9242,  56.1116,  41.1326, 146.6223,  63.3353,\n",
              "                                     93.9062,  49.2060,  38.4032, 104.9752, 134.3802,\n",
              "                                    105.7649,  70.9028,  76.2165,  73.1412,  66.8351,\n",
              "                                     99.2146,  77.0728, 100.7026,  97.4205,  77.6272,\n",
              "                                     82.6549,  83.9964,  47.8868,  65.5655,  96.6687,\n",
              "                                     64.7814,  78.6977,  85.9045, 122.3106,  70.7369,\n",
              "                                     93.5668,  95.8506,  55.3455,  48.6030,  45.0369,\n",
              "                                    128.9932,  96.9417,  51.6589,  49.8761,  74.4491,\n",
              "                                     76.6528, 101.0056, 100.9293, 162.0840,  83.8537,\n",
              "                                     61.7310, 181.3377,  78.7143,  53.6682,  87.1458,\n",
              "                                    106.5024, 157.2567, 138.6848, 100.8885,  53.2651,\n",
              "                                     76.4533,  94.0826,  69.4177,  82.5261, 110.5781,\n",
              "                                     81.5044,  76.5129, 135.9931,  68.1395,  93.1008,\n",
              "                                     79.0991,  59.9264, 108.5773, 129.4547,  98.8417,\n",
              "                                     61.0898, 135.3688,  54.0062,  80.5274, 147.2643,\n",
              "                                     76.7853,  72.4329,  85.3837,  93.3661,  95.2061,\n",
              "                                     60.3876,  82.8447,  39.9054,  79.3893,  53.9977,\n",
              "                                     86.1950,  69.8504,  44.3218,  63.2305,  86.1560,\n",
              "                                     51.2085,  56.9847,  76.0114,  61.9269,  80.4367,\n",
              "                                     86.2232,  83.2600]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([-0.0414, -0.0431,  0.0161,  ...,  0.0321,  0.0582,\n",
              "                                    -0.0034]),\n",
              "                     size=(512, 512, 3, 3), nnz=2359296, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([1.0169, 0.9839, 0.9954, 0.9412, 0.9763, 0.9689, 0.9888,\n",
              "                                    1.0228, 0.9797, 1.0299, 0.9685, 0.9476, 1.0110, 1.0142,\n",
              "                                    0.9787, 0.9449, 0.9862, 1.0205, 0.9647, 1.0515, 1.0005,\n",
              "                                    1.0176, 1.0151, 1.0386, 0.9798, 1.0377, 0.9976, 0.9520,\n",
              "                                    0.9764, 0.9976, 1.0047, 0.9792, 0.9758, 0.9652, 0.9767,\n",
              "                                    1.0046, 1.0734, 1.0515, 0.9903, 1.0391, 0.9446, 0.9696,\n",
              "                                    1.0101, 1.0447, 1.0443, 0.9846, 0.9779, 0.9869, 0.9742,\n",
              "                                    1.0016, 1.0437, 0.9311, 1.0238, 0.9315, 1.0320, 0.9830,\n",
              "                                    1.0280, 1.0097, 1.0028, 0.9635, 0.9589, 1.0273, 0.9968,\n",
              "                                    1.0330, 0.9404, 1.0131, 1.0127, 0.9664, 0.9769, 1.0322,\n",
              "                                    0.9989, 1.0202, 0.9886, 1.0102, 1.0155, 1.0123, 1.0862,\n",
              "                                    0.9957, 0.9258, 0.9654, 0.9482, 1.0400, 1.0315, 1.0163,\n",
              "                                    0.9647, 0.9678, 1.0446, 1.0575, 0.9646, 0.9522, 1.0226,\n",
              "                                    0.9305, 0.9980, 1.0030, 0.9924, 0.9804, 0.9937, 1.0049,\n",
              "                                    1.0164, 1.0195, 1.0063, 0.9934, 1.0709, 0.9912, 0.9585,\n",
              "                                    1.0239, 1.0170, 1.0151, 1.0051, 0.9563, 0.9656, 1.0403,\n",
              "                                    0.9556, 1.0354, 1.0338, 1.0208, 0.9601, 1.0250, 1.0589,\n",
              "                                    0.9283, 0.9428, 1.0078, 0.9388, 0.9502, 1.0210, 1.0365,\n",
              "                                    0.9600, 1.0079, 0.9885, 0.9966, 0.9867, 0.9795, 1.0099,\n",
              "                                    1.0308, 1.0290, 0.9393, 1.0702, 1.0264, 0.9227, 0.9981,\n",
              "                                    0.9584, 0.9555, 0.9881, 1.0400, 1.0182, 0.9877, 0.9611,\n",
              "                                    1.0203, 0.9942, 1.0347, 0.9699, 1.0444, 1.0358, 1.0775,\n",
              "                                    0.9884, 1.0132, 0.9618, 0.9433, 1.0100, 0.9554, 0.8909,\n",
              "                                    1.0149, 0.9843, 1.0222, 1.0096, 1.0347, 1.0305, 0.9920,\n",
              "                                    1.0268, 1.0170, 1.0085, 1.0144, 0.9999, 0.9745, 1.0260,\n",
              "                                    1.0277, 0.9952, 1.0477, 1.0006, 1.0330, 1.0196, 0.9648,\n",
              "                                    1.0150, 1.0380, 1.0360, 1.0129, 0.9781, 1.0421, 1.0293,\n",
              "                                    1.0360, 0.9940, 1.0705, 0.9957, 0.9882, 1.0217, 0.9994,\n",
              "                                    0.9965, 0.9972, 0.9994, 0.9646, 0.9811, 1.0090, 0.9837,\n",
              "                                    0.9558, 1.0107, 1.0478, 0.9973, 1.0044, 1.0008, 1.0183,\n",
              "                                    0.9210, 0.9961, 1.0227, 0.9729, 1.0599, 0.9929, 0.9790,\n",
              "                                    1.0241, 0.9849, 1.0319, 1.0105, 0.9836, 1.0177, 1.0477,\n",
              "                                    1.0183, 0.9840, 1.0026, 1.0166, 0.9619, 0.9523, 1.0213,\n",
              "                                    0.9602, 0.9515, 0.9999, 1.0521, 0.9805, 1.0154, 0.9768,\n",
              "                                    0.9915, 1.0433, 0.9602, 1.0184, 0.9550, 0.9417, 1.0451,\n",
              "                                    1.0056, 1.0240, 1.0005, 0.9934, 1.0144, 0.9892, 0.9435,\n",
              "                                    0.9839, 1.0061, 1.0017, 0.9822, 0.9938, 0.9834, 0.9861,\n",
              "                                    1.0181, 1.0322, 0.9964, 0.9600, 0.9532, 1.0454, 1.0119,\n",
              "                                    0.9827, 1.0032, 0.9976, 0.9983, 0.8941, 0.9985, 0.9505,\n",
              "                                    1.0145, 0.9525, 0.9941, 0.9892, 0.9946, 0.9826, 1.0150,\n",
              "                                    1.0072, 0.9129, 0.9697, 1.0721, 0.9764, 1.0308, 0.9721,\n",
              "                                    1.0100, 0.9920, 1.0240, 1.0390, 0.9959, 1.0498, 0.9578,\n",
              "                                    1.0047, 0.9668, 0.9679, 1.0206, 0.9572, 1.0169, 1.0071,\n",
              "                                    0.9341, 0.9494, 1.0209, 0.9972, 1.0415, 0.9714, 0.9241,\n",
              "                                    0.9842, 1.0226, 0.9490, 1.0151, 1.0031, 0.9752, 0.9732,\n",
              "                                    1.0496, 0.9431, 0.9891, 0.9993, 0.9786, 0.9966, 0.9751,\n",
              "                                    1.0043, 0.9689, 1.0356, 1.0553, 0.9453, 1.0303, 0.9677,\n",
              "                                    0.9646, 1.0093, 0.9794, 0.9965, 1.0786, 1.0066, 1.0083,\n",
              "                                    0.9741, 1.0323, 0.9653, 0.9701, 0.9538, 0.9541, 1.0194,\n",
              "                                    0.9888, 0.9791, 0.9164, 0.9528, 0.9538, 0.9950, 0.9567,\n",
              "                                    0.9746, 0.9857, 0.9760, 1.0173, 0.9869, 0.9372, 1.0021,\n",
              "                                    1.0990, 0.9934, 0.9662, 0.9287, 0.9618, 1.0108, 0.9986,\n",
              "                                    0.9620, 1.0580, 1.0047, 0.9470, 1.0084, 0.9990, 0.9883,\n",
              "                                    0.9753, 1.0080, 1.0103, 0.9622, 0.9841, 1.0051, 0.9697,\n",
              "                                    1.0003, 1.0344, 0.9746, 0.9936, 0.9823, 1.0527, 1.0245,\n",
              "                                    0.9861, 0.9994, 1.0008, 0.9231, 0.9898, 0.9979, 0.9774,\n",
              "                                    0.9729, 0.9965, 0.9372, 0.9991, 0.9594, 1.0174, 1.0254,\n",
              "                                    0.9953, 1.0025, 0.9865, 1.0147, 1.0247, 1.0081, 0.9625,\n",
              "                                    0.9753, 0.9622, 1.0368, 0.9737, 0.9963, 0.9846, 0.9734,\n",
              "                                    0.9984, 0.9953, 0.9892, 0.9763, 0.9678, 1.0374, 0.9551,\n",
              "                                    0.9787, 0.9922, 0.9742, 1.0192, 0.9832, 0.9281, 1.0135,\n",
              "                                    0.9597, 0.9669, 0.9371, 0.9702, 0.9687, 0.9706, 1.0480,\n",
              "                                    0.9129, 0.9796, 0.9848, 1.0346, 0.9538, 0.9935, 0.9993,\n",
              "                                    0.9562, 0.9876, 0.9462, 0.9944, 1.0441, 0.9428, 1.0324,\n",
              "                                    1.0318, 0.9876, 1.0308, 0.9781, 0.9672, 1.0014, 1.0044,\n",
              "                                    1.0503, 1.0081, 1.0096, 0.9763, 0.9484, 1.0415, 1.0228,\n",
              "                                    1.0357, 1.0350, 1.0401, 0.9494, 0.9606, 0.9808, 1.0218,\n",
              "                                    0.9763, 0.9892, 1.0098, 0.9464, 0.9694, 0.9613, 1.0214,\n",
              "                                    1.0162, 0.9887, 0.9955, 1.0188, 1.0066, 1.0071, 0.9719,\n",
              "                                    0.9774, 0.9397, 0.9913, 1.0032, 0.9827, 0.9862, 0.9890,\n",
              "                                    0.9876, 1.0351, 0.9191, 0.9990, 1.1047, 1.0043, 1.0005,\n",
              "                                    0.9934, 0.9843, 0.9297, 0.9940, 0.9656, 0.9741, 1.0072,\n",
              "                                    1.0086, 1.0042, 0.9980, 1.0142, 1.0275, 1.0626, 1.0071,\n",
              "                                    0.9677]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-0.0970, -0.0667, -0.0687, -0.1125, -0.1526, -0.1076,\n",
              "                                    -0.1448, -0.1692, -0.0766, -0.0607, -0.0561, -0.1037,\n",
              "                                    -0.0322, -0.0545, -0.0372, -0.1060, -0.0856, -0.0894,\n",
              "                                    -0.1424, -0.0891, -0.0814, -0.0947, -0.0858, -0.0456,\n",
              "                                    -0.1901, -0.0279, -0.0564, -0.0703, -0.0702, -0.0729,\n",
              "                                    -0.1592, -0.0959, -0.0340, -0.0654, -0.0783, -0.0820,\n",
              "                                    -0.0972, -0.0860, -0.0690, -0.1683, -0.0935, -0.0789,\n",
              "                                    -0.1099, -0.0831, -0.0776, -0.0589, -0.0840, -0.1276,\n",
              "                                    -0.0399, -0.0487, -0.0980, -0.0862, -0.1425, -0.0678,\n",
              "                                    -0.1386, -0.1151, -0.0396, -0.1067, -0.0998, -0.0633,\n",
              "                                    -0.0696, -0.1118, -0.1077, -0.0363, -0.1288, -0.1124,\n",
              "                                    -0.1109, -0.0996, -0.0865, -0.0723, -0.0917, -0.0240,\n",
              "                                    -0.0743, -0.0626, -0.0891, -0.1062, -0.1729, -0.0807,\n",
              "                                    -0.1310, -0.0624, -0.0510, -0.0798, -0.0779, -0.1833,\n",
              "                                    -0.0845, -0.0917, -0.0763, -0.1268, -0.1047, -0.0694,\n",
              "                                    -0.1326, -0.1144, -0.1337, -0.0764, -0.1058, -0.0547,\n",
              "                                    -0.0868, -0.0825, -0.0576, -0.0576, -0.0945, -0.1099,\n",
              "                                    -0.0781, -0.1857, -0.0784, -0.0955, -0.0506, -0.1468,\n",
              "                                    -0.0252, -0.0861, -0.0522, -0.0478, -0.0318, -0.0646,\n",
              "                                    -0.0426, -0.0817, -0.1052, -0.0429, -0.1059, -0.1082,\n",
              "                                    -0.0932, -0.0215, -0.1146, -0.0705, -0.0881, -0.0590,\n",
              "                                    -0.0749, -0.0303, -0.0183, -0.0666, -0.0849, -0.0384,\n",
              "                                    -0.1386, -0.0575, -0.0550, -0.0991, -0.0664, -0.0807,\n",
              "                                    -0.1153, -0.0635, -0.0226, -0.1041, -0.0647, -0.0974,\n",
              "                                    -0.0651, -0.0732, -0.1006, -0.0914, -0.0569, -0.0249,\n",
              "                                    -0.0581, -0.1096, -0.1407, -0.1150, -0.0827, -0.1355,\n",
              "                                    -0.1062, -0.0642, -0.0006, -0.0614, -0.0997, -0.0701,\n",
              "                                    -0.0796, -0.0203, -0.0801, -0.0482, -0.0341, -0.1012,\n",
              "                                    -0.0208, -0.0462, -0.0462, -0.0434, -0.0809, -0.0838,\n",
              "                                    -0.0943, -0.0742, -0.1253, -0.1235, -0.0345, -0.0500,\n",
              "                                    -0.0461, -0.1124, -0.0534, -0.0763, -0.0296, -0.1032,\n",
              "                                    -0.0916, -0.0363, -0.1426, -0.0617, -0.1080, -0.1288,\n",
              "                                    -0.1382, -0.0821, -0.0176, -0.1465, -0.0510, -0.1221,\n",
              "                                    -0.0419, -0.0571, -0.0469, -0.0603, -0.1303, -0.0465,\n",
              "                                    -0.0526, -0.0888, -0.0973, -0.0732, -0.1291, -0.0484,\n",
              "                                    -0.1175, -0.1101, -0.0417, -0.2157, -0.1289, -0.1018,\n",
              "                                    -0.0598, -0.0859, -0.1021, -0.0367, -0.0785, -0.1029,\n",
              "                                    -0.0733, -0.0912, -0.0745, -0.1155, -0.0621, -0.0706,\n",
              "                                    -0.1539, -0.1111, -0.1024, -0.0229, -0.0905, -0.0831,\n",
              "                                    -0.0004, -0.0410, -0.0297, -0.1066, -0.1324, -0.0230,\n",
              "                                    -0.0551, -0.0646, -0.0907, -0.0570, -0.0302, -0.0365,\n",
              "                                    -0.0556, -0.1122, -0.0525, -0.0424, -0.1322, -0.0886,\n",
              "                                    -0.0757, -0.0823, -0.1173, -0.1006, -0.0271, -0.1102,\n",
              "                                    -0.0561, -0.0880, -0.0326, -0.0419, -0.0948, -0.0552,\n",
              "                                    -0.0926, -0.0386, -0.0215, -0.0774, -0.0854, -0.1558,\n",
              "                                    -0.1116, -0.0970, -0.0824, -0.1136, -0.0906, -0.0689,\n",
              "                                    -0.0825, -0.0745, -0.0721, -0.0835, -0.0898, -0.1042,\n",
              "                                    -0.0987, -0.1217, -0.1122, -0.0907, -0.1505, -0.0609,\n",
              "                                    -0.1133, -0.1094, -0.1672, -0.1115, -0.0706, -0.1131,\n",
              "                                    -0.0772, -0.1276, -0.1000, -0.1092, -0.1118, -0.1045,\n",
              "                                    -0.0325, -0.0598, -0.0620, -0.0783, -0.0503, -0.0558,\n",
              "                                    -0.0863, -0.0756, -0.0489, -0.1048, -0.0981, -0.1023,\n",
              "                                    -0.0684, -0.0621, -0.0847, -0.0729, -0.1307, -0.0592,\n",
              "                                    -0.0938, -0.0964, -0.0756, -0.0616, -0.0699, -0.0695,\n",
              "                                    -0.0234, -0.1172, -0.0405, -0.1749, -0.0975, -0.0540,\n",
              "                                    -0.0930, -0.0700, -0.0689, -0.1024, -0.0562, -0.1202,\n",
              "                                    -0.0954, -0.1185, -0.1047, -0.0834, -0.1217, -0.0619,\n",
              "                                    -0.0646, -0.0831, -0.0748, -0.0776, -0.0467, -0.1263,\n",
              "                                    -0.0246, -0.0561, -0.1079, -0.0638, -0.0640, -0.0848,\n",
              "                                    -0.0860, -0.0478, -0.0092, -0.0271, -0.0555, -0.0441,\n",
              "                                    -0.0433, -0.0916, -0.0453, -0.0610, -0.0746, -0.0258,\n",
              "                                    -0.0438, -0.0308, -0.1125, -0.0973, -0.1326, -0.0879,\n",
              "                                    -0.1142, -0.1379, -0.0777, -0.0873, -0.0824, -0.1051,\n",
              "                                    -0.0528, -0.0231, -0.0770, -0.1240, -0.0781, -0.0949,\n",
              "                                    -0.0983, -0.1439, -0.0899, -0.0378, -0.0883, -0.0856,\n",
              "                                    -0.1867, -0.0478, -0.1077, -0.1118, -0.0672, -0.0424,\n",
              "                                    -0.0990, -0.0537, -0.0519, -0.0949, -0.1414, -0.0711,\n",
              "                                    -0.0518, -0.0740, -0.0464, -0.0897, -0.1136, -0.0726,\n",
              "                                    -0.1014, -0.0773, -0.1006, -0.0576, -0.1401, -0.0671,\n",
              "                                    -0.0359, -0.0492, -0.0636, -0.0853,  0.0241, -0.0946,\n",
              "                                    -0.0466, -0.0743, -0.0558, -0.0567, -0.1055, -0.0665,\n",
              "                                    -0.0539, -0.0821, -0.0362, -0.0605, -0.0835, -0.1217,\n",
              "                                    -0.1015, -0.0915, -0.0708, -0.0813, -0.0867, -0.0749,\n",
              "                                    -0.0629, -0.1008, -0.0737, -0.0894, -0.0660, -0.0641,\n",
              "                                    -0.1098, -0.0843, -0.0711, -0.0997, -0.0844, -0.0868,\n",
              "                                    -0.0859, -0.0424, -0.0792, -0.1372, -0.0772, -0.1228,\n",
              "                                    -0.0678, -0.1107, -0.0525, -0.0546, -0.0533, -0.0967,\n",
              "                                    -0.0493, -0.1309, -0.0620, -0.1442, -0.0788, -0.1223,\n",
              "                                    -0.0766, -0.1026, -0.0796, -0.0781, -0.1289, -0.1499,\n",
              "                                    -0.0844, -0.1065, -0.0841, -0.0725, -0.0734, -0.0327,\n",
              "                                    -0.0383, -0.0581, -0.1376, -0.0671, -0.1177, -0.0605,\n",
              "                                    -0.0881, -0.0826, -0.1039, -0.0734, -0.0846, -0.0180,\n",
              "                                    -0.1367, -0.1256, -0.0818, -0.1232, -0.0815, -0.1101,\n",
              "                                    -0.0971, -0.0833, -0.0697, -0.1002, -0.0814, -0.1120,\n",
              "                                    -0.0595, -0.0605, -0.0639, -0.1271, -0.1039, -0.1220,\n",
              "                                    -0.1562, -0.0626]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-6.0497e+00, -7.3149e+00,  1.4533e+00, -5.8699e+00,\n",
              "                                    -4.4863e+00, -1.3356e+00, -2.3008e+00,  1.2187e+00,\n",
              "                                    -9.0104e+00,  1.4322e+00,  4.0983e-01,  1.0262e+00,\n",
              "                                    -1.9857e+00, -3.4157e+00,  6.0327e+00, -7.3722e+00,\n",
              "                                    -5.1962e+00,  1.1563e+00, -7.7364e-01,  5.0052e+00,\n",
              "                                    -1.4196e+00, -2.1795e+00, -1.9805e+00, -1.0101e+01,\n",
              "                                    -1.3226e+00, -8.8480e+00, -5.2853e+00, -3.0825e+00,\n",
              "                                     7.2518e-01,  5.7964e+00,  5.2880e-01,  1.1825e+00,\n",
              "                                    -1.3932e+00, -6.3050e-01, -3.1863e+00, -4.2376e+00,\n",
              "                                    -4.9532e+00, -4.9620e-01, -5.7928e+00, -1.3409e+00,\n",
              "                                     6.1916e+00, -5.3595e+00,  2.6073e+00, -1.7429e+00,\n",
              "                                    -7.4858e+00,  6.8787e+00, -1.0197e+01,  4.2696e+00,\n",
              "                                    -5.6524e+00, -5.3911e+00, -2.7127e+00, -2.4383e+00,\n",
              "                                    -1.0254e+01, -1.4663e-01,  2.2122e-01, -6.6518e-01,\n",
              "                                    -6.9639e-01, -2.4207e+00, -3.3653e-01,  2.1323e-01,\n",
              "                                    -5.6753e+00,  1.1748e+00,  2.1875e+00, -3.5419e+00,\n",
              "                                    -3.0499e+00, -6.1324e+00, -9.3354e+00, -4.6946e+00,\n",
              "                                     5.6424e+00, -1.0285e+00, -7.3797e+00,  1.1500e+00,\n",
              "                                    -4.8361e+00, -4.1092e+00, -1.7562e+00, -2.3902e+00,\n",
              "                                     7.2222e-01,  5.9949e+00, -3.1021e+00,  1.2260e+00,\n",
              "                                    -2.8382e+00, -4.6134e+00,  2.1360e-01, -5.9903e+00,\n",
              "                                    -5.0391e+00, -2.7752e+00, -4.5909e+00, -1.3429e+00,\n",
              "                                    -2.1530e+00,  1.1632e+00, -4.0332e+00, -1.5143e+00,\n",
              "                                     5.4853e-01, -4.2506e+00, -3.6055e+00,  2.9022e+00,\n",
              "                                    -3.7607e-01, -5.2772e+00, -6.9491e+00,  1.2752e+00,\n",
              "                                    -2.4931e-01, -4.7625e+00, -3.3587e+00, -2.5261e+00,\n",
              "                                    -5.7373e+00, -6.4331e+00, -2.4401e+00, -4.4367e+00,\n",
              "                                    -9.6731e-01,  4.3479e+00,  8.9790e-01, -4.1543e+00,\n",
              "                                    -2.0747e+00,  1.4066e+00, -4.1676e+00, -2.3583e+00,\n",
              "                                    -4.8017e+00,  4.0312e-01, -6.2118e+00, -4.5929e+00,\n",
              "                                     4.1502e+00,  1.2357e+00, -2.7863e+00, -1.0204e+01,\n",
              "                                     1.4597e+00, -8.5136e+00, -4.1010e+00, -7.8867e+00,\n",
              "                                    -3.8079e+00,  9.1156e-01, -2.6192e+00, -2.7561e-01,\n",
              "                                    -4.2033e-01, -3.5188e+00,  2.5123e+00, -4.7046e+00,\n",
              "                                    -5.9163e+00, -2.8319e+00, -2.5440e+00, -2.8296e+00,\n",
              "                                    -8.0813e+00, -6.6973e+00, -1.4846e+00, -3.9324e+00,\n",
              "                                    -3.1299e+00, -4.2655e+00,  2.0938e+00, -2.4009e+00,\n",
              "                                    -6.4988e-01, -8.0882e-01, -1.9997e-01,  1.8022e+00,\n",
              "                                    -1.0849e+00,  4.8938e-02,  5.3463e+00,  6.0147e+00,\n",
              "                                    -3.2106e+00, -6.3842e+00, -3.2554e+00, -1.2648e+00,\n",
              "                                    -1.2526e+00,  1.5676e+00,  4.7982e-01, -4.8989e+00,\n",
              "                                    -1.0641e+01,  1.5884e-01, -1.9482e+00, -9.7035e-01,\n",
              "                                    -6.0181e+00,  2.6430e+00, -3.1744e+00, -6.1984e+00,\n",
              "                                    -6.8298e+00, -2.4270e+00,  1.1983e+00, -3.0149e+00,\n",
              "                                     2.5704e+00, -3.2384e+00,  1.9197e+00, -3.8818e+00,\n",
              "                                    -5.3750e+00,  4.4643e+00, -5.0421e+00, -5.8594e+00,\n",
              "                                    -1.0196e+01, -2.9895e+00, -8.4489e+00, -6.9013e+00,\n",
              "                                    -5.7552e+00, -5.4000e+00, -1.6259e+00,  2.2468e+00,\n",
              "                                    -1.4359e+00, -6.5535e+00, -3.9801e+00, -4.1276e-01,\n",
              "                                    -1.6467e+00,  2.2814e-02, -5.1283e+00,  4.1984e+00,\n",
              "                                    -1.4634e+00, -5.3104e+00,  4.0348e+00, -4.8854e+00,\n",
              "                                    -4.7094e+00, -4.0733e-01,  3.3099e+00, -1.5991e+00,\n",
              "                                     2.8272e+00, -3.4966e+00, -3.0098e+00, -3.3285e+00,\n",
              "                                    -6.1741e+00,  8.3864e-01, -2.8579e+00, -1.2627e-01,\n",
              "                                    -6.7133e+00, -4.9784e-01, -8.0349e+00, -2.1471e+00,\n",
              "                                     4.2422e+00, -7.3166e+00, -6.1980e+00, -1.9034e+00,\n",
              "                                    -3.9980e+00, -1.7749e+00, -4.8525e+00,  2.2932e+00,\n",
              "                                    -2.9455e+00,  4.4546e+00, -7.7851e+00,  1.1087e+00,\n",
              "                                    -3.6124e+00, -3.7803e+00,  3.4165e+00, -5.9368e+00,\n",
              "                                    -7.0381e+00, -6.2957e+00, -5.6861e+00,  4.0024e+00,\n",
              "                                     1.5232e-01,  6.3456e+00, -1.5108e+00, -3.0139e+00,\n",
              "                                    -6.4904e-01, -3.3975e+00, -4.5012e+00, -2.3926e+00,\n",
              "                                    -2.0703e+00, -6.9544e+00,  6.8932e-01, -6.6925e+00,\n",
              "                                     4.5357e+00,  2.8709e+00,  1.2682e+00, -1.7957e+00,\n",
              "                                    -6.4143e+00,  4.9324e-01, -2.0089e+00, -3.7296e+00,\n",
              "                                    -4.1888e+00, -2.0222e+00,  1.4314e+00,  5.3450e+00,\n",
              "                                    -9.5417e+00,  7.5505e-01,  3.6262e-01,  3.0632e+00,\n",
              "                                    -3.0700e+00,  2.9553e-01, -3.0660e+00, -1.9983e+00,\n",
              "                                     3.5520e+00, -9.7343e+00, -9.7762e+00, -4.4380e+00,\n",
              "                                    -3.1987e+00, -5.0071e+00, -1.5489e+00, -7.4250e+00,\n",
              "                                     1.8276e+00, -8.5320e+00, -3.2924e-03,  8.0085e+00,\n",
              "                                    -1.2270e+00, -6.9276e+00, -3.9072e+00,  2.2675e+00,\n",
              "                                    -3.3205e+00, -4.4211e-01, -5.7318e+00, -8.7323e+00,\n",
              "                                     1.6771e+00,  8.6098e-01, -1.0625e+01, -6.5519e+00,\n",
              "                                     2.4703e+00, -1.6018e+00, -3.3102e+00, -7.2007e+00,\n",
              "                                    -3.0320e+00, -6.9101e+00, -4.8717e+00, -2.4482e+00,\n",
              "                                    -6.1226e+00, -6.5228e-01, -4.7370e+00, -4.0360e+00,\n",
              "                                     1.5349e-01, -1.2315e-01, -5.7700e+00, -1.0693e+01,\n",
              "                                     1.7402e+00, -3.8159e+00, -3.9252e+00, -4.2206e+00,\n",
              "                                    -5.3986e+00, -3.5485e+00, -2.3514e+00,  1.0753e+00,\n",
              "                                    -4.5836e-01, -6.7225e+00, -6.2997e+00, -2.8172e+00,\n",
              "                                    -2.6207e+00, -2.9073e+00, -3.7819e+00, -2.2363e+00,\n",
              "                                     5.3381e-01, -3.4921e+00,  5.9706e+00, -1.9319e+00,\n",
              "                                    -1.4857e+00, -6.6921e+00, -7.2532e+00, -4.4169e+00,\n",
              "                                     6.6792e-01, -5.0510e-01, -2.0714e+00, -1.9038e+00,\n",
              "                                     1.1420e+00, -4.0686e+00,  1.3868e+00, -5.1782e+00,\n",
              "                                    -9.5192e+00, -1.0977e+01, -6.6380e-01, -1.7666e+00,\n",
              "                                    -3.8616e+00, -1.3199e+00,  1.4466e+00,  1.3049e+00,\n",
              "                                     4.8989e+00, -4.9079e+00,  3.6660e+00, -6.1775e+00,\n",
              "                                    -2.5239e-01,  3.0239e-01,  3.2407e+00, -3.1368e+00,\n",
              "                                    -7.4218e+00,  1.2229e+00,  3.0260e-01, -5.5250e+00,\n",
              "                                    -3.9195e+00, -7.2066e+00,  1.1009e+00, -8.3962e+00,\n",
              "                                     5.8918e-01, -2.3111e+00, -7.4843e+00, -2.0080e+00,\n",
              "                                    -4.4308e+00, -8.7722e+00, -8.5701e+00,  2.3236e+00,\n",
              "                                    -9.1941e-01,  1.5997e+00, -3.4801e+00, -4.0000e+00,\n",
              "                                     4.8648e-01, -5.3763e+00,  3.3683e+00, -3.9379e+00,\n",
              "                                    -4.2358e-01, -5.0899e+00, -2.5163e+00, -1.9639e+00,\n",
              "                                    -4.4134e+00, -1.1141e+01, -5.0946e+00, -5.6961e+00,\n",
              "                                    -5.4713e+00,  2.6307e+00, -1.0066e+01, -4.8730e-03,\n",
              "                                    -6.9994e+00,  4.0878e-02,  6.6906e+00, -6.1101e+00,\n",
              "                                    -1.5778e+00, -4.9135e+00, -1.3897e+00, -1.3747e+00,\n",
              "                                    -2.4362e+00, -1.1424e-01,  3.7160e+00, -2.6243e+00,\n",
              "                                     1.4585e+00, -2.2803e+00,  1.3947e+00,  2.4718e+00,\n",
              "                                     2.0185e-02,  9.1010e+00,  1.6494e+00, -1.6391e+00,\n",
              "                                    -9.4318e+00, -4.6338e+00, -3.4168e+00, -1.6847e+00,\n",
              "                                    -3.0555e+00, -5.6302e+00, -5.2512e+00, -5.0096e-01,\n",
              "                                    -3.1952e+00, -3.7938e+00, -4.5043e+00, -1.3524e+00,\n",
              "                                    -3.3527e+00,  1.0989e+00, -1.0391e+00, -3.5782e+00,\n",
              "                                    -9.2120e+00,  1.2720e+00, -8.9272e+00, -5.6923e+00,\n",
              "                                    -5.9296e+00, -1.3093e+00,  2.0653e+00, -8.2908e+00,\n",
              "                                     1.7354e+00, -7.5349e+00,  1.0123e-01, -2.6853e+00,\n",
              "                                    -1.6782e+00, -1.0414e+01, -2.7567e+00, -3.1766e+00,\n",
              "                                     9.4480e-02, -7.6443e+00, -5.1831e+00,  3.1647e-01,\n",
              "                                    -6.3095e+00,  2.8989e+00, -7.7953e+00, -6.1527e+00,\n",
              "                                    -5.8519e-01,  1.4893e+00,  3.1256e+00,  7.9854e-01,\n",
              "                                    -4.2992e+00, -1.0384e+00, -1.9514e+00, -4.8552e+00,\n",
              "                                    -8.3919e+00, -9.1068e+00, -3.5378e+00, -1.9906e+00,\n",
              "                                     2.1000e+00, -1.8149e+00, -6.5662e+00, -3.4870e+00,\n",
              "                                    -9.6516e+00, -3.7763e+00,  1.7692e+00,  6.2798e-01,\n",
              "                                     2.1841e+00,  3.5379e+00, -4.2550e+00, -3.8645e+00,\n",
              "                                    -1.1652e+00,  1.2837e+00, -4.7924e+00, -3.5909e+00,\n",
              "                                     2.1223e+00, -6.7251e+00, -3.2039e+00,  3.7988e+00,\n",
              "                                    -2.6488e+00, -4.1247e+00,  5.2508e-01, -2.9911e+00,\n",
              "                                    -4.6118e+00, -8.4635e+00,  4.5655e+00, -3.9218e+00,\n",
              "                                    -6.5158e+00,  1.8242e+00, -1.0481e+00, -4.0381e+00,\n",
              "                                    -7.6563e+00,  1.4151e-01, -3.5476e+00, -1.0649e+00,\n",
              "                                    -2.7283e+00,  4.8060e-01, -2.5778e-01,  1.2199e+00,\n",
              "                                    -9.7837e-01,  4.9084e+00, -2.8342e+00, -4.9439e+00]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 80.4446,  93.2996,  55.0102,  51.7883,  60.3937,\n",
              "                                     39.0850,  64.5441,  53.7028,  81.2950,  77.2832,\n",
              "                                     52.9917,  50.5205,  95.4826,  73.4346,  47.9495,\n",
              "                                     76.4596,  92.7184,  96.2420,  69.0879,  58.4881,\n",
              "                                     65.4839,  65.3756,  49.3264,  96.9983,  79.6509,\n",
              "                                    114.4879,  71.3093,  70.4600,  73.3503,  89.2516,\n",
              "                                     65.8938,  69.9441,  47.1015,  46.1221,  96.1967,\n",
              "                                     45.5882,  72.5073,  75.1877,  69.2697,  85.6621,\n",
              "                                     50.3003,  95.7083,  60.9816,  70.8335,  87.3832,\n",
              "                                     56.0309,  91.4058,  46.8384,  80.3506,  79.0198,\n",
              "                                     73.2700,  47.6557,  83.3957,  40.1966,  78.9843,\n",
              "                                     74.2722,  56.2108,  51.9111,  80.0193,  68.2713,\n",
              "                                     46.5706,  47.3870,  69.5181,  73.1745,  39.0499,\n",
              "                                     76.8058,  81.0821,  51.9014,  48.8204,  49.5876,\n",
              "                                     92.0261,  92.1894,  76.2680,  48.8100,  73.8589,\n",
              "                                     59.0790,  91.3368,  77.6645,  64.6943,  44.2202,\n",
              "                                     57.5428,  63.2593,  71.3599,  63.6429,  54.2782,\n",
              "                                     59.4695,  94.7130, 105.3298,  53.9707,  43.6440,\n",
              "                                     64.4460,  45.6824,  90.2885,  93.6794,  34.5740,\n",
              "                                     34.4226,  69.2786,  55.7207,  78.8891,  59.0807,\n",
              "                                     54.4231,  51.0104,  86.5278,  80.6858,  36.7926,\n",
              "                                    113.2462,  51.1142,  64.2395,  47.7447,  74.4696,\n",
              "                                     62.0995,  67.2711,  51.2681,  56.3479,  96.3642,\n",
              "                                     64.8433,  63.6602,  75.8520,  66.7615,  60.2928,\n",
              "                                     37.2632,  52.2853,  40.7939,  66.1856,  67.7403,\n",
              "                                     64.6216,  42.8991, 126.7634,  67.6421,  45.7544,\n",
              "                                     59.4612,  58.7335,  74.5911,  72.7869,  58.8787,\n",
              "                                    102.6958,  97.0185,  68.9979,  38.9058,  39.6572,\n",
              "                                     89.3832,  46.2406,  75.7633,  46.1301,  76.8230,\n",
              "                                     57.9214,  58.9989,  68.3669,  58.5075,  71.4427,\n",
              "                                     65.6021,  44.4522,  90.9031,  82.1181,  52.7516,\n",
              "                                     61.5180,  47.7991,  87.0770,  62.9654,  40.6520,\n",
              "                                     67.5355,  60.1112,  49.9575,  55.6827,  78.4602,\n",
              "                                     67.8838,  80.7649,  54.9846,  79.7459,  59.5667,\n",
              "                                     49.4498,  72.2829,  76.1068,  64.9263,  51.9539,\n",
              "                                     84.8441,  49.5082,  85.8697,  41.0805,  76.9808,\n",
              "                                     67.3130,  46.2152,  48.9871,  55.2073,  86.8531,\n",
              "                                     71.4596,  56.3109,  86.1058,  78.9936,  60.9178,\n",
              "                                     53.9381,  90.1365,  70.3113,  90.8377, 109.3604,\n",
              "                                     65.6604,  37.8424,  64.4553,  60.9252,  46.6474,\n",
              "                                     76.2721,  67.9016,  57.3358,  60.3207, 102.4685,\n",
              "                                     57.7643,  47.4944,  58.8058,  68.7891,  81.2246,\n",
              "                                     43.8863,  57.7303,  90.1416,  61.4007, 101.4997,\n",
              "                                     40.8492,  85.5750,  51.0806,  70.5902,  84.1828,\n",
              "                                     90.6380,  75.3110,  65.4400,  83.4525,  52.0998,\n",
              "                                     69.4489,  84.0817,  73.5471,  65.4035,  54.4806,\n",
              "                                     64.9111,  65.6010,  42.7076,  53.4365,  71.6746,\n",
              "                                     52.2723,  74.1529,  61.0118,  54.1441,  46.3074,\n",
              "                                     48.0124,  89.5328,  79.9233,  42.8696,  62.5028,\n",
              "                                     42.9259,  71.7480,  38.7302,  44.0859,  70.7747,\n",
              "                                     48.0672,  79.6567,  82.3987,  78.5879,  74.7677,\n",
              "                                     89.6373, 145.9215,  54.0233,  60.9869,  63.9240,\n",
              "                                     87.7223,  86.3959,  59.8656,  45.9746, 101.1609,\n",
              "                                     90.8634,  72.8886,  58.3292,  59.5405,  72.2927,\n",
              "                                     38.3887,  47.2626,  58.6535,  80.0412,  89.4797,\n",
              "                                     42.2853, 111.4320,  86.7991,  45.0082,  72.2035,\n",
              "                                     52.9138,  51.6656,  51.8988,  54.6690,  60.7640,\n",
              "                                     61.3592,  55.4457,  48.0893,  85.9803,  83.0890,\n",
              "                                     61.4981,  66.2815,  82.9625,  54.5186, 112.2348,\n",
              "                                     48.4501,  63.7745,  66.7667,  70.0322,  41.3975,\n",
              "                                     59.1105,  68.0388,  42.1984,  60.0672,  75.4598,\n",
              "                                    124.5417,  58.8987,  45.6198,  70.3411,  84.6535,\n",
              "                                     52.2732,  97.9982,  53.8910,  53.0881,  75.0928,\n",
              "                                     76.7522,  69.2913,  91.6834,  51.4040,  56.6706,\n",
              "                                     43.0415,  51.0831,  71.9334,  60.0054, 110.3503,\n",
              "                                    110.0701,  49.1834,  64.4976,  63.5192,  76.2383,\n",
              "                                     71.3942,  70.1110,  60.6753,  67.7664,  78.2172,\n",
              "                                     64.7002,  50.9605,  65.9835,  71.7905,  64.0102,\n",
              "                                     86.6682,  58.4653,  96.9500,  64.4692,  70.5845,\n",
              "                                     82.1967,  51.6625,  77.2041,  49.9622,  44.2063,\n",
              "                                     61.5890,  53.4938,  99.7103,  98.7846,  46.8121,\n",
              "                                     58.0462,  45.1044,  75.5311,  54.3448,  43.7860,\n",
              "                                     63.6284,  63.2189,  73.0999, 116.5529,  91.0925,\n",
              "                                    101.0526,  47.0551,  62.3628,  59.7621,  55.7598,\n",
              "                                     55.9781,  68.4098,  88.2951,  91.5358,  66.2709,\n",
              "                                     61.5132,  70.1544,  61.3282,  71.2171,  63.2086,\n",
              "                                     70.1528,  92.5804,  37.3276,  72.5697,  41.8652,\n",
              "                                     90.6264,  61.4626,  59.5891,  63.1046,  87.3782,\n",
              "                                     81.3075,  62.6686,  81.3242,  56.3359,  67.2163,\n",
              "                                     74.3565,  87.9187,  70.1856,  42.8926,  58.1015,\n",
              "                                     72.2807,  70.4333,  52.6650,  62.3504,  53.1924,\n",
              "                                     58.0235,  68.6021, 131.4799,  47.1724,  50.3574,\n",
              "                                     45.5650,  48.8999,  73.8385, 102.6929,  65.1787,\n",
              "                                     55.6348,  52.8982,  60.1329,  52.0416,  62.6227,\n",
              "                                     86.8638, 109.9780,  63.3115,  70.8280,  72.8438,\n",
              "                                     90.1676,  88.9758,  51.4602,  41.1370,  71.0047,\n",
              "                                     53.1395,  57.2328, 115.3848,  82.9248,  92.9359,\n",
              "                                     67.7003,  98.3566,  93.1610,  40.4827,  62.3222,\n",
              "                                     69.7887,  75.6623,  70.4629,  59.8354,  54.4340,\n",
              "                                     79.9338,  62.7085,  77.4710,  61.3941,  97.0718,\n",
              "                                     65.2081,  46.7648, 106.8134,  47.5967,  96.5554,\n",
              "                                     73.4894,  65.9469,  68.8347,  51.2750,  84.1999,\n",
              "                                     56.2179,  66.3204,  55.4385,  86.8445,  92.8235,\n",
              "                                    105.4263,  72.6839,  79.5417,  47.8367,  51.8334,\n",
              "                                    117.2155,  59.7072,  99.4528,  34.1037,  57.1680,\n",
              "                                     65.9475,  54.8702,  69.7631, 105.5964,  82.9657,\n",
              "                                     93.8752,  54.9371,  75.5613,  67.7021,  76.3655,\n",
              "                                     75.4153,  52.6318,  65.0212,  71.9242,  70.1542,\n",
              "                                     80.1855,  79.8436,  72.9013,  90.7957,  39.1393,\n",
              "                                     80.0783,  78.5365,  63.2656,  65.8270,  41.5327,\n",
              "                                     95.1893,  73.3739,  63.9090,  60.6066, 116.5477,\n",
              "                                     81.2899,  70.3298,  74.9073,  64.4372,  69.0104,\n",
              "                                     58.6754,  72.5325]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 2047, 2047, 2047],\n",
              "                                     [   0,    1,    2,  ...,  509,  510,  511],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0258, -0.0044,  0.0082,  ...,  0.0297,  0.0657,\n",
              "                                    -0.0170]),\n",
              "                     size=(2048, 512, 1, 1), nnz=1048576, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([0.9997, 0.9869, 1.0033,  ..., 0.9924, 0.9944, 0.9730]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([-0.0376, -0.0354, -0.0383,  ..., -0.0370, -0.0288,\n",
              "                                    -0.0610]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([ 0.3901, -0.8700,  0.5850,  ...,  0.1291,  0.1353,\n",
              "                                     0.2038]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([1.7062, 1.3552, 1.3917,  ..., 1.2438, 1.1892, 1.1770]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.1.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.conv1.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,  511,  511,  511],\n",
              "                                     [   0,    1,    2,  ..., 2045, 2046, 2047],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([-0.0246,  0.0757,  0.0171,  ..., -0.0709, -0.0749,\n",
              "                                     0.0473]),\n",
              "                     size=(512, 2048, 1, 1), nnz=1048576, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn1.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9735, 0.9807, 1.0010, 1.0313, 1.0013, 1.0026, 0.9627,\n",
              "                                    1.0129, 1.0051, 0.9738, 1.0581, 0.9991, 0.9478, 0.9466,\n",
              "                                    0.9708, 0.9801, 0.9871, 0.9501, 1.0114, 1.0092, 0.9855,\n",
              "                                    0.9886, 0.9684, 1.0194, 0.9880, 0.9985, 0.9322, 1.0157,\n",
              "                                    0.9905, 1.0139, 1.0224, 1.0232, 0.9862, 1.0129, 1.0157,\n",
              "                                    1.0122, 1.0150, 0.9897, 0.9894, 1.0418, 0.9358, 1.0148,\n",
              "                                    0.9934, 1.0290, 1.0048, 1.0094, 0.9706, 0.9708, 0.9661,\n",
              "                                    0.9951, 0.9760, 0.9660, 1.0465, 0.9640, 1.0066, 0.9230,\n",
              "                                    0.9746, 1.0631, 1.0112, 0.9450, 1.0304, 0.9723, 1.0349,\n",
              "                                    1.0084, 0.9871, 1.0536, 0.9747, 1.0053, 0.9432, 0.9558,\n",
              "                                    1.0045, 0.9941, 0.9684, 0.9936, 0.9680, 0.9618, 1.0050,\n",
              "                                    1.0049, 1.0148, 0.9540, 1.0365, 1.0026, 1.0027, 1.0320,\n",
              "                                    1.0156, 1.0026, 1.0342, 0.9630, 1.0139, 1.0736, 1.0114,\n",
              "                                    0.9494, 1.0406, 0.9916, 1.0022, 0.9848, 1.0308, 1.0158,\n",
              "                                    0.9585, 0.9660, 0.9728, 0.9511, 1.0290, 0.9890, 0.9826,\n",
              "                                    1.0496, 0.9603, 0.9790, 0.9692, 1.0193, 0.9931, 1.0122,\n",
              "                                    1.0218, 0.9802, 0.9825, 0.9708, 1.0124, 1.0014, 1.0392,\n",
              "                                    1.0524, 1.0344, 0.9961, 1.0127, 1.0042, 1.0656, 1.0113,\n",
              "                                    0.9876, 1.0049, 1.0119, 0.9325, 1.0119, 1.0207, 1.0116,\n",
              "                                    1.0025, 0.9751, 0.9511, 1.0109, 1.0325, 1.0174, 1.0493,\n",
              "                                    0.9644, 1.0559, 0.9993, 1.0017, 1.0013, 1.0032, 0.9688,\n",
              "                                    0.9949, 0.9901, 0.9891, 1.0319, 0.9722, 1.0081, 1.0074,\n",
              "                                    1.0016, 0.9364, 0.9989, 1.0640, 1.0204, 0.9452, 0.9757,\n",
              "                                    1.0042, 1.0189, 1.0216, 0.9698, 0.9890, 1.0057, 1.0143,\n",
              "                                    0.9645, 1.0184, 1.0207, 0.9894, 0.9611, 0.9946, 0.9884,\n",
              "                                    0.9971, 1.0141, 1.0228, 0.9495, 0.9770, 1.0483, 0.9900,\n",
              "                                    0.9628, 0.9968, 1.0078, 0.9916, 1.0333, 0.9298, 1.0426,\n",
              "                                    0.9748, 1.0049, 0.9985, 1.0320, 1.0089, 0.9477, 1.0114,\n",
              "                                    1.0131, 1.0429, 1.0046, 0.9987, 0.9678, 1.0142, 1.0035,\n",
              "                                    0.9978, 0.9973, 1.0032, 1.0117, 0.9994, 0.9984, 1.0358,\n",
              "                                    0.9294, 0.9903, 0.9900, 0.9537, 1.0674, 1.0090, 1.0235,\n",
              "                                    0.9423, 0.9776, 0.9945, 0.9996, 0.9866, 1.0284, 0.9876,\n",
              "                                    0.9735, 0.9836, 0.9844, 0.9853, 1.0320, 0.9501, 1.0070,\n",
              "                                    1.0049, 0.9831, 0.9824, 1.0153, 0.9768, 0.9856, 1.0066,\n",
              "                                    1.0094, 1.0418, 0.9445, 1.0453, 0.9775, 0.9987, 0.9818,\n",
              "                                    0.9349, 1.0236, 0.9485, 1.0281, 1.0193, 0.9690, 1.0005,\n",
              "                                    1.0145, 0.9783, 0.9766, 1.0079, 0.9767, 1.0008, 1.0068,\n",
              "                                    0.9863, 0.9993, 1.0904, 0.9449, 1.0240, 1.0080, 1.0081,\n",
              "                                    1.0611, 1.0430, 0.9693, 1.0020, 1.0331, 0.9710, 0.9830,\n",
              "                                    0.9924, 1.0170, 1.0302, 1.0050, 0.9812, 0.9808, 0.9904,\n",
              "                                    0.9787, 1.0538, 0.9837, 0.9984, 1.0049, 0.9525, 1.0106,\n",
              "                                    1.0198, 0.9801, 0.9490, 1.0171, 0.9777, 0.9711, 0.9827,\n",
              "                                    0.9782, 1.0334, 0.9876, 0.9652, 0.9539, 0.9971, 0.9762,\n",
              "                                    1.0223, 0.9662, 1.0323, 1.0539, 1.0150, 0.9796, 1.0268,\n",
              "                                    0.9683, 1.0318, 0.9524, 1.0105, 0.9622, 1.0239, 0.9406,\n",
              "                                    0.9752, 0.9950, 0.9577, 0.9738, 1.0280, 1.0085, 0.9773,\n",
              "                                    1.0108, 0.9571, 1.0453, 0.9565, 0.9502, 1.0045, 1.0059,\n",
              "                                    0.9656, 1.0123, 0.9728, 1.0069, 0.9938, 1.0096, 0.9654,\n",
              "                                    1.0020, 1.0160, 1.0223, 0.9875, 1.0254, 0.9895, 1.0639,\n",
              "                                    0.9417, 1.0084, 1.0075, 0.9866, 1.0048, 1.0065, 0.9720,\n",
              "                                    0.9934, 1.0004, 1.0113, 1.0013, 0.9948, 0.9867, 1.0536,\n",
              "                                    0.9356, 1.0053, 0.9903, 0.9816, 1.0247, 0.9971, 1.0219,\n",
              "                                    0.9554, 0.9739, 1.0141, 1.0445, 0.9777, 1.0036, 1.0042,\n",
              "                                    0.9710, 0.9950, 0.9989, 0.9629, 0.9661, 0.9898, 1.0240,\n",
              "                                    0.9974, 0.9971, 0.9752, 0.9405, 1.0694, 0.9379, 1.0467,\n",
              "                                    1.0408, 1.0010, 0.9973, 1.0369, 0.9853, 0.9314, 0.9500,\n",
              "                                    0.9641, 1.0010, 1.0147, 0.9820, 1.0200, 1.0054, 1.0110,\n",
              "                                    1.0253, 0.9935, 1.0311, 0.9587, 1.0055, 0.9900, 1.0253,\n",
              "                                    1.0300, 1.0280, 0.9799, 1.0035, 0.9497, 1.0609, 0.9636,\n",
              "                                    0.9786, 0.9682, 0.9540, 1.0048, 0.9853, 1.0336, 0.9984,\n",
              "                                    1.0160, 0.9588, 1.0068, 0.9608, 0.9878, 1.0045, 0.9782,\n",
              "                                    0.9810, 0.9836, 0.9834, 0.9973, 1.0040, 0.9853, 1.0008,\n",
              "                                    0.9714, 1.0297, 1.0221, 0.9605, 0.9980, 0.9902, 1.0194,\n",
              "                                    1.0037, 0.9876, 1.0139, 1.0082, 1.0234, 0.9739, 1.0063,\n",
              "                                    0.9958, 1.0045, 1.0047, 1.0030, 1.0222, 0.9657, 0.9750,\n",
              "                                    1.0065, 0.9981, 0.9851, 1.0239, 1.0000, 0.9554, 1.0133,\n",
              "                                    0.9670, 0.9693, 0.9793, 0.9624, 1.0023, 1.0002, 1.0274,\n",
              "                                    1.0228, 1.0528, 0.9948, 0.9823, 0.9544, 1.0117, 0.9352,\n",
              "                                    1.0049, 1.0034, 0.9922, 0.9780, 1.0017, 1.0054, 0.9528,\n",
              "                                    1.0141, 0.9778, 1.0012, 1.0117, 1.0152, 0.9968, 0.9787,\n",
              "                                    0.9969, 1.0011, 0.9732, 1.0194, 1.0288, 0.9990, 0.9738,\n",
              "                                    0.9848, 1.0075, 0.9419, 0.9927, 0.9707, 0.9948, 1.0018,\n",
              "                                    1.0186, 0.9741, 0.9671, 0.9481, 0.9976, 0.9787, 0.9978,\n",
              "                                    0.9595]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn1.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-3.6854e-02, -2.0388e-02,  3.9180e-03, -5.5810e-02,\n",
              "                                    -4.9115e-02, -1.0808e-02, -3.4488e-02, -8.1968e-02,\n",
              "                                    -3.5109e-02, -1.3341e-01, -5.7607e-02, -9.8227e-02,\n",
              "                                    -8.4343e-02, -4.8102e-02, -2.9322e-02,  1.8297e-02,\n",
              "                                     2.9067e-02, -5.3263e-02, -4.6309e-02, -2.4623e-02,\n",
              "                                     2.2919e-02, -6.3710e-02, -4.5927e-02, -1.8106e-02,\n",
              "                                    -6.6114e-02, -6.3342e-02, -7.1271e-02, -4.8896e-02,\n",
              "                                    -8.5554e-02, -4.2431e-02, -4.0796e-02, -3.7940e-02,\n",
              "                                    -7.0971e-02, -9.1863e-02,  3.5142e-03, -1.4263e-02,\n",
              "                                    -6.8123e-02, -5.2310e-02, -4.0181e-02, -3.5697e-02,\n",
              "                                    -8.6241e-02, -7.3432e-02, -2.0038e-02, -4.3935e-02,\n",
              "                                    -5.2366e-02, -1.4096e-02, -2.5389e-02, -6.1834e-02,\n",
              "                                    -5.6580e-02, -3.3168e-02, -2.2870e-02, -9.2853e-02,\n",
              "                                    -2.6401e-02, -8.7344e-02, -5.5642e-02, -1.2274e-01,\n",
              "                                    -5.1275e-02, -2.5694e-02, -1.9643e-02, -4.7042e-02,\n",
              "                                    -1.2724e-01, -6.4265e-02, -1.5353e-02, -7.1809e-02,\n",
              "                                    -7.6866e-02, -6.0274e-02, -7.8133e-02, -3.8656e-02,\n",
              "                                    -4.7656e-02, -8.5044e-02, -2.9869e-02, -5.7899e-02,\n",
              "                                    -9.8592e-02, -7.9146e-02, -7.5310e-02, -6.3101e-02,\n",
              "                                    -2.0673e-02, -6.6952e-04, -5.9954e-02, -3.8021e-02,\n",
              "                                    -4.2051e-02, -5.7968e-03, -4.8062e-02, -1.5876e-02,\n",
              "                                    -6.7651e-02, -4.4818e-02, -6.7223e-02, -4.6414e-02,\n",
              "                                    -7.5445e-02, -7.2281e-02, -5.5352e-02, -3.7972e-02,\n",
              "                                    -7.2737e-02, -4.1465e-02, -2.9015e-02, -6.1001e-03,\n",
              "                                    -3.8716e-02, -3.8797e-02, -2.3829e-02, -7.5891e-02,\n",
              "                                    -2.8511e-02, -7.3258e-02, -1.7320e-02, -1.7312e-02,\n",
              "                                    -3.8336e-02,  2.4063e-03, -6.9121e-02, -4.0407e-02,\n",
              "                                    -5.0004e-02, -4.7574e-02, -4.4617e-02, -3.4435e-02,\n",
              "                                    -3.9370e-02, -4.1503e-02, -4.1797e-02, -6.5663e-02,\n",
              "                                    -3.3505e-02, -4.6099e-02, -4.7806e-02, -6.1050e-02,\n",
              "                                    -9.7238e-02, -8.4092e-03, -2.3762e-02, -8.0848e-02,\n",
              "                                     9.3129e-02, -9.8290e-02, -6.4840e-02, -2.5136e-02,\n",
              "                                     2.0087e-02, -5.6188e-02, -3.9395e-02, -3.3187e-02,\n",
              "                                    -5.9244e-02, -3.6694e-02, -5.9620e-02, -8.2122e-02,\n",
              "                                    -3.7888e-02, -5.6459e-02, -1.3944e-02, -3.0466e-02,\n",
              "                                    -3.6999e-02, -1.9981e-02, -4.6540e-02, -1.0386e-01,\n",
              "                                    -4.4051e-02, -9.8726e-02, -6.2181e-02, -2.4706e-02,\n",
              "                                    -6.2138e-02, -7.6660e-02, -5.8054e-02, -6.7955e-03,\n",
              "                                    -3.1654e-02, -6.0634e-02, -5.6520e-02, -7.6238e-02,\n",
              "                                    -6.3114e-02, -8.6028e-02, -2.6221e-02, -4.9972e-02,\n",
              "                                    -1.0743e-01,  8.2707e-04, -4.1577e-02, -4.9754e-02,\n",
              "                                    -8.0762e-02, -4.2630e-02, -2.0417e-03, -4.1025e-03,\n",
              "                                    -4.6592e-02, -5.1633e-02, -4.8015e-02, -3.0115e-02,\n",
              "                                     2.0274e-02, -4.0590e-02, -5.8438e-02, -5.7239e-02,\n",
              "                                    -5.3375e-02, -4.6626e-02, -2.2943e-02, -4.5659e-02,\n",
              "                                    -2.6396e-02, -6.6122e-02, -7.4020e-02, -3.7287e-02,\n",
              "                                    -8.9846e-03, -1.0483e-01, -6.8625e-02, -2.6533e-02,\n",
              "                                    -7.1821e-02,  1.1662e-02, -3.0342e-02, -5.7372e-02,\n",
              "                                    -3.2908e-02, -5.9236e-02, -3.1989e-02, -7.4680e-02,\n",
              "                                    -3.2211e-02, -1.1249e-02, -6.1043e-02, -4.5114e-02,\n",
              "                                    -5.9861e-02, -3.6183e-02, -4.4221e-02, -3.9865e-02,\n",
              "                                    -4.9925e-02, -2.4885e-02, -3.9234e-02, -1.5726e-02,\n",
              "                                    -8.7509e-02, -6.2898e-02, -6.3445e-02, -6.5392e-02,\n",
              "                                    -4.2281e-02, -4.2454e-02, -2.3365e-02, -5.3788e-02,\n",
              "                                    -4.4687e-02, -2.4319e-02, -7.2379e-02, -4.0319e-02,\n",
              "                                    -4.1829e-02, -2.7246e-02, -4.4370e-02, -4.3603e-03,\n",
              "                                    -7.0244e-02, -5.1478e-02, -2.3750e-02, -6.8495e-02,\n",
              "                                    -3.8440e-02, -4.0090e-02, -1.0032e-02, -5.8069e-02,\n",
              "                                    -4.3199e-02, -3.5217e-02, -1.5072e-04, -1.5116e-02,\n",
              "                                    -4.7757e-02, -7.8695e-02, -4.4844e-02, -1.6715e-02,\n",
              "                                    -1.8341e-02, -6.6787e-03, -4.9372e-02, -3.2872e-02,\n",
              "                                    -5.6667e-02, -7.7841e-02, -2.0371e-02, -4.1645e-02,\n",
              "                                    -2.8504e-02, -5.1738e-02, -2.0562e-02, -2.0544e-02,\n",
              "                                    -2.2279e-02, -3.3270e-02, -7.0674e-02, -2.7202e-02,\n",
              "                                    -1.4040e-02, -3.6822e-02, -1.4375e-02, -7.2602e-02,\n",
              "                                    -7.1504e-02, -5.4027e-02, -6.3751e-02, -6.9272e-02,\n",
              "                                    -7.6044e-02, -8.7100e-02, -3.0844e-02, -2.2004e-02,\n",
              "                                    -5.8972e-02, -3.8500e-02, -1.5928e-02, -7.8114e-02,\n",
              "                                    -1.0157e-01, -2.9315e-02, -5.0660e-02, -4.5014e-02,\n",
              "                                    -3.7174e-02, -5.7599e-02, -8.0563e-02, -5.5766e-02,\n",
              "                                    -1.1852e-02, -9.2418e-02, -6.9156e-02, -8.2420e-02,\n",
              "                                    -4.3905e-02, -2.3725e-02, -3.3793e-02, -3.7756e-02,\n",
              "                                    -1.4566e-02, -7.3370e-02, -2.9092e-02, -6.9716e-02,\n",
              "                                    -7.5278e-02, -6.6206e-02, -3.7711e-02, -3.3509e-02,\n",
              "                                     1.3265e-03, -6.0064e-02, -6.4234e-02, -1.0084e-01,\n",
              "                                    -4.7722e-02, -1.1268e-01, -9.5814e-02, -2.9983e-02,\n",
              "                                    -3.9827e-02,  2.4218e-03, -1.1352e-01, -5.8840e-02,\n",
              "                                    -9.5619e-02, -4.2117e-02, -6.7628e-02, -2.1199e-03,\n",
              "                                    -7.7411e-02, -4.1789e-02, -5.4169e-02, -4.2289e-02,\n",
              "                                    -3.3483e-02, -6.3877e-02, -3.6171e-02, -3.2042e-02,\n",
              "                                    -4.4067e-02, -6.5165e-02, -3.9699e-02, -1.0329e-01,\n",
              "                                    -5.0730e-02, -4.7209e-02, -9.2265e-02, -4.6438e-02,\n",
              "                                    -7.7132e-02, -7.2745e-02, -9.8953e-02, -2.2080e-02,\n",
              "                                    -6.1197e-02,  3.9563e-03, -3.6048e-02, -4.4097e-02,\n",
              "                                    -2.2915e-02, -5.7713e-02, -7.3889e-02, -7.0404e-02,\n",
              "                                    -4.1731e-02, -7.4734e-02, -2.9509e-02, -6.4398e-02,\n",
              "                                    -2.7639e-02, -3.3602e-02, -2.2464e-02, -5.3668e-02,\n",
              "                                    -6.5867e-02, -7.3470e-02, -8.6314e-02, -6.9646e-02,\n",
              "                                    -2.2355e-03, -5.5774e-02, -4.4593e-02, -4.6307e-02,\n",
              "                                    -3.7896e-02, -5.5902e-02,  4.0840e-03, -4.6638e-02,\n",
              "                                    -1.3245e-02, -5.0482e-02,  1.8123e-04, -7.8718e-02,\n",
              "                                    -5.4829e-02, -1.1942e-01, -5.9973e-02, -4.9382e-02,\n",
              "                                    -5.8965e-02, -2.1034e-02,  1.3914e-02, -2.6633e-02,\n",
              "                                    -5.8486e-02, -4.4661e-02, -2.3246e-02, -6.9023e-02,\n",
              "                                    -2.3344e-02, -5.7657e-02, -5.8845e-02, -4.7285e-02,\n",
              "                                    -4.9906e-02, -6.5719e-02, -6.2047e-02, -1.5490e-02,\n",
              "                                    -3.2697e-02, -4.8730e-02, -2.5565e-02, -1.5562e-02,\n",
              "                                    -9.2241e-03, -8.9355e-02, -3.9359e-02, -8.1963e-02,\n",
              "                                    -6.3245e-02,  2.1441e-03, -1.7348e-02, -2.4113e-02,\n",
              "                                    -4.2227e-02, -3.7437e-02, -6.2544e-02, -5.8583e-02,\n",
              "                                    -1.8394e-03, -6.7039e-02, -1.1579e-02, -1.9419e-02,\n",
              "                                    -4.9317e-02, -4.3489e-02, -8.3486e-02, -9.2955e-02,\n",
              "                                    -6.8273e-02, -2.6924e-02, -2.7642e-03, -3.6987e-03,\n",
              "                                    -4.0749e-02, -7.4348e-02, -6.2031e-03, -8.5753e-02,\n",
              "                                    -3.9883e-02, -8.2665e-02, -1.3336e-02, -2.0761e-02,\n",
              "                                    -5.5316e-02, -6.1968e-02, -6.8711e-02,  8.8929e-03,\n",
              "                                    -1.2081e-01, -5.8407e-02,  2.0361e-02, -6.5225e-02,\n",
              "                                    -4.4506e-02, -6.2008e-02, -4.8116e-02, -4.8960e-02,\n",
              "                                    -5.2096e-02,  5.6858e-03, -1.2553e-01, -8.9985e-02,\n",
              "                                    -6.3953e-02, -8.0484e-03, -5.7183e-02, -1.0444e-03,\n",
              "                                    -1.1479e-02, -3.5208e-02, -1.0843e-01, -3.6115e-02,\n",
              "                                    -2.7973e-02, -5.7743e-02, -4.9458e-02, -1.9388e-02,\n",
              "                                    -4.2067e-02, -4.9903e-02, -3.5278e-02, -3.3247e-02,\n",
              "                                     2.1301e-05, -5.5038e-02, -8.3638e-02, -4.7725e-02,\n",
              "                                    -6.1621e-03, -1.1752e-04, -1.3201e-02, -1.0228e-01,\n",
              "                                    -1.7439e-02, -4.6761e-02, -1.0266e-02, -1.3002e-01,\n",
              "                                    -4.7180e-02, -2.9519e-02, -5.8573e-02, -6.0554e-02,\n",
              "                                    -2.2336e-02, -4.4831e-02, -3.7070e-02, -1.9502e-02,\n",
              "                                    -5.7296e-02, -8.5094e-02, -2.2786e-02, -3.6433e-02,\n",
              "                                    -1.1735e-02, -5.6729e-02, -7.7937e-02, -5.0652e-02,\n",
              "                                     3.6216e-02, -6.7441e-02, -4.9820e-02, -7.5578e-02,\n",
              "                                    -4.8611e-02, -3.3780e-02, -4.3134e-02, -8.2830e-02,\n",
              "                                    -4.3969e-02, -8.2796e-02, -1.8618e-02, -4.7126e-02,\n",
              "                                    -5.4575e-02, -1.1250e-01, -8.1377e-02, -7.3043e-02,\n",
              "                                    -3.6133e-02, -7.0874e-02, -2.3551e-02, -4.2024e-02,\n",
              "                                    -4.8203e-02, -3.2826e-02, -3.0895e-02, -1.2076e-01,\n",
              "                                    -4.7867e-02, -2.3142e-02, -2.2217e-02, -9.5905e-02,\n",
              "                                    -3.5910e-02,  1.5239e-02, -3.7613e-02, -3.9030e-02]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn1.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-4.3224e+00, -2.1764e+00,  7.3962e-01, -4.4104e+00,\n",
              "                                     3.7543e+00, -1.3379e+01,  1.9356e+00, -1.5329e+00,\n",
              "                                     6.0256e-01,  1.3536e-01, -2.7445e+00, -6.7086e-01,\n",
              "                                    -2.7901e+00, -1.1636e+01, -5.6988e+00, -1.0079e+01,\n",
              "                                    -4.9480e+00, -5.9042e-01, -1.2881e+00,  1.1773e+00,\n",
              "                                    -7.2465e+00, -7.9310e-02, -1.1993e+01, -8.5714e+00,\n",
              "                                     6.5406e+00, -3.5579e+00, -1.1244e+01,  5.0506e-01,\n",
              "                                     3.4589e+00, -4.3913e+00,  1.8718e+00,  4.2929e-02,\n",
              "                                    -3.3179e+00,  5.4000e+00, -2.8680e+00, -6.8426e+00,\n",
              "                                    -2.3166e+00,  2.1292e+00, -2.1101e+00, -1.1571e+00,\n",
              "                                     3.0076e+00,  7.9256e-01, -1.0121e+01,  1.3542e+00,\n",
              "                                     8.2507e+00,  2.4855e-01, -1.9239e+00,  3.8698e+00,\n",
              "                                     7.4279e+00, -7.3253e+00, -3.1423e+00,  1.6729e+00,\n",
              "                                     4.7775e+00, -3.7580e+00,  2.3044e-01,  1.7663e+00,\n",
              "                                    -1.3561e+00, -2.1919e+00, -2.5885e+00, -6.9655e+00,\n",
              "                                     3.1185e+00, -1.0287e+01,  1.2566e+00,  6.9558e-01,\n",
              "                                    -1.5740e+00, -2.1933e+00,  3.3911e+00,  2.2245e+00,\n",
              "                                    -6.2340e+00, -4.3029e+00,  3.4627e-01,  2.0279e+00,\n",
              "                                    -1.1587e+00,  5.4970e+00, -1.1210e+00,  1.0457e+01,\n",
              "                                    -1.4082e+00, -8.0481e+00, -3.2353e+00, -1.0528e+01,\n",
              "                                    -1.7424e+00, -9.8922e+00, -1.6176e+00, -6.5179e+00,\n",
              "                                    -1.7404e+00,  8.5952e-01,  4.0709e+00, -1.0873e+01,\n",
              "                                    -4.5698e+00, -2.0955e+00,  3.9411e+00, -3.6423e+00,\n",
              "                                    -7.9888e-01,  1.0710e+01, -6.3268e+00, -2.2535e+00,\n",
              "                                    -3.8983e-01, -8.7695e-01, -1.8121e+01, -2.9107e+00,\n",
              "                                     4.9451e+00, -9.1166e-01,  1.4898e-01, -7.4174e+00,\n",
              "                                    -5.0947e+00, -8.5477e-01, -5.6821e-01,  1.1069e-01,\n",
              "                                    -1.8734e+00,  8.9299e-01, -1.0111e+00, -4.1680e+00,\n",
              "                                    -1.0996e+00, -1.0988e+01,  1.9552e-01,  1.4369e-01,\n",
              "                                     3.8046e+00, -1.1825e+00, -7.4677e+00, -2.2531e+00,\n",
              "                                    -1.4686e+00, -2.2437e+00, -5.1510e+00, -6.8090e-01,\n",
              "                                    -5.7327e+00,  3.0056e+00, -4.2379e+00, -4.3597e-01,\n",
              "                                    -8.1480e+00,  1.1331e+00,  7.1764e+00,  3.8409e+00,\n",
              "                                    -4.1688e+00,  2.3741e+00,  3.7905e+00,  5.3140e-01,\n",
              "                                    -7.7323e+00, -8.5907e-01,  3.5800e+00, -3.3274e+00,\n",
              "                                    -9.6933e+00, -9.3118e-01, -8.2009e+00,  8.6279e+00,\n",
              "                                     2.6706e+00, -1.0159e+00, -4.2178e+00, -1.6127e+00,\n",
              "                                     2.6416e+00, -6.5127e+00,  3.9514e-01, -4.8124e+00,\n",
              "                                     6.7308e+00,  1.4257e+00,  2.6590e+00,  1.5260e+00,\n",
              "                                     5.9292e+00, -8.1435e-01,  1.1061e+00, -9.8825e+00,\n",
              "                                     1.6148e+00, -7.4912e+00, -6.7166e-01, -5.7441e-02,\n",
              "                                     3.0016e+00, -7.9083e+00, -4.7854e+00, -4.6847e+00,\n",
              "                                    -8.1827e-01,  3.5110e+00,  1.1003e+00, -1.2244e+00,\n",
              "                                    -8.0326e+00,  5.0167e+00, -3.3575e+00, -1.0484e+01,\n",
              "                                    -4.1882e-01, -3.7971e+00, -1.2034e+01, -2.4716e+00,\n",
              "                                    -4.8463e-03,  1.5042e+00, -7.3179e+00, -7.2851e-01,\n",
              "                                     1.2464e+00,  9.0359e-01, -3.2179e-01, -9.6349e+00,\n",
              "                                     9.4545e-02, -1.1914e+01, -9.2930e+00,  7.6217e-01,\n",
              "                                     3.5435e+00,  1.8573e+00, -5.8198e+00, -7.3831e-01,\n",
              "                                    -5.2609e+00,  6.6527e-01, -2.4654e-01,  2.1400e+00,\n",
              "                                    -4.3921e+00, -6.7468e+00, -1.2684e+00, -8.1669e+00,\n",
              "                                     9.8645e-01, -1.8817e+00, -4.0472e+00, -9.5656e+00,\n",
              "                                     3.7335e+00,  9.7352e-01,  1.5895e+00, -6.1686e+00,\n",
              "                                    -1.1568e+01,  2.0294e+00, -5.9006e+00,  7.3721e-01,\n",
              "                                    -1.6290e+00, -7.4944e+00,  3.1693e+00, -7.4237e+00,\n",
              "                                    -8.9304e+00, -1.8600e+00, -4.1504e+00, -1.0285e+01,\n",
              "                                    -1.3313e+00,  3.5364e+00, -7.0131e+00,  8.2984e-02,\n",
              "                                    -5.0059e+00, -1.5355e+01, -6.3537e+00, -8.7298e+00,\n",
              "                                     6.8007e+00,  7.4901e-02, -5.9566e+00, -1.3929e+01,\n",
              "                                    -1.1432e+00,  7.7499e-01,  3.0457e+00,  6.2161e+00,\n",
              "                                    -6.8303e+00,  1.3312e+00, -5.8123e+00, -1.1838e+01,\n",
              "                                    -1.0410e+00, -8.1439e+00, -2.8004e+00, -8.3676e+00,\n",
              "                                     2.7351e+00,  3.2030e+00, -6.8190e+00, -7.2631e+00,\n",
              "                                     2.6879e+00, -6.7349e+00, -8.1047e+00,  3.5867e-01,\n",
              "                                    -5.7402e+00,  2.6801e+00, -8.6478e+00, -1.1014e+00,\n",
              "                                     1.9221e+00,  4.4132e-01, -7.0538e+00,  4.2933e+00,\n",
              "                                    -3.0052e+00,  4.4351e+00,  2.2948e+00, -1.1279e-01,\n",
              "                                    -4.1909e+00,  4.7365e+00, -6.0499e+00,  1.7960e+00,\n",
              "                                     1.3258e+00, -5.1415e+00,  8.7260e-01,  2.6522e+00,\n",
              "                                     2.0341e+00, -8.4046e+00,  1.8966e+00, -6.1337e+00,\n",
              "                                    -5.4570e+00, -1.3706e+00, -6.2397e+00, -8.7357e+00,\n",
              "                                    -2.8973e+00, -9.3725e+00, -1.0328e+00, -8.0329e+00,\n",
              "                                    -7.7051e+00, -4.0223e+00, -2.2119e+00, -5.5299e+00,\n",
              "                                     4.7887e+00, -2.8044e+00,  4.1224e+00,  9.1806e-01,\n",
              "                                    -6.1735e+00, -4.6091e+00, -4.7187e+00, -1.5071e-01,\n",
              "                                    -6.7523e+00,  3.7617e+00,  2.0098e+00,  7.4468e+00,\n",
              "                                     4.3254e-01, -6.9556e+00,  3.1603e+00,  2.5326e+00,\n",
              "                                     1.2870e+00, -4.8814e-01, -5.7369e+00,  9.7991e-01,\n",
              "                                    -2.4499e+00, -3.7351e+00, -8.5973e+00, -5.9255e+00,\n",
              "                                    -3.6342e+00, -2.9479e+00,  1.4606e+00, -6.1068e+00,\n",
              "                                     5.6400e+00,  2.0621e+00,  4.6872e+00,  2.8369e+00,\n",
              "                                     7.3395e-01,  2.6181e+00,  2.2445e+00, -7.7647e+00,\n",
              "                                    -4.7433e+00,  2.3576e+00, -1.1441e+00, -1.2708e+01,\n",
              "                                     6.4055e+00, -5.2566e+00,  4.9047e+00, -6.1019e-01,\n",
              "                                     8.5137e-01,  4.5210e+00,  3.8993e+00, -4.9637e+00,\n",
              "                                     2.0308e+00,  5.6026e+00, -4.5131e+00, -6.2766e+00,\n",
              "                                     3.2672e+00,  1.0023e-01,  6.6816e+00, -3.0268e-02,\n",
              "                                     7.3689e+00, -9.7728e+00,  9.7856e-01,  1.9565e+00,\n",
              "                                    -3.6928e-01, -2.0132e+00,  4.8279e+00, -1.6731e+00,\n",
              "                                    -2.2770e+00, -1.7760e+00, -8.2801e+00, -6.3201e-02,\n",
              "                                    -9.8531e+00,  3.9539e+00, -1.3986e-01,  3.1930e+00,\n",
              "                                    -7.0874e+00, -2.3979e+00, -5.8353e+00,  3.0857e+00,\n",
              "                                    -3.3016e+00,  2.7197e-01, -7.9625e+00, -1.3798e+00,\n",
              "                                    -4.2695e-01,  2.6300e+00, -9.0032e+00,  1.0725e+01,\n",
              "                                    -4.5949e+00,  1.7593e+00, -2.5256e+00, -1.8383e+00,\n",
              "                                     9.6297e+00, -8.5353e+00, -1.1136e+00, -9.7008e+00,\n",
              "                                     1.9796e+00, -1.0810e+00,  4.6084e+00,  2.5921e+00,\n",
              "                                    -3.8370e+00, -9.5060e+00, -1.5090e+01,  1.0268e+00,\n",
              "                                     4.2000e+00, -4.4648e+00, -6.9093e+00,  8.2645e-01,\n",
              "                                     6.0959e+00,  2.5224e+00, -1.1713e+00, -4.2216e-01,\n",
              "                                    -1.0883e+01, -2.7097e+00, -1.3083e+01, -3.2671e+00,\n",
              "                                     7.2645e+00, -3.3026e+00,  3.0905e+00,  2.7824e+00,\n",
              "                                    -1.5664e+00, -9.4635e+00, -1.3946e+01, -3.6143e+00,\n",
              "                                    -6.8208e+00,  1.7827e+00, -4.8179e+00,  4.8947e-01,\n",
              "                                    -8.2703e+00,  4.1538e+00,  1.2300e+00,  2.7924e+00,\n",
              "                                    -1.9325e+00,  7.2024e-02,  3.5225e+00, -7.1558e+00,\n",
              "                                    -3.4270e+00, -6.9220e-01, -1.1579e+01,  4.6723e+00,\n",
              "                                    -2.8001e-02, -5.0104e+00,  6.7098e+00,  9.3682e+00,\n",
              "                                     4.4817e+00, -1.1812e+00,  1.1045e+00,  2.6619e+00,\n",
              "                                    -5.0371e+00, -9.7779e+00,  1.6654e+00, -1.0266e+01,\n",
              "                                     1.6254e+00, -3.4367e+00,  4.9929e+00, -4.5048e+00,\n",
              "                                    -7.2513e+00,  3.5366e-02, -1.0544e+01, -3.8789e+00,\n",
              "                                    -3.6440e+00,  2.1401e-01,  7.4437e+00, -1.5315e+00,\n",
              "                                    -6.4815e-01,  1.6928e+00, -1.8192e+00, -4.1936e+00,\n",
              "                                    -2.7525e+00, -1.3750e+01,  2.6667e-01,  3.0120e+00,\n",
              "                                    -7.4049e+00,  1.9231e+00, -1.3509e+01, -3.0836e-01,\n",
              "                                    -4.6922e+00, -7.9461e+00,  2.3274e-01,  5.7679e+00,\n",
              "                                     3.2927e-01,  2.7206e+00, -1.4205e+00, -3.1381e+00,\n",
              "                                     4.1704e+00, -8.6967e+00, -2.2090e+00, -1.1470e+01,\n",
              "                                    -5.0776e+00,  5.0448e+00, -2.1260e+00,  3.7091e+00,\n",
              "                                    -1.3129e+00,  6.1541e+00,  8.4818e+00, -4.3444e+00,\n",
              "                                    -2.0294e+00, -4.2595e+00, -2.1716e+00, -7.6330e-02,\n",
              "                                     1.5478e+00,  4.9089e-01,  7.3160e+00, -8.9467e+00,\n",
              "                                    -1.1740e+01,  1.6518e-01,  2.9696e-01, -5.5377e+00,\n",
              "                                    -6.4233e+00, -4.5302e-01, -1.0776e+01,  4.0645e+00,\n",
              "                                    -1.5101e+00,  6.6016e-01, -8.6237e+00,  2.2541e+00,\n",
              "                                    -4.1853e+00, -1.0291e+01, -1.5211e+01,  8.6708e+00,\n",
              "                                    -4.0071e+00, -1.4385e+01, -2.1414e+00, -1.1121e+01]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn1.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 90.9995, 108.5423, 108.7406,  99.5480, 190.9124,\n",
              "                                    118.1266,  85.5489, 147.6704, 140.8539, 144.6026,\n",
              "                                    107.6912,  80.5927,  60.1234, 107.0888,  85.9129,\n",
              "                                    115.1984,  90.8668, 107.9418,  79.5624,  89.2179,\n",
              "                                     96.0183,  87.8723, 115.4182,  97.0490, 119.9474,\n",
              "                                    114.1038, 124.7516, 142.9256, 102.9619,  92.1666,\n",
              "                                    155.5584,  82.0999, 111.7217, 119.7365,  88.9422,\n",
              "                                     86.9438, 144.6811,  68.0739, 133.3645, 130.5225,\n",
              "                                     47.3296, 103.8146,  88.2184,  87.5957, 121.9749,\n",
              "                                    141.5676,  88.1004,  95.0081, 118.2651, 107.7505,\n",
              "                                     99.4503,  91.6911, 123.2147, 122.1116,  81.9393,\n",
              "                                    107.5813,  85.2655, 146.3348, 114.2089,  79.8966,\n",
              "                                    122.1816,  85.8719, 103.5705,  68.0068,  99.4424,\n",
              "                                    112.0584, 104.9025,  88.6359,  70.0877,  73.8399,\n",
              "                                    132.1144, 165.7733,  74.9209, 103.9741, 102.2108,\n",
              "                                    120.3770,  82.4046,  86.2602, 109.5580, 105.0070,\n",
              "                                    121.1014, 201.3689,  70.6412, 124.9582,  85.9097,\n",
              "                                     97.9762, 153.0018, 186.5885,  73.9513, 103.8416,\n",
              "                                    114.1811,  61.5988, 130.6548, 110.0765, 164.0680,\n",
              "                                    118.5662,  87.5191,  86.5955, 224.3740,  99.0973,\n",
              "                                    102.6432, 101.7064, 111.1706, 115.9739,  90.3541,\n",
              "                                    100.8774,  80.9969, 100.0926,  89.6232,  97.7272,\n",
              "                                    101.1809,  90.7998, 116.4310, 121.3437, 125.9518,\n",
              "                                     84.5496, 123.3731,  91.6827, 108.7334, 120.1232,\n",
              "                                     88.9930,  99.0310, 109.5344,  99.1637, 134.9933,\n",
              "                                     89.3023,  87.4419,  93.9614,  94.5917,  81.3817,\n",
              "                                     98.7847, 166.5844, 115.3098,  96.9255,  97.9510,\n",
              "                                     60.2671,  99.4707,  95.5349, 115.3815,  88.2821,\n",
              "                                    138.5278, 123.1580, 126.0968, 143.8481, 105.3997,\n",
              "                                    135.2043,  76.9507, 163.9238,  83.3621, 102.7690,\n",
              "                                     94.5187,  75.2170, 131.5572, 122.8741, 100.0565,\n",
              "                                     96.3198,  68.3644, 154.6233,  90.5669,  82.0189,\n",
              "                                    145.1021, 100.9420,  97.0358, 146.3942, 133.3494,\n",
              "                                    110.2176, 103.5508,  92.3134,  92.0227, 158.6477,\n",
              "                                     81.4650,  87.5819,  88.2878, 126.9565, 130.5000,\n",
              "                                     94.1662, 136.9257,  96.6264,  97.1105,  74.1697,\n",
              "                                     78.7136, 100.7660, 105.1851,  56.4294, 106.3954,\n",
              "                                    149.7353, 140.6095,  93.4105,  81.9402, 110.6305,\n",
              "                                    188.0534, 117.0090,  95.0369, 120.7154, 170.4794,\n",
              "                                    124.2743,  88.4085, 107.2734, 135.4845, 143.7038,\n",
              "                                     86.5359, 161.9619,  59.5614, 149.5237,  73.3664,\n",
              "                                    112.2595,  77.6866, 107.5473, 100.9124, 120.9598,\n",
              "                                     91.2715, 125.8930, 155.3520,  65.2226, 105.7128,\n",
              "                                     94.7534, 124.5146,  80.1419,  92.4669,  69.4520,\n",
              "                                    187.0563, 111.7150, 103.0015, 134.7434,  86.3112,\n",
              "                                    161.6840, 152.3931, 117.0779,  92.7738, 115.2593,\n",
              "                                    163.0820, 158.5839, 124.8349, 106.0213, 119.4245,\n",
              "                                    170.0499,  81.7099,  94.6728,  55.5696,  89.3532,\n",
              "                                     96.3395,  83.7468,  92.8787, 170.9714,  91.2351,\n",
              "                                     88.2688,  90.5578,  97.9533, 109.2559, 135.0862,\n",
              "                                    129.5539,  98.4027, 115.0185,  67.7268, 118.2595,\n",
              "                                     77.5591,  57.9064,  67.6477, 130.1410,  98.4115,\n",
              "                                    124.8065,  86.7273, 108.2199, 109.0315, 112.4188,\n",
              "                                     70.7791, 124.8660, 106.6669,  60.4624,  88.2032,\n",
              "                                     94.1593, 114.5597, 122.0838,  71.2676,  93.8140,\n",
              "                                     99.3647, 104.3649,  98.0779,  89.0118,  84.4122,\n",
              "                                     60.6364, 100.4041,  98.2347, 141.6228, 104.6981,\n",
              "                                    113.9440, 136.8699,  85.6042, 109.9178, 104.9218,\n",
              "                                     99.3479, 134.2877, 115.2841, 119.6335,  98.3047,\n",
              "                                    132.1537, 111.5473,  69.1202,  68.9091,  52.2156,\n",
              "                                    139.1523, 118.2856,  60.4867, 124.9043, 115.0762,\n",
              "                                     91.6711,  91.0795, 102.1193, 126.5839, 137.6184,\n",
              "                                     84.6137,  79.3331,  93.7101, 100.9352,  64.5963,\n",
              "                                    119.0447,  89.2814,  99.3343, 148.2782, 114.3065,\n",
              "                                    138.8627, 131.4324,  79.4398,  70.6690, 106.6455,\n",
              "                                     74.4538, 109.5519,  76.1329,  87.0270,  93.4706,\n",
              "                                     98.4780, 130.7261, 100.5013,  80.5611, 124.9725,\n",
              "                                    119.1909,  67.6697, 108.7458, 126.8743, 113.8175,\n",
              "                                    117.1896,  85.3638,  92.8773,  67.3371,  84.9484,\n",
              "                                    126.9690, 105.4063, 100.9059, 127.6916,  81.9929,\n",
              "                                    102.0591,  63.9472, 102.5141, 114.8257, 126.2958,\n",
              "                                     82.8847, 144.7464,  80.1460,  82.0999, 134.6726,\n",
              "                                    168.9655, 142.4332, 108.3222,  99.5601,  94.7349,\n",
              "                                    123.4542,  78.2844,  85.7043,  93.9799,  99.4909,\n",
              "                                     73.2715,  56.1148,  84.2898,  77.5177, 168.2083,\n",
              "                                    120.0233, 104.8169, 165.1420, 112.5768,  99.7391,\n",
              "                                    151.7679, 106.1944, 137.7760, 116.0821,  93.4676,\n",
              "                                     97.6213,  96.8108, 115.7252, 127.0437, 124.9704,\n",
              "                                    104.7671, 103.7506, 133.5346, 110.7822,  79.2964,\n",
              "                                    118.1958, 122.6506, 127.2572, 117.5465, 148.9299,\n",
              "                                    122.8356, 103.3801, 135.3156,  81.7052, 171.6680,\n",
              "                                     91.0879, 145.8873, 148.8876,  81.0448, 137.4799,\n",
              "                                    106.0590, 108.7473, 113.6414, 107.0649,  81.0870,\n",
              "                                    113.9726, 159.6581,  89.0501, 122.0692,  87.6736,\n",
              "                                    102.4232,  75.7810, 108.3145,  89.7210, 121.7042,\n",
              "                                     90.5012, 121.3449, 126.1353,  78.9722,  99.3850,\n",
              "                                     87.9013, 125.7052,  99.1858,  85.0308, 110.9169,\n",
              "                                    128.9130, 105.1454, 112.3999, 138.5265, 141.0417,\n",
              "                                    120.3439,  75.4295, 119.6046, 115.8491, 122.5336,\n",
              "                                    106.2313, 106.3839, 122.0264, 170.3368,  75.8190,\n",
              "                                    137.7335,  85.8188, 108.9353,  85.3470, 101.3328,\n",
              "                                     80.7487, 132.5667, 122.4432, 126.7192,  82.9417,\n",
              "                                     98.0601,  91.5179, 137.5419, 127.3977,  88.4469,\n",
              "                                     98.0243,  92.5471,  87.5270,  98.3809, 147.4950,\n",
              "                                    114.6135, 103.2676,  86.4916, 111.0030, 104.5621,\n",
              "                                    104.1686, 116.7840,  84.7371, 106.6982,  79.9246,\n",
              "                                     78.4005,  89.9925, 111.5292, 125.3028, 108.2924,\n",
              "                                     95.6613,  97.6964, 105.0653,  87.7511, 113.7272,\n",
              "                                    124.4541, 132.5756, 165.9219, 119.9715, 153.5912,\n",
              "                                     94.4284, 120.8570,  84.0098, 112.9937,  95.2574,\n",
              "                                    125.8426,  97.6434,  95.5752, 106.0797, 166.3199,\n",
              "                                    215.2513, 179.7031, 143.8373, 107.5095, 133.8546,\n",
              "                                     93.8367, 131.4844]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn1.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.conv2.weight',\n",
              "              tensor(indices=tensor([[  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   0,   0,  ..., 511, 511, 511],\n",
              "                                     [  0,   0,   0,  ...,   2,   2,   2],\n",
              "                                     [  0,   1,   2,  ...,   0,   1,   2]]),\n",
              "                     values=tensor([-0.0190, -0.0007, -0.0172,  ..., -0.0284,  0.0008,\n",
              "                                    -0.0051]),\n",
              "                     size=(512, 512, 3, 3), nnz=2359296, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn2.weight',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([0.9930, 1.0269, 0.9795, 1.0254, 0.9578, 0.9735, 0.9924,\n",
              "                                    1.0351, 0.9315, 0.9802, 0.9749, 0.9831, 1.0190, 1.0061,\n",
              "                                    1.0197, 0.9684, 1.0201, 1.0028, 0.9876, 0.9833, 0.9472,\n",
              "                                    0.9976, 0.9950, 1.0112, 1.0114, 0.9711, 0.9819, 0.9999,\n",
              "                                    0.9844, 1.0207, 1.0118, 1.0182, 0.9869, 1.0082, 0.9635,\n",
              "                                    0.9953, 0.9456, 1.0130, 1.0078, 0.9652, 0.9687, 0.9653,\n",
              "                                    0.9924, 0.9771, 1.0233, 1.0381, 0.9451, 1.0181, 0.9855,\n",
              "                                    0.9939, 0.9728, 1.0005, 1.0282, 1.0085, 0.9222, 0.9673,\n",
              "                                    1.0093, 0.9062, 0.9789, 0.9922, 1.0077, 0.9566, 1.0308,\n",
              "                                    1.0093, 1.0411, 1.0183, 1.0143, 0.9450, 0.9951, 0.9970,\n",
              "                                    0.9603, 1.0260, 1.0210, 0.9654, 1.0143, 1.0699, 1.0374,\n",
              "                                    1.0173, 0.9465, 1.0235, 0.9800, 0.9767, 0.9812, 1.0175,\n",
              "                                    0.9758, 1.0071, 0.9472, 0.9677, 1.0264, 1.0140, 1.0137,\n",
              "                                    0.9565, 1.0718, 0.9949, 1.0172, 0.9991, 0.9594, 1.0662,\n",
              "                                    0.9692, 1.0161, 1.0194, 1.0157, 0.9827, 0.9611, 0.9585,\n",
              "                                    0.9480, 0.9637, 0.9802, 1.0157, 0.9942, 1.0072, 1.0153,\n",
              "                                    0.9876, 0.9739, 1.0065, 0.9868, 0.9798, 0.9816, 1.0440,\n",
              "                                    1.0119, 1.0254, 1.0415, 0.9903, 0.9752, 1.0004, 0.9826,\n",
              "                                    0.9841, 1.0074, 0.9799, 1.0035, 1.0081, 0.9991, 1.0425,\n",
              "                                    0.9344, 1.0229, 1.0244, 0.9625, 0.9892, 1.0113, 0.9680,\n",
              "                                    1.0160, 0.9942, 0.9530, 0.9865, 0.9874, 0.9910, 0.9747,\n",
              "                                    1.0554, 0.9428, 1.0301, 1.0310, 0.9971, 1.0118, 0.9994,\n",
              "                                    1.0320, 0.9802, 1.0412, 1.0202, 0.9532, 0.9152, 1.0497,\n",
              "                                    0.9975, 1.0066, 1.0055, 0.9903, 0.9993, 0.9884, 1.0784,\n",
              "                                    0.9766, 1.0167, 0.9737, 0.9797, 0.9840, 1.0360, 0.9951,\n",
              "                                    0.9703, 1.0175, 1.0284, 0.9395, 0.9858, 0.9572, 1.0021,\n",
              "                                    1.0055, 0.9719, 0.9766, 1.0227, 1.0191, 1.0645, 0.9977,\n",
              "                                    0.9805, 0.9870, 0.9935, 0.9861, 1.0161, 0.9474, 0.9802,\n",
              "                                    0.9961, 0.9634, 0.9892, 0.9562, 1.0019, 0.9786, 1.0042,\n",
              "                                    1.0366, 1.0384, 0.9845, 0.9272, 1.0609, 0.9939, 0.9359,\n",
              "                                    0.9953, 1.0250, 0.9695, 0.9796, 1.0207, 1.0013, 1.0460,\n",
              "                                    0.9865, 1.0151, 0.9873, 1.0015, 0.9878, 1.0246, 0.9714,\n",
              "                                    1.0030, 0.9492, 0.9676, 1.0034, 0.9857, 1.0081, 0.9669,\n",
              "                                    1.0151, 1.0031, 1.0154, 1.0060, 1.0335, 1.0354, 1.0343,\n",
              "                                    1.0091, 1.0191, 0.9989, 0.9182, 0.9655, 0.9827, 1.0233,\n",
              "                                    0.9791, 1.0279, 0.9650, 0.9833, 1.0107, 1.0291, 1.0024,\n",
              "                                    0.9838, 0.9660, 0.9648, 0.9439, 0.9822, 1.0016, 0.9713,\n",
              "                                    1.0395, 1.0111, 0.9930, 0.9636, 0.9881, 0.9785, 1.0384,\n",
              "                                    1.0138, 0.9624, 1.0394, 0.9341, 0.9737, 0.9926, 0.9769,\n",
              "                                    0.9605, 0.9817, 0.9597, 1.0054, 1.0096, 0.9838, 0.9083,\n",
              "                                    1.0156, 0.9486, 0.9904, 0.9807, 0.9825, 1.0378, 0.9507,\n",
              "                                    0.9941, 1.0337, 0.9897, 1.0228, 0.9825, 0.9575, 0.9966,\n",
              "                                    0.9318, 0.9821, 0.9723, 0.9686, 1.0090, 1.0537, 1.0493,\n",
              "                                    0.9910, 1.0124, 0.9640, 0.9543, 0.9813, 1.0146, 1.0026,\n",
              "                                    0.9998, 0.9602, 0.9861, 0.9717, 0.9319, 0.9413, 1.0122,\n",
              "                                    0.9680, 0.9477, 1.0439, 0.9636, 1.0207, 0.9847, 1.0139,\n",
              "                                    1.0153, 0.9985, 1.0035, 1.0205, 0.9992, 1.0177, 0.9780,\n",
              "                                    1.0217, 0.9666, 0.9484, 0.9757, 0.9712, 0.9845, 0.9355,\n",
              "                                    0.9638, 0.9883, 0.9783, 1.0016, 0.9157, 1.0007, 1.0155,\n",
              "                                    0.9438, 1.0117, 1.0507, 1.0166, 0.9947, 0.9895, 1.0064,\n",
              "                                    0.9957, 0.9758, 0.9844, 0.9834, 1.0543, 0.9333, 1.0063,\n",
              "                                    1.0045, 0.9843, 0.9983, 0.9706, 1.0329, 0.9835, 0.9436,\n",
              "                                    1.0183, 1.0068, 1.0023, 0.9832, 0.9705, 0.9781, 0.9801,\n",
              "                                    1.0347, 0.9753, 0.9623, 1.0278, 1.0096, 0.9665, 0.9401,\n",
              "                                    0.9554, 0.9910, 0.9678, 0.9499, 0.9835, 1.0101, 0.9712,\n",
              "                                    0.9807, 1.0222, 1.0098, 1.0251, 0.9997, 0.9772, 0.9915,\n",
              "                                    0.9951, 1.0542, 1.0107, 0.9826, 1.0126, 0.9726, 1.0576,\n",
              "                                    1.0075, 1.0318, 0.9603, 0.9679, 0.9523, 1.0212, 1.0049,\n",
              "                                    0.9679, 0.9650, 0.9654, 0.9251, 0.9960, 0.9877, 1.0281,\n",
              "                                    0.9737, 1.0233, 1.0135, 0.9893, 0.9807, 1.0206, 0.9888,\n",
              "                                    0.9936, 1.0139, 0.9828, 0.9860, 0.9606, 0.9660, 1.0191,\n",
              "                                    1.0322, 0.9848, 1.0147, 0.9853, 1.0184, 0.9937, 1.0278,\n",
              "                                    1.0187, 0.9915, 0.9989, 1.0077, 0.9975, 1.0064, 1.0003,\n",
              "                                    1.0244, 1.0001, 0.9961, 0.9877, 0.9733, 0.9934, 1.0096,\n",
              "                                    1.0202, 1.0356, 0.9452, 1.0070, 0.9832, 0.9635, 0.9455,\n",
              "                                    1.0118, 0.9803, 0.9288, 0.9933, 0.9834, 1.0058, 1.0061,\n",
              "                                    1.0204, 1.0225, 1.0152, 0.9932, 0.9696, 1.0327, 0.9983,\n",
              "                                    0.9786, 1.0328, 0.9725, 1.0261, 0.9955, 0.9956, 0.9448,\n",
              "                                    0.9985, 1.0309, 0.9993, 1.0297, 0.9729, 1.0455, 1.0489,\n",
              "                                    1.0298, 0.9740, 0.9490, 0.9782, 1.0597, 0.9692, 0.9829,\n",
              "                                    1.0195, 1.0120, 0.9519, 1.0096, 0.9753, 1.0286, 1.0186,\n",
              "                                    0.9805, 0.9794, 0.9902, 0.9697, 1.0267, 0.9686, 0.9960,\n",
              "                                    0.9165, 0.9636, 1.0087, 1.0561, 0.9949, 1.0791, 0.9712,\n",
              "                                    0.9705]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn2.bias',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-0.0871, -0.0283, -0.1104, -0.0619, -0.1002, -0.0363,\n",
              "                                    -0.0714, -0.0586, -0.0704, -0.0821, -0.0528, -0.0747,\n",
              "                                    -0.0768, -0.0345, -0.0939, -0.0889, -0.0651, -0.0539,\n",
              "                                    -0.0992, -0.1073, -0.0352, -0.1444, -0.0568, -0.0489,\n",
              "                                    -0.0864, -0.0478, -0.0706, -0.0889, -0.0836, -0.0518,\n",
              "                                    -0.0679, -0.0695, -0.0514, -0.0826, -0.0697, -0.0692,\n",
              "                                    -0.0678, -0.0207, -0.0780, -0.1132, -0.0598, -0.0712,\n",
              "                                    -0.0709, -0.0522, -0.0808, -0.0835, -0.1013, -0.0183,\n",
              "                                    -0.0993, -0.1277, -0.0139, -0.0622, -0.0580, -0.0768,\n",
              "                                    -0.1426, -0.0585, -0.0588, -0.1423, -0.0987, -0.0906,\n",
              "                                    -0.1021, -0.0514, -0.0508, -0.0861, -0.0583, -0.0610,\n",
              "                                    -0.0625, -0.0721, -0.0929, -0.0573, -0.0738, -0.0341,\n",
              "                                    -0.0349, -0.0372, -0.0335, -0.0385, -0.1206, -0.1085,\n",
              "                                    -0.0801, -0.0658, -0.0556, -0.0404, -0.0652, -0.0487,\n",
              "                                    -0.0779, -0.0797, -0.0518, -0.0794, -0.0037, -0.0592,\n",
              "                                    -0.0391, -0.0907, -0.0685, -0.1306, -0.0090, -0.0605,\n",
              "                                    -0.0798, -0.1216, -0.0836, -0.0344, -0.1125, -0.0694,\n",
              "                                    -0.0296, -0.1396, -0.0658, -0.0835, -0.0689, -0.0795,\n",
              "                                    -0.0394, -0.1017, -0.0422, -0.1043, -0.0968, -0.0452,\n",
              "                                    -0.0370, -0.0766, -0.0979, -0.0973, -0.1095, -0.0631,\n",
              "                                    -0.0702, -0.0734, -0.0727, -0.0695, -0.1002, -0.0871,\n",
              "                                    -0.0516, -0.1191, -0.0893, -0.0970, -0.0736, -0.0268,\n",
              "                                    -0.0280, -0.1349, -0.0497, -0.0890, -0.0823, -0.0586,\n",
              "                                    -0.0379, -0.0628, -0.0670, -0.0542, -0.0565, -0.0312,\n",
              "                                    -0.0727, -0.0314, -0.0406, -0.0631, -0.0374, -0.0437,\n",
              "                                    -0.0664, -0.0472, -0.1587, -0.0578, -0.0450, -0.0706,\n",
              "                                    -0.0418, -0.0826, -0.1144, -0.0732, -0.0428, -0.0663,\n",
              "                                    -0.0358, -0.0465, -0.0802, -0.0660, -0.0673, -0.0390,\n",
              "                                    -0.0562, -0.0947, -0.0799, -0.1054, -0.0807, -0.0950,\n",
              "                                    -0.0273, -0.1113, -0.0262, -0.1129, -0.0990, -0.0855,\n",
              "                                    -0.1089, -0.0770, -0.0567, -0.1012, -0.0602, -0.0509,\n",
              "                                    -0.0735, -0.0840, -0.0837, -0.0614, -0.1213, -0.0804,\n",
              "                                    -0.0934, -0.1297, -0.0739, -0.0301, -0.0641, -0.0594,\n",
              "                                    -0.1119, -0.0820, -0.0743, -0.0656, -0.0967, -0.0383,\n",
              "                                    -0.0666, -0.1209, -0.0371, -0.0684, -0.1094, -0.0399,\n",
              "                                    -0.0513, -0.0868, -0.0787, -0.0696, -0.0440, -0.1317,\n",
              "                                    -0.0680, -0.0203, -0.0734, -0.0833, -0.0812, -0.0209,\n",
              "                                    -0.1221, -0.0771, -0.0712, -0.0435, -0.0904, -0.0905,\n",
              "                                    -0.0924, -0.0475, -0.1045, -0.0957, -0.1409, -0.0480,\n",
              "                                    -0.0637, -0.1349, -0.0847, -0.0516, -0.0910, -0.0951,\n",
              "                                    -0.0432, -0.1085, -0.1166, -0.0607, -0.0699, -0.1403,\n",
              "                                    -0.0599, -0.0501, -0.1206, -0.0366, -0.1247, -0.0974,\n",
              "                                    -0.0581, -0.1049, -0.0581, -0.0664, -0.0964, -0.0719,\n",
              "                                    -0.0584, -0.0238, -0.0394, -0.0871, -0.0518, -0.0301,\n",
              "                                    -0.0627, -0.0593, -0.0530, -0.0857, -0.0385, -0.1183,\n",
              "                                    -0.0943, -0.0377, -0.0450, -0.0639, -0.0557, -0.0631,\n",
              "                                    -0.0393, -0.0512, -0.0586, -0.0630, -0.0262, -0.0680,\n",
              "                                    -0.0916, -0.0785, -0.0534, -0.0303, -0.1100, -0.0799,\n",
              "                                    -0.0438, -0.0625, -0.0362, -0.1302, -0.0619, -0.0709,\n",
              "                                    -0.0961, -0.0815, -0.0988, -0.0654, -0.0546, -0.0551,\n",
              "                                    -0.0462, -0.0473, -0.0351, -0.0252, -0.0480, -0.0870,\n",
              "                                    -0.0932, -0.0349, -0.0997, -0.0738, -0.0867, -0.0816,\n",
              "                                    -0.0749, -0.0423, -0.1030, -0.1062,  0.0026, -0.0191,\n",
              "                                    -0.0726, -0.0420, -0.0700, -0.0324, -0.0745, -0.0473,\n",
              "                                    -0.0753, -0.0857, -0.0348, -0.1078, -0.0786, -0.0287,\n",
              "                                    -0.0449, -0.1107, -0.0833, -0.1063, -0.0937, -0.0706,\n",
              "                                    -0.0591, -0.0724, -0.0805, -0.1083, -0.1005, -0.0629,\n",
              "                                    -0.0834, -0.1239, -0.0884, -0.0406, -0.1006, -0.0562,\n",
              "                                    -0.0372, -0.0402, -0.0286, -0.0561, -0.0651, -0.0993,\n",
              "                                    -0.0236, -0.0660, -0.1102, -0.1039, -0.0525, -0.1027,\n",
              "                                    -0.0840, -0.0823, -0.0580, -0.0789, -0.0396, -0.0364,\n",
              "                                    -0.0603, -0.0647, -0.0872, -0.0483, -0.0970, -0.1158,\n",
              "                                    -0.0543, -0.0611, -0.0564, -0.0460, -0.0674, -0.0811,\n",
              "                                    -0.0707, -0.1547, -0.0979, -0.0818, -0.0585, -0.0893,\n",
              "                                    -0.0659, -0.0484, -0.0470, -0.0605, -0.0970, -0.0886,\n",
              "                                    -0.1019, -0.0803, -0.1544, -0.0885, -0.0528, -0.1398,\n",
              "                                    -0.0295, -0.0331, -0.1403, -0.0603, -0.0537, -0.0684,\n",
              "                                    -0.1179, -0.1008, -0.0606, -0.0654, -0.0846, -0.0841,\n",
              "                                    -0.1024, -0.1116, -0.0692, -0.0845, -0.0449, -0.1091,\n",
              "                                    -0.1138, -0.0517, -0.1005, -0.0641, -0.1244, -0.1717,\n",
              "                                    -0.0604, -0.0358, -0.1061, -0.0374, -0.0446, -0.1182,\n",
              "                                    -0.0663, -0.0816, -0.0799, -0.0391, -0.0720, -0.1017,\n",
              "                                    -0.0607, -0.0861, -0.0933, -0.1061, -0.0731, -0.0633,\n",
              "                                    -0.0517, -0.1215, -0.0176, -0.0687, -0.1345, -0.1327,\n",
              "                                    -0.0706, -0.0940, -0.1123, -0.0854, -0.0829, -0.0669,\n",
              "                                    -0.0623, -0.0229, -0.0571, -0.0871, -0.0769, -0.0853,\n",
              "                                    -0.1069, -0.1455, -0.0679, -0.0808, -0.0287, -0.0936,\n",
              "                                    -0.0994, -0.0732, -0.1077, -0.0666, -0.0766, -0.1078,\n",
              "                                    -0.0390, -0.1295, -0.0769, -0.0536, -0.1304, -0.0559,\n",
              "                                    -0.0872, -0.0889, -0.0471, -0.0872, -0.0661, -0.0627,\n",
              "                                    -0.0763, -0.0563, -0.0004, -0.0854, -0.0698, -0.1157,\n",
              "                                    -0.0420, -0.0304, -0.0642, -0.0759, -0.0523, -0.0923,\n",
              "                                    -0.0959, -0.0718, -0.0837, -0.0452, -0.0627, -0.1140,\n",
              "                                    -0.0623, -0.0373, -0.0236, -0.0566, -0.1102, -0.0539,\n",
              "                                    -0.0742, -0.0834, -0.0769, -0.0603, -0.0323, -0.0908,\n",
              "                                    -0.0530, -0.0665]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn2.running_mean',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([-3.9285e-01,  3.6954e+00,  4.9072e+00,  3.2664e+00,\n",
              "                                    -5.5706e+00, -9.0454e+00,  3.1392e-02, -3.1734e+00,\n",
              "                                     2.4614e+00, -1.4723e+00,  2.5328e+00,  5.5391e+00,\n",
              "                                     1.6311e+00, -5.7119e+00,  2.9254e+00, -4.6086e+00,\n",
              "                                     2.8851e+00, -1.6160e+00, -1.6850e+00, -1.3544e+00,\n",
              "                                    -5.1143e+00,  3.8650e-02, -1.9302e+00, -2.1321e+00,\n",
              "                                    -5.8414e-01, -1.8362e-01,  2.6809e-01,  6.5723e-01,\n",
              "                                     2.5544e+00,  5.4358e+00, -2.6900e+00,  3.3396e+00,\n",
              "                                    -1.9075e+00,  1.7472e+00,  2.0461e+00, -1.6608e+00,\n",
              "                                    -4.6953e+00, -2.3291e+00,  5.6058e+00, -1.6595e+00,\n",
              "                                    -4.5455e+00, -2.1682e+00, -2.0914e+00, -2.2566e+00,\n",
              "                                     3.9397e+00, -2.8892e+00, -1.0564e+00, -1.6850e-01,\n",
              "                                    -4.6422e+00,  1.5155e+00, -4.8144e+00, -7.6015e+00,\n",
              "                                     4.8290e+00, -2.4422e+00,  1.8724e+00, -5.6835e-01,\n",
              "                                    -1.2024e+00,  1.5852e+00, -1.2397e+00,  6.5539e-01,\n",
              "                                    -9.9566e-01, -5.9252e+00, -7.3873e-01,  1.0678e+00,\n",
              "                                     3.2651e+00,  6.5499e-02,  4.1879e-01, -4.3973e+00,\n",
              "                                     2.6215e+00, -3.2472e+00, -1.2069e+00, -5.3162e-01,\n",
              "                                     3.3602e+00, -2.0656e+00, -1.6126e+00,  2.0080e+00,\n",
              "                                     2.3328e+00, -3.5640e+00, -9.9292e+00, -6.4762e-01,\n",
              "                                     4.6872e+00, -8.9455e-01, -9.3088e+00,  2.2571e+00,\n",
              "                                     8.9468e-01,  4.1617e-01, -5.6248e+00, -2.8943e+00,\n",
              "                                    -8.6990e+00, -4.8408e+00, -6.4227e+00, -1.1616e+00,\n",
              "                                     1.1869e+00,  1.3398e+00, -3.2814e+00,  2.2017e+00,\n",
              "                                    -5.0267e+00,  3.5653e+00, -6.8511e+00, -9.7714e-01,\n",
              "                                     5.0468e+00, -2.7310e+00, -2.7366e+00, -2.8371e+00,\n",
              "                                    -8.6002e+00,  2.6024e-02,  1.8593e+00,  3.8121e+00,\n",
              "                                    -7.4527e+00,  2.8761e+00, -1.8694e+00, -2.3890e+00,\n",
              "                                    -3.8657e-01, -5.6042e-01,  9.5285e-01, -1.4910e+00,\n",
              "                                     3.6654e+00,  7.6773e+00, -7.3083e-01, -9.4901e+00,\n",
              "                                     6.1786e-01,  6.0457e+00,  7.0317e+00,  3.0076e+00,\n",
              "                                    -2.5748e+00,  2.6268e-01, -1.1192e-01,  3.2303e+00,\n",
              "                                    -6.4413e+00, -8.6667e-01,  3.8765e+00, -5.8517e-01,\n",
              "                                    -8.3093e+00,  9.5409e-01, -4.6179e+00,  8.6851e-01,\n",
              "                                     1.8047e-02,  2.1748e+00, -6.1964e-01,  5.4921e+00,\n",
              "                                     2.1080e+00, -3.6365e+00, -5.1496e+00, -3.3704e-01,\n",
              "                                    -4.3834e+00, -8.1570e+00, -4.4396e+00,  9.6978e-01,\n",
              "                                    -5.8678e+00,  3.6180e+00, -2.2980e+00,  2.3798e+00,\n",
              "                                     1.7183e+00, -1.1121e+00, -2.5666e+00,  4.5537e+00,\n",
              "                                    -7.1702e-01,  2.4510e+00, -1.0881e+00, -9.8851e+00,\n",
              "                                     3.2862e+00, -9.6819e-01, -3.2023e+00, -7.6567e+00,\n",
              "                                     3.2381e+00,  3.5141e-01,  6.1316e+00, -3.7863e-01,\n",
              "                                    -8.2585e-01, -5.5545e-01, -4.7195e+00,  1.8514e+00,\n",
              "                                    -1.0547e+00,  2.6836e+00, -4.8967e+00, -3.9697e-01,\n",
              "                                     8.9943e-01,  2.1012e-01, -1.5551e+00, -2.1757e+00,\n",
              "                                    -1.8824e+00, -1.2307e+00,  5.4937e+00,  2.5208e-01,\n",
              "                                     2.3158e-01, -5.1917e+00,  3.1440e+00, -6.2806e-01,\n",
              "                                     2.5019e+00, -1.6193e+00, -1.3707e+00, -2.2698e+00,\n",
              "                                     1.4033e+00,  7.1676e-01,  1.2270e+00, -7.8839e+00,\n",
              "                                    -2.8265e+00, -7.4681e+00,  4.9048e+00, -6.9966e+00,\n",
              "                                     1.4806e+00,  8.3010e-01, -1.3897e-01,  3.6360e+00,\n",
              "                                     2.5693e+00,  3.6642e+00, -4.4365e+00, -1.1003e+00,\n",
              "                                     3.7547e+00, -6.3690e+00, -7.8718e+00,  3.4949e+00,\n",
              "                                     1.1473e+00,  5.5115e+00,  2.3112e-01, -2.7162e+00,\n",
              "                                    -2.3663e+00, -7.0975e+00,  6.0018e+00, -3.3311e+00,\n",
              "                                    -8.6394e-02, -8.6658e+00,  5.1546e+00, -7.3767e+00,\n",
              "                                    -2.5211e+00, -4.1577e+00, -8.7482e+00,  2.3281e+00,\n",
              "                                     5.2002e+00, -4.5662e+00,  7.1634e-01,  2.2249e+00,\n",
              "                                     6.5325e+00, -1.9319e+00, -1.4020e+00, -2.6804e-01,\n",
              "                                    -4.3051e+00,  4.3003e+00, -7.5943e+00,  3.1435e+00,\n",
              "                                    -9.1945e+00, -8.1277e+00,  5.7288e+00, -5.3658e+00,\n",
              "                                    -2.2018e+00,  4.8022e+00, -8.8058e-02, -8.5854e+00,\n",
              "                                    -7.1763e-01,  4.3333e+00, -1.6768e+00,  1.1682e+00,\n",
              "                                    -6.9518e+00, -2.7043e+00, -9.2134e+00, -5.5330e+00,\n",
              "                                     2.8528e+00,  5.6699e-01, -8.2137e+00, -5.5715e+00,\n",
              "                                    -6.2698e+00,  3.6806e-02, -4.6267e+00, -5.5930e+00,\n",
              "                                     5.5387e+00,  4.7995e+00, -3.8264e+00, -3.9076e+00,\n",
              "                                    -4.5211e+00,  5.4040e+00,  6.9084e+00, -6.1489e+00,\n",
              "                                    -8.1191e+00,  7.9815e-01, -5.2457e+00, -9.7206e-01,\n",
              "                                     8.2535e-01, -2.2864e+00, -1.2232e-01, -8.7328e+00,\n",
              "                                    -1.7872e-01, -6.6722e+00,  7.0815e+00,  4.7797e+00,\n",
              "                                    -6.5780e+00,  3.4725e+00, -3.2927e+00,  6.1300e-01,\n",
              "                                    -3.3776e+00,  3.8461e+00,  2.0437e+00,  3.3886e+00,\n",
              "                                    -2.9538e+00,  4.7276e+00,  2.9930e+00, -9.9963e-01,\n",
              "                                     8.5713e-01, -4.9033e+00,  3.5449e+00, -1.0004e-01,\n",
              "                                    -1.0522e-02, -3.4840e+00, -1.7518e+00, -5.3258e+00,\n",
              "                                    -5.8969e+00, -5.5775e+00, -2.3603e+00, -3.3978e+00,\n",
              "                                     1.2137e+00, -8.9116e+00, -1.5459e+00, -3.8084e+00,\n",
              "                                    -2.2457e-01, -5.3521e+00,  5.3555e+00, -5.9576e+00,\n",
              "                                    -4.5462e+00,  3.9497e+00,  1.9046e+00, -5.6069e+00,\n",
              "                                     1.4249e+00, -2.5309e-01, -6.1865e-01, -3.1841e+00,\n",
              "                                     2.5504e+00,  1.8342e+00, -1.5071e+00,  7.0631e-01,\n",
              "                                    -7.2962e+00, -1.8151e+00, -8.3414e+00,  9.9292e+00,\n",
              "                                     6.1485e-01, -4.6787e-01,  8.8269e+00, -4.4539e+00,\n",
              "                                     2.4709e-01,  7.4185e-02, -8.5544e+00,  3.3541e+00,\n",
              "                                    -4.2875e+00, -4.0159e+00, -1.4845e+00,  5.4370e+00,\n",
              "                                     1.5109e+00, -9.9521e+00,  2.8467e+00, -1.2581e+00,\n",
              "                                    -6.0453e+00, -6.6057e+00, -8.3705e+00, -4.9060e+00,\n",
              "                                     3.4501e+00, -3.8341e-01,  8.4702e-01, -7.4994e+00,\n",
              "                                     3.3190e+00, -3.7060e+00, -2.7075e+00, -6.5318e+00,\n",
              "                                    -3.6879e+00,  3.2632e+00, -5.0305e+00, -1.2687e+01,\n",
              "                                     1.3936e-01, -1.7458e-01, -1.4036e+00, -3.4417e+00,\n",
              "                                    -3.7623e+00, -7.8998e+00,  3.4889e+00,  2.1894e+00,\n",
              "                                     1.3465e+00, -4.0542e+00,  8.2105e-01, -6.7360e+00,\n",
              "                                    -6.5920e-02, -5.9229e+00, -9.0062e+00,  6.2416e+00,\n",
              "                                    -4.9678e-02, -1.2505e+00, -9.8347e+00, -2.7855e+00,\n",
              "                                    -2.4012e+00, -4.9672e+00,  4.8615e-01, -3.4519e+00,\n",
              "                                    -7.2838e-01,  4.6991e+00,  6.5769e-01, -2.2451e+00,\n",
              "                                     2.4747e+00, -5.8137e-01, -1.6653e+00,  9.0336e+00,\n",
              "                                    -3.4676e-01, -2.7393e+00,  4.7210e+00,  3.0821e+00,\n",
              "                                     7.1305e-01,  3.1899e+00,  2.6948e+00,  2.3418e+00,\n",
              "                                     5.0068e+00, -2.9628e+00,  2.4680e+00,  6.7605e+00,\n",
              "                                    -6.6925e-01, -5.1644e+00, -6.6154e-01,  4.6877e+00,\n",
              "                                     2.0708e+00,  1.9833e+00,  2.2202e-01, -1.4685e+00,\n",
              "                                    -1.8776e-01,  2.9105e+00, -3.1755e+00,  4.7309e-01,\n",
              "                                    -1.0830e+00, -4.0410e+00,  1.3281e+00, -3.8808e+00,\n",
              "                                    -7.3956e+00, -2.1979e+00, -1.0672e+01, -1.6665e+00,\n",
              "                                    -2.6471e+00, -3.6751e+00, -3.1202e+00, -5.2251e+00,\n",
              "                                    -5.6785e+00,  2.0479e+00, -7.9888e-01,  1.5040e+00,\n",
              "                                    -2.8644e+00, -1.4146e+00, -2.9652e+00, -6.6892e-01,\n",
              "                                    -2.1970e+00, -2.7393e+00,  4.9703e+00,  3.3819e+00,\n",
              "                                     2.1451e+00, -2.1312e+00,  3.0711e+00, -4.7114e-01,\n",
              "                                    -3.0116e-01,  2.0570e+00, -3.5578e-01, -1.4880e+00,\n",
              "                                     3.8115e+00, -4.0103e+00, -3.0214e+00,  6.3564e+00,\n",
              "                                     2.3031e+00, -3.0899e-01, -5.1960e+00, -2.4543e+00,\n",
              "                                    -5.1143e+00, -2.3137e+00,  3.1383e-01, -5.0420e+00,\n",
              "                                     1.4102e+00,  1.9633e-01, -2.7073e+00, -1.3326e+00,\n",
              "                                    -5.1453e+00,  1.5302e-01,  1.5496e+00, -6.5932e+00,\n",
              "                                     3.3905e+00,  1.8281e+00,  5.9720e+00, -5.5244e+00,\n",
              "                                    -3.7436e+00, -2.3070e+00,  1.3707e+00,  1.4446e+00,\n",
              "                                     2.0818e-01,  5.2917e+00, -6.1280e+00, -4.0589e+00,\n",
              "                                     2.4825e+00, -2.2130e+00, -4.3063e+00, -4.0062e+00,\n",
              "                                     4.8669e+00, -6.7051e+00, -1.7779e+00, -1.2287e+00,\n",
              "                                    -6.5134e+00,  2.9345e+00,  8.0430e-01,  1.4879e+00,\n",
              "                                    -4.6243e-01, -3.4973e+00, -2.5804e+00,  2.6926e+00,\n",
              "                                    -5.6338e+00, -2.4937e-01,  6.2124e+00,  3.7979e+00,\n",
              "                                    -6.5760e+00, -4.5400e+00,  3.5735e+00, -6.1639e-01,\n",
              "                                    -9.2458e+00,  1.2366e+00, -7.0237e+00, -7.2067e+00]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn2.running_var',\n",
              "              tensor(indices=tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
              "                                       11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n",
              "                                       22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
              "                                       33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
              "                                       44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
              "                                       55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "                                       66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
              "                                       77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
              "                                       88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "                                       99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                                      110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
              "                                      121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "                                      132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "                                      143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
              "                                      154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "                                      165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175,\n",
              "                                      176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
              "                                      187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "                                      198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
              "                                      209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
              "                                      220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230,\n",
              "                                      231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                                      242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
              "                                      253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
              "                                      264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "                                      275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "                                      286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296,\n",
              "                                      297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
              "                                      308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318,\n",
              "                                      319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
              "                                      330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340,\n",
              "                                      341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "                                      352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
              "                                      363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                                      374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n",
              "                                      385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
              "                                      396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
              "                                      407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
              "                                      418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
              "                                      429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
              "                                      440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
              "                                      451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "                                      462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
              "                                      473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
              "                                      484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
              "                                      495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                                      506, 507, 508, 509, 510, 511]]),\n",
              "                     values=tensor([ 54.0617,  52.1036,  63.4607,  54.2120,  44.1089,\n",
              "                                     61.8406,  66.6632,  47.9640,  50.6369,  50.8374,\n",
              "                                     35.8241,  89.6609,  51.9591,  73.3304,  71.3110,\n",
              "                                     41.2638,  50.0882,  61.3069,  65.2147,  36.4129,\n",
              "                                     56.7142,  68.6513,  43.8776,  44.3454,  62.7506,\n",
              "                                     65.5773,  44.4606,  49.2081,  57.6066,  62.2760,\n",
              "                                     56.7269,  47.2564,  73.9641,  70.3119,  69.5989,\n",
              "                                     41.9173,  35.3909,  53.1659,  73.9379,  70.1322,\n",
              "                                     34.4980,  70.0993,  41.0531,  76.5742,  64.8483,\n",
              "                                     57.0200,  47.1335,  39.1166,  33.2829,  60.6111,\n",
              "                                     56.4830,  70.2506,  77.7733,  52.2578,  51.5154,\n",
              "                                     65.9746,  60.9806,  62.2886,  65.3991,  46.1960,\n",
              "                                     47.8082,  79.8192,  47.1759,  61.9477,  60.8825,\n",
              "                                     63.1405,  54.9166,  49.9227,  67.0630,  75.0611,\n",
              "                                     66.9319,  55.3584,  70.8124,  51.9996,  53.9928,\n",
              "                                     95.2924,  55.0785,  61.8598,  78.3376,  56.6741,\n",
              "                                     61.8615,  44.2561,  85.2106,  79.7589,  37.7256,\n",
              "                                     44.4119,  31.1196,  32.9911,  53.5683,  93.0965,\n",
              "                                     52.6282,  36.1505,  56.9130,  54.6494,  48.3409,\n",
              "                                     44.0008,  56.5127,  61.8959,  76.2598,  69.5383,\n",
              "                                     90.2680,  53.0382,  40.3123,  42.7149,  85.7013,\n",
              "                                     40.5546,  50.8546,  48.2346,  87.8883,  75.3427,\n",
              "                                     42.8178,  43.9544,  38.0652,  45.7300,  53.2580,\n",
              "                                     41.6504,  55.8363,  74.9746,  60.8130,  63.1572,\n",
              "                                     67.8798,  71.0639,  50.1028,  65.4875,  70.0498,\n",
              "                                     65.7506,  72.5448,  52.0550,  39.0272,  51.2077,\n",
              "                                     68.2997,  58.6912,  70.6470,  39.1638,  56.2965,\n",
              "                                     51.5451,  30.4647,  53.2874,  50.2524,  59.9890,\n",
              "                                     59.1566,  71.2259,  45.0326,  64.7285,  43.0666,\n",
              "                                     88.2176,  65.9433, 100.0125,  56.0726,  53.0553,\n",
              "                                     46.8936,  43.5118,  49.0760,  39.9337,  60.4098,\n",
              "                                     51.6956,  59.0870,  38.7719,  73.1394,  78.8134,\n",
              "                                     75.4487,  57.5976,  48.2003, 104.3423,  75.7582,\n",
              "                                     55.8775,  53.7766,  55.2545,  37.4671,  45.5794,\n",
              "                                     33.5724,  41.2331,  63.7981,  64.7797,  51.1627,\n",
              "                                     37.3599,  68.3854,  61.7611,  49.0180,  45.7242,\n",
              "                                     60.5277,  39.9459,  72.7046,  54.5201,  51.7246,\n",
              "                                     59.5753,  64.1467,  89.3698,  67.2163,  87.5015,\n",
              "                                     44.4253,  65.4010,  50.3202,  67.5007,  56.9569,\n",
              "                                    101.2690,  62.6435,  58.2347,  58.2909,  77.1931,\n",
              "                                     69.6158,  52.2077,  48.8184,  69.6350,  63.3509,\n",
              "                                     86.6422,  42.9288,  61.8282,  44.2680,  58.7605,\n",
              "                                     64.8384,  58.1006,  53.3173,  80.7423,  46.7389,\n",
              "                                     75.1214,  55.0845,  85.5904,  87.3613,  41.6701,\n",
              "                                     46.6256,  60.5700,  49.8442,  66.2489,  93.4342,\n",
              "                                     68.6428,  84.6579,  61.8610,  54.6366,  42.7454,\n",
              "                                     49.3402,  57.2994,  68.3960,  43.3202,  35.0602,\n",
              "                                     68.6781,  74.4644,  65.6208,  59.8506,  84.3427,\n",
              "                                    111.0940,  79.8116,  85.7280,  58.2656,  73.1335,\n",
              "                                     62.1684,  55.1749,  49.2076,  71.9621,  57.3050,\n",
              "                                     40.2355,  59.5620,  54.8101,  47.8107,  76.6907,\n",
              "                                     79.3274,  71.4253,  63.0396,  79.9680,  69.7624,\n",
              "                                     60.5547,  50.2622,  54.7256,  37.7265,  71.9167,\n",
              "                                     60.5579,  65.1301,  58.1470,  60.3474,  58.6780,\n",
              "                                     64.3933,  61.8770, 114.3813,  64.1237,  53.9660,\n",
              "                                     56.2529,  74.3619,  57.3014,  61.4763,  71.0304,\n",
              "                                     61.1429,  79.2220,  88.3249,  70.7717,  69.6157,\n",
              "                                     66.0142,  48.6286,  55.4391,  62.2423,  64.6602,\n",
              "                                     61.4069,  47.9825,  58.1714,  85.9214,  40.3870,\n",
              "                                     37.6928,  54.2635,  62.8904,  59.0434,  74.5949,\n",
              "                                     43.2997, 121.6755,  92.3870,  69.0131,  74.2224,\n",
              "                                     87.9705,  55.2178,  62.7947,  73.0282,  74.4965,\n",
              "                                     49.3680,  62.1600,  71.3179,  38.8947,  53.1746,\n",
              "                                     55.0956,  96.3044,  65.2576,  57.8195,  48.2190,\n",
              "                                     63.5108,  50.8058,  61.1920,  56.5192,  48.0695,\n",
              "                                     51.0660,  73.2427,  54.7274,  57.5819,  61.1764,\n",
              "                                     50.8676,  77.4444,  45.1772,  54.0085,  66.0579,\n",
              "                                     47.4477,  47.1522,  66.4072,  57.7205,  65.1315,\n",
              "                                     50.1222,  48.3500,  69.9408,  70.6960,  46.8301,\n",
              "                                     79.2087,  55.8684,  69.3856,  38.9827,  67.0622,\n",
              "                                     73.2052,  42.7826,  70.8764,  50.2776,  43.3475,\n",
              "                                     52.6042,  65.8787,  60.9126,  53.9818,  53.6514,\n",
              "                                     51.2180,  65.9910,  76.6081,  81.4613,  86.1073,\n",
              "                                     59.2454,  68.8664,  32.1232,  59.8837,  81.9054,\n",
              "                                     53.8203,  61.0650,  46.5850,  61.3736,  75.4494,\n",
              "                                     94.9479,  44.6735,  37.7285,  58.7275,  64.7697,\n",
              "                                     69.9454,  43.3413,  89.5807,  48.9882,  48.2123,\n",
              "                                     59.4581,  43.9291,  57.0320,  46.4148,  76.4438,\n",
              "                                     75.9863,  67.1665,  52.8815,  50.5831,  36.9674,\n",
              "                                     67.8303,  86.9277,  49.6061,  58.3879,  67.0812,\n",
              "                                     43.2360,  68.1809,  71.7914,  61.1518,  54.5254,\n",
              "                                     61.9804,  53.2107,  82.0454,  45.8815,  32.8634,\n",
              "                                     70.2741,  49.5108,  54.6766,  58.9093,  58.6891,\n",
              "                                     69.3233,  58.6403,  64.6838,  49.5844,  35.3918,\n",
              "                                     51.5977,  55.6505,  63.7606,  69.4620,  57.1906,\n",
              "                                     53.6281,  76.1065,  40.2316,  55.3527,  60.5843,\n",
              "                                     70.8750,  40.0191,  72.4388,  68.8196,  57.1648,\n",
              "                                     59.8302,  60.9239,  73.4719,  48.8624,  35.6561,\n",
              "                                     46.3070,  51.9323,  59.2290,  68.6882,  59.7165,\n",
              "                                     43.4765,  54.6341,  44.5369,  81.5183,  66.0977,\n",
              "                                     45.1037,  60.0493,  49.4062,  74.6226,  28.6368,\n",
              "                                     52.7708,  41.2529,  47.7056,  61.5952,  47.0534,\n",
              "                                     90.1110,  52.9796,  51.2844,  85.0701,  90.1820,\n",
              "                                     80.9439,  44.9193,  63.3739,  29.9928,  42.7812,\n",
              "                                     59.3684,  54.2947,  64.6514,  46.4057,  48.4558,\n",
              "                                     50.4285,  37.3045,  48.8859,  76.0301,  71.4932,\n",
              "                                     70.6709,  78.5767,  65.7793, 120.9326,  56.2547,\n",
              "                                     48.0561,  99.9547,  65.3061,  64.6601,  66.1426,\n",
              "                                     73.1759,  47.8384,  31.0219,  62.4009,  44.8264,\n",
              "                                     54.1782,  42.3087,  43.3371,  41.0657,  68.6768,\n",
              "                                     43.3291,  67.9887,  47.9493,  59.0432,  64.3265,\n",
              "                                     48.6774,  60.0728,  62.5289,  58.3238,  58.3703,\n",
              "                                     58.7135,  36.4329]),\n",
              "                     size=(512,), nnz=512, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn2.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.conv3.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ..., 2047, 2047, 2047],\n",
              "                                     [   0,    1,    2,  ...,  509,  510,  511],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0],\n",
              "                                     [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              "                     values=tensor([ 0.0243,  0.0215, -0.0237,  ...,  0.0266, -0.0045,\n",
              "                                     0.0056]),\n",
              "                     size=(2048, 512, 1, 1), nnz=1048576, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn3.weight',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([1.0155, 1.0159, 1.0101,  ..., 1.0048, 1.0192, 0.9797]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn3.bias',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([-0.0315, -0.0273, -0.0359,  ..., -0.0290, -0.0258,\n",
              "                                    -0.0521]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn3.running_mean',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([0.1005, 0.6160, 0.1985,  ..., 0.0583, 0.2806, 0.4398]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn3.running_var',\n",
              "              tensor(indices=tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]]),\n",
              "                     values=tensor([1.8048, 2.7161, 2.3372,  ..., 2.3976, 2.0886, 1.9670]),\n",
              "                     size=(2048,), nnz=2048, layout=torch.sparse_coo)),\n",
              "             ('layer4.2.bn3.num_batches_tracked',\n",
              "              tensor(indices=tensor([], size=(0, 1)),\n",
              "                     values=tensor([1876]),\n",
              "                     size=(), nnz=1, layout=torch.sparse_coo)),\n",
              "             ('fc.bias',\n",
              "              tensor(indices=tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),\n",
              "                     values=tensor([ 0.0102, -0.0140, -0.0213,  0.0168,  0.0229, -0.0033,\n",
              "                                     0.0125,  0.0074,  0.0102,  0.0163]),\n",
              "                     size=(10,), nnz=10, layout=torch.sparse_coo)),\n",
              "             ('fc.weight',\n",
              "              tensor(indices=tensor([[   0,    0,    0,  ...,    9,    9,    9],\n",
              "                                     [   4,    5,    9,  ..., 2020, 2029, 2046]]),\n",
              "                     values=tensor([ 0.0381,  0.0294, -0.0297,  ...,  0.0321,  0.0268,\n",
              "                                     0.0331]),\n",
              "                     size=(10, 2048), nnz=4345, layout=torch.sparse_coo))])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, you can save the sparse model\n",
        "torch.save(sd, \"sparse_model.pt\")\n",
        "\n",
        "# measure new size on disk:\n",
        "print(f'{os.path.getsize(\"sparse_model.pt\")/1e6} MB')\n",
        "\n",
        "# notice the new size is not actually 1/10 of the size... consider why this might be the case"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFptNexR9vfG",
        "outputId": "260888be-0ed3-4b6a-f682-183836c897fe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "844.768966 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_sd = torch.load(\"sparse_model.pt\")\n",
        "\n",
        "new_model = models.resnet50(pretrained=False)\n",
        "new_model.fc = nn.Linear(new_model.fc.in_features, 10)\n",
        "\n",
        "# Populate the new model's state dict, converting sparse tensors back to dense\n",
        "new_model.load_state_dict({k: (v if v.layout == torch.strided else v.to_dense()) for k, v in sparse_sd.items()})\n",
        "\n",
        "# Verify that the new model has been loaded correctly\n",
        "new_model.eval()\n",
        "print(\"Sparsified ResNet model loaded and ready for inference.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfZuxEpj_AVT",
        "outputId": "3be87e16-e769-4651-fa29-9ecd790fcf9d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-9017aba8faf4>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sparse_sd = torch.load(\"sparse_model.pt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsified ResNet model loaded and ready for inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kD0m4lN9n2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pUCFSSs8DJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To read and load a .mlmodel file on Google Colab, you need to use Apple's Core ML framework, which requires macOS. However, since Colab runs on Linux, you can't directly load and run Core ML models. Instead, here are two options:\n",
        "\n",
        "1) do it on mac\n",
        "\n",
        "2) Convert the .mlmodel to an ONNX model, which you can then load on Colab.\n",
        "\n",
        "Tried to do (2) but didn't work out so ignore. I just trained from scratch"
      ],
      "metadata": {
        "id": "XDen8RWeLJTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install coremltools onnx\n"
      ],
      "metadata": {
        "id": "7KbT2gy-LIhT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import coremltools as ct\n",
        "# import onnx\n",
        "\n",
        "# # Load the .mlmodel file\n",
        "# model = ct.models.MLModel(path)\n",
        "\n",
        "# # Convert the Core ML model to ONNX\n",
        "# onnx_model = ct.converters.onnx.convert(model)\n",
        "\n",
        "# # Save the converted ONNX model\n",
        "# onnx.save(onnx_model, \"model_original.onnx\")\n"
      ],
      "metadata": {
        "id": "wr3PW4leLV_f"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfEbrJRmLe-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekOBcir8LfAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "df2-ItqILfCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ac3Z3x0OJ8ZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}