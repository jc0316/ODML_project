{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_scale_and_zeropoint(\n",
    "    min_val: float, max_val: float, num_bits: int) -> Tuple[float, int]:\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "    initial_zero_point = qmin - min_val / scale\n",
    "\n",
    "    zero_point = 0\n",
    "    if initial_zero_point < qmin:\n",
    "        zero_point = int(qmin)\n",
    "    elif initial_zero_point > qmax:\n",
    "        zero_point = int(qmax)\n",
    "    else:\n",
    "        zero_point = int(initial_zero_point)\n",
    "    \n",
    "    return scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x: torch.Tensor, scale: float, zero_point: int, dtype=torch.uint8):\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(0, 255).round_()\n",
    "    q_x = q_x.to(dtype)\n",
    "    return q_x\n",
    "\n",
    "def dequantize(x: torch.Tensor, scale: float, zero_point: int):\n",
    "    return scale * (x.float() - zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def test_case_0():\n",
    "  torch.manual_seed(999)\n",
    "  test_input = torch.randn((4,4))\n",
    "\n",
    "  min_val, max_val = torch.min(test_input), torch.max(test_input)\n",
    "  scale, zero_point = _calculate_scale_and_zeropoint(min_val, max_val, 8)\n",
    "\n",
    "  your_quant = quantize(test_input, scale, zero_point)\n",
    "  your_dequant = dequantize(your_quant, scale, zero_point)\n",
    "\n",
    "  test_case_0 = torch.Tensor([\n",
    "      [-0.2623,  1.3991,  0.2842,  1.0275],\n",
    "      [-0.9838, -3.4104,  1.4866,  0.2405],\n",
    "      [ 1.4866, -0.3716,  0.0874,  2.1424],\n",
    "      [ 0.6340, -1.1587, -0.7870,  0.0656]])\n",
    "\n",
    "  assert torch.allclose(your_dequant, test_case_0, atol=1e-4)\n",
    "  assert torch.allclose(your_dequant, test_input, atol=5e-2)\n",
    "\n",
    "  return test_input, your_dequant, your_quant\n",
    "\n",
    "\n",
    "\n",
    "### Test Case 1\n",
    "def test_case_1():\n",
    "  torch.manual_seed(999)\n",
    "  test_input = torch.randn((8,8))\n",
    "\n",
    "  min_val, max_val = torch.min(test_input), torch.max(test_input)\n",
    "  scale, zero_point = _calculate_scale_and_zeropoint(min_val, max_val, 8)\n",
    "\n",
    "  your_quant = quantize(test_input, scale, zero_point)\n",
    "  your_dequant = dequantize(your_quant, scale, zero_point)\n",
    "\n",
    "  test_case_1 = torch.Tensor(\n",
    "      [[-0.2623,  1.3991,  0.2842,  1.0275, -0.9838, -3.4104,  1.4866,  0.2405],\n",
    "      [ 1.4866, -0.3716,  0.0874,  2.1424,  0.6340, -1.1587, -0.7870,  0.0656],\n",
    "      [ 0.0000, -0.6558, -1.0056,  0.3061,  0.6340, -1.0931, -1.6178,  1.5740],\n",
    "      [-1.7927,  0.6121, -0.7214,  0.6121,  0.3279, -1.5959, -0.5247,  0.3498],\n",
    "      [-1.3773,  1.1149, -0.7870,  0.2842,  0.9182, -1.1805, -0.7433, -1.5522],\n",
    "      [ 1.0056, -0.1093,  1.3991, -0.9182, -1.1805, -0.6777, -0.3061,  0.9838],\n",
    "      [ 0.2186,  1.6396,  1.0712,  1.7489,  0.0874,  0.3498,  0.9838,  1.2024],\n",
    "      [-0.3935, -0.6340,  1.9238,  1.2898,  0.0219,  0.3935,  1.4866, -0.9401]])\n",
    "\n",
    "  assert torch.allclose(your_dequant, test_case_1, atol=1e-4)\n",
    "  assert torch.allclose(your_dequant, test_input, atol=5e-2)\n",
    "\n",
    "  return test_input, your_dequant, your_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0059), tensor(0.0115))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empirically, report the average and maximum quantization error for the test cases\n",
    "def test():\n",
    "  test_input, your_dequant, your_quant = test_case_0()\n",
    "  test_input, your_dequant, your_quant = test_case_1()\n",
    "\n",
    "  avg_error = torch.mean(torch.abs(test_input - your_dequant))\n",
    "  max_error = torch.max(torch.abs(test_input - your_dequant))\n",
    "\n",
    "  return avg_error, max_error\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the original fp32 tensor and quantized tensor to disk with torch.save. Report the difference in disk utilization\n",
    "output_folder = \"data/lab3\"\n",
    "\n",
    "def save_to_disk(test_input, your_quant, output_folder):\n",
    "    torch.save(test_input, f\"{output_folder}/test_input.pt\")\n",
    "    torch.save(your_quant, f\"{output_folder}/your_quant.pt\")\n",
    "    \n",
    "    test_input_size = test_input.element_size() * test_input.nelement()\n",
    "    your_quant_size = your_quant.element_size() * your_quant.nelement()\n",
    "    \n",
    "    return test_input_size, your_quant_size\n",
    "\n",
    "test_input, your_dequant, your_quant = test_case_1()\n",
    "save_to_disk(test_input, your_quant, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        data = pd.read_csv(csv_file)\n",
    "        self.labels = data.iloc[:, 0].values\n",
    "        self.pixels = data.iloc[:, 1:].values.astype('float32')\n",
    "        self.pixels = self.pixels.reshape(-1, 28, 28)  # Reshape to 28x28 images\n",
    "\n",
    "        # Normalize the pixel values\n",
    "        self.pixels_mean = self.pixels.mean()\n",
    "        self.pixels_std = self.pixels.std()\n",
    "        self.pixels = (self.pixels - self.pixels_mean) / self.pixels_std\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.pixels[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(torch.tensor(image).unsqueeze(0))\n",
    "\n",
    "        return image.squeeze(0), torch.tensor(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
