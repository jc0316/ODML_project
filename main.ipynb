{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/sign_mnist_train.csv\"\n",
    "test_dir = \"data/sign_mnist_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class SignLanguageDataset(data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = self.df.iloc[index, 0]\n",
    "        img = self.df.iloc[index, 1:].values.astype('uint8').reshape(28, 28)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.from_numpy(img).unsqueeze(0).float()\n",
    "        \n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data and transforming it to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Lambda(lambda img: img.convert('RGB')),  # Convert grayscale to RGB\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(train_dir)\n",
    "test_df = pd.read_csv(test_dir)\n",
    "\n",
    "# Split the data into train and eval\n",
    "ratio = 0.8\n",
    "train_df, eval_df = train_df[:int(ratio*len(train_df))], train_df[int(ratio*len(train_df)):]\n",
    "\n",
    "# Print all labels\n",
    "print(sorted(train_df['label'].unique()), len(train_df['label'].unique()))\n",
    "print(sorted(eval_df['label'].unique()), len(eval_df['label'].unique()))\n",
    "\n",
    "train_dataset = SignLanguageDataset(train_df, transform=transform)\n",
    "eval_dataset = SignLanguageDataset(eval_df, transform=transform)\n",
    "test_dataset = SignLanguageDataset(test_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, label):\n",
    "    plt.imshow(img.squeeze().permute(1, 2, 0))\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "show_img(*train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pretrained ResNet model that is frozen\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "frozen = False\n",
    "if frozen:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Add a new layer to the model\n",
    "model.fc = nn.Linear(512, 26)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the data loaders\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "eval_loader = data.DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for img, label in tqdm(train_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, eval_loader, criterion):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(eval_loader, desc=\"Evaluating\"):\n",
    "            output = model(img)\n",
    "            loss = criterion(output, label)\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    avg_loss = eval_loss / len(eval_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 10\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "train_acc = []\n",
    "eval_acc = []\n",
    "\n",
    "model.to('cuda') if torch.cuda.is_available() else model.to('cpu')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion)\n",
    "    eval_loss, eval_accuracy = evaluate(model, eval_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    eval_losses.append(eval_loss)\n",
    "    eval_acc.append(eval_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.3f} | Train Accuracy: {train_accuracy:.3f}\")\n",
    "    print(f\"Eval Loss: {eval_loss:.3f} | Eval Accuracy: {eval_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x2 subplot to display the loss and accuracy side by side\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot the training and evaluation loss on the left\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(eval_losses, label='Eval Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Evaluation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and evaluation accuracy on the right\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(eval_acc, label='Eval Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Evaluation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
